# Consolidated Repository Files

## `admin/app/api/chats/[id]/approve/route.ts`

```typescript
import { NextResponse } from "next/server";
import { atticusFetch } from "../../../../../lib/atticus-client";
import { deriveCsvTarget, appendChatCsvRecord } from "../../../../../lib/csv";
import { getReviewerIdentity } from "../../../../../lib/config";
import { logPhaseTwoError } from "../../../../../lib/logging";
import type { SourceSummary } from "../../../../../lib/types";

type ApprovePayload = {
  question?: string;
  answer?: string;
  topSources?: SourceSummary[];
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const body = (await request.json().catch(() => ({}))) as ApprovePayload;
  const answer = body.answer?.trim() ?? "";
  if (!answer) {
    return NextResponse.json({ error: "invalid_request", detail: "Answer must not be empty." }, { status: 400 });
  }

  const upstream = await atticusFetch(`/api/admin/uncertain/${params.id}/approve`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ answer }),
  });

  let upstreamPayload: unknown = null;
  try {
    upstreamPayload = await upstream.json();
  } catch {
    upstreamPayload = null;
  }

  if (!upstream.ok) {
    return NextResponse.json(
      upstreamPayload ?? { error: "upstream_error", detail: "Approval failed upstream." },
      { status: upstream.status }
    );
  }

  const sources = Array.isArray(body.topSources) ? body.topSources : [];
  const { family, model } = deriveCsvTarget(sources);
  const reviewer = getReviewerIdentity();

  try {
    await appendChatCsvRecord({
      family,
      model,
      question: body.question ?? "Unknown question",
      answer,
      reviewer: reviewer.name,
    });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Unknown CSV error";
    await logPhaseTwoError(`Failed to append CSV for chat ${params.id}: ${message}`);
  }

  return NextResponse.json(upstreamPayload ?? { ok: true });
}

```

## `admin/app/api/chats/[id]/reject/route.ts`

```typescript
import { NextResponse } from "next/server";
import { atticusFetch } from "../../../../../lib/atticus-client";

export async function POST(_: Request, { params }: { params: { id: string } }) {
  const upstream = await atticusFetch(`/api/admin/uncertain/${params.id}/reject`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ notes: "Rejected via admin service" }),
  });

  let payload: unknown = null;
  try {
    payload = await upstream.json();
  } catch {
    payload = null;
  }

  if (!upstream.ok) {
    return NextResponse.json(
      payload ?? { error: "upstream_error", detail: "Unable to reject chat." },
      { status: upstream.status }
    );
  }

  return NextResponse.json(payload ?? { ok: true });
}

```

## `admin/app/api/chats/[id]/save-draft/route.ts`

```typescript
import { NextResponse } from "next/server";
import { atticusFetch } from "../../../../../lib/atticus-client";

type DraftPayload = {
  answer?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const body = (await request.json().catch(() => ({}))) as DraftPayload;
  const answer = body.answer?.trim() ?? "";
  if (!answer) {
    return NextResponse.json({ error: "invalid_request", detail: "Draft answer must not be empty." }, { status: 400 });
  }

  const upstream = await atticusFetch(`/api/admin/uncertain/${params.id}/save-draft`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ answer }),
  });

  let payload: unknown = null;
  try {
    payload = await upstream.json();
  } catch {
    payload = null;
  }

  if (!upstream.ok) {
    return NextResponse.json(
      payload ?? { error: "upstream_error", detail: "Unable to save draft." },
      { status: upstream.status }
    );
  }

  return NextResponse.json(payload ?? { ok: true });
}

```

## `admin/app/layout.tsx`

```tsx
import type { Metadata } from "next";
import type { ReactNode } from "react";
import "./globals.css";

export const metadata: Metadata = {
  title: "Atticus Admin Service",
  description: "Review and curate escalated Atticus chats",
};

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>{children}</body>
    </html>
  );
}

```

## `admin/app/page.tsx`

```tsx
import { fetchReviewQueue } from "../lib/atticus-client";
import { logPhaseTwoError } from "../lib/logging";
import { ChatReviewBoard } from "../components/chat-review-board";
import type { ReviewChat } from "../lib/types";

export const dynamic = "force-dynamic";

export default async function AdminHome() {
  let chats: ReviewChat[] = [];
  try {
    chats = await fetchReviewQueue();
  } catch (error) {
    const message =
      error instanceof Error ? error.message : "Failed to load escalation queue.";
    await logPhaseTwoError(`Admin service failed to load queue: ${message}`);
  }

  return (
    <main>
      <ChatReviewBoard initialChats={chats} />
    </main>
  );
}

```

## `admin/components/chat-review-board.tsx`

```tsx
"use client";

import { useMemo, useState } from "react";
import type { ReviewChat, SourceSummary } from "../lib/types";

type AlertState =
  | { type: "success"; message: string }
  | { type: "error"; message: string }
  | null;

interface ChatReviewBoardProps {
  initialChats: ReviewChat[];
}

const statusPalette: Record<string, string> = {
  pending_review: "#f97316",
  draft: "#3b82f6",
  rejected: "#ef4444",
  reviewed: "#10b981",
};

function formatTimestamp(iso: string | null | undefined): string {
  if (!iso) {
    return "Unknown timestamp";
  }
  try {
    return new Date(iso).toLocaleString();
  } catch {
    return iso;
  }
}

function summarise(value: string | null | undefined): string {
  if (!value) {
    return "No answer captured yet.";
  }
  return value.length > 140 ? `${value.slice(0, 137)}…` : value;
}

export function ChatReviewBoard({ initialChats }: ChatReviewBoardProps) {
  const [chats, setChats] = useState<ReviewChat[]>(initialChats);
  const [selectedId, setSelectedId] = useState<string | null>(initialChats[0]?.id ?? null);
  const [drafts, setDrafts] = useState<Record<string, string>>(() =>
    initialChats.reduce<Record<string, string>>((acc, chat) => {
      acc[chat.id] = chat.answer ?? "";
      return acc;
    }, {})
  );
  const [alert, setAlert] = useState<AlertState>(null);
  const [isSubmitting, setIsSubmitting] = useState(false);

  const selectedChat = useMemo(
    () => chats.find((chat) => chat.id === selectedId) ?? null,
    [chats, selectedId]
  );

  function updateDraft(chatId: string, value: string) {
    setDrafts((prev) => ({ ...prev, [chatId]: value }));
  }

  function clearAlertAfterDelay() {
    setTimeout(() => setAlert(null), 4000);
  }

  async function callAction(action: "approve" | "reject" | "save-draft") {
    if (!selectedChat) {
      return;
    }
    const draftAnswer = drafts[selectedChat.id]?.trim() ?? "";
    if (action !== "reject" && !draftAnswer) {
      setAlert({ type: "error", message: "Answer cannot be empty." });
      clearAlertAfterDelay();
      return;
    }

    setIsSubmitting(true);
    setAlert(null);
    try {
      const response = await fetch(`/api/chats/${selectedChat.id}/${action}`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          question: selectedChat.question,
          answer: draftAnswer,
          topSources: selectedChat.topSources,
          requestId: selectedChat.requestId,
        }),
      });

      if (!response.ok) {
        const payload = await response.json().catch(() => ({}));
        const detail = typeof payload.detail === "string" ? payload.detail : "Unexpected error.";
        throw new Error(detail);
      }

      if (action === "approve") {
        setChats((prev) => prev.filter((chat) => chat.id !== selectedChat.id));
        setDrafts((prev) => {
          const next = { ...prev };
          delete next[selectedChat.id];
          return next;
        });
        setAlert({ type: "success", message: "Chat approved and archived." });
        clearAlertAfterDelay();
        setSelectedId((prevId) => {
          if (prevId !== selectedChat.id) {
            return prevId;
          }
          const remaining = chats.filter((chat) => chat.id !== selectedChat.id);
          return remaining[0]?.id ?? null;
        });
      } else {
        setChats((prev) =>
          prev.map((chat) => {
            if (chat.id !== selectedChat.id) {
              return chat;
            }
            const nextStatus = action === "reject" ? "rejected" : "draft";
            return {
              ...chat,
              status: nextStatus,
              answer: draftAnswer || chat.answer,
            };
          })
        );
        setAlert({
          type: "success",
          message: action === "reject" ? "Chat marked as rejected." : "Draft saved for further editing.",
        });
        clearAlertAfterDelay();
      }
    } catch (error) {
      const message = error instanceof Error ? error.message : "Request failed.";
      setAlert({ type: "error", message });
      clearAlertAfterDelay();
    } finally {
      setIsSubmitting(false);
    }
  }

  return (
    <div style={{ display: "flex", flexDirection: "column", gap: "1rem", padding: "1.5rem" }}>
      <header style={{ display: "flex", flexDirection: "column", gap: "0.35rem" }}>
        <h1 style={{ fontSize: "1.75rem", fontWeight: 600, margin: 0 }}>Escalated Chats</h1>
        <p style={{ margin: 0, color: "#475569" }}>
          Review low-confidence answers, curate improved responses, and keep the Atticus corpus fresh.
        </p>
        {alert ? (
          <div
            style={{
              marginTop: "0.75rem",
              padding: "0.75rem 1rem",
              borderRadius: "0.75rem",
              backgroundColor: alert.type === "success" ? "#dcfce7" : "#fee2e2",
              color: alert.type === "success" ? "#166534" : "#991b1b",
              fontSize: "0.9rem",
            }}
          >
            {alert.message}
          </div>
        ) : null}
      </header>
      <div
        style={{
          display: "grid",
          gridTemplateColumns: "minmax(260px, 1fr) 2fr",
          gap: "1.5rem",
        }}
      >
        <aside
          style={{
            maxHeight: "calc(100vh - 180px)",
            overflowY: "auto",
            paddingRight: "0.5rem",
            display: "flex",
            flexDirection: "column",
            gap: "0.75rem",
          }}
        >
          {chats.length === 0 ? (
            <div
              style={{
                padding: "1.25rem",
                borderRadius: "1rem",
                border: "1px dashed #cbd5f5",
                background: "rgba(148, 163, 184, 0.1)",
                color: "#475569",
                fontSize: "0.95rem",
              }}
            >
              No escalations remaining. Fresh reviews will appear here automatically.
            </div>
          ) : (
            chats.map((chat) => {
              const isSelected = chat.id === selectedId;
              const badgeColor = statusPalette[chat.status] ?? "#64748b";
              return (
                <button
                  key={chat.id}
                  type="button"
                  onClick={() => setSelectedId(chat.id)}
                  style={{
                    textAlign: "left",
                    borderRadius: "1rem",
                    border: isSelected ? "2px solid #4f46e5" : "1px solid #e2e8f0",
                    backgroundColor: isSelected ? "#eef2ff" : "#ffffff",
                    boxShadow: isSelected ? "0 10px 20px rgba(79, 70, 229, 0.15)" : "none",
                    padding: "1rem 1.15rem",
                    cursor: "pointer",
                    display: "flex",
                    flexDirection: "column",
                    gap: "0.5rem",
                    transition: "transform 0.15s ease-in-out",
                    transform: isSelected ? "translateY(-2px)" : "none",
                  }}
                >
                  <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center" }}>
                    <span
                      style={{
                        backgroundColor: badgeColor,
                        color: "#ffffff",
                        fontSize: "0.7rem",
                        padding: "0.15rem 0.6rem",
                        borderRadius: "999px",
                        textTransform: "uppercase",
                        letterSpacing: "0.05em",
                      }}
                    >
                      {chat.status.replace("_", " ")}
                    </span>
                    <span style={{ fontSize: "0.75rem", color: "#64748b" }}>
                      {(chat.confidence * 100).toFixed(0)}% confidence
                    </span>
                  </div>
                  <div style={{ display: "flex", flexDirection: "column", gap: "0.35rem" }}>
                    <h2 style={{ margin: 0, fontSize: "1rem", fontWeight: 600, color: "#0f172a" }}>
                      {chat.question}
                    </h2>
                    <p style={{ margin: 0, fontSize: "0.85rem", color: "#475569" }}>
                      {summarise(chat.answer)}
                    </p>
                  </div>
                  <span style={{ fontSize: "0.7rem", color: "#94a3b8" }}>
                    Captured {formatTimestamp(chat.createdAt)}
                  </span>
                </button>
              );
            })
          )}
        </aside>
        <section
          style={{
            padding: "1.5rem",
            backgroundColor: "#fff",
            borderRadius: "1.5rem",
            border: "1px solid rgba(148, 163, 184, 0.25)",
            boxShadow: "0 20px 30px rgba(15, 23, 42, 0.08)",
            minHeight: "420px",
            display: "flex",
            flexDirection: "column",
            gap: "1.2rem",
          }}
        >
          {selectedChat ? (
            <>
              <header style={{ display: "flex", flexDirection: "column", gap: "0.4rem" }}>
                <span style={{ fontSize: "0.75rem", color: "#6366f1", letterSpacing: "0.08em" }}>
                  Review Queue
                </span>
                <h2 style={{ margin: 0, fontSize: "1.5rem", fontWeight: 600 }}>{selectedChat.question}</h2>
                <p style={{ margin: 0, fontSize: "0.85rem", color: "#475569" }}>
                  Request {selectedChat.requestId ?? "N/A"} · {formatTimestamp(selectedChat.createdAt)}
                </p>
              </header>
              <div style={{ display: "flex", flexDirection: "column", gap: "0.6rem" }}>
                <label htmlFor="answer-editor" style={{ fontWeight: 500, fontSize: "0.9rem" }}>
                  Curated answer
                </label>
                <textarea
                  id="answer-editor"
                  value={drafts[selectedChat.id] ?? ""}
                  onChange={(event) => updateDraft(selectedChat.id, event.target.value)}
                  rows={10}
                  style={{
                    width: "100%",
                    resize: "vertical",
                    fontSize: "0.95rem",
                    lineHeight: 1.5,
                    padding: "0.85rem 1rem",
                    borderRadius: "1rem",
                    border: "1px solid #cbd5f5",
                    backgroundColor: "#f8fafc",
                  }}
                  placeholder="Compose the final answer that should be filed and used for future responses."
                />
              </div>
              <div style={{ display: "flex", flexDirection: "column", gap: "0.6rem" }}>
                <span style={{ fontWeight: 500, fontSize: "0.9rem" }}>Top sources</span>
                <div
                  style={{
                    display: "grid",
                    gap: "0.6rem",
                    maxHeight: "120px",
                    overflowY: "auto",
                  }}
                >
                  {selectedChat.topSources.length === 0 ? (
                    <div
                      style={{
                        padding: "0.75rem",
                        borderRadius: "0.9rem",
                        backgroundColor: "#f1f5f9",
                        color: "#475569",
                        fontSize: "0.85rem",
                      }}
                    >
                      No sources captured for this chat.
                    </div>
                  ) : (
                    selectedChat.topSources.map((source: SourceSummary, index: number) => (
                      <div
                        key={`${selectedChat.id}-source-${index}`}
                        style={{
                          padding: "0.85rem",
                          borderRadius: "1rem",
                          border: "1px solid rgba(148, 163, 184, 0.35)",
                          background: "#f8fafc",
                        }}
                      >
                        <p style={{ margin: 0, fontWeight: 500, color: "#1e293b" }}>{source.path}</p>
                        {source.heading ? (
                          <p style={{ margin: "0.35rem 0 0", fontSize: "0.8rem", color: "#475569" }}>
                            {source.heading}
                          </p>
                        ) : null}
                        <div
                          style={{
                            marginTop: "0.5rem",
                            display: "flex",
                            gap: "0.75rem",
                            fontSize: "0.75rem",
                            color: "#64748b",
                          }}
                        >
                          {source.page != null ? <span>Page {source.page}</span> : null}
                          {source.score != null ? <span>Score {(source.score * 100).toFixed(1)}%</span> : null}
                          {source.chunkId ? <span>Chunk {source.chunkId}</span> : null}
                        </div>
                      </div>
                    ))
                  )}
                </div>
              </div>
              <footer
                style={{
                  display: "flex",
                  flexWrap: "wrap",
                  gap: "0.75rem",
                  justifyContent: "space-between",
                  alignItems: "center",
                }}
              >
                <div style={{ display: "flex", gap: "0.75rem", flexWrap: "wrap" }}>
                  <button
                    type="button"
                    onClick={() => callAction("save-draft")}
                    disabled={isSubmitting}
                    style={{
                      padding: "0.65rem 1.1rem",
                      borderRadius: "999px",
                      border: "1px solid #4f46e5",
                      backgroundColor: "#eef2ff",
                      color: "#4f46e5",
                      fontWeight: 600,
                      cursor: "pointer",
                    }}
                  >
                    Save Draft
                  </button>
                  <button
                    type="button"
                    onClick={() => callAction("approve")}
                    disabled={isSubmitting}
                    style={{
                      padding: "0.65rem 1.1rem",
                      borderRadius: "999px",
                      border: "none",
                      background: "linear-gradient(135deg, #4f46e5, #7c3aed)",
                      color: "#ffffff",
                      fontWeight: 600,
                      cursor: "pointer",
                    }}
                  >
                    Approve
                  </button>
                  <button
                    type="button"
                    onClick={() => callAction("reject")}
                    disabled={isSubmitting}
                    style={{
                      padding: "0.65rem 1.1rem",
                      borderRadius: "999px",
                      border: "1px solid #ef4444",
                      backgroundColor: "#fef2f2",
                      color: "#b91c1c",
                      fontWeight: 600,
                      cursor: "pointer",
                    }}
                  >
                    Reject
                  </button>
                </div>
                <span style={{ fontSize: "0.75rem", color: "#94a3b8" }}>
                  Actions sync with the primary Atticus workspace instantly.
                </span>
              </footer>
            </>
          ) : (
            <div
              style={{
                flex: 1,
                display: "flex",
                alignItems: "center",
                justifyContent: "center",
                color: "#94a3b8",
                fontSize: "0.95rem",
              }}
            >
              Select a chat from the list to begin reviewing.
            </div>
          )}
        </section>
      </div>
    </div>
  );
}

```

## `admin/lib/atticus-client.ts`

```typescript
import type { ReviewChat } from "./types";
import { buildUpstreamHeaders, getAtticusBaseUrl } from "./config";

function mergeHeaders(base: Headers, extra?: HeadersInit): Headers {
  if (!extra) {
    return base;
  }
  const merged = new Headers(base);
  const temp = new Headers(extra);
  temp.forEach((value, key) => merged.set(key, value));
  return merged;
}

export async function atticusFetch(
  path: string,
  init: RequestInit = {}
): Promise<Response> {
  const target = path.startsWith("/") ? path : `/${path}`;
  const headers = mergeHeaders(buildUpstreamHeaders(), init.headers);
  return fetch(`${getAtticusBaseUrl()}${target}`, {
    ...init,
    headers,
    cache: "no-store",
  });
}

export async function fetchReviewQueue(): Promise<ReviewChat[]> {
  const response = await atticusFetch("/api/admin/uncertain");
  if (!response.ok) {
    throw new Error(`Upstream returned ${response.status} while loading review queue.`);
  }
  const data = (await response.json()) as unknown;
  if (!Array.isArray(data)) {
    throw new Error("Unexpected response when loading review queue.");
  }
  return data as ReviewChat[];
}

```

## `admin/lib/config.ts`

```typescript
const DEFAULT_BASE_URL = "http://localhost:3000";
const DEFAULT_REVIEWER_ID = "admin-service";
const DEFAULT_REVIEWER_NAME = "Admin Service";
const DEFAULT_REVIEWER_EMAIL = "admin@example.com";

export function getAtticusBaseUrl(): string {
  const raw = process.env.ATTICUS_MAIN_BASE_URL ?? DEFAULT_BASE_URL;
  return raw.endsWith("/") ? raw.slice(0, -1) : raw;
}

export function getReviewerIdentity() {
  return {
    id: process.env.ATTICUS_REVIEWER_ID?.trim() || DEFAULT_REVIEWER_ID,
    name: process.env.ATTICUS_REVIEWER_NAME?.trim() || DEFAULT_REVIEWER_NAME,
    email: process.env.ATTICUS_REVIEWER_EMAIL?.trim() || DEFAULT_REVIEWER_EMAIL,
  };
}

export function buildUpstreamHeaders(additional?: HeadersInit): Headers {
  const reviewer = getReviewerIdentity();
  const headers = new Headers(additional);
  headers.set("x-atticus-user-id", reviewer.id);
  headers.set("x-atticus-user-name", reviewer.name);
  headers.set("x-atticus-user-email", reviewer.email);
  headers.set("x-atticus-role", "ADMIN");
  headers.set("x-atticus-org-id", "org-atticus");
  return headers;
}

```

## `admin/lib/csv.ts`

```typescript
import { access, appendFile, mkdir, writeFile } from "node:fs/promises";
import { constants } from "node:fs";
import path from "node:path";
import type { SourceSummary } from "./types";

const CSV_HEADER = "timestamp,question,answer,model,reviewer\n";

function sanitizeValue(value: string): string {
  const cleaned = value.replace(/\r?\n+/g, " ").replace(/\s{2,}/g, " ").trim();
  return `"${cleaned.replace(/"/g, '""')}"`;
}

async function ensureCsvFile(filePath: string): Promise<void> {
  try {
    await access(filePath, constants.F_OK);
  } catch {
    await mkdir(path.dirname(filePath), { recursive: true });
    await writeFile(filePath, CSV_HEADER, { encoding: "utf-8" });
  }
}

export function deriveCsvTarget(sources: SourceSummary[]): { family: string; model: string } {
  for (const source of sources) {
    if (!source.path) {
      continue;
    }
    const normalized = source.path.replace(/\\/g, "/");
    const parts = normalized.split("/").filter(Boolean);
    const contentIndex = parts.findIndex((part) => part === "content");
    if (contentIndex === -1) {
      continue;
    }
    const family = parts[contentIndex + 1] ?? "general";
    const filePart = parts[parts.length - 1] ?? "answers";
    const model = filePart.replace(/\.[^/.]+$/, "") || "answers";
    return { family, model };
  }
  return { family: "general", model: "answers" };
}

export async function appendChatCsvRecord(params: {
  family: string;
  model: string;
  question: string;
  answer: string;
  reviewer: string;
}): Promise<string> {
  const { family, model, question, answer, reviewer } = params;
  const baseDir = path.resolve(process.cwd(), "..", "content", family);
  const filePath = path.join(baseDir, `${model}.csv`);
  await ensureCsvFile(filePath);

  const timestamp = new Date().toISOString();
  const row = [
    sanitizeValue(timestamp),
    sanitizeValue(question),
    sanitizeValue(answer),
    sanitizeValue(`${family}/${model}`),
    sanitizeValue(reviewer),
  ].join(",");

  await appendFile(filePath, `${row}\n`, { encoding: "utf-8" });
  return filePath;
}

```

## `admin/lib/logging.ts`

```typescript
import { appendFile, mkdir } from "node:fs/promises";
import path from "node:path";

const REPORT_PATH = path.resolve(process.cwd(), "..", "reports", "phase2-errors.txt");

export async function logPhaseTwoError(message: string): Promise<void> {
  const entry = `[${new Date().toISOString()}] ${message}\n`;
  try {
    await mkdir(path.dirname(REPORT_PATH), { recursive: true });
    await appendFile(REPORT_PATH, entry, { encoding: "utf-8" });
  } catch {
    // Swallow logging errors to keep request handlers resilient.
  }
}

```

## `admin/lib/types.ts`

```typescript
export type SourceSummary = {
  path: string;
  score: number | null;
  page: number | null;
  heading: string | null;
  chunkId: string | null;
};

export type ReviewChat = {
  id: string;
  question: string;
  answer: string | null;
  confidence: number;
  status: string;
  requestId: string | null;
  createdAt: string;
  topSources: SourceSummary[];
  auditLog: Array<Record<string, unknown>> | null;
};

```

## `admin/next-env.d.ts`

```typescript
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.

```

## `admin/next.config.js`

```javascript
/** @type {import("next").NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  experimental: {
    serverActions: {
      bodySizeLimit: "2mb",
    },
  },
};

module.exports = nextConfig;

```

## `admin/package.json`

```json
{
  "name": "atticus-admin-service",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev -p 3101",
    "build": "next build",
    "start": "next start -p 3101",
    "lint": "next lint",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "next": "^14.2.33",
    "react": "18.2.0",
    "react-dom": "18.2.0"
  },
  "devDependencies": {
    "@types/node": "20.14.9",
    "@types/react": "18.3.5",
    "@types/react-dom": "18.3.0",
    "eslint": "8.57.0",
    "eslint-config-next": "14.2.5",
    "typescript": "5.4.5"
  }
}

```

## `admin/tailwind.config.js`

```javascript
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: ["./app/**/*.{ts,tsx}", "./components/**/*.{ts,tsx}", "./lib/**/*.{ts,tsx}"],
  theme: {
    extend: {},
  },
  plugins: [],
};

```

## `admin/tsconfig.json`

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": false,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "forceConsistentCasingInFileNames": true,
    "baseUrl": ".",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "types": [
      "node"
    ],
    "plugins": [
      {
        "name": "next"
      }
    ]
  },
  "include": [
    "next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    ".next/types/**/*.ts"
  ],
  "exclude": [
    "node_modules"
  ]
}

```

## `api/__init__.py`

```python
"""FastAPI application factory for Atticus."""

from .main import app

__all__ = ["app"]

```

## `api/dependencies.py`

```python
"""Shared FastAPI dependencies."""

import logging
from functools import lru_cache
from pathlib import Path
from typing import Annotated

from fastapi import Depends, HTTPException, Request, status

from atticus.config import AppSettings, load_settings
from atticus.logging import configure_logging
from atticus.metrics import MetricsRecorder


def get_settings() -> AppSettings:
    settings = load_settings()
    settings.ensure_directories()
    return settings


SettingsDep = Annotated[AppSettings, Depends(get_settings)]


def get_logger(settings: SettingsDep) -> logging.Logger:
    return configure_logging(settings)


@lru_cache(maxsize=1)
def get_metrics(settings: SettingsDep) -> MetricsRecorder:
    recorder = MetricsRecorder(settings=settings, store_path=Path("logs/metrics/metrics.csv"))
    return recorder


LoggerDep = Annotated[logging.Logger, Depends(get_logger)]
MetricsDep = Annotated[MetricsRecorder, Depends(get_metrics)]


def require_admin_token(request: Request, settings: SettingsDep) -> None:
    token = settings.admin_api_token
    if not token:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Admin API token not configured.",
        )
    provided = request.headers.get("X-Admin-Token")
    if not provided:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Missing X-Admin-Token header.",
        )
    if provided != token:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Invalid admin token.",
        )


AdminGuard = Annotated[None, Depends(require_admin_token)]

```

## `api/Dockerfile`

```dockerfile
FROM python:3.12-slim AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

WORKDIR /app

RUN apt-get update \
    && apt-get install -y --no-install-recommends build-essential curl \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt ./requirements.txt
RUN pip install --no-cache-dir --upgrade pip \
    && pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]

```

## `api/errors.py`

```python
"""Custom exception handlers returning the shared JSON error schema."""

from __future__ import annotations

from collections.abc import Iterable
from typing import Any

from fastapi import Request, status
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from starlette.exceptions import HTTPException as StarletteHTTPException

from atticus.logging import log_error

from .schemas import ErrorResponse

_ERROR_CODE_BY_STATUS: dict[int, str] = {
    status.HTTP_400_BAD_REQUEST: "bad_request",
    status.HTTP_401_UNAUTHORIZED: "unauthorized",
    status.HTTP_403_FORBIDDEN: "forbidden",
    status.HTTP_404_NOT_FOUND: "not_found",
    status.HTTP_409_CONFLICT: "conflict",
    status.HTTP_422_UNPROCESSABLE_ENTITY: "validation_error",
    status.HTTP_429_TOO_MANY_REQUESTS: "rate_limited",
}


def _lookup_error_code(status_code: int) -> str:
    if status_code in _ERROR_CODE_BY_STATUS:
        return _ERROR_CODE_BY_STATUS[status_code]
    if 500 <= status_code < 600:
        return "internal_error"
    return "http_error"


def _normalize_detail(detail: Any) -> str:
    if isinstance(detail, str):
        return detail
    if isinstance(detail, dict):
        return "; ".join(f"{k}: {v}" for k, v in detail.items()) or "An error occurred"
    if isinstance(detail, Iterable) and not isinstance(detail, (str, bytes)):
        return "; ".join(str(item) for item in detail)
    return str(detail) if detail is not None else "An error occurred"


def _build_response(
    request: Request,
    *,
    status_code: int,
    error: str,
    detail: str,
    fields: dict[str, str] | None = None,
) -> JSONResponse:
    request_id = getattr(request.state, "request_id", "unknown")
    payload = ErrorResponse(
        error=error,
        detail=detail,
        request_id=request_id,
        fields=fields,
    ).model_dump(exclude_none=True)
    response = JSONResponse(status_code=status_code, content=payload)
    response.headers["X-Request-ID"] = request_id
    return response


async def http_exception_handler(request: Request, exc: StarletteHTTPException) -> JSONResponse:
    error_code = _lookup_error_code(exc.status_code)
    detail = _normalize_detail(exc.detail)
    if exc.status_code >= status.HTTP_500_INTERNAL_SERVER_ERROR:
        logger = getattr(request.app.state, "logger", None)
        if logger is not None:
            log_error(
                logger,
                "http_exception",
                request_id=getattr(request.state, "request_id", "unknown"),
                status_code=exc.status_code,
                detail=detail,
            )
    return _build_response(
        request,
        status_code=exc.status_code,
        error=error_code,
        detail=detail,
    )


async def validation_exception_handler(
    request: Request, exc: RequestValidationError
) -> JSONResponse:
    fields: dict[str, str] = {}
    messages: list[str] = []
    for err in exc.errors():
        loc = err.get("loc", ())
        field_parts = [str(part) for part in loc if part not in {"body", "query"}]
        field = ".".join(field_parts) if field_parts else "payload"
        message = err.get("msg", "Invalid value")
        fields[field] = message
        messages.append(f"{field}: {message}")
    detail = "; ".join(messages) if messages else "Invalid request payload"

    logger = getattr(request.app.state, "logger", None)
    if logger is not None:
        log_error(
            logger,
            "request_validation_error",
            request_id=getattr(request.state, "request_id", "unknown"),
            detail=detail,
            fields=fields,
        )
    return _build_response(
        request,
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        error=_lookup_error_code(status.HTTP_422_UNPROCESSABLE_ENTITY),
        detail=detail,
        fields=fields or None,
    )


async def unhandled_exception_handler(request: Request, exc: Exception) -> JSONResponse:
    logger = getattr(request.app.state, "logger", None)
    detail = "An internal error occurred."
    if logger is not None:
        log_error(
            logger,
            "unhandled_exception",
            request_id=getattr(request.state, "request_id", "unknown"),
            detail=str(exc),
        )
    return _build_response(
        request,
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        error="internal_error",
        detail=detail,
    )

```

## `api/main.py`

```python
"""FastAPI application for Atticus."""

from __future__ import annotations

from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from pathlib import Path

from fastapi import FastAPI
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException

from atticus.logging import configure_logging
from atticus.metrics import MetricsRecorder

from .dependencies import get_settings
from .errors import (
    http_exception_handler,
    unhandled_exception_handler,
    validation_exception_handler,
)
from .middleware import RequestContextMiddleware
from .rate_limit import RateLimiter
from .routes import admin, chat, contact, eval, health, ingest, ui


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncIterator[None]:
    settings = get_settings()
    logger = configure_logging(settings)
    metrics = MetricsRecorder(settings=settings)
    app.state.settings = settings
    app.state.logger = logger
    app.state.metrics = metrics
    app.state.rate_limiter = RateLimiter(
        limit=settings.rate_limit_requests,
        window_seconds=settings.rate_limit_window_seconds,
    )
    # Warn when critical secrets are missing (non-fatal in dev/test)
    if not (settings.openai_api_key or "").strip():
        logger.warning(
            "OPENAI_API_KEY not set; embeddings/generation may fail",
            extra={"extra_payload": {"env": ".env", "key": "OPENAI_API_KEY"}},
        )
    try:
        yield
    finally:
        metrics.flush()


def _load_version() -> str:
    """Return the semantic version recorded in the repository root."""

    version_path = Path(__file__).resolve().parents[1] / "VERSION"
    try:
        version = version_path.read_text(encoding="utf-8").strip()
    except OSError:
        return "0.0.0"
    return version or "0.0.0"


app = FastAPI(
    title="Atticus RAG API",
    version=_load_version(),
    docs_url=None,
    redoc_url=None,
    lifespan=lifespan,
)
app.add_middleware(RequestContextMiddleware)
app.add_exception_handler(StarletteHTTPException, http_exception_handler)
app.add_exception_handler(RequestValidationError, validation_exception_handler)
app.add_exception_handler(Exception, unhandled_exception_handler)
app.include_router(health.router)
app.include_router(ingest.router)
app.include_router(chat.router)
app.include_router(admin.router)
app.include_router(eval.router)
app.include_router(contact.router)
app.include_router(ui.router)

```

## `api/middleware.py`

```python
"""Custom middleware for request IDs and logging."""

from __future__ import annotations

import hashlib
import time
import uuid
from collections.abc import Awaitable, Callable

from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse, Response

from atticus.config import load_settings
from atticus.logging import log_event

from .rate_limit import RateLimiter


class RequestContextMiddleware(BaseHTTPMiddleware):
    """Attach a request ID to each call and emit structured logs."""

    async def dispatch(
        self,
        request: Request,
        call_next: Callable[[Request], Awaitable[Response]],
    ) -> Response:
        request_id = request.headers.get("X-Request-ID") or uuid.uuid4().hex
        request.state.request_id = request_id
        request.state.trace_id = request_id

        start = time.perf_counter()
        logger = getattr(request.app.state, "logger", None)

        limiter = getattr(request.app.state, "rate_limiter", None)
        # Clarification: rate limit applies to FastAPI /ask endpoint only.
        # The Next.js handler lives under /api/ask and is rate-limited separately via frontend middleware/infra.
        if request.url.path == "/ask":
            settings = load_settings()
            if (
                limiter is None
                or limiter.limit != settings.rate_limit_requests
                or limiter.window_seconds != settings.rate_limit_window_seconds
            ):
                limiter = RateLimiter(
                    limit=settings.rate_limit_requests,
                    window_seconds=settings.rate_limit_window_seconds,
                )
                request.app.state.rate_limiter = limiter
            request.app.state.settings = settings
            identifier = (
                request.headers.get("X-User-ID")
                or request.headers.get("X-Forwarded-For")
                or (request.client.host if request.client else "anonymous")
            )
            allowed, retry_after = limiter.allow(identifier)
            if not allowed:
                hashed = hashlib.sha256(identifier.encode("utf-8")).hexdigest()[:12]
                if logger is not None:
                    log_event(
                        logger,
                        "rate_limit_blocked",
                        request_id=request_id,
                        identifier_hash=hashed,
                        retry_after=retry_after,
                    )
                payload = {
                    "error": "rate_limited",
                    "detail": "Rate limit exceeded. Please retry later.",
                    "request_id": request_id,
                }
                return JSONResponse(
                    payload,
                    status_code=429,
                    headers={"Retry-After": str(retry_after), "X-Request-ID": request_id},
                )

        try:
            response = await call_next(request)
        except Exception as exc:  # pragma: no cover - runtime error path
            if logger is not None:
                log_event(
                    logger,
                    "request_error",
                    request_id=request_id,
                    method=request.method,
                    path=request.url.path,
                    error=str(exc),
                )
            raise

        elapsed_ms = (time.perf_counter() - start) * 1000
        response.headers["X-Request-ID"] = request_id

        if logger is not None:
            log_event(
                logger,
                "request_complete",
                request_id=request_id,
                method=request.method,
                path=request.url.path,
                status=response.status_code,
                latency_ms=round(elapsed_ms, 2),
            )

        metrics = getattr(request.app.state, "metrics", None)
        if (
            metrics is not None
            and request.url.path == "/ask"
            and hasattr(request.state, "confidence")
        ):
            metrics.record(
                float(request.state.confidence),
                elapsed_ms,
                bool(getattr(request.state, "escalate", False)),
                trace_id=request_id,
            )

        return response

```

## `api/rate_limit.py`

```python
"""Simple in-memory rate limiter for API requests."""

from __future__ import annotations

import time
from collections import deque
from dataclasses import dataclass, field


@dataclass(slots=True)
class RateLimiter:
    limit: int
    window_seconds: int
    blocked: int = 0
    _buckets: dict[str, deque[float]] = field(default_factory=dict)

    def allow(self, key: str) -> tuple[bool, int]:
        now = time.monotonic()
        bucket = self._buckets.setdefault(key, deque())
        cutoff = now - self.window_seconds
        while bucket and bucket[0] <= cutoff:
            bucket.popleft()
        if len(bucket) >= self.limit:
            self.blocked += 1
            retry_after = int(max(1, round(bucket[0] + self.window_seconds - now)))
            return False, retry_after
        bucket.append(now)
        return True, self.limit - len(bucket)

    def snapshot(self) -> dict[str, int]:
        return {
            "limit": self.limit,
            "window_seconds": self.window_seconds,
            "active_keys": len(self._buckets),
            "blocked": self.blocked,
        }

    def reset(self) -> None:
        self.blocked = 0
        self._buckets.clear()

```

## `api/routes/__init__.py`

```python
"""Route modules for Atticus API."""

from . import admin, chat, eval, health, ingest, ui

__all__ = ["admin", "chat", "eval", "health", "ingest", "ui"]

```

## `api/routes/admin.py`

```python
"""Admin endpoints for dictionary and error logs."""

import json
from datetime import datetime

from fastapi import APIRouter, HTTPException, Query, Request
from fastapi.responses import HTMLResponse

from atticus.logging import log_event

from ..dependencies import AdminGuard, LoggerDep, MetricsDep, SettingsDep
from ..schemas import (
    DictionaryEntry,
    DictionaryPayload,
    ErrorLogEntry,
    MetricsDashboard,
    MetricsHistogram,
    SessionLogEntry,
    SessionLogResponse,
)
from ..utils import load_dictionary, load_error_logs, load_session_logs, save_dictionary

router = APIRouter(prefix="/admin")


@router.get("/dictionary", response_model=DictionaryPayload)
async def read_dictionary(_: AdminGuard, settings: SettingsDep) -> DictionaryPayload:
    try:
        entries = [DictionaryEntry(**item) for item in load_dictionary(settings.dictionary_path)]
    except ValueError as exc:  # pragma: no cover - corrupted file path
        raise HTTPException(status_code=500, detail=str(exc)) from exc
    return DictionaryPayload(entries=entries)


@router.post("/dictionary", response_model=DictionaryPayload)
async def write_dictionary(
    _: AdminGuard,
    payload: DictionaryPayload,
    settings: SettingsDep,
    logger: LoggerDep,
) -> DictionaryPayload:
    save_dictionary(settings.dictionary_path, [entry.model_dump() for entry in payload.entries])
    log_event(logger, "dictionary_updated", entries=len(payload.entries))
    return payload


@router.get("/errors", response_model=list[ErrorLogEntry])
async def get_errors(
    _: AdminGuard,
    settings: SettingsDep,
    since: str | None = Query(default=None, description="Return errors since ISO timestamp"),
) -> list[ErrorLogEntry]:
    entries = load_error_logs(settings.errors_path, limit=100)
    filtered: list[ErrorLogEntry] = []
    cutoff = None
    if since:
        try:
            cutoff = datetime.fromisoformat(since)
        except ValueError as exc:
            raise HTTPException(status_code=400, detail="Invalid ISO timestamp") from exc
    for entry in entries:
        timestamp = entry.get("time") or entry.get("timestamp")
        if cutoff and timestamp:
            try:
                entry_time = datetime.fromisoformat(str(timestamp))
            except ValueError:
                continue
            if entry_time < cutoff:
                continue
        filtered.append(
            ErrorLogEntry(
                time=str(timestamp),
                message=str(entry.get("message", "")),
                details={k: str(v) for k, v in entry.items() if k not in {"time", "message"}},
            )
        )
    return filtered


def _render_session_html(entries: list[dict[str, object]]) -> str:
    rows = []
    for entry in entries:
        filters = entry.get("filters")
        filters_str = json.dumps(filters, indent=2) if isinstance(filters, dict) else str(filters)
        rows.append(
            "<tr>"
            f"<td>{entry.get('time', '')}</td>"
            f"<td>{entry.get('request_id', '')}</td>"
            f"<td>{entry.get('method', '')}</td>"
            f"<td>{entry.get('path', '')}</td>"
            f"<td>{entry.get('status', '')}</td>"
            f"<td>{entry.get('latency_ms', '')}</td>"
            f"<td>{entry.get('confidence', '')}</td>"
            f"<td>{entry.get('escalate', '')}</td>"
            f"<td><pre>{filters_str}</pre></td>"
            "</tr>"
        )
    table_rows = "\n".join(rows)
    return (
        "<html><head><title>Session Logs</title>"
        "<style>table{border-collapse:collapse;width:100%;}"
        "th,td{border:1px solid #ccc;padding:8px;text-align:left;}"
        "pre{margin:0;white-space:pre-wrap;}</style></head><body>"
        "<h1>Recent Sessions</h1>"
        "<table>"
        "<thead><tr><th>Time</th><th>Request ID</th><th>Method</th><th>Path</th><th>Status</th>"
        "<th>Latency (ms)</th><th>Confidence</th><th>Escalate</th><th>Filters</th></tr></thead>"
        f"<tbody>{table_rows}</tbody></table></body></html>"
    )


@router.get(
    "/sessions", response_model=SessionLogResponse, responses={200: {"content": {"text/html": {}}}}
)
async def get_sessions(
    _: AdminGuard,
    settings: SettingsDep,
    format: str = Query("json", pattern="^(json|html)$", description="Return JSON or HTML"),
    limit: int = Query(20, ge=1, le=200),
) -> SessionLogResponse | HTMLResponse:
    entries = load_session_logs(settings.logs_path, limit=limit)
    if format.lower() == "html":
        html = _render_session_html(entries)
        return HTMLResponse(html)
    payload = [SessionLogEntry(**entry) for entry in entries]
    return SessionLogResponse(sessions=payload)


@router.get("/metrics", response_model=MetricsDashboard)
async def get_metrics_dashboard(
    _: AdminGuard,
    metrics: MetricsDep,
    request: Request,
) -> MetricsDashboard:
    data = metrics.dashboard()
    histogram = [
        MetricsHistogram(bucket=bucket, count=int(count))
        for bucket, count in data.get("latency_histogram", {}).items()
    ]
    limiter = getattr(request.app.state, "rate_limiter", None)
    rate_limit = limiter.snapshot() if limiter else None
    return MetricsDashboard(
        queries=int(data.get("queries", 0)),
        avg_confidence=float(data.get("avg_confidence", 0.0)),
        escalations=int(data.get("escalations", 0)),
        avg_latency_ms=float(data.get("avg_latency_ms", 0.0)),
        p95_latency_ms=float(data.get("p95_latency_ms", 0.0)),
        histogram=histogram,
        recent_trace_ids=list(data.get("recent_trace_ids", [])),
        rate_limit=rate_limit,
    )

```

## `api/routes/chat.py`

```python
"""Unified chat route returning the canonical ask response contract."""

import time
from collections.abc import Iterable, Sequence

from fastapi import APIRouter, HTTPException, Request

from atticus.logging import log_event
from atticus.tokenization import count_tokens
from retriever import answer_question
from retriever.models import Citation
from retriever.resolver import ModelResolution, ModelScope, resolve_models

from ..dependencies import LoggerDep, SettingsDep
from ..schemas import (
    AskAnswer,
    AskRequest,
    AskResponse,
    AskSource,
    ClarificationOption,
    ClarificationPayload,
)

router = APIRouter()
_Q_PLACEHOLDERS = {"string", "test", "example"}
_Q_MIN_LEN = 4
_CLARIFICATION_MESSAGE = "Which model are you referring to? If you like, I can provide a list of product families that I can assist with."


def _format_sources(citations: Iterable[AskSource]) -> list[str]:
    sources: list[str] = []
    for citation in citations:
        desc = citation.path
        if citation.page is not None:
            desc += f" (page {citation.page})"
        if citation.heading:
            desc += f" - {citation.heading}"
        sources.append(desc)
    return sources


def _convert_citations(citations: Iterable[Citation]) -> list[AskSource]:
    return [
        AskSource(
            chunkId=item.chunk_id,
            path=item.source_path,
            page=item.page_number,
            heading=item.heading,
            score=item.score,
        )
        for item in citations
    ]


def _build_answer_payloads(
    question: str,
    scopes: Sequence[ModelScope],
    payload: AskRequest,
    settings: SettingsDep,
    logger: LoggerDep,
) -> list[AskAnswer]:
    answers: list[AskAnswer] = []
    for scope in scopes:
        filters = dict(payload.filters or {})
        answer = answer_question(
            question,
            settings=settings,
            filters=filters,
            logger=logger,
            top_k=payload.top_k,
            context_hints=payload.context_hints,
            product_family=scope.family_id or None,
            family_label=scope.family_label or None,
            model=scope.model,
        )
        ask_sources = _convert_citations(answer.citations)
        answers.append(
            AskAnswer(
                answer=answer.response,
                confidence=answer.confidence,
                should_escalate=answer.should_escalate,
                model=getattr(answer, "model", scope.model),
                family=getattr(answer, "family", scope.family_id or None),
                family_label=getattr(answer, "family_label", scope.family_label or None),
                sources=ask_sources,
            )
        )
    return answers


def _aggregate_answer_text(answers: Sequence[AskAnswer]) -> str:
    segments: list[str] = []
    for entry in answers:
        header_parts = [entry.model, entry.family_label or entry.family]
        header = " · ".join(part for part in header_parts if part)
        body = entry.answer.strip()
        if header:
            segments.append(f"### {header}\n\n{body}")
        else:
            segments.append(body)
    return "\n\n".join(segment for segment in segments if segment).strip()


def _clarification_response(resolution: ModelResolution, request_id: str) -> AskResponse:
    options = [
        ClarificationOption(id=option.id, label=option.label)
        for option in resolution.clarification_options
    ]
    clarification = ClarificationPayload(message=_CLARIFICATION_MESSAGE, options=options)
    return AskResponse(
        request_id=request_id,
        clarification=clarification,
        sources=[],
        answers=[],
        confidence=0.0,
        should_escalate=False,
    )


@router.post("/ask", response_model=AskResponse)
async def ask_endpoint(
    payload: AskRequest,
    request: Request,
    settings: SettingsDep,
    logger: LoggerDep,
) -> AskResponse:
    start = time.perf_counter()
    question = payload.question.strip()
    if len(question) < _Q_MIN_LEN or question.lower() in _Q_PLACEHOLDERS:
        raise HTTPException(
            status_code=400,
            detail="Provide a real question (not a placeholder like 'string')",
        )

    resolution = resolve_models(question, payload.models)

    request_id = getattr(request.state, "request_id", "unknown")

    if resolution.needs_clarification:
        response = _clarification_response(resolution, request_id)
        request.state.confidence = 0.0
        request.state.escalate = False
        elapsed_ms = (time.perf_counter() - start) * 1000
        log_event(
            logger,
            "ask_endpoint_clarification",
            request_id=request_id,
            latency_ms=round(elapsed_ms, 2),
        )
        return response

    scopes: Sequence[ModelScope]
    if resolution.scopes:
        scopes = resolution.scopes
    else:
        scopes = [ModelScope(family_id="", family_label="", model=None)]

    answers = _build_answer_payloads(
        question=question,
        scopes=scopes,
        payload=payload,
        settings=settings,
        logger=logger,
    )

    confidence_values = [entry.confidence for entry in answers if entry.confidence is not None]
    aggregated_confidence = min(confidence_values) if confidence_values else 0.0
    aggregated_escalation = any(entry.should_escalate for entry in answers)
    flattened_sources = [source for entry in answers for source in entry.sources]
    aggregated_answer = _aggregate_answer_text(answers)

    request.state.confidence = aggregated_confidence
    request.state.escalate = aggregated_escalation

    elapsed_ms = (time.perf_counter() - start) * 1000

    if len(answers) == 1:
        primary = answers[0]
        response = AskResponse(
            answer=primary.answer,
            confidence=primary.confidence,
            should_escalate=primary.should_escalate,
            request_id=request_id,
            sources=primary.sources,
            answers=list(answers),
        )
    else:
        response = AskResponse(
            answer=aggregated_answer,
            confidence=aggregated_confidence,
            should_escalate=aggregated_escalation,
            request_id=request_id,
            sources=flattened_sources,
            answers=list(answers),
        )

    log_event(
        logger,
        "ask_endpoint_complete",
        request_id=request_id,
        confidence=aggregated_confidence,
        escalate=aggregated_escalation,
        latency_ms=round(elapsed_ms, 2),
        filters=payload.filters or {},
        models=payload.models or [],
    )

    if getattr(settings, "verbose_logging", False):
        try:
            user_tokens = count_tokens(question)
        except Exception:  # pragma: no cover - diagnostics only
            user_tokens = None
        try:
            answer_tokens = count_tokens(aggregated_answer or "")
        except Exception:  # pragma: no cover - diagnostics only
            answer_tokens = None

        trace: list[str] | None = None
        if getattr(settings, "trace_logging", False):
            trace = [
                "received_question",
                f"resolved_scopes={len(scopes)}",
                f"confidence={float(aggregated_confidence):.3f}",
                "escalate=true" if aggregated_escalation else "escalate=false",
            ]

        log_event(
            logger,
            "chat_turn",
            request_id=request_id,
            question=question,
            answer=aggregated_answer,
            sources=_format_sources(flattened_sources),
            confidence=float(aggregated_confidence),
            tokens={
                "question": user_tokens,
                "answer": answer_tokens,
                "total": (user_tokens or 0) + (answer_tokens or 0),
            },
            openai_key_present=bool(getattr(settings, "openai_api_key", None)),
            trace=trace,
        )

    return response

```

## `api/routes/contact.py`

```python
"""Contact escalation endpoint.

POST /contact accepts JSON payload and sends an escalation email via SMTP.
"""

from __future__ import annotations

import json

from fastapi import APIRouter, HTTPException, Request, status
from pydantic import BaseModel, Field

from atticus.config import load_settings
from atticus.logging import configure_logging, log_error, log_event
from atticus.notify.mailer import EscalationDeliveryError, send_escalation

router = APIRouter()


class TraceDocument(BaseModel):
    chunk_id: str
    score: float
    source_path: str | None = None
    page_number: int | None = None
    heading: str | None = None


class EscalationTrace(BaseModel):
    user_id: str | None = None
    chat_id: str | None = None
    message_id: str | None = None
    request_id: str | None = None
    question: str | None = None
    documents: list[TraceDocument] = Field(
        default_factory=list,
        alias="top_documents",
        description="Top retrieved documents and scores",
    )


class ContactRequest(BaseModel):
    reason: str = Field(description="Reason for contacting support/escalation")
    transcript: list[str] | str | None = Field(
        default=None,
        description="Optional chat transcript (list of lines) or a single string",
    )
    trace: EscalationTrace | None = Field(
        default=None,
        description="Optional trace payload including user/chat/document context",
    )


@router.post("/contact", status_code=status.HTTP_202_ACCEPTED)
async def contact(payload: ContactRequest, request: Request) -> dict[str, str]:
    settings = load_settings()
    logger = configure_logging(settings)

    request_id = getattr(request.state, "request_id", "unknown")
    body_lines = [f"Reason: {payload.reason}"]
    if payload.transcript:
        body_lines.append("")
        body_lines.append("Transcript:")
        if isinstance(payload.transcript, list):
            body_lines.extend(str(x) for x in payload.transcript)
        else:
            body_lines.append(str(payload.transcript))
    trace_payload: dict[str, object] | None = None
    if payload.trace:
        trace_payload = payload.trace.model_dump(by_alias=True, exclude_none=True)
        body_lines.append("")
        body_lines.append("Trace Payload:")
        body_lines.append(json.dumps(trace_payload, indent=2, ensure_ascii=False))
    body = "\n".join(body_lines)

    subject = f"Atticus escalation: {payload.reason}"[:200]
    try:
        send_escalation(subject=subject, body=body, trace=trace_payload)
    except EscalationDeliveryError as exc:
        log_error(
            logger,
            "contact_escalation_failed",
            request_id=request_id,
            reason=exc.reason,
        )
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="Unable to deliver escalation email. Please try again shortly.",
        ) from exc

    trace_id = None
    if trace_payload:
        trace_id = str(trace_payload.get("request_id") or request_id)

    log_event(
        logger,
        "contact_escalation_sent",
        request_id=request_id,
        has_transcript=bool(payload.transcript),
        trace_id=trace_id or request_id,
    )
    return {"status": "accepted"}

```

## `api/routes/eval.py`

```python
"""Evaluation API endpoint."""

from fastapi import APIRouter, HTTPException

from atticus.logging import log_event
from eval.runner import run_evaluation

from ..dependencies import LoggerDep, SettingsDep
from ..schemas import EvalResponse

router = APIRouter()


@router.post("/eval/run", response_model=EvalResponse)
async def run_eval(settings: SettingsDep, logger: LoggerDep) -> EvalResponse:
    result = run_evaluation(settings=settings)
    log_event(logger, "eval_api_complete", metrics=result.metrics, deltas=result.deltas)
    threshold = settings.eval_regression_threshold / 100.0
    if any(delta < -threshold for delta in result.deltas.values()):
        raise HTTPException(
            status_code=400, detail={"metrics": result.metrics, "deltas": result.deltas}
        )
    return EvalResponse(
        metrics=result.metrics,
        deltas=result.deltas,
        summary_csv=str(result.summary_csv),
        summary_json=str(result.summary_json),
        summary_html=str(result.summary_html),
    )

```

## `api/routes/health.py`

```python
"""Health endpoints."""

from fastapi import APIRouter

from atticus.config import load_manifest

from ..dependencies import SettingsDep
from ..schemas import HealthResponse

router = APIRouter()


@router.get("/health", response_model=HealthResponse)
async def health(settings: SettingsDep) -> HealthResponse:
    manifest = load_manifest(settings.manifest_path)
    return HealthResponse(
        status="ok",
        manifest_present=manifest is not None,
        document_count=manifest.document_count if manifest else 0,
        chunk_count=manifest.chunk_count if manifest else 0,
        embedding_model=(manifest.embedding_model if manifest else settings.embed_model),
        embedding_model_version=(
            manifest.embedding_model_version if manifest else settings.embedding_model_version
        ),
    )

```

## `api/routes/ingest.py`

```python
from fastapi import APIRouter

from atticus.logging import log_event
from ingest.pipeline import IngestionOptions, ingest_corpus

from ..dependencies import LoggerDep, SettingsDep
from ..schemas import IngestRequest, IngestResponse

router = APIRouter()


@router.post("/ingest", response_model=IngestResponse)
async def trigger_ingestion(
    payload: IngestRequest,
    settings: SettingsDep,
    logger: LoggerDep,
) -> IngestResponse:
    options = IngestionOptions(full_refresh=payload.full_refresh, paths=payload.paths)
    summary = ingest_corpus(settings=settings, options=options)
    log_event(
        logger,
        "ingest_api_complete",
        documents_processed=summary.documents_processed,
        documents_skipped=summary.documents_skipped,
        chunks_indexed=summary.chunks_indexed,
    )
    return IngestResponse(
        documents_processed=summary.documents_processed,
        documents_skipped=summary.documents_skipped,
        chunks_indexed=summary.chunks_indexed,
        elapsed_seconds=summary.elapsed_seconds,
        manifest_path=str(summary.manifest_path),
        index_path=str(summary.index_path),
        snapshot_path=str(summary.snapshot_path),
        ingested_at=summary.ingested_at,
        embedding_model=summary.embedding_model,
        embedding_model_version=summary.embedding_model_version,
    )

```

## `api/routes/ui.py`

```python
"""Lightweight HTML shell for test and health checks."""

from __future__ import annotations

from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter()

_HTML_RESPONSE = """<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Atticus Admin Console</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body {
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
        margin: 2rem;
        line-height: 1.5;
      }
      h1 {
        font-size: 1.75rem;
        margin-bottom: 0.5rem;
      }
      p {
        margin: 0;
        color: #475569;
      }
    </style>
  </head>
  <body>
    <h1>Atticus</h1>
    <p>The Atticus API is running. Use the Next.js frontend for the full experience.</p>
  </body>
</html>
"""


@router.get("/ui", response_class=HTMLResponse, include_in_schema=False)
async def ui_landing() -> str:
    """Serve a minimal HTML response that confirms the API is available."""

    return _HTML_RESPONSE

```

## `api/schemas.py`

```python
"""Pydantic models for API payloads."""

from __future__ import annotations

from pathlib import Path
from typing import Any

from pydantic import BaseModel, Field
from pydantic.config import ConfigDict


class HealthResponse(BaseModel):
    status: str
    manifest_present: bool
    document_count: int
    chunk_count: int
    embedding_model: str | None = None
    embedding_model_version: str | None = None


class IngestRequest(BaseModel):
    full_refresh: bool = False
    paths: list[Path] | None = None


class IngestResponse(BaseModel):
    documents_processed: int
    documents_skipped: int
    chunks_indexed: int
    elapsed_seconds: float
    manifest_path: str
    index_path: str
    snapshot_path: str
    ingested_at: str
    embedding_model: str
    embedding_model_version: str


class AskRequest(BaseModel):
    """Canonical ask request contract shared across services."""

    model_config = ConfigDict(populate_by_name=True)

    # Accept both {"question": "..."} and legacy {"query": "..."}
    question: str = Field(validation_alias="query")
    filters: dict[str, str] | None = Field(
        default=None, description="Metadata filters such as path_prefix or source_type"
    )
    context_hints: list[str] | None = Field(
        default=None,
        alias="contextHints",
        description="Optional hints supplied by the UI to bias retrieval",
    )
    top_k: int | None = Field(
        default=None,
        ge=1,
        le=32,
        alias="topK",
        description="Override for the retrieval top-k window",
    )
    models: list[str] | None = Field(
        default=None,
        description="Optional explicit models or families selected by the user",
    )


class AskSource(BaseModel):
    """Structured citation returned to the UI."""

    model_config = ConfigDict(populate_by_name=True)

    path: str
    page: int | None = None
    heading: str | None = None
    chunkId: str | None = None
    score: float | None = None


class AskResponse(BaseModel):
    answer: str | None = None
    confidence: float | None = None
    should_escalate: bool | None = None
    request_id: str
    sources: list[AskSource] | None = None
    answers: list[AskAnswer] | None = None
    clarification: ClarificationPayload | None = None


class AskAnswer(BaseModel):
    answer: str
    confidence: float
    should_escalate: bool
    model: str | None = None
    family: str | None = None
    family_label: str | None = None
    sources: list[AskSource]


class ClarificationOption(BaseModel):
    id: str
    label: str


class ClarificationPayload(BaseModel):
    message: str
    options: list[ClarificationOption]


class EvalResponse(BaseModel):
    metrics: dict[str, float]
    deltas: dict[str, float]
    summary_csv: str
    summary_json: str
    summary_html: str


class ErrorResponse(BaseModel):
    """Standard error payload for API responses."""

    error: str
    detail: str
    request_id: str
    fields: dict[str, str] | None = None


class DictionaryEntry(BaseModel):
    term: str
    synonyms: list[str]


class DictionaryPayload(BaseModel):
    entries: list[DictionaryEntry]


class ErrorLogEntry(BaseModel):
    time: str
    message: str
    details: dict[str, str] = Field(default_factory=dict)


class SessionLogEntry(BaseModel):
    request_id: str
    method: str | None = None
    path: str | None = None
    status: int | None = None
    latency_ms: float | None = None
    time: str | None = None
    confidence: float | None = None
    escalate: bool | None = None
    filters: dict[str, Any] | None = None


class SessionLogResponse(BaseModel):
    sessions: list[SessionLogEntry]


class MetricsHistogram(BaseModel):
    bucket: str
    count: int


class MetricsDashboard(BaseModel):
    queries: int
    avg_confidence: float
    escalations: int
    avg_latency_ms: float
    p95_latency_ms: float
    histogram: list[MetricsHistogram]
    recent_trace_ids: list[str]
    rate_limit: dict[str, int] | None = None


AskResponse.model_rebuild()

```

## `api/utils.py`

```python
"""Utility helpers for API operations."""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any


def load_dictionary(path: Path) -> list[dict[str, object]]:
    if not path.exists():
        return []
    payload = json.loads(path.read_text(encoding="utf-8"))
    if isinstance(payload, list):
        return payload
    raise ValueError("Dictionary file is malformed; expected a list of entries")


def save_dictionary(path: Path, entries: list[dict[str, object]]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(entries, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")


def load_error_logs(path: Path, limit: int = 50) -> list[dict[str, object]]:
    if not path.exists():
        return []
    lines = path.read_text(encoding="utf-8").splitlines()
    tail = lines[-limit:]
    entries: list[dict[str, object]] = []
    for line in tail:
        try:
            entries.append(json.loads(line))
        except json.JSONDecodeError:
            continue
    return entries


def load_session_logs(path: Path, limit: int = 20) -> list[dict[str, Any]]:  # noqa: PLR0912
    if not path.exists():
        return []
    lines = path.read_text(encoding="utf-8").splitlines()
    sessions: list[dict[str, Any]] = []
    ask_metadata: dict[str, dict[str, Any]] = {}
    for line in reversed(lines):
        try:
            record = json.loads(line)
        except json.JSONDecodeError:
            continue
        message = str(record.get("message", ""))
        payload = record.copy()
        payload.pop("message", None)
        if message == "ask_endpoint_complete":
            request_id = str(payload.get("request_id", ""))
            if request_id:
                meta = ask_metadata.setdefault(request_id, {})
                for key in ("confidence", "escalate", "filters"):
                    if key in payload:
                        meta[key] = payload[key]
        if message == "chat_turn":
            request_id = str(payload.get("request_id", ""))
            if request_id:
                meta = ask_metadata.setdefault(request_id, {})
                for key in ("confidence", "tokens", "trace"):
                    if key in payload and payload[key] is not None:
                        meta[key] = payload[key]
        if message == "request_complete":
            request_id = str(payload.get("request_id", ""))
            entry: dict[str, Any] = {
                "request_id": request_id,
                "method": payload.get("method"),
                "path": payload.get("path"),
                "status": payload.get("status"),
                "latency_ms": payload.get("latency_ms"),
                "time": record.get("time"),
            }
            if request_id in ask_metadata:
                entry.update(ask_metadata[request_id])
            sessions.append(entry)
            if len(sessions) >= limit:
                break
    sessions.reverse()
    return sessions

```

## `app/admin/content/page.tsx`

```tsx
import type { Metadata } from "next";
import { listContent } from "@/lib/content-manager";
import { ContentManager } from "@/components/admin/content-manager";

export const metadata: Metadata = {
  title: "Content Manager - Atticus",
  description: "Manage source documents and trigger ingestion updates.",
};

export default async function ContentManagerPage() {
  const entries = await listContent(".");

  return (
    <div className="mx-auto max-w-6xl px-6 py-10">
      <ContentManager initialPath="." initialEntries={entries} />
    </div>
  );
}

```

## `app/admin/page.tsx`

```tsx
import type { Metadata } from "next";
import { redirect } from "next/navigation";
import { GlossaryStatus, Prisma, Role } from "@prisma/client";
import { PageHeader } from "@/components/page-header";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { withRlsContext } from "@/lib/rls";
import { AdminOpsConsole, TicketSummary, UncertainChat } from "@/components/admin/admin-ops-console";
import type { GlossaryEntryDto } from "@/components/glossary/admin-panel";
import { getRequestContext } from "@/lib/request-context";

export const metadata: Metadata = {
  title: "Admin - Atticus",
};

type GlossaryEntryRecord = {
  id: string;
  term: string;
  definition: string;
  synonyms: string[];
  status: GlossaryStatus;
  createdAt: Date;
  updatedAt: Date;
  reviewedAt: Date | null;
  reviewNotes: string | null;
  author: { id: string; email: string | null; name: string | null } | null;
  updatedBy: { id: string; email: string | null; name: string | null } | null;
  reviewer: { id: string; email: string | null; name: string | null } | null;
};

export default async function AdminPage() {
  const { user } = getRequestContext();
  if (user.role !== Role.ADMIN && user.role !== Role.REVIEWER) {
    redirect("/");
  }

  const { chats, tickets, glossary } = await withRlsContext(user, async (tx) => {
    const [pendingChats, ticketRows, glossaryRows] = await Promise.all([
      tx.chat.findMany({
        where: { status: "pending_review" },
        include: {
          author: { select: { id: true, email: true, name: true } },
          reviewer: { select: { id: true, email: true, name: true } },
          tickets: {
            select: { id: true, key: true, status: true, assignee: true, lastActivity: true },
          },
        },
        orderBy: { createdAt: "desc" },
      }),
      tx.ticket.findMany({
        orderBy: { updatedAt: "desc" },
        select: {
          id: true,
          key: true,
          status: true,
          assignee: true,
          lastActivity: true,
          summary: true,
        },
      }),
      tx.glossaryEntry.findMany({
        orderBy: { term: "asc" },
        include: {
          author: { select: { id: true, email: true, name: true } },
          updatedBy: { select: { id: true, email: true, name: true } },
          reviewer: { select: { id: true, email: true, name: true } },
        },
      }),
    ]);

    return { chats: pendingChats, tickets: ticketRows, glossary: glossaryRows };
  });

  const glossaryEntries: GlossaryEntryDto[] = (glossary as GlossaryEntryRecord[]).map((entry) => ({
    id: entry.id,
    term: entry.term,
    definition: entry.definition,
    synonyms: entry.synonyms,
    status: entry.status,
    createdAt: entry.createdAt.toISOString(),
    updatedAt: entry.updatedAt.toISOString(),
    reviewedAt: entry.reviewedAt ? entry.reviewedAt.toISOString() : null,
    author: entry.author,
    updatedBy: entry.updatedBy,
    reviewer: entry.reviewer,
    reviewNotes: entry.reviewNotes ?? null,
  }));

  function parseSources(value: Prisma.JsonValue | null): UncertainChat["topSources"] {
    if (!Array.isArray(value)) {
      return [];
    }
    const sources: UncertainChat["topSources"] = [];
    for (const item of value) {
      if (typeof item !== "object" || item === null) {
        continue;
      }
      const path = "path" in item && typeof item.path === "string" ? item.path : null;
      if (!path) {
        continue;
      }
      sources.push({
        path,
        score: "score" in item && typeof item.score === "number" ? item.score : null,
        page: "page" in item && typeof item.page === "number" ? item.page : null,
        heading: "heading" in item && typeof item.heading === "string" ? item.heading : null,
        chunkId: "chunkId" in item && typeof item.chunkId === "string" ? item.chunkId : null,
      });
    }
    return sources;
  }

  function parseAuditLog(value: Prisma.JsonValue | null): Record<string, unknown>[] {
    if (!Array.isArray(value)) {
      return [];
    }
    const entries: Record<string, unknown>[] = [];
    for (const item of value) {
      if (typeof item === "object" && item !== null && !Array.isArray(item)) {
        entries.push(item as Record<string, unknown>);
      }
    }
    return entries;
  }

  const uncertainChats: UncertainChat[] = chats.map((chat) => ({
    id: chat.id,
    question: chat.question,
    answer: chat.answer ?? null,
    confidence: chat.confidence,
    status: chat.status,
    requestId: chat.requestId ?? null,
    createdAt: chat.createdAt.toISOString(),
    topSources: parseSources(chat.topSources),
    author: chat.author,
    reviewer: chat.reviewer,
    tickets: chat.tickets.map((ticket) => ({
      id: ticket.id,
      key: ticket.key,
      status: ticket.status,
      assignee: ticket.assignee,
      lastActivity: ticket.lastActivity ? ticket.lastActivity.toISOString() : null,
    })),
    followUpPrompt: chat.followUpPrompt ?? null,
    auditLog: parseAuditLog(chat.auditLog),
  }));

  const ticketSummaries: TicketSummary[] = tickets.map((ticket) => ({
    id: ticket.id,
    key: ticket.key,
    status: ticket.status,
    assignee: ticket.assignee,
    lastActivity: ticket.lastActivity ? ticket.lastActivity.toISOString() : null,
    summary: ticket.summary ?? null,
  }));

  return (
    <div className="mx-auto flex w-full max-w-6xl flex-col gap-10">
      <PageHeader
        eyebrow="Admin"
        title="Operations console"
        description="Review low-confidence chats, manage ticket escalations, and curate glossary terminology."
      />
      <AdminOpsConsole
        role={user.role}
        uncertain={uncertainChats}
        tickets={ticketSummaries}
        glossaryEntries={glossaryEntries}
      />
    </div>
  );
}

```

## `app/api/admin/content/entry/route.ts`

```typescript
import { NextResponse } from "next/server";
import { deleteEntry } from "@/lib/content-manager";

type Payload = {
  path?: string;
};

export async function DELETE(request: Request) {
  const body = (await request.json().catch(() => ({}))) as Payload;
  if (!body.path) {
    return NextResponse.json({ error: "Path is required." }, { status: 400 });
  }
  try {
    await deleteEntry(body.path);
    return NextResponse.json({ ok: true });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Unable to delete entry.";
    return NextResponse.json({ error: message }, { status: 400 });
  }
}

```

## `app/api/admin/content/folder/route.ts`

```typescript
import { NextResponse } from "next/server";
import { ensureFolder } from "@/lib/content-manager";

type Payload = {
  parentPath?: string;
  folderName?: string;
};

export async function POST(request: Request) {
  const body = (await request.json().catch(() => ({}))) as Payload;
  if (!body.folderName) {
    return NextResponse.json({ error: "Folder name is required." }, { status: 400 });
  }
  try {
    const storedPath = await ensureFolder(body.parentPath, body.folderName);
    return NextResponse.json({ path: storedPath });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Unable to create folder.";
    return NextResponse.json({ error: message }, { status: 400 });
  }
}

```

## `app/api/admin/content/list/route.ts`

```typescript
import type { NextRequest } from "next/server";
import { NextResponse } from "next/server";
import { listContent } from "@/lib/content-manager";

export async function GET(request: NextRequest) {
  const relativePath = request.nextUrl.searchParams.get("path") ?? ".";
  try {
    const entries = await listContent(relativePath);
    return NextResponse.json({ entries });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Unable to list content.";
    return NextResponse.json({ error: message }, { status: 400 });
  }
}

```

## `app/api/admin/content/reingest/route.ts`

```typescript
import { NextResponse } from "next/server";
import { spawn } from "node:child_process";
import path from "node:path";
import { logContentAction } from "@/lib/content-manager";

function runIngestion(): Promise<{ logs: string[]; code: number }> {
  return new Promise((resolve, reject) => {
    const logs: string[] = [];
    const processEnv = { ...process.env };
    const scriptPath = path.resolve(process.cwd(), "scripts", "ingest_cli.py");
    const proc = spawn("python", [scriptPath], {
      cwd: process.cwd(),
      env: processEnv,
    });

    proc.stdout.on("data", (chunk) => {
      logs.push(chunk.toString());
    });

    proc.stderr.on("data", (chunk) => {
      logs.push(`[stderr] ${chunk.toString()}`);
    });

    proc.on("error", (error) => {
      reject(error);
    });

    proc.on("close", (code) => {
      resolve({ logs, code: code ?? -1 });
    });
  });
}

function extractDocumentCount(logs: string[]): number | null {
  const joined = logs.join("\n");
  const match = joined.match(/Indexed\s+(\d+)\s+documents?/i);
  if (match && match[1]) {
    return Number.parseInt(match[1], 10);
  }
  return null;
}

export async function POST() {
  try {
    const { logs, code } = await runIngestion();
    const documents = extractDocumentCount(logs);
    await logContentAction("reingest", ".", `exit=${code}${documents != null ? ` docs=${documents}` : ""}`);

    if (code !== 0) {
      return NextResponse.json(
        { error: "Ingestion failed", logs, exitCode: code },
        { status: 500 }
      );
    }

    return NextResponse.json({
      ok: true,
      logs,
      exitCode: code,
      documents,
    });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Ingestion process failed.";
    await logContentAction("reingest", ".", `error=${message}`);
    return NextResponse.json({ error: message }, { status: 500 });
  }
}

```

## `app/api/admin/content/upload/route.ts`

```typescript
import type { NextRequest } from "next/server";
import { NextResponse } from "next/server";
import { saveFile } from "@/lib/content-manager";

export async function POST(request: NextRequest) {
  const formData = await request.formData();
  const targetPath = typeof formData.get("path") === "string" ? (formData.get("path") as string) : ".";
  const file = formData.get("file");
  if (!(file instanceof File)) {
    return NextResponse.json({ error: "Missing file upload." }, { status: 400 });
  }

  const buffer = Buffer.from(await file.arrayBuffer());
  try {
    const storedPath = await saveFile(targetPath, file.name, buffer);
    return NextResponse.json({ path: storedPath, size: buffer.length });
  } catch (error) {
    const message = error instanceof Error ? error.message : "Unable to save file.";
    return NextResponse.json({ error: message }, { status: 400 });
  }
}

```

## `app/api/admin/uncertain/[id]/approve/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Prisma, Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function canApprove(role: Role | undefined): boolean {
  return role === Role.ADMIN || role === Role.REVIEWER;
}

type ApproveBody = {
  notes?: string;
  answer?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const { user } = getRequestContext();
  if (!canApprove(user.role)) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const { id } = params;
  let body: ApproveBody = {};
  try {
    body = (await request.json()) as ApproveBody;
  } catch (error) {
    body = {};
  }
  const notes = typeof body.notes === "string" ? body.notes.trim() : undefined;
  const editedAnswer = typeof body.answer === "string" ? body.answer.trim() : undefined;
  const eventTimestamp = new Date().toISOString();

  try {
    const result = await withRlsContext(user, async (tx) => {
      const existing = await tx.chat.findUnique({
        where: { id },
        select: { auditLog: true, status: true, orgId: true, requestId: true },
      });
      if (!existing) {
        return null;
      }
      if (existing.status !== "pending_review" && existing.status !== "draft") {
        return "not_pending" as const;
      }

      const auditLog: Prisma.JsonArray = Array.isArray(existing.auditLog)
        ? [...(existing.auditLog as Prisma.JsonArray)]
        : [];
      const logEntry: Prisma.JsonObject = {
        action: "approve",
        actorId: user.id,
        actorRole: user.role,
        at: eventTimestamp,
        notes: notes ?? null,
      };
      if (editedAnswer !== undefined) {
        logEntry.answerUpdated = editedAnswer.length > 0;
      }
      auditLog.push(logEntry);

      const updateData: Prisma.ChatUncheckedUpdateInput = {
        status: "reviewed",
        reviewedAt: new Date(eventTimestamp),
        reviewedById: user.id,
        auditLog,
      };

      if (editedAnswer !== undefined) {
        updateData.answer = editedAnswer;
      }

      const updated = await tx.chat.update({
        where: { id },
        data: updateData,
        select: {
          id: true,
          status: true,
          reviewedAt: true,
          reviewer: { select: { id: true, email: true, name: true } },
          auditLog: true,
          orgId: true,
          requestId: true,
        },
      });

      await tx.ragEvent.create({
        data: {
          orgId: existing.orgId,
          actorId: user.id,
          actorRole: user.role,
          action: "chat.approved",
          entity: "chat",
          chatId: updated.id,
          requestId: updated.requestId,
          after: {
            status: updated.status,
            reviewedAt: updated.reviewedAt?.toISOString() ?? null,
          },
        },
      });

      return updated;
    });

    if (result === null) {
      return NextResponse.json({ error: "not_found" }, { status: 404 });
    }
    if (result === "not_pending") {
      return NextResponse.json({ error: "invalid_status" }, { status: 409 });
    }

    return NextResponse.json({
      id: result.id,
      status: result.status,
      reviewedAt: result.reviewedAt?.toISOString() ?? null,
      reviewer: result.reviewer,
      auditLog: result.auditLog ?? [],
    });
  } catch (error) {
    return NextResponse.json({ error: "server_error" }, { status: 500 });
  }
}

```

## `app/api/admin/uncertain/[id]/ask-followup/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function canRecordFollowUp(role: Role | undefined): boolean {
  return role === Role.ADMIN || role === Role.REVIEWER;
}

type FollowUpBody = {
  prompt?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const { user } = getRequestContext();
  if (!canRecordFollowUp(user.role)) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const { id } = params;
  let body: FollowUpBody;
  try {
    body = (await request.json()) as FollowUpBody;
  } catch (error) {
    body = {};
  }

  const prompt = typeof body.prompt === "string" ? body.prompt.trim() : "";
  if (!prompt) {
    return NextResponse.json(
      { error: "invalid_request", detail: "Follow-up prompt is required." },
      { status: 400 }
    );
  }

  const timestamp = new Date().toISOString();

  const result = await withRlsContext(user, async (tx) => {
    const existing = await tx.chat.findUnique({
      where: { id },
      select: { id: true, status: true, auditLog: true, orgId: true },
    });
    if (!existing) {
      return null;
    }

    const auditLog = Array.isArray(existing.auditLog) ? [...existing.auditLog] : [];
    auditLog.push({
      action: "followup",
      at: timestamp,
      actorId: user.id,
      actorRole: user.role,
      prompt,
    });

    const updated = await tx.chat.update({
      where: { id },
      data: { followUpPrompt: prompt, auditLog },
      select: {
        id: true,
        followUpPrompt: true,
        auditLog: true,
        status: true,
        requestId: true,
      },
    });

    await tx.ragEvent.create({
      data: {
        orgId: existing.orgId,
        actorId: user.id,
        actorRole: user.role,
        action: "chat.followup_recorded",
        entity: "chat",
        chatId: updated.id,
        requestId: updated.requestId,
        after: {
          status: updated.status,
          followUpPrompt: updated.followUpPrompt,
        },
      },
    });

    return updated;
  });

  if (result === null) {
    return NextResponse.json({ error: "not_found" }, { status: 404 });
  }

  return NextResponse.json({
    id: result.id,
    followUpPrompt: result.followUpPrompt,
    auditLog: result.auditLog ?? [],
  });
}

```

## `app/api/admin/uncertain/[id]/escalate/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function generateTicketKey(now: Date): string {
  const year = now.getUTCFullYear();
  const month = String(now.getUTCMonth() + 1).padStart(2, "0");
  const day = String(now.getUTCDate()).padStart(2, "0");
  const suffix = now.getUTCHours().toString().padStart(2, "0") + now.getUTCMinutes().toString().padStart(2, "0");
  return `AE-${year}${month}${day}-${suffix}`;
}

type EscalateBody = {
  summary?: string;
  assignee?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const { user } = getRequestContext();
  if (user.role !== Role.ADMIN) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const { id } = params;
  let body: EscalateBody = {};
  try {
    body = (await request.json()) as EscalateBody;
  } catch (error) {
    body = {};
  }
  const now = new Date();
  const nowIso = now.toISOString();
  const summary = typeof body.summary === "string" && body.summary.trim().length > 0 ? body.summary.trim() : undefined;
  const assignee = typeof body.assignee === "string" && body.assignee.trim().length > 0 ? body.assignee.trim() : undefined;

  const result = await withRlsContext(user, async (tx) => {
    const chat = await tx.chat.findUnique({
      where: { id },
      select: {
        id: true,
        orgId: true,
        status: true,
        question: true,
        requestId: true,
        auditLog: true,
      },
    });
    if (!chat) {
      return null;
    }
    if (chat.status === "escalated") {
      return "already_escalated" as const;
    }

    const auditLog = Array.isArray(chat.auditLog) ? [...chat.auditLog] : [];
    auditLog.push({
      action: "escalate",
      actorId: user.id,
      actorRole: user.role,
      at: nowIso,
      assignee: assignee ?? null,
      summary: summary ?? chat.question,
    });

    const ticket = await tx.ticket.create({
      data: {
        orgId: chat.orgId,
        key: generateTicketKey(now),
        status: "open",
        assignee: assignee ?? null,
        lastActivity: now,
        summary: summary ?? chat.question,
        chatId: chat.id,
        auditLog: [
          {
            action: "created",
            actorId: user.id,
            actorRole: user.role,
            at: nowIso,
          },
        ],
      },
      select: {
        id: true,
        key: true,
        status: true,
        assignee: true,
        lastActivity: true,
        summary: true,
      },
    });

    await tx.chat.update({
      where: { id: chat.id },
      data: {
        status: "escalated",
        auditLog,
      },
    });

    await tx.ragEvent.create({
      data: {
        orgId: chat.orgId,
        actorId: user.id,
        actorRole: user.role,
        action: "chat.escalated",
        entity: "chat",
        chatId: chat.id,
        requestId: chat.requestId,
        after: {
          status: "escalated",
          ticketId: ticket.id,
          assignee: ticket.assignee ?? null,
        },
      },
    });

    return ticket;
  });

  if (result === null) {
    return NextResponse.json({ error: "not_found" }, { status: 404 });
  }
  if (result === "already_escalated") {
    return NextResponse.json({ error: "invalid_status" }, { status: 409 });
  }

  return NextResponse.json({
    id: result.id,
    key: result.key,
    status: result.status,
    assignee: result.assignee,
    lastActivity: result.lastActivity ? result.lastActivity.toISOString() : null,
    summary: result.summary ?? summary ?? null,
  });
}

```

## `app/api/admin/uncertain/[id]/reject/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function canReject(role: Role | undefined): boolean {
  return role === Role.ADMIN || role === Role.REVIEWER;
}

type RejectBody = {
  notes?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const { user } = getRequestContext();
  if (!canReject(user.role)) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const { id } = params;
  let body: RejectBody = {};
  try {
    body = (await request.json()) as RejectBody;
  } catch {
    body = {};
  }

  const notes = typeof body.notes === "string" ? body.notes.trim() : undefined;
  const eventTimestamp = new Date().toISOString();

  try {
    const result = await withRlsContext(user, async (tx) => {
      const existing = await tx.chat.findUnique({
        where: { id },
        select: { auditLog: true, status: true, orgId: true, requestId: true },
      });
      if (!existing) {
        return null;
      }
      if (existing.status !== "pending_review" && existing.status !== "draft") {
        return "not_reviewable" as const;
      }

      const auditLog = Array.isArray(existing.auditLog) ? [...existing.auditLog] : [];
      auditLog.push({
        action: "reject",
        actorId: user.id,
        actorRole: user.role,
        at: eventTimestamp,
        notes: notes ?? null,
      });

      const updated = await tx.chat.update({
        where: { id },
        data: {
          status: "rejected",
          auditLog,
        },
        select: {
          id: true,
          status: true,
          orgId: true,
          requestId: true,
          auditLog: true,
        },
      });

      await tx.ragEvent.create({
        data: {
          orgId: existing.orgId,
          actorId: user.id,
          actorRole: user.role,
          action: "chat.rejected",
          entity: "chat",
          chatId: updated.id,
          requestId: updated.requestId,
          after: {
            status: updated.status,
          },
        },
      });

      return updated;
    });

    if (result === null) {
      return NextResponse.json({ error: "not_found" }, { status: 404 });
    }
    if (result === "not_reviewable") {
      return NextResponse.json({ error: "invalid_status" }, { status: 409 });
    }

    return NextResponse.json({
      id: result.id,
      status: result.status,
      auditLog: result.auditLog ?? [],
    });
  } catch {
    return NextResponse.json({ error: "server_error" }, { status: 500 });
  }
}

```

## `app/api/admin/uncertain/[id]/save-draft/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function canSaveDraft(role: Role | undefined): boolean {
  return role === Role.ADMIN || role === Role.REVIEWER;
}

type DraftBody = {
  answer?: string;
  notes?: string;
};

export async function POST(request: Request, { params }: { params: { id: string } }) {
  const { user } = getRequestContext();
  if (!canSaveDraft(user.role)) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const { id } = params;
  let body: DraftBody = {};
  try {
    body = (await request.json()) as DraftBody;
  } catch {
    body = {};
  }

  const answer = typeof body.answer === "string" ? body.answer.trim() : "";
  if (!answer) {
    return NextResponse.json({ error: "invalid_request", detail: "Answer draft cannot be empty." }, { status: 400 });
  }
  const notes = typeof body.notes === "string" ? body.notes.trim() : undefined;
  const eventTimestamp = new Date().toISOString();

  try {
    const result = await withRlsContext(user, async (tx) => {
      const existing = await tx.chat.findUnique({
        where: { id },
        select: { auditLog: true, status: true, orgId: true, requestId: true },
      });
      if (!existing) {
        return null;
      }
      if (existing.status !== "pending_review" && existing.status !== "draft") {
        return "not_reviewable" as const;
      }

      const auditLog = Array.isArray(existing.auditLog) ? [...existing.auditLog] : [];
      auditLog.push({
        action: "save_draft",
        actorId: user.id,
        actorRole: user.role,
        at: eventTimestamp,
        notes: notes ?? null,
      });

      const updated = await tx.chat.update({
        where: { id },
        data: {
          status: "draft",
          answer,
          auditLog,
        },
        select: {
          id: true,
          status: true,
          answer: true,
          orgId: true,
          requestId: true,
          auditLog: true,
        },
      });

      await tx.ragEvent.create({
        data: {
          orgId: existing.orgId,
          actorId: user.id,
          actorRole: user.role,
          action: "chat.draft_saved",
          entity: "chat",
          chatId: updated.id,
          requestId: updated.requestId,
          after: {
            status: updated.status,
          },
        },
      });

      return updated;
    });

    if (result === null) {
      return NextResponse.json({ error: "not_found" }, { status: 404 });
    }
    if (result === "not_reviewable") {
      return NextResponse.json({ error: "invalid_status" }, { status: 409 });
    }

    return NextResponse.json({
      id: result.id,
      status: result.status,
      answer: result.answer,
      auditLog: result.auditLog ?? [],
    });
  } catch {
    return NextResponse.json({ error: "server_error" }, { status: 500 });
  }
}

```

## `app/api/admin/uncertain/route.ts`

```typescript
import { NextResponse } from "next/server";
import { Prisma, Role } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { getRequestContext } from "@/lib/request-context";

function canReview(role: Role | undefined): boolean {
  return role === Role.ADMIN || role === Role.REVIEWER;
}

const reviewableStatuses: string[] = ["pending_review", "draft", "rejected"];
type ReviewableChat = Prisma.ChatGetPayload<{
  include: {
    author: { select: { id: true; email: true; name: true } };
    reviewer: { select: { id: true; email: true; name: true } };
    tickets: { select: { id: true; key: true; status: true; assignee: true; lastActivity: true } };
  };
}>;

export async function GET() {
  const { user } = getRequestContext();
  if (!canReview(user.role)) {
    return NextResponse.json({ error: "forbidden" }, { status: 403 });
  }

  const chats = await withRlsContext<ReviewableChat[]>(user, (tx) =>
    tx.chat.findMany({
      where: { status: { in: reviewableStatuses } },
      include: {
        author: { select: { id: true, email: true, name: true } },
        reviewer: { select: { id: true, email: true, name: true } },
        tickets: {
          select: {
            id: true,
            key: true,
            status: true,
            assignee: true,
            lastActivity: true,
          },
        },
      },
      orderBy: { createdAt: "desc" },
    })
  );

  const payload = chats.map((chat) => ({
    id: chat.id,
    question: chat.question,
    answer: chat.answer ?? null,
    confidence: chat.confidence,
    status: chat.status,
    createdAt: chat.createdAt.toISOString(),
    requestId: chat.requestId,
    topSources: normalizeSources(chat.topSources),
    author: chat.author,
    reviewer: chat.reviewer,
    tickets: chat.tickets.map((ticket) => ({
      id: ticket.id,
      key: ticket.key,
      status: ticket.status,
      assignee: ticket.assignee,
      lastActivity: ticket.lastActivity ? ticket.lastActivity.toISOString() : null,
    })),
    followUpPrompt: chat.followUpPrompt ?? null,
    auditLog: Array.isArray(chat.auditLog) ? chat.auditLog : [],
  }));

  return NextResponse.json(payload);
}

function normalizeSources(value: Prisma.JsonValue | null): Array<Record<string, unknown>> {
  if (!Array.isArray(value)) {
    return [];
  }
  const normalized: Array<Record<string, unknown>> = [];
  for (const item of value) {
    if (typeof item !== "object" || item === null) {
      continue;
    }
    const path = "path" in item && typeof item.path === "string" ? item.path : null;
    if (!path) {
      continue;
    }
    normalized.push({
      path,
      score: "score" in item && typeof item.score === "number" ? item.score : null,
      page: "page" in item && typeof item.page === "number" ? item.page : null,
      heading: "heading" in item && typeof item.heading === "string" ? item.heading : null,
      chunkId: "chunkId" in item && typeof item.chunkId === "string" ? item.chunkId : null,
    });
  }
  return normalized;
}

```

## `app/api/ask/route.ts`

```typescript
import { randomUUID } from "node:crypto";
import { NextResponse } from "next/server";
import { askRequestSchema, askResponseSchema } from "@/lib/ask-contract";
import type { AskRequest } from "@/lib/ask-contract";
import { captureLowConfidenceChat } from "@/lib/chat-capture";
import { getRequestUser } from "@/lib/request-context";

const encoder = new TextEncoder();
const decoder = new TextDecoder();

function getServiceUrl() {
  const raw = process.env.RAG_SERVICE_URL ?? process.env.ASK_SERVICE_URL ?? "http://localhost:8000";
  return raw.replace(/\/$/, "");
}

function normalizeFields(value: unknown): Record<string, string> | undefined {
  if (!value || typeof value !== "object") {
    return undefined;
  }
  const result: Record<string, string> = {};
  for (const [key, raw] of Object.entries(value)) {
    result[String(key)] = typeof raw === "string" ? raw : JSON.stringify(raw);
  }
  return Object.keys(result).length ? result : undefined;
}

function buildErrorResponse(
  status: number,
  requestId: string,
  error: string,
  detail: string,
  fields?: Record<string, string>
) {
  const payload: Record<string, unknown> = {
    error,
    detail,
    request_id: requestId,
  };
  if (fields) {
    payload.fields = fields;
  }
  return NextResponse.json(payload, {
    status,
    headers: {
      "X-Request-ID": requestId,
    },
  });
}

async function readErrorBody(response: Response, fallbackRequestId: string) {
  const contentType = response.headers.get("content-type") ?? "";
  let parsedBody: unknown = null;
  if (contentType.includes("application/json")) {
    try {
      parsedBody = await response.json();
    } catch (error) {
      return {
        status: response.status === 0 ? 502 : response.status,
        error: "upstream_error",
        detail: "Failed to parse upstream JSON response.",
        requestId: fallbackRequestId,
      } as const;
    }
  } else {
    const text = await response.text();
    parsedBody = text;
  }

  const status = response.status === 0 ? 502 : response.status;
  if (parsedBody && typeof parsedBody === "object" && !Array.isArray(parsedBody)) {
    const body = parsedBody as Record<string, unknown>;
    const requestId = typeof body.request_id === "string" ? body.request_id : fallbackRequestId;
    const error = typeof body.error === "string" ? body.error : "upstream_error";
    const detail = typeof body.detail === "string" ? body.detail : "Unknown upstream error.";
    const fields = normalizeFields(body.fields);
    return { status, error, detail, fields, requestId } as const;
  }

  const detail = typeof parsedBody === "string" && parsedBody.length ? parsedBody : "Unknown upstream error.";
  return { status, error: "upstream_error", detail, requestId: fallbackRequestId } as const;
}

export async function POST(request: Request) {
  const acceptsSse = (request.headers.get("accept") ?? "").includes("text/event-stream");
  const requestId = request.headers.get("x-request-id") ?? randomUUID();

  let parsed: AskRequest;
  try {
    const payload = await request.json();
    parsed = askRequestSchema.parse(payload);
  } catch (error) {
    const detail = error instanceof Error ? error.message : "Invalid request payload";
    return buildErrorResponse(400, requestId, "validation_error", detail);
  }

  const requestUser = getRequestUser();

  let upstream: Response;
  try {
    upstream = await fetch(`${getServiceUrl()}/ask`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Accept: acceptsSse ? "text/event-stream" : "application/json",
        "X-Request-ID": requestId,
      },
      body: JSON.stringify({
        question: parsed.question,
        filters: parsed.filters ?? undefined,
        contextHints: parsed.contextHints ?? undefined,
        topK: parsed.topK ?? undefined,
        models: parsed.models ?? undefined,
      }),
    });
  } catch (error) {
    const detail = error instanceof Error ? error.message : "Failed to contact retrieval service.";
    return buildErrorResponse(502, requestId, "upstream_unreachable", detail);
  }

  const upstreamRequestId = upstream.headers.get("x-request-id") ?? requestId;

  if (!upstream.ok) {
    const normalized = await readErrorBody(upstream, upstreamRequestId);
    return buildErrorResponse(normalized.status, normalized.requestId, normalized.error, normalized.detail, normalized.fields);
  }

  const contentType = upstream.headers.get("content-type") ?? "";

  if (acceptsSse && contentType.includes("text/event-stream") && upstream.body) {
    const reader = upstream.body.getReader();
    let buffer = "";
    let capturePromise: Promise<void> | null = null;
    const stream = new ReadableStream<Uint8Array>({
      start(controller) {
        controller.enqueue(
          encoder.encode(`event: start\ndata: ${JSON.stringify({ request_id: upstreamRequestId })}\n\n`)
        );
      },
      async pull(controller) {
        const { done, value } = await reader.read();
        if (done) {
          if (capturePromise) {
            await capturePromise.catch(() => undefined);
          }
          controller.enqueue(
            encoder.encode(`event: end\ndata: ${JSON.stringify({ request_id: upstreamRequestId })}\n\n`)
          );
          controller.close();
          return;
        }
        if (value) {
          controller.enqueue(value);
          buffer += decoder.decode(value, { stream: true });
          let boundary = buffer.indexOf("\n\n");
          while (boundary !== -1) {
            const rawEvent = buffer.slice(0, boundary);
            buffer = buffer.slice(boundary + 2);
            boundary = buffer.indexOf("\n\n");

            let eventType = "";
            let dataPayload = "";
            for (const rawLine of rawEvent.split("\n")) {
              const line = rawLine.trim();
              if (!line) {
                continue;
              }
              if (line.startsWith("event:")) {
                eventType = line.slice(6).trim();
              } else if (line.startsWith("data:")) {
                const fragment = line.slice(5).trim();
                dataPayload = dataPayload ? `${dataPayload}${fragment}` : fragment;
              }
            }

            if (eventType === "answer" && dataPayload && !capturePromise) {
              try {
                const parsedAnswer = askResponseSchema.parse(JSON.parse(dataPayload));
                capturePromise = captureLowConfidenceChat({
                  question: parsed.question,
                  response: parsedAnswer,
                  user: requestUser,
                });
              } catch (error) {
                // Ignore malformed payloads; the client will handle upstream data.
              }
            }
          }
        }
      },
      cancel(reason) {
        reader.cancel(reason).catch(() => undefined);
      },
    });

    return new Response(stream, {
      status: 200,
      headers: {
        "Content-Type": "text/event-stream; charset=utf-8",
        "Cache-Control": "no-cache, no-transform",
        Connection: "keep-alive",
        "X-Request-ID": upstreamRequestId,
      },
    });
  }

  let askResponse;
  try {
    const raw = await upstream.json();
    askResponse = askResponseSchema.parse(raw);
  } catch (error) {
    const detail = error instanceof Error ? error.message : "Invalid upstream response";
    return buildErrorResponse(502, upstreamRequestId, "invalid_upstream_response", detail);
  }

  await captureLowConfidenceChat({ question: parsed.question, response: askResponse, user: requestUser });

  if (acceptsSse) {
    const stream = new ReadableStream<Uint8Array>({
      start(controller) {
        controller.enqueue(
          encoder.encode(`event: start\ndata: ${JSON.stringify({ request_id: askResponse.request_id })}\n\n`)
        );
        controller.enqueue(
          encoder.encode(`event: answer\ndata: ${JSON.stringify(askResponse)}\n\n`)
        );
        controller.enqueue(
          encoder.encode(`event: end\ndata: ${JSON.stringify({ request_id: askResponse.request_id })}\n\n`)
        );
        controller.close();
      },
    });

    return new Response(stream, {
      status: 200,
      headers: {
        "Content-Type": "text/event-stream; charset=utf-8",
        "Cache-Control": "no-cache, no-transform",
        Connection: "keep-alive",
        "X-Request-ID": askResponse.request_id,
      },
    });
  }

  return NextResponse.json(askResponse, {
    status: 200,
    headers: {
      "X-Request-ID": askResponse.request_id,
    },
  });
}

```

## `app/api/glossary/[id]/route.ts`

```typescript
import { NextResponse } from "next/server";
import { GlossaryStatus, Prisma } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { canEditGlossary } from "@/lib/rbac";
import {
  parseStatus,
  parseSynonyms,
  serializeEntry,
  handleGlossaryError,
  snapshotEntry,
} from "@/app/api/glossary/utils";
import { getRequestContext } from "@/lib/request-context";

const relationSelect = {
  author: { select: { id: true, email: true, name: true } },
  updatedBy: { select: { id: true, email: true, name: true } },
  reviewer: { select: { id: true, email: true, name: true } },
} as const;

export async function PUT(request: Request, { params }: { params: { id: string } }) {
  try {
    const { user } = getRequestContext();
    const editor = canEditGlossary(user);
    const payload = await request.json();
    const definition = typeof payload.definition === "string" ? payload.definition.trim() : "";
    if (!definition) {
      return NextResponse.json(
        { error: "invalid_request", detail: "Definition is required." },
        { status: 400 }
      );
    }
    const term = typeof payload.term === "string" && payload.term.trim().length > 0 ? payload.term.trim() : undefined;
    const synonyms = parseSynonyms(payload.synonyms);
    const status = parseStatus(payload.status);
    const reviewNotes =
      typeof payload.reviewNotes === "string"
        ? payload.reviewNotes.trim() || null
        : payload.reviewNotes === null
        ? null
        : undefined;

    const entry = await withRlsContext(editor, async (tx) => {
      const existing = await tx.glossaryEntry.findUnique({
        where: { id: params.id },
        include: relationSelect,
      });
      if (!existing) {
        return null;
      }

      const before = snapshotEntry(existing);
      const data: Record<string, unknown> = {
        definition,
        synonyms,
        status,
        updatedById: editor.id,
      };
      if (term) {
        data.term = term;
      }
      if (reviewNotes !== undefined) {
        data.reviewNotes = reviewNotes;
      }
      if (status === GlossaryStatus.PENDING) {
        data.reviewedAt = null;
        data.reviewerId = null;
      } else {
        data.reviewedAt = new Date();
        data.reviewerId = editor.id;
      }

      const updated = await tx.glossaryEntry.update({
        where: { id: params.id },
        data,
        include: relationSelect,
      } as any);

      await tx.ragEvent.create({
        data: {
          orgId: editor.orgId,
          actorId: editor.id,
          actorRole: editor.role,
          action: "glossary.updated",
          entity: "glossary",
          glossaryId: updated.id,
          before,
          after: snapshotEntry(updated),
        },
      });

      return updated;
    });

    if (!entry) {
      return NextResponse.json({ error: "not_found" }, { status: 404 });
    }

    return NextResponse.json(serializeEntry(entry));
  } catch (error) {
    return handleGlossaryError(error);
  }
}

export async function PATCH(request: Request, ctx: { params: { id: string } }) {
  return PUT(request, ctx);
}

export async function DELETE(_: Request, { params }: { params: { id: string } }) {
  try {
    const { user } = getRequestContext();
    const editor = canEditGlossary(user);
    const result = await withRlsContext(editor, async (tx) => {
      const existing = await tx.glossaryEntry.findUnique({ where: { id: params.id } });
      if (!existing) {
        return null;
      }
      await tx.glossaryEntry.delete({ where: { id: params.id } });
      await tx.ragEvent.create({
        data: {
          orgId: editor.orgId,
          actorId: editor.id,
          actorRole: editor.role,
          action: "glossary.deleted",
          entity: "glossary",
          glossaryId: existing.id,
          before: snapshotEntry(existing),
          after: Prisma.JsonNull,
        },
      });
      return true;
    });
    if (result === null) {
      return NextResponse.json({ error: "not_found" }, { status: 404 });
    }
    return NextResponse.json({ status: "ok" });
  } catch (error) {
    return handleGlossaryError(error);
  }
}

```

## `app/api/glossary/route.ts`

```typescript
import { NextResponse } from "next/server";
import { GlossaryStatus, Prisma } from "@prisma/client";
import { withRlsContext } from "@/lib/rls";
import { canEditGlossary, canReviewGlossary } from "@/lib/rbac";
import {
  handleGlossaryError,
  parseStatus,
  parseSynonyms,
  serializeEntry,
  snapshotEntry,
} from "@/app/api/glossary/utils";
import { getRequestContext } from "@/lib/request-context";

const relationSelect = {
  author: { select: { id: true, email: true, name: true } },
  updatedBy: { select: { id: true, email: true, name: true } },
  reviewer: { select: { id: true, email: true, name: true } },
} as const;

export async function GET() {
  try {
    const { user } = getRequestContext();
    const reviewer = canReviewGlossary(user);
    const entries = (await withRlsContext(reviewer, (tx) =>
      tx.glossaryEntry.findMany({
        orderBy: { term: "asc" },
        include: {
          author: { select: { id: true, email: true, name: true } },
          updatedBy: { select: { id: true, email: true, name: true } },
          reviewer: { select: { id: true, email: true, name: true } },
        },
      } as any)
    )) as unknown[];
    return NextResponse.json(entries.map(serializeEntry));
  } catch (error) {
    return handleGlossaryError(error);
  }
}

export async function POST(request: Request) {
  try {
    const { user } = getRequestContext();
    const editor = canEditGlossary(user);
    const payload = await request.json();
    const term = typeof payload.term === "string" ? payload.term.trim() : "";
    const definition = typeof payload.definition === "string" ? payload.definition.trim() : "";
    const synonyms = parseSynonyms(payload.synonyms);
    if (!term || !definition) {
      return NextResponse.json(
        { error: "invalid_request", detail: "Both term and definition are required." },
        { status: 400 }
      );
    }

    const status = parseStatus(payload.status);
    const reviewNotes =
      typeof payload.reviewNotes === "string"
        ? payload.reviewNotes.trim() || null
        : payload.reviewNotes === null
        ? null
        : undefined;

    const result = await withRlsContext(editor, async (tx) => {
      const existing = await tx.glossaryEntry.findFirst({
        where: { orgId: editor.orgId, term },
      });

      const data: Record<string, unknown> = {
        definition,
        synonyms,
        status,
        updatedById: editor.id,
      };
      if (reviewNotes !== undefined) {
        data.reviewNotes = reviewNotes;
      }
      if (status === GlossaryStatus.PENDING) {
        data.reviewedAt = null;
        data.reviewerId = null;
      } else {
        data.reviewedAt = new Date();
        data.reviewerId = editor.id;
      }

      const entry = await tx.glossaryEntry.upsert({
        where: { orgId_term: { orgId: editor.orgId, term } },
        create: {
          term,
          definition,
          synonyms,
          status,
          orgId: editor.orgId,
          authorId: editor.id,
          updatedById: editor.id,
          reviewNotes: reviewNotes ?? null,
          reviewedAt: status === GlossaryStatus.PENDING ? null : new Date(),
          reviewerId: status === GlossaryStatus.PENDING ? null : editor.id,
        },
        update: data,
        include: relationSelect,
      } as any);

      await tx.ragEvent.create({
        data: {
          orgId: editor.orgId,
          actorId: editor.id,
          actorRole: editor.role,
          action: existing ? "glossary.updated" : "glossary.created",
          entity: "glossary",
          glossaryId: entry.id,
          before: existing ? snapshotEntry(existing) : Prisma.JsonNull,
          after: snapshotEntry(entry),
        },
      });

      return { entry, created: !existing };
    });

    return NextResponse.json(serializeEntry(result.entry), { status: result.created ? 201 : 200 });
  } catch (error) {
    return handleGlossaryError(error);
  }
}

```

## `app/api/glossary/utils.ts`

```typescript
import { randomUUID } from "node:crypto";
import { NextResponse } from "next/server";
import { GlossaryStatus, Prisma } from "@prisma/client";
import { ForbiddenError, UnauthorizedError } from "@/lib/rbac";

function buildError(
  status: number,
  error: string,
  detail: string,
  fields?: Record<string, string>
) {
  const requestId = randomUUID();
  const payload: Record<string, unknown> = {
    error,
    detail,
    request_id: requestId,
  };
  if (fields) {
    payload.fields = fields;
  }
  const response = NextResponse.json(payload, { status });
  response.headers.set("X-Request-ID", requestId);
  return response;
}

export function parseStatus(value: unknown): GlossaryStatus {
  if (value === undefined || value === null || value === "") {
    return GlossaryStatus.PENDING;
  }
  if (typeof value !== "string") {
    throw new Error("Invalid status type");
  }
  const upper = value.toUpperCase();
  if (!(upper in GlossaryStatus)) {
    throw new Error("Unknown glossary status");
  }
  return GlossaryStatus[upper as keyof typeof GlossaryStatus];
}

export function parseSynonyms(value: unknown): string[] {
  if (!value) {
    return [];
  }
  if (Array.isArray(value)) {
    return value
      .map((item) => (typeof item === "string" ? item.trim() : ""))
      .filter((item) => item.length > 0);
  }
  if (typeof value === "string") {
    return value
      .split(",")
      .map((item) => item.trim())
      .filter((item) => item.length > 0);
  }
  throw new Error("Invalid synonyms payload");
}

export function serializeEntry(entry: any) {
  return {
    id: entry.id,
    term: entry.term,
    definition: entry.definition,
    synonyms: Array.isArray(entry.synonyms) ? entry.synonyms : [],
    status: entry.status,
    createdAt: entry.createdAt.toISOString(),
    updatedAt: entry.updatedAt.toISOString(),
    reviewedAt: entry.reviewedAt ? entry.reviewedAt.toISOString() : null,
    author: entry.author
      ? {
          id: entry.author.id,
          email: entry.author.email,
          name: entry.author.name,
        }
      : null,
    updatedBy: entry.updatedBy
      ? {
          id: entry.updatedBy.id,
          email: entry.updatedBy.email,
          name: entry.updatedBy.name,
        }
      : null,
    reviewer: entry.reviewer
      ? {
          id: entry.reviewer.id,
          email: entry.reviewer.email,
          name: entry.reviewer.name,
        }
      : null,
    reviewNotes: entry.reviewNotes ?? null,
  };
}

export function snapshotEntry(entry: any) {
  return {
    term: entry.term,
    definition: entry.definition,
    synonyms: Array.isArray(entry.synonyms) ? entry.synonyms : [],
    status: entry.status,
    reviewNotes: entry.reviewNotes ?? null,
  };
}

export function handleGlossaryError(error: unknown) {
  if (error instanceof UnauthorizedError) {
    return buildError(401, "unauthorized", error.message || "Authentication required.");
  }
  if (error instanceof ForbiddenError) {
    return buildError(403, "forbidden", error.message || "Forbidden");
  }
  if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === "P2002") {
    return buildError(409, "conflict", "Term already exists for this organization.");
  }
  if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === "P2025") {
    return buildError(404, "not_found", "Glossary entry not found.");
  }
  if (error instanceof Error && error.message?.toLowerCase().includes("status")) {
    return buildError(400, "invalid_request", error.message);
  }
  return buildError(500, "internal_error", "An internal error occurred.");
}

```

## `app/apps/page.tsx`

```tsx
import type { Metadata } from "next";
import Link from "next/link";
import { Calendar, FileText, KanbanSquare, Layers } from "lucide-react";
import { PageHeader } from "@/components/page-header";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { Button } from "@/components/ui/button";

const integrations = [
  {
    name: "Prisma ingestion",
    description:
      "Sync product sheets, tables, and field notes from Postgres with deterministic chunking.",
    icon: Layers,
    href: "#prisma",
  },
  {
    name: "Salesforce service cloud",
    description:
      "Escalate chat transcripts to a case queue with the full retrieval trace and request ID.",
    icon: KanbanSquare,
    href: "#salesforce",
  },
  {
    name: "SharePoint content feeds",
    description: "Monitor document libraries for updates and trigger incremental embeddings.",
    icon: FileText,
    href: "#sharepoint",
  },
  {
    name: "Teams meeting sync",
    description: "Push escalations and release notes to your customer success Teams channel.",
    icon: Calendar,
    href: "#teams",
  },
];

export const metadata: Metadata = {
  title: "Apps · Atticus",
};

export default function AppsPage() {
  return (
    <div className="mx-auto flex w-full max-w-6xl flex-col gap-10">
      <PageHeader
        eyebrow="Apps"
        title="Integrate Atticus across your stack"
        description="Connect ingest pipelines, escalation workflows, and downstream analytics in a few clicks."
      />

      <section className="grid gap-6 md:grid-cols-2">
        {integrations.map((integration) => (
          <Card
            key={integration.name}
            className="transition hover:-translate-y-1 hover:shadow-lg dark:hover:shadow-indigo-500/10"
          >
            <CardHeader className="gap-3 pb-0">
              <div className="inline-flex h-11 w-11 items-center justify-center rounded-2xl bg-indigo-600/10 text-indigo-600 dark:bg-indigo-500/20 dark:text-indigo-300">
                <integration.icon className="h-5 w-5" aria-hidden="true" />
              </div>
              <CardTitle>{integration.name}</CardTitle>
              <CardDescription>{integration.description}</CardDescription>
            </CardHeader>
            <CardContent className="pt-4">
              <Button asChild variant="link" className="px-0">
                <Link href={integration.href}>View setup guide</Link>
              </Button>
            </CardContent>
          </Card>
        ))}
      </section>
    </div>
  );
}

```

## `app/contact/page.tsx`

```tsx
import type { Metadata } from "next";
import { MailCheck } from "lucide-react";
import { PageHeader } from "@/components/page-header";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Textarea } from "@/components/ui/textarea";

export const metadata: Metadata = {
  title: "Contact · Atticus",
};

export default function ContactPage() {
  return (
    <div className="mx-auto flex w-full max-w-4xl flex-col gap-10">
      <PageHeader
        eyebrow="Escalations"
        title="Raise an escalation"
        description="Submit production issues or low-confidence answers and the Atticus team will receive the full trace payload."
      />

      <Card>
        <CardHeader className="pb-4">
          <CardTitle>Escalation details</CardTitle>
          <CardDescription>
            Provide enough context for the admin team to reproduce the issue and link it to an existing request.
          </CardDescription>
        </CardHeader>
        <CardContent>
          <form className="space-y-6">
            <div className="grid gap-6 md:grid-cols-2">
              <div className="space-y-2">
                <Label htmlFor="name">Name</Label>
                <Input id="name" name="name" placeholder="Alex Finnegan" required />
              </div>
              <div className="space-y-2">
                <Label htmlFor="email">Work email</Label>
                <Input id="email" name="email" type="email" placeholder="alex@contoso.com" required />
              </div>
            </div>
            <div className="space-y-2">
              <Label htmlFor="summary">Issue summary</Label>
              <Input
                id="summary"
                name="summary"
                placeholder="Low confidence response for Managed Print RFP"
                required
              />
            </div>
            <div className="space-y-2">
              <Label htmlFor="details">Details</Label>
              <Textarea
                id="details"
                name="details"
                rows={5}
                placeholder="Share the question, customer, and any attachments that should be included in the follow-up."
                required
              />
            </div>
            <Button type="submit" className="inline-flex items-center gap-2 rounded-full">
              Submit escalation
              <MailCheck className="h-4 w-4" aria-hidden="true" />
            </Button>
          </form>
        </CardContent>
      </Card>
    </div>
  );
}

```

## `app/layout.tsx`

```tsx
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import type { ReactNode } from "react";
import "./globals.css";
import { SiteHeader } from "@/components/site-header";
import { Providers } from "@/app/providers";

const inter = Inter({ subsets: ["latin"], variable: "--font-inter", display: "swap" });

export const metadata: Metadata = {
  title: "Atticus",
  description: "Grounded AI assistance for Sales teams with enterprise guardrails.",
};

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en" className={inter.variable}>
      <body className="flex min-h-screen flex-col bg-slate-50 font-sans text-slate-900 dark:bg-slate-950 dark:text-slate-100">
        <Providers>
          <SiteHeader />
          <main className="flex-1 overflow-hidden">{children}</main>
        </Providers>
      </body>
    </html>
  );
}

```

## `app/page.tsx`

```tsx
import { ChatWorkspace } from "@/components/chat/chat-workspace";

export default function HomePage() {
  return <ChatWorkspace />;
}

```

## `app/providers.tsx`

```tsx
"use client";

import type { ReactNode } from "react";

interface ProvidersProps {
  children: ReactNode;
}

export function Providers({ children }: ProvidersProps) {
  return <>{children}</>;
}

```

## `app/settings/page.tsx`

```tsx
import type { Metadata } from "next";
import Link from "next/link";
import { Shield, Zap } from "lucide-react";
import { PageHeader } from "@/components/page-header";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { Button } from "@/components/ui/button";

const toggles = [
  {
    id: "escalations",
    label: "Escalate low-confidence answers",
    description:
      "Automatically open an escalation email when answer confidence drops below the policy threshold.",
    defaultChecked: true,
  },
  {
    id: "request-logging",
    label: "Attach anonymised request logs",
    description:
      "Include hashed user IDs and request IDs so admins can correlate tickets with chat sessions.",
    defaultChecked: true,
  },
  {
    id: "typing-preview",
    label: "Streaming responses",
    description: "Show tokens as they are generated for faster operator feedback.",
    defaultChecked: false,
  },
];

export const metadata: Metadata = {
  title: "Settings · Atticus",
};

export default function SettingsPage() {
  return (
    <div className="mx-auto flex w-full max-w-4xl flex-col gap-10">
      <PageHeader
        eyebrow="Settings"
        title="Workspace preferences"
        description="Configure escalation behaviour, logging guardrails, and chat defaults."
        actions={
          <Button asChild variant="outline" className="rounded-full">
            <Link href="/admin">View admin console</Link>
          </Button>
        }
      />

      <section className="space-y-6">
        <h2 className="text-sm font-semibold uppercase tracking-widest text-slate-500">Policies</h2>
        <Card>
          <CardContent className="space-y-4">
            {toggles.map((toggle) => (
              <label
                key={toggle.id}
                htmlFor={toggle.id}
                className="flex flex-col gap-2 rounded-2xl border border-transparent p-4 transition hover:border-indigo-200 dark:hover:border-indigo-500/40"
              >
                <div className="flex items-center justify-between gap-4">
                  <div>
                    <p className="text-sm font-semibold text-slate-900 dark:text-white">
                      {toggle.label}
                    </p>
                    <p
                      id={`${toggle.id}-description`}
                      className="text-xs text-slate-500 dark:text-slate-400"
                    >
                      {toggle.description}
                    </p>
                  </div>
                  <input
                    id={toggle.id}
                    type="checkbox"
                    defaultChecked={toggle.defaultChecked}
                    className="h-5 w-10 cursor-pointer appearance-none rounded-full border border-slate-300 bg-slate-200 transition before:block before:h-4 before:w-4 before:translate-x-0 before:rounded-full before:bg-white before:shadow before:transition checked:border-indigo-400 checked:bg-indigo-500 checked:before:translate-x-5 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 dark:border-slate-700 dark:bg-slate-800 dark:checked:border-indigo-400 dark:checked:bg-indigo-500"
                    aria-describedby={`${toggle.id}-description`}
                  />
                </div>
              </label>
            ))}
          </CardContent>
        </Card>
      </section>

      <section className="grid gap-6 md:grid-cols-2">
        <Card>
          <CardHeader className="gap-3 pb-0">
            <div className="inline-flex h-11 w-11 items-center justify-center rounded-2xl bg-indigo-600/10 text-indigo-600 dark:bg-indigo-500/20 dark:text-indigo-300">
              <Shield className="h-5 w-5" aria-hidden="true" />
            </div>
            <CardTitle>Safety guardrails</CardTitle>
            <CardDescription>
              Escalation allow-lists and role-based policies ensure sensitive documents never leave
              your tenant.
            </CardDescription>
          </CardHeader>
        </Card>
        <Card>
          <CardHeader className="gap-3 pb-0">
            <div className="inline-flex h-11 w-11 items-center justify-center rounded-2xl bg-indigo-600/10 text-indigo-600 dark:bg-indigo-500/20 dark:text-indigo-300">
              <Zap className="h-5 w-5" aria-hidden="true" />
            </div>
            <CardTitle>Performance tuning</CardTitle>
            <CardDescription>
              Adjust search probes, reranker policies, and streaming defaults to match your
              team&apos;s workflow.
            </CardDescription>
          </CardHeader>
        </Card>
      </section>
    </div>
  );
}

```

## `app/tsconfig.json`

```json
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}

```

## `archive/legacy-ui/README.md`

```md
# Legacy UI Archive

The static HTML prototype previously served from `web/static` has been moved here for
reference. The Next.js application under `app/` is the canonical UI. Do not deploy these
assets; they are retained to preserve historical design notes until parity is confirmed.

```

## `archive/legacy-ui/static/js/script.js`

```javascript
const STORAGE_KEY = "atticus.chat.history.v1";
const API_BASE = (() => {
  const explicit = document.body?.dataset?.apiBase?.trim();
  if (explicit) {
    return explicit.replace(/\/$/, "");
  }
  if (typeof window.ATTICUS_API_BASE === "string" && window.ATTICUS_API_BASE.trim()) {
    return window.ATTICUS_API_BASE.trim().replace(/\/$/, "");
  }
  if (window.location.port === "8081") {
    return "http://localhost:8000";
  }
  return "";
})();

function resolveApi(path) {
  if (!API_BASE) {
    return path;
  }
  return `${API_BASE}${path.startsWith("/") ? path : `/${path}`}`;
}

function restoreDarkMode() {
  if (localStorage.getItem("atticus.darkMode") === "true") {
    document.body.classList.add("dark");
  }
}

function persistDarkMode(isDark) {
  localStorage.setItem("atticus.darkMode", String(isDark));
}

function saveChat(chatOutput) {
  if (chatOutput) {
    localStorage.setItem(STORAGE_KEY, chatOutput.innerHTML);
  }
}

function loadChat(chatOutput) {
  if (!chatOutput) {
    return;
  }
  const history = localStorage.getItem(STORAGE_KEY);
  if (history) {
    chatOutput.innerHTML = history;
  }
}

function formatTimestamp(date = new Date()) {
  return date.toLocaleTimeString([], { hour: "2-digit", minute: "2-digit" });
}

document.addEventListener("DOMContentLoaded", () => {
  const sidebar = document.getElementById("sidebar");
  const sidebarToggle = document.getElementById("sidebar-toggle");

  function setSidebarCollapsed(collapsed) {
    if (!sidebar) {
      return;
    }
    sidebar.classList.toggle("sidebar-collapsed", collapsed);
    sidebar.classList.toggle("w-64", !collapsed);
    sidebar.classList.toggle("w-20", collapsed);
    document.querySelectorAll(".menu-text").forEach((el) => {
      el.classList.toggle("hidden", collapsed);
    });
    document.querySelectorAll(".menu-item").forEach((el) => {
      el.classList.toggle("justify-center", collapsed);
      el.classList.toggle("justify-start", !collapsed);
    });
  }

  function toggleSidebar() {
    if (!sidebar) {
      return;
    }
    const collapsed = sidebar.classList.contains("sidebar-collapsed");
    setSidebarCollapsed(!collapsed);
  }

  if (sidebar) {
    sidebar.addEventListener("dblclick", () => {
      toggleSidebar();
    });
  }

  if (sidebarToggle) {
    sidebarToggle.addEventListener("click", () => {
      toggleSidebar();
    });
  }

  const darkToggle = document.getElementById("dark-toggle");
  if (darkToggle) {
    darkToggle.addEventListener("click", () => {
      document.body.classList.toggle("dark");
      persistDarkMode(document.body.classList.contains("dark"));
    });
  }
  restoreDarkMode();

  const chatForm = document.getElementById("chat-form");
  const chatInput = document.getElementById("chat-input");
  const chatOutput = document.getElementById("chat-output");
  const typingIndicator = document.getElementById("typing-indicator");
  const clearChatBtn = document.getElementById("clear-chat");
  const fileUpload = document.getElementById("file-upload");
  const fileNameDisplay = document.getElementById("file-name");

  function addMessage(text, sender = "user", options = {}) {
    if (!chatOutput) {
      return;
    }
    const wrapper = document.createElement("div");
    wrapper.className = sender === "system" ? "flex justify-center" : "flex flex-col gap-1";

    const msgContainer = document.createElement("div");
    msgContainer.className =
      sender === "user"
        ? "ml-auto max-w-3xl rounded-xl bg-blue-600 px-4 py-3 text-white shadow-lg animate-fadeIn"
        : sender === "system"
          ? "mx-auto rounded-full bg-gray-200 px-4 py-2 text-sm text-gray-700 dark:bg-gray-700 dark:text-gray-100 animate-fadeIn"
          : "mr-auto max-w-3xl rounded-xl bg-gray-200 px-4 py-3 text-sm text-gray-900 shadow-lg animate-fadeIn dark:bg-gray-800 dark:text-gray-100";

    if (options.allowHtml) {
      msgContainer.innerHTML = text;
    } else {
      const content = document.createElement("div");
      content.className = "whitespace-pre-line";
      content.textContent = text;
      msgContainer.appendChild(content);
    }

    if (sender !== "system") {
      const timeEl = document.createElement("span");
      timeEl.className = "block text-xs text-gray-300";
      const time =
        options.timestamp instanceof Date ? formatTimestamp(options.timestamp) : formatTimestamp();
      timeEl.textContent = time;
      if (sender === "user") {
        timeEl.classList.add("text-right");
      } else {
        timeEl.classList.add("text-gray-400", "dark:text-gray-500");
      }
      wrapper.appendChild(msgContainer);
      wrapper.appendChild(timeEl);
    } else {
      wrapper.appendChild(msgContainer);
    }

    if (Array.isArray(options.sources) && options.sources.length) {
      const listWrapper = document.createElement("div");
      listWrapper.className =
        "mt-3 rounded-lg border border-gray-200 bg-white/70 p-3 text-xs text-gray-700 dark:border-gray-700 dark:bg-gray-900/60 dark:text-gray-300";
      const listTitle = document.createElement("p");
      listTitle.className =
        "font-semibold uppercase tracking-wide text-[0.7rem] text-gray-500 dark:text-gray-400";
      listTitle.textContent = "Sources";
      listWrapper.appendChild(listTitle);

      const list = document.createElement("ul");
      list.className = "mt-2 space-y-1";
      options.sources.forEach((source) => {
        const item = document.createElement("li");
        item.textContent = source;
        list.appendChild(item);
      });
      listWrapper.appendChild(list);
      msgContainer.appendChild(listWrapper);
    }

    if (options.metaText) {
      const meta = document.createElement("p");
      meta.className = "mt-2 text-xs text-gray-400 dark:text-gray-500";
      meta.textContent = options.metaText;
      msgContainer.appendChild(meta);
    }

    chatOutput.appendChild(wrapper);
    chatOutput.scrollTo({ top: chatOutput.scrollHeight, behavior: "smooth" });
    saveChat(chatOutput);
  }

  if (chatOutput) {
    loadChat(chatOutput);
  }

  if (fileUpload && fileNameDisplay) {
    fileUpload.addEventListener("change", () => {
      fileNameDisplay.textContent = fileUpload.files?.[0]?.name ?? "";
    });
  }

  if (clearChatBtn && chatOutput) {
    clearChatBtn.addEventListener("click", () => {
      chatOutput.innerHTML = "";
      localStorage.removeItem(STORAGE_KEY);
      addMessage(`Chat cleared at ${formatTimestamp()}`, "system");
    });
  }

  let submitController = null;

  async function sendToApi(query) {
    if (submitController) {
      submitController.abort();
    }
    submitController = new AbortController();
    const payload = { query };
    const response = await fetch(resolveApi("/ask"), {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
      signal: submitController.signal,
    });

    if (!response.ok && response.status !== 206) {
      const detail = await response.text();
      throw new Error(detail || response.statusText);
    }

    const data = await response.json();
    return { status: response.status, data };
  }

  function normalizeCitations(citations) {
    if (!Array.isArray(citations)) {
      return [];
    }
    return citations
      .map((citation) => {
        if (!citation || typeof citation !== "object") {
          return "";
        }
        const parts = [];
        if (citation.source_path) {
          parts.push(citation.source_path);
        }
        if (typeof citation.page_number === "number") {
          parts.push(`page ${citation.page_number}`);
        }
        if (citation.heading) {
          parts.push(citation.heading);
        }
        return parts.join(" · ") || "";
      })
      .filter(Boolean);
  }

  function renderBotReply({ answer, citations, confidence, should_escalate, ae_id, request_id }) {
    const parts = [answer || "(No answer returned)"];
    const metaChunks = [];
    if (typeof confidence === "number") {
      metaChunks.push(`Confidence: ${(confidence * 100).toFixed(0)}%`);
    }
    if (request_id) {
      metaChunks.push(`Request ID: ${request_id}`);
    }
    const metaText = metaChunks.length ? metaChunks.join(" · ") : undefined;
    addMessage(parts.join("\n\n"), "bot", {
      sources: normalizeCitations(citations),
      metaText,
    });

    if (should_escalate) {
      const escalationMsg = ae_id
        ? `Confidence below threshold. Escalation created (ticket ${ae_id}).`
        : "Confidence below threshold. Escalation created.";
      addMessage(escalationMsg, "system");
    }
  }

  if (chatForm && chatInput && chatOutput && typingIndicator) {
    chatForm.addEventListener("submit", async (event) => {
      event.preventDefault();
      const message = chatInput.value.trim();
      if (!message) {
        return;
      }

      addMessage(message, "user");
      chatInput.value = "";
      if (fileNameDisplay) {
        fileNameDisplay.textContent = "";
      }

      typingIndicator.classList.remove("hidden");

      try {
        const { status, data } = await sendToApi(message);
        renderBotReply({
          answer: data.answer,
          citations: data.citations ?? data.sources,
          confidence: data.confidence,
          should_escalate: Boolean(data.should_escalate || data.escalated || status === 206),
          ae_id: data.ae_id,
          request_id: data.request_id,
        });
      } catch (error) {
        const detail = error instanceof Error ? error.message : String(error);
        addMessage(`Something went wrong: ${detail}`, "system");
      } finally {
        typingIndicator.classList.add("hidden");
        chatInput.focus();
      }
    });

    chatInput.addEventListener("keydown", (event) => {
      if (event.key === "Enter" && !event.shiftKey) {
        event.preventDefault();
        chatForm.requestSubmit();
      }
    });
  }

  const contactForm = document.getElementById("contact-form");
  const contactSubject = document.getElementById("contact-subject");
  const contactBody = document.getElementById("contact-body");
  const contactStatus = document.getElementById("contact-status");
  const contactSend = document.getElementById("contact-send");

  if (contactForm && contactSubject && contactBody && contactStatus && contactSend) {
    contactForm.addEventListener("submit", async (event) => {
      event.preventDefault();
      const subject = contactSubject.value.trim();
      const message = contactBody.value.trim();
      if (!subject || !message) {
        contactStatus.textContent = "Subject and message are required.";
        return;
      }

      contactStatus.textContent = "Sending escalation…";
      contactSend.disabled = true;

      try {
        const response = await fetch(resolveApi("/contact"), {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            reason: subject,
            transcript: message,
          }),
        });

        if (!response.ok) {
          const detail = await response.text();
          throw new Error(detail || response.statusText);
        }

        contactStatus.textContent = "Escalation sent successfully.";
        contactSubject.value = "";
        contactBody.value = "";
      } catch (error) {
        const detail = error instanceof Error ? error.message : String(error);
        contactStatus.textContent = `Unable to send escalation: ${detail}`;
      } finally {
        contactSend.disabled = false;
      }
    });
  }
});

```

## `atticus/__init__.py`

```python
"""Atticus core utilities."""

from __future__ import annotations

import os
from pathlib import Path

_REPO_ROOT = Path(__file__).resolve().parent.parent
_PATH_ENTRIES = os.environ.get("PATH", "").split(os.pathsep) if os.environ.get("PATH") else []
if str(_REPO_ROOT) not in _PATH_ENTRIES:
    os.environ["PATH"] = (
        f"{_REPO_ROOT}{os.pathsep}{os.environ['PATH']}" if _PATH_ENTRIES else str(_REPO_ROOT)
    )

from .config import AppSettings

__all__ = ["AppSettings"]

```

## `atticus/config.py`

```python
"""Configuration objects for Atticus."""

from __future__ import annotations

import hashlib
import json
import os
from dataclasses import dataclass
from datetime import UTC, datetime
from pathlib import Path
from typing import Any
from zoneinfo import ZoneInfo

import yaml
from pydantic import AliasChoices, Field
from pydantic_settings import BaseSettings, SettingsConfigDict

SECRET_FIELD_NAMES = {
    "database_url",
    "openai_api_key",
    "smtp_user",
    "smtp_pass",
    "smtp_from",
    "smtp_to",
    "smtp_allow_list_raw",
    "contact_email",
    "admin_api_token",
}


def _fingerprint_secret(value: str | None) -> str | None:
    if not value:
        return None
    return hashlib.sha256(value.encode("utf-8")).hexdigest()[:12]


class AppSettings(BaseSettings):
    """Application configuration sourced from environment variables."""

    content_dir: Path = Field(
        default=Path("content"), validation_alias=AliasChoices("CONTENT_ROOT", "CONTENT_DIR")
    )
    indices_dir: Path = Field(default=Path("indices"), validation_alias="INDICES_DIR")
    logs_path: Path = Field(default=Path("logs/app.jsonl"), validation_alias="LOG_PATH")
    errors_path: Path = Field(default=Path("logs/errors.jsonl"), validation_alias="ERROR_LOG_PATH")
    manifest_path: Path = Field(default=Path("indices/manifest.json"))
    metadata_path: Path = Field(default=Path("indices/index_metadata.json"))
    snapshots_dir: Path = Field(default=Path("indices/snapshots"))
    dictionary_path: Path = Field(default=Path("indices/dictionary.json"), alias="DICTIONARY_PATH")
    database_url: str | None = Field(default=None, alias="DATABASE_URL")
    pgvector_lists: int = Field(default=100, alias="PGVECTOR_LISTS")
    pgvector_probes: int = Field(default=4, alias="PGVECTOR_PROBES")
    chunk_size: int = Field(default=512, ge=64)
    chunk_overlap_ratio: float = Field(default=0.0, ge=0.0, lt=1.0)
    chunk_target_tokens: int = Field(default=512, alias="CHUNK_TARGET_TOKENS")
    chunk_min_tokens: int = Field(default=256, alias="CHUNK_MIN_TOKENS")
    chunk_overlap_tokens_setting: int | None = Field(
        default=None, alias="CHUNK_OVERLAP_TOKENS", ge=0
    )
    max_context_chunks: int = Field(default=10, ge=1)
    enable_reranker: bool = Field(default=False, alias="ENABLE_RERANKER")
    top_k: int = Field(default=20, ge=1)
    openai_api_key: str | None = Field(default=None, alias="OPENAI_API_KEY")
    embed_model: str = Field(default="text-embedding-3-large", alias="EMBED_MODEL")
    embedding_model_version: str = Field(
        default="text-embedding-3-large@2025-01-15",
        alias="EMBEDDING_MODEL_VERSION",
    )
    embed_dimensions: int = Field(default=3072, ge=128)
    generation_model: str = Field(default="gpt-4.1", alias="GEN_MODEL")
    confidence_threshold: float = Field(default=0.70, alias="CONFIDENCE_THRESHOLD")
    log_level: str = Field(default="INFO", alias="LOG_LEVEL")
    log_format: str = Field(default="json", alias="LOG_FORMAT")
    verbose_logging: bool = Field(default=False, alias="LOG_VERBOSE")
    trace_logging: bool = Field(default=False, alias="LOG_TRACE")
    timezone: str = Field(default="UTC", alias="TIMEZONE")
    evaluation_runs_dir: Path = Field(default=Path("eval/runs"))
    baseline_path: Path = Field(default=Path("eval/baseline.json"))
    gold_set_path: Path = Field(default=Path("eval/gold_set.csv"))
    eval_regression_threshold: float = Field(default=3.0, alias="EVAL_REGRESSION_THRESHOLD")
    config_path: Path = Field(default=Path("config.yaml"), alias="CONFIG_PATH")

    # Notification / escalation (from .env)
    contact_email: str | None = Field(default=None, alias="CONTACT_EMAIL")
    smtp_host: str | None = Field(default=None, alias="SMTP_HOST")
    smtp_port: int = Field(default=587, alias="SMTP_PORT")
    smtp_user: str | None = Field(default=None, alias="SMTP_USER")
    smtp_pass: str | None = Field(default=None, alias="SMTP_PASS")
    smtp_from: str | None = Field(default=None, alias="SMTP_FROM")
    smtp_to: str | None = Field(default=None, alias="SMTP_TO")
    smtp_dry_run: bool = Field(
        default=False, validation_alias=AliasChoices("SMTP_DRY_RUN", "EMAIL_SANDBOX")
    )
    smtp_allow_list_raw: str | list[str] | None = Field(default=None, alias="SMTP_ALLOW_LIST")
    rate_limit_requests: int = Field(default=5, alias="RATE_LIMIT_REQUESTS", ge=1)
    rate_limit_window_seconds: int = Field(default=60, alias="RATE_LIMIT_WINDOW_SECONDS", ge=1)
    admin_api_token: str | None = Field(default=None, alias="ADMIN_API_TOKEN")
    secrets_report: dict[str, dict[str, Any]] = Field(
        default_factory=dict, exclude=True, repr=False
    )

    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8", extra="ignore")

    @property
    def tzinfo(self) -> ZoneInfo:
        return ZoneInfo(self.timezone)

    @property
    def chunk_overlap_tokens(self) -> int:
        if self.chunk_overlap_tokens_setting is not None:
            return max(0, self.chunk_overlap_tokens_setting)
        return max(0, int(self.chunk_size * self.chunk_overlap_ratio))

    def ensure_directories(self) -> None:
        for path in [
            self.content_dir,
            self.indices_dir,
            self.logs_path.parent,
            self.snapshots_dir,
            self.evaluation_runs_dir,
        ]:
            path.mkdir(parents=True, exist_ok=True)

    def timestamp(self) -> str:
        return datetime.now(tz=self.tzinfo).isoformat(timespec="seconds")

    def smtp_allowlist(self) -> set[str]:
        return {value.lower() for value in self.smtp_allow_list if value}

    @property
    def smtp_allow_list(self) -> list[str]:
        raw = self.smtp_allow_list_raw
        if raw is None:
            return []
        if isinstance(raw, str):
            return [item.strip() for item in raw.split(",") if item.strip()]
        return [str(item).strip() for item in raw if str(item).strip()]


@dataclass(slots=True)
class Manifest:
    """Represents a stored manifest of the active index."""

    embedding_model: str
    embedding_model_version: str
    embedding_dimensions: int
    chunk_size: int
    chunk_overlap_ratio: float
    corpus_hash: str
    document_count: int
    chunk_count: int
    created_at: str
    metadata_path: Path
    index_path: Path
    snapshot_path: Path
    documents: dict[str, dict[str, Any]]

    def to_dict(self) -> dict[str, Any]:
        return {
            "embedding_model": self.embedding_model,
            "embedding_model_version": self.embedding_model_version,
            "embedding_dimensions": self.embedding_dimensions,
            "chunk_size": self.chunk_size,
            "chunk_overlap_ratio": self.chunk_overlap_ratio,
            "corpus_hash": self.corpus_hash,
            "document_count": self.document_count,
            "chunk_count": self.chunk_count,
            "created_at": self.created_at,
            "metadata_path": str(self.metadata_path),
            "index_path": str(self.index_path),
            "snapshot_path": str(self.snapshot_path),
            "documents": self.documents,
        }


def load_manifest(path: Path) -> Manifest | None:
    if not path.exists():
        return None
    data = json.loads(path.read_text(encoding="utf-8"))
    return Manifest(
        embedding_model=data["embedding_model"],
        embedding_model_version=data.get("embedding_model_version", "unknown"),
        embedding_dimensions=int(data["embedding_dimensions"]),
        chunk_size=int(data["chunk_size"]),
        chunk_overlap_ratio=float(data["chunk_overlap_ratio"]),
        corpus_hash=data["corpus_hash"],
        document_count=int(data["document_count"]),
        chunk_count=int(data["chunk_count"]),
        created_at=data["created_at"],
        metadata_path=Path(data["metadata_path"]),
        index_path=Path(data["index_path"]),
        snapshot_path=Path(data["snapshot_path"]),
        documents={key: dict(value) for key, value in data.get("documents", {}).items()},
    )


def write_manifest(path: Path, manifest: Manifest) -> None:
    path.write_text(
        json.dumps(manifest.to_dict(), indent=2, ensure_ascii=False) + "\n", encoding="utf-8"
    )


def _load_yaml_config(path: Path) -> dict[str, Any]:
    if not path.exists():
        return {}
    data = yaml.safe_load(path.read_text(encoding="utf-8"))
    if isinstance(data, dict):
        return {str(key): value for key, value in data.items()}
    raise ValueError(f"Configuration file {path} must contain a mapping")


@dataclass(slots=True)
class _SettingsCache:
    """Mutable holder for cached settings and their provenance."""

    key: tuple[float, float, str] | None = None
    settings: AppSettings | None = None


_SETTINGS_CACHE = _SettingsCache()


def _iter_alias_strings(value: Any) -> list[str]:
    if value is None:
        return []
    if isinstance(value, str):
        return [value]
    choices = getattr(value, "choices", None)
    if choices is not None:
        return [str(item) for item in choices]
    result: list[str] = []
    try:
        for item in value:
            if isinstance(item, str):
                result.append(item)
            else:
                result.extend(_iter_alias_strings(item))
    except TypeError:
        pass
    return result


def _env_variables_fingerprint() -> str:
    keys: set[str] = set()
    for name, field in AppSettings.model_fields.items():
        keys.add(name.upper())
        alias = getattr(field, "alias", None)
        if alias:
            keys.update(_iter_alias_strings(alias))
        validation_alias = getattr(field, "validation_alias", None)
        keys.update(_iter_alias_strings(validation_alias))
    material = "|".join(f"{key}={os.environ.get(key, '')}" for key in sorted(keys))
    return hashlib.sha256(material.encode("utf-8")).hexdigest()


def _parse_env_file(path: Path) -> dict[str, str]:
    if not path.exists():
        return {}

    values: dict[str, str] = {}
    for raw_line in path.read_text(encoding="utf-8").splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        if line.startswith("export "):
            line = line[len("export ") :]
        if "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip()
        if value and value[0] == value[-1] and value[0] in {"'", '"'}:
            value = value[1:-1]
        values[key] = value
    return values


def _path_metadata(path: Path) -> dict[str, Any]:
    absolute = path if path.is_absolute() else path.resolve()
    metadata = {"path": str(absolute), "exists": absolute.exists()}
    if absolute.exists():
        stat_result = absolute.stat()
        metadata["modified_at"] = datetime.fromtimestamp(stat_result.st_mtime, tz=UTC).isoformat()
        metadata["size_bytes"] = stat_result.st_size
    else:
        metadata["modified_at"] = None
        metadata["size_bytes"] = None
    return metadata


def _serialize_value(value: Any) -> Any:
    if isinstance(value, Path):
        return str(value)
    if isinstance(value, ZoneInfo):
        return value.key
    if isinstance(value, dict):
        return {str(k): _serialize_value(v) for k, v in value.items()}
    if isinstance(value, (list, tuple, set)):
        return [_serialize_value(item) for item in value]
    return value


def _resolve_env_file() -> Path | None:
    env_file = AppSettings.model_config.get("env_file")
    if isinstance(env_file, (list, tuple)):
        if not env_file:
            return None
        first = env_file[0]
        return Path(str(first))
    if isinstance(env_file, str):
        return Path(env_file)
    return None


def reset_settings_cache() -> None:
    """Clear the cached settings instance (primarily for tests)."""

    _SETTINGS_CACHE.key = None
    _SETTINGS_CACHE.settings = None


def load_settings() -> AppSettings:
    env_path = _resolve_env_file() or Path(".env")
    env_mtime = env_path.stat().st_mtime if env_path.exists() else -1.0
    env_values = _parse_env_file(env_path)
    env_fingerprint = _env_variables_fingerprint()

    base = AppSettings()
    config_path = base.config_path
    config_mtime = config_path.stat().st_mtime if config_path.exists() else -1.0

    cache_key = (env_mtime, config_mtime, env_fingerprint)

    if _SETTINGS_CACHE.key == cache_key and _SETTINGS_CACHE.settings is not None:
        return _SETTINGS_CACHE.settings

    config_data = _load_yaml_config(config_path)

    if config_data:
        updates: dict[str, Any] = {}
        for name, value in config_data.items():
            field = AppSettings.model_fields.get(name)
            if field is None:
                updates[name] = value
                continue

            aliases = {name.upper()}
            aliases.update(_iter_alias_strings(getattr(field, "alias", None)))
            aliases.update(_iter_alias_strings(getattr(field, "validation_alias", None)))

            if any(alias in os.environ for alias in aliases):
                continue
            if any(alias in env_values for alias in aliases):
                continue

            updates[name] = value

        updates.setdefault("config_path", config_path)
        # Rebuild settings with validation so YAML string paths are coerced to Path
        # and other field types are normalized. model_copy(update=...) does not
        # perform validation in pydantic v2, which led to str values lacking
        # Path methods like `.mkdir()`.
        combined: dict[str, Any] = base.model_dump()
        combined.update(updates)
        settings = AppSettings.model_validate(combined)
    else:
        settings = base

    _SETTINGS_CACHE.key = cache_key
    _SETTINGS_CACHE.settings = settings
    return settings


def environment_diagnostics() -> dict[str, Any]:
    """Return sanitized diagnostics for environment configuration resolution."""

    env_path = _resolve_env_file() or Path(".env")
    env_values = _parse_env_file(env_path)

    settings = load_settings()
    config_path = settings.config_path
    config_data = _load_yaml_config(config_path)

    relevant_keys: set[str] = set()
    non_secret_settings: dict[str, Any] = {}
    secrets_report: dict[str, dict[str, Any]] = {}

    for name, field in AppSettings.model_fields.items():
        if name == "secrets_report":
            continue

        aliases = {name.upper()}
        aliases.update(_iter_alias_strings(getattr(field, "alias", None)))
        aliases.update(_iter_alias_strings(getattr(field, "validation_alias", None)))
        relevant_keys.update(aliases)

        env_key = next((key for key in aliases if key in os.environ), None)
        env_file_key = next((key for key in aliases if key in env_values), None)
        config_key = name if name in config_data else None

        if env_key:
            source = f"os.environ:{env_key}"
        elif env_file_key:
            source = f".env:{env_file_key}"
        elif config_key:
            source = f"config.yaml:{config_key}"
        else:
            source = "default"

        value = getattr(settings, name)

        if name in SECRET_FIELD_NAMES:
            fingerprint = _fingerprint_secret(str(value) if value is not None else None)
            secrets_report[name] = {
                "aliases": sorted(aliases),
                "defined": bool(value),
                "fingerprint": fingerprint,
                "source": source,
            }
        else:
            non_secret_settings[name] = {
                "aliases": sorted(aliases),
                "source": source,
                "value": _serialize_value(value),
            }

    settings.secrets_report = secrets_report

    env_override_keys = sorted(key for key in os.environ if key in relevant_keys)
    env_file_override_keys = sorted(key for key in env_values if key in relevant_keys)

    return {
        "generated_at": datetime.now(tz=UTC).isoformat(),
        "environment_fingerprint": _env_variables_fingerprint(),
        "env_file": _path_metadata(env_path),
        "config_file": _path_metadata(config_path),
        "overrides": {
            "environment": env_override_keys,
            ".env": env_file_override_keys,
            "config": sorted(str(key) for key in config_data.keys()),
        },
        "settings": non_secret_settings,
        "secrets": secrets_report,
    }

```

## `atticus/embeddings.py`

```python
"""Embedding helpers using OpenAI or deterministic fallback."""

from __future__ import annotations

import hashlib
import importlib
import logging
import os
from collections.abc import Iterable
from typing import Any, cast

import numpy as np

from .config import AppSettings


class EmbeddingClient:
    """Provides embeddings with deterministic offline fallback."""

    def __init__(self, settings: AppSettings, logger: logging.Logger | None = None) -> None:
        self.settings = settings
        self.logger = logger or logging.getLogger("atticus")
        self.model_name = settings.embed_model
        self.dimension = settings.embed_dimensions

        # Resolve API key and record source for diagnostics
        source = "none"
        api_key = None
        if getattr(settings, "openai_api_key", None):
            api_key = settings.openai_api_key
            source = "settings"
        elif os.getenv("OPENAI_API_KEY"):
            api_key = os.getenv("OPENAI_API_KEY")
            source = "os.environ"
        self._client: Any | None = None
        if api_key:  # pragma: no cover - requires network
            try:
                openai_module = importlib.import_module("openai")
                openai_class = cast(Any, openai_module).OpenAI
                # Pass the key explicitly so we don't rely on process env
                self._client = openai_class(api_key=api_key)
                # Safe fingerprint (sha256 prefix) for troubleshooting without leaking secrets
                try:
                    fp = hashlib.sha256(str(api_key).encode("utf-8")).hexdigest()[:12]
                except Exception:
                    fp = "unknown"
                self.logger.info(
                    "openai_client_initialized",
                    extra={
                        "extra_payload": {
                            "client": "embeddings",
                            "source": source,
                            "key_fp": fp,
                            "model": self.model_name,
                        }
                    },
                )
            except Exception as exc:  # pragma: no cover - network path
                self.logger.warning(
                    "OpenAI client initialization failed; using fallback embeddings",
                    extra={"extra_payload": {"error": str(exc)}},
                )
        else:
            self.logger.info(
                "Using deterministic embeddings because no OpenAI API key was provided"
            )

    def embed_texts(self, texts: Iterable[str]) -> list[list[float]]:
        payload = list(texts)
        if not payload:
            return []

        if self._client is not None:  # pragma: no cover - requires network
            try:
                response: Any = self._client.embeddings.create(model=self.model_name, input=payload)
                return [list(map(float, item.embedding)) for item in response.data]
            except Exception as exc:
                self.logger.error(
                    "OpenAI embedding request failed; falling back to deterministic embeddings",
                    extra={"extra_payload": {"error": str(exc), "model": self.model_name}},
                )

        return [self._deterministic_embedding(text) for text in payload]

    def _deterministic_embedding(self, text: str) -> list[float]:
        tokens = text.lower().split()
        vector = np.zeros(self.dimension, dtype=np.float32)
        for token in tokens:
            digest = hashlib.sha256(token.encode("utf-8")).digest()
            for index in range(0, len(digest), 4):
                offset = int.from_bytes(digest[index : index + 4], "little") % self.dimension
                vector[offset] += 1.0
        norm = np.linalg.norm(vector)
        if norm:
            vector /= norm
        return vector.astype(np.float32).tolist()

```

## `atticus/logging.py`

```python
"""Structured logging utilities."""

from __future__ import annotations

import json
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Any

from .config import AppSettings


class JsonFormatter(logging.Formatter):
    """Formats log records as JSON lines."""

    def format(self, record: logging.LogRecord) -> str:
        payload: dict[str, Any] = {
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "time": self.formatTime(record, datefmt="%Y-%m-%dT%H:%M:%S%z"),
        }

        extra_data = getattr(record, "extra_payload", None)
        if isinstance(extra_data, dict):
            payload.update(extra_data)

        if record.exc_info:
            payload["exc_info"] = self.formatException(record.exc_info)

        return json.dumps(payload, ensure_ascii=False)


def _build_file_handler(path: Path) -> RotatingFileHandler:
    path.parent.mkdir(parents=True, exist_ok=True)
    handler = RotatingFileHandler(path, maxBytes=5_000_000, backupCount=5, encoding="utf-8")
    handler.setFormatter(JsonFormatter())
    return handler


def configure_logging(settings: AppSettings) -> logging.Logger:
    """Return a configured root logger for the service."""

    logger = logging.getLogger("atticus")
    if not logger.handlers:
        logger.setLevel(getattr(logging, settings.log_level.upper(), logging.INFO))
        logger.addHandler(_build_file_handler(settings.logs_path))

        error_handler = _build_file_handler(settings.errors_path)
        error_handler.setLevel(logging.ERROR)
        logger.addHandler(error_handler)
        # Prevent propagation to root handlers (avoids console encoding issues on Windows)
        logger.propagate = False
    return logger


def log_event(logger: logging.Logger, event: str, **payload: Any) -> None:
    if "trace_id" not in payload and "request_id" in payload:
        payload["trace_id"] = payload["request_id"]
    logger.info(event, extra={"extra_payload": payload})


def log_error(logger: logging.Logger, event: str, **payload: Any) -> None:
    payload.setdefault("severity", "ERROR")
    if "trace_id" not in payload and "request_id" in payload:
        payload["trace_id"] = payload["request_id"]
    logger.error(event, extra={"extra_payload": payload})

```

## `atticus/logging_utils.py`

```python
from __future__ import annotations

import logging
import os
import sys
from typing import cast

import structlog
from structlog.stdlib import BoundLogger

_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
_FORMAT = os.getenv("LOG_FORMAT", "json").lower()


def _configure_once() -> None:
    if getattr(_configure_once, "_did", False):
        return

    processors: list[structlog.types.Processor] = [
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.add_log_level,
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
    ]
    if _FORMAT == "console":
        processors.append(structlog.dev.ConsoleRenderer())
    else:
        processors.append(structlog.processors.JSONRenderer())

    level = getattr(logging, _LEVEL, logging.INFO)
    logging.basicConfig(format="%(message)s", stream=sys.stdout, level=level)

    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(level),
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
    _configure_once._did = True  # type: ignore[attr-defined]


def get_logger(name: str = "atticus") -> BoundLogger:
    _configure_once()
    logger = structlog.get_logger(name)
    return cast(BoundLogger, logger)

```

## `atticus/metrics.py`

```python
"""Simple metrics aggregator for Atticus."""

from __future__ import annotations

import csv
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path

from .config import AppSettings


@dataclass(slots=True)
class MetricsRecorder:
    settings: AppSettings
    store_path: Path = field(default_factory=lambda: Path("logs/metrics/metrics.csv"))
    queries: int = 0
    total_confidence: float = 0.0
    escalations: int = 0
    total_latency_ms: float = 0.0
    latency_samples: list[float] = field(default_factory=list)
    recent_trace_ids: list[str] = field(default_factory=list)
    trace_id_limit: int = 50

    def record(
        self,
        confidence: float,
        latency_ms: float,
        escalated: bool,
        *,
        trace_id: str | None = None,
    ) -> None:
        self.queries += 1
        self.total_confidence += confidence
        self.total_latency_ms += latency_ms
        self.latency_samples.append(latency_ms)
        if len(self.latency_samples) > 500:
            self.latency_samples = self.latency_samples[-500:]
        if escalated:
            self.escalations += 1
        if trace_id:
            self.recent_trace_ids.append(trace_id)
            if len(self.recent_trace_ids) > self.trace_id_limit:
                self.recent_trace_ids = self.recent_trace_ids[-self.trace_id_limit :]

    def _latency_percentile(self, percentile: float) -> float:
        if not self.latency_samples:
            return 0.0
        ordered = sorted(self.latency_samples)
        index = int(round((percentile / 100.0) * (len(ordered) - 1)))
        return float(ordered[index])

    def latency_histogram(self) -> dict[str, int]:
        buckets = {"0-250": 0, "250-500": 0, "500-1000": 0, "1000+": 0}
        for value in self.latency_samples:
            if value < 250:
                buckets["0-250"] += 1
            elif value < 500:
                buckets["250-500"] += 1
            elif value < 1000:
                buckets["500-1000"] += 1
            else:
                buckets["1000+"] += 1
        return buckets

    def snapshot(self) -> dict[str, float | int]:
        if self.queries == 0:
            return {
                "queries": 0,
                "avg_confidence": 0.0,
                "escalations": 0,
                "avg_latency_ms": 0.0,
                "p95_latency_ms": 0.0,
            }
        return {
            "queries": self.queries,
            "avg_confidence": round(self.total_confidence / self.queries, 3),
            "escalations": self.escalations,
            "avg_latency_ms": round(self.total_latency_ms / self.queries, 2),
            "p95_latency_ms": round(self._latency_percentile(95), 2),
        }

    def dashboard(self) -> dict[str, object]:
        return {
            **self.snapshot(),
            "latency_histogram": self.latency_histogram(),
            "recent_trace_ids": list(self.recent_trace_ids),
        }

    def flush(self) -> None:
        if self.queries == 0:
            return
        snapshot = self.snapshot()
        self.store_path.parent.mkdir(parents=True, exist_ok=True)
        write_header = not self.store_path.exists()
        with self.store_path.open("a", newline="", encoding="utf-8") as handle:
            writer = csv.DictWriter(
                handle,
                fieldnames=[
                    "timestamp",
                    "queries",
                    "avg_confidence",
                    "escalations",
                    "avg_latency_ms",
                    "p95_latency_ms",
                ],
            )
            if write_header:
                writer.writeheader()
            writer.writerow(
                {
                    "timestamp": datetime.now(tz=self.settings.tzinfo).isoformat(
                        timespec="seconds"
                    ),
                    **snapshot,
                }
            )
        self.reset()

    def reset(self) -> None:
        self.queries = 0
        self.total_confidence = 0.0
        self.escalations = 0
        self.total_latency_ms = 0.0
        self.latency_samples.clear()
        self.recent_trace_ids.clear()

```

## `atticus/notify/__init__.py`

```python
"""Notification helpers (email escalation, etc.)."""

from .mailer import EscalationDeliveryError, send_escalation

__all__ = ["EscalationDeliveryError", "send_escalation"]

```

## `atticus/notify/mailer.py`

```python
"""SMTP mailer for escalation emails.

Reads SMTP_* and CONTACT_EMAIL from AppSettings (which sources .env).

Exports:
    send_escalation(subject, body, to=None)
"""

from __future__ import annotations

import json
import logging
import smtplib
from collections.abc import Iterable
from email.message import EmailMessage
from typing import Any, Literal, TypedDict

from atticus.config import load_settings
from atticus.logging import configure_logging, log_error


class EscalationDeliveryError(RuntimeError):
    """Raised when an escalation email cannot be delivered."""

    def __init__(self, message: str, *, reason: str = "unknown") -> None:
        super().__init__(message)
        self.reason = reason


class _DryRunResult(TypedDict):
    status: Literal["dry-run"]
    host: str
    port: int


def _normalise_allow_list(values: Iterable[str]) -> list[str]:
    result: list[str] = []
    for value in values:
        if not value:
            continue
        cleaned = value.strip().lower()
        if cleaned:
            result.append(cleaned)
    return result


def _address_allowed(address: str, allow_list: Iterable[str]) -> bool:
    normalised = _normalise_allow_list(allow_list)
    if not normalised:
        return True
    candidate = address.strip().lower()
    if candidate in normalised:
        return True
    if "@" in candidate:
        _, _, domain = candidate.partition("@")
        patterns = {domain, f"@{domain}", f"*@{domain}"}
        if any(pattern in normalised for pattern in patterns):
            return True
    return False


def _compose_message(
    subject: str,
    body: str,
    sender: str,
    recipient: str,
    trace: dict[str, Any] | None = None,
) -> EmailMessage:
    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = sender
    msg["To"] = recipient
    if trace:
        trace_dump = json.dumps(trace, indent=2, ensure_ascii=False)
        body = f"{body}\n\nTrace Payload\n--------------\n{trace_dump}"
    msg.set_content(body)
    return msg


def _log_failure(
    logger: logging.Logger, *, reason: str, host: str, port: int, exc: Exception
) -> None:
    log_error(
        logger,
        "escalation_email_failed",
        reason=reason,
        host=host,
        port=port,
        error=str(exc),
    )


def _summarize_trace(trace: dict[str, Any] | None) -> dict[str, Any] | None:
    if not trace:
        return None
    summary: dict[str, Any] = {}
    for key in ("user_id", "chat_id", "message_id", "request_id"):
        if trace.get(key):
            summary[key] = trace[key]
    question = trace.get("question")
    if isinstance(question, str) and question.strip():
        summary["question_preview"] = question.strip()[:120]
    documents = trace.get("documents") or trace.get("top_documents")
    if isinstance(documents, list) and documents:
        summary["documents"] = [
            {
                "chunk_id": item.get("chunk_id"),
                "score": item.get("score"),
                "source_path": item.get("source_path"),
            }
            for item in documents[:5]
            if isinstance(item, dict)
        ]
    return summary or None


def send_escalation(
    subject: str,
    body: str,
    to: str | None = None,
    *,
    trace: dict[str, Any] | None = None,
) -> _DryRunResult | None:
    """Send an escalation email via SMTP.

    Recipient resolution order: explicit `to` -> `SMTP_TO` -> `CONTACT_EMAIL`.
    Returns dry-run metadata when SMTP_DRY_RUN is enabled; otherwise None.
    """
    settings = load_settings()
    logger = configure_logging(settings)

    candidates = [
        (to or "").strip(),
        (settings.smtp_to or "").strip(),
        (settings.contact_email or "").strip(),
    ]
    allow_list = settings.smtp_allow_list
    recipient: str | None = None
    for candidate in candidates:
        if not candidate:
            continue
        if allow_list and not _address_allowed(candidate, allow_list):
            continue
        recipient = candidate
        break

    if recipient is None:
        if allow_list:
            raise EscalationDeliveryError(
                "Recipient not approved for escalation email.",
                reason="recipient_not_allowed",
            )
        logger.warning("No recipient configured for escalation email; skipping send")
        return None

    host = (settings.smtp_host or "").strip()
    if not host:
        logger.warning("SMTP_HOST not configured; skipping send")
        return None

    port = int(settings.smtp_port or 587)
    sender = settings.smtp_from or settings.smtp_user or f"no-reply@{host}"

    if not _address_allowed(recipient, allow_list):
        raise EscalationDeliveryError(
            "Recipient not approved for escalation email.",
            reason="recipient_not_allowed",
        )
    if sender and not _address_allowed(sender, allow_list):
        raise EscalationDeliveryError(
            "SMTP_FROM address not present in allow list.",
            reason="sender_not_allowed",
        )

    msg = _compose_message(
        subject=subject,
        body=body,
        sender=sender,
        recipient=recipient,
        trace=trace,
    )

    trace_summary = _summarize_trace(trace)

    if settings.smtp_dry_run:
        logger.info(
            "escalation_email_dry_run",
            extra={
                "extra_payload": {
                    "to": "(redacted)",
                    "host": host,
                    "port": port,
                    "trace": trace_summary,
                }
            },
        )
        return {"status": "dry-run", "host": host, "port": int(port)}

    try:
        with smtplib.SMTP(host, port, timeout=20) as client:
            client.ehlo()
            try:
                client.starttls()
            except smtplib.SMTPNotSupportedError as exc:  # pragma: no cover - legacy SMTP
                _log_failure(logger, reason="tls_not_supported", host=host, port=port, exc=exc)
                raise EscalationDeliveryError(
                    "SMTP server does not support STARTTLS; escalation email not sent.",
                    reason="tls_not_supported",
                ) from exc

            if settings.smtp_user and settings.smtp_pass:
                client.login(settings.smtp_user, settings.smtp_pass)

            try:
                client.send_message(msg)
            except AttributeError:
                client.sendmail(sender, [recipient], msg.as_string())

            logger.info(
                "escalation_email_sent",
                extra={
                    "extra_payload": {
                        "to": "(redacted)",
                        "host": host,
                        "port": port,
                        "trace": trace_summary,
                    }
                },
            )
    except smtplib.SMTPAuthenticationError as exc:
        _log_failure(logger, reason="authentication_failed", host=host, port=port, exc=exc)
        raise EscalationDeliveryError(
            "SMTP authentication failed while sending escalation email.",
            reason="authentication_failed",
        ) from exc
    except (smtplib.SMTPConnectError, OSError) as exc:
        _log_failure(logger, reason="connection_error", host=host, port=port, exc=exc)
        raise EscalationDeliveryError(
            "Unable to connect to the SMTP server for escalation email.",
            reason="connection_error",
        ) from exc
    except smtplib.SMTPException as exc:
        _log_failure(logger, reason="smtp_error", host=host, port=port, exc=exc)
        raise EscalationDeliveryError(
            "Unexpected SMTP error while sending escalation email.",
            reason="smtp_error",
        ) from exc

    return None

```

## `atticus/tokenization.py`

```python
"""Tokenization utilities for chunking."""

from __future__ import annotations

from collections.abc import Iterable, Sequence
from functools import lru_cache

import tiktoken


@lru_cache(maxsize=1)
def _encoding() -> tiktoken.Encoding:
    return tiktoken.get_encoding("cl100k_base")


def encode(text: str) -> list[int]:
    return _encoding().encode(text, disallowed_special=())


def decode(tokens: Sequence[int]) -> str:
    return _encoding().decode(list(tokens))


def count_tokens(text: str) -> int:
    return len(encode(text))


def split_tokens(tokens: Sequence[int], window: int, overlap: int) -> Iterable[tuple[int, int]]:
    if window <= 0:
        raise ValueError("window must be positive")
    if overlap >= window:
        raise ValueError("overlap must be smaller than window")

    step = max(1, window - overlap)
    total = len(tokens)
    for start in range(0, total, step):
        end = min(start + window, total)
        yield start, end
        if end == total:
            break

```

## `atticus/utils/__init__.py`

```python
"""Helper utilities for Atticus."""

from .hashing import sha256_file, sha256_text

__all__ = ["sha256_file", "sha256_text"]

```

## `atticus/utils/hashing.py`

```python
"""Utility helpers for hashing and manifest management."""

from __future__ import annotations

import hashlib
from pathlib import Path


def sha256_file(path: Path) -> str:
    digest = hashlib.sha256()
    with path.open("rb") as handle:
        for chunk in iter(lambda: handle.read(8192), b""):
            digest.update(chunk)
    return digest.hexdigest()


def sha256_text(value: str) -> str:
    return hashlib.sha256(value.encode("utf-8")).hexdigest()

```

## `CHANGELOG.md`

```md
# Changelog

## [Unreleased]

### Merged from TODO_COMPLETE (Unversioned)

## TODO — Completed / Obsolete

This file is the **permanent log of completed tasks**.
Each entry includes the completion date and commit reference for traceability.

The following items are done or no longer relevant and are recorded here for traceability.

## Completed

- **FND-001 → FND-008** (Audit): Next.js UI, proxy contracts, schema ownership, env scaffolding, request-id propagation, CI audits — delivered.
- **Ask Contract & Streaming**: `/api/ask` SSE endpoint and UI consumer normalised; error contracts include `request_id`.
- **Frontend Hygiene & Repo Structure**: Legacy FastAPI UI archived; canonical Next.js app; docs updated.
- **DX & Docs**: Makefile `quality` runs Python + Next gates + audits; pre-commit configured; release docs added.
- **Structured Logging**: Centralised logger with JSON output; instrumented key scripts.
- **Unified CLI**: `scripts/atticus_cli.py` with Makefile alias `atticus`.

## Obsolete / Superseded

- “Prisma duplicates and `Glossary.synonyms` type fix” — resolved in current schema/migrations.
- “Decide on Framer Motion” — kept as optional; AGENTS reflects this.
- “Archive web/static” — done; legacy moved under `archive/legacy-ui/`.
- “CONTENT_DIR → CONTENT_ROOT rename” — standardised across code/docs.
- “Rebuild evaluator harness” — present via tests and `eval` target.
- “Glossary API error normalisation” — implemented with `request_id`.

---

### 2025-10-10

- [x] Added model parser/resolver unit tests, retrieval filter coverage, API clarification regressions, UI integration tests, and a gated Playwright chat clarification flow — completed 2025-10-10 (this change set).
- [x] Documented model disambiguation behaviour in `AGENTS.md`, `README.md`, and `docs/ATTICUS_DETAILED_GUIDE.md`; updated `CHANGELOG.md`, and reconciled TODO status — completed 2025-10-10 (this change set).
- [x] Verified direct/unclear/multi-model acceptance criteria via automated tests and ensured `make quality` (lint, typecheck, pytest, Next build, ts audit) passes end-to-end — completed 2025-10-10 (this change set).

---

### 2025-09-21

- [x] Provided `.env.example` for local configuration scaffolding — completed 2025-09-21 (commit 5df0d73).
- [x] Delivered Dockerized stack (API/Nginx Dockerfiles, docker-compose workflow, healthchecks, Makefile targets) — completed 2025-09-21 (commit 5df0d73).
- [x] Published hardened `nginx.conf` for TLS termination and proxying to the FastAPI service — completed 2025-09-21 (commit 5df0d73).
- [x] Established single-node, containerized stack with minimal dependencies — completed 2025-09-21 (commit 3013a1a).
- [x] Removed Azure AD/SSO code paths and noted migration in README — completed 2025-09-21 (commit 3013a1a).
- [x] Pinned OpenAI defaults to `text-embedding-3-large` and `gpt-4.1` — completed 2025-09-21 (commit 3013a1a).
- [x] Created base repository structure (`atticus/`, `api/`, `ingest/`, etc.) — completed 2025-09-21 (commit 3013a1a).
- [x] Added `.editorconfig`, `.gitattributes`, `.gitignore`, and `.vscode` settings — completed 2025-09-21 (commit 3013a1a).
- [x] Implemented pre-commit hooks with `ruff`, `mypy`, `markdownlint-cli2` — completed 2025-09-21 (commit 3013a1a).
- [x] Adopted `pip-tools` for locked dependencies — completed 2025-09-21 (commit 3013a1a).
- [x] Pinned core libraries (`fastapi`, `uvicorn`, `pydantic`, etc.) — completed 2025-09-21 (commit 3013a1a).
- [x] Built parsers for PDF, DOCX, XLSX, and HTML with OCR support — completed 2025-09-21 (commit 3013a1a).
- [x] Implemented evaluation harness with baseline metrics and gold set — completed 2025-09-21 (commit 3013a1a).

### 2025-09-23

- [x] Added environment generator (`scripts/generate_env.py`) with `--force` flag — completed 2025-09-23.
- [x] Implemented SMTP mailer (`atticus/notify/mailer.py`) using `.env` — completed 2025-09-23.
- [x] Created API `/contact` route for escalation email (202 Accepted) — completed 2025-09-23.
- [x] Built API `/ask` endpoint returning `{answer, sources, confidence}` — completed 2025-09-23.
- [x] Integrated modern UI served by FastAPI templates and static mounts — completed 2025-09-23.
- [x] Added `examples/dev.http` with sample `/ask` and `/contact` requests — completed 2025-09-23.

### 2025-09-25

- [x] Verified README/AGENTS/OPERATIONS cross-links and fixed relative paths - completed 2025-09-25 (commit 2a3b760).
- [x] Added SES IAM policy region lock guidance to SECURITY.md and reinforced README cross-link - completed 2025-09-25 (commit 2a3b760).
- [x] TODO "SECURITY.md — env-only secrets; SMTP `From` allow-list; RLS examples." - completed 2025-09-25 (commit 2a3b760).
- [x] Reviewed repository documentation set and normalised coverage messaging - completed 2025-09-25 (commit cd280f8).
- [x] Published secure remote access playbook (Tailscale, Cloudflare Tunnel, SSH) - completed 2025-09-25 (commit cd280f8).

### 2025-09-27

- [x] Implemented shared JSON error schema for API responses with request ID propagation tests — completed 2025-09-27 (commit 6dbf0b8).
- [x] TODO "Error JSON contract" - completed 2025-09-27 (commit 6dbf0b8).
- [x] Verified API-served UI via automated tests (pytest) and captured guidance in ATTICUS detailed guide - completed 2025-09-25 (commit cd280f8).
- [x] Enabled optional hybrid reranker with `ENABLE_RERANKER` flag and documented behaviour - completed 2025-09-25 (commit cd280f8).
- [x] Updated README hero copy to spotlight Sales/tender acceleration messaging - completed 2025-09-25 (commit cd280f8).
- [x] Documented `/ask` request/response schema in docs/api/README.md - completed 2025-09-25 (commit cd280f8).
- [x] Added `SMTP_DRY_RUN` mailer branch with tests and surfaced behaviour in docs - completed 2025-09-25 (commit cd280f8).
- [x] Made pytest parallelism conditional on pytest-xdist availability - completed 2025-09-25 (commit cd280f8).
- [x] Retired the legacy Jinja2/Eleventy UI in favour of a Tailwind-powered Next.js app covering chat, admin, settings, contact, and apps — completed 2025-09-27.

### 2025-09-28

- [x] TODO "Sample Seed corpus — Add verification tests and contributor docs." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "reports/ — Update evaluation pipeline to emit CSV/HTML artifacts." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "reports/ — Configure CI to upload artifacts and document consumption workflow." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "README.md — rewrite for Next.js/pgvector stack with Windows guidance and quick start." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "ARCHITECTURE.md — update diagrams/narrative for Next.js + SSE flow." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "OPERATIONS.md — document pgvector maintenance, CI parity, and dependency risk handling." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "TROUBLESHOOTING.md — capture Auth.js email flow, SSE mitigation, lint/format guidance." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "REQUIREMENTS.md — align runtime/tooling requirements with Next.js + Prisma stack." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "CI gates — align GitHub Actions + local make quality" — completed 2025-09-28 (commit 5c4ff5e).
  > Continue logging future completed tasks below, grouped by date, to maintain a clear historical record.

### 2025-09-29

- [x] TODO "Tests: ingestion/retrieval unit + integration suite, regenerate requirements lock." — completed 2025-09-29 (commit 04216be).

### 2025-09-30

- [x] TODO "TROUBLESHOOTING.md — Add pgvector + Prisma troubleshooting (extension enablement, migration drift)." — completed 2025-09-30 (commit b7779b8).

### 2025-10-04

- [x] TODO "`Makefile` — remove `ui` target (`http.server`); add Next.js scripts (`dev`, `build`, `start`); keep `api` until migration complete." — completed 2025-10-04 (commit b7779b8).
- [x] TODO "`api/routes/chat.py` and `api/routes/ask.py` — consolidate; ensure request_id & should_escalate; remove unused import in api/routes/**init**.py." — completed 2025-10-04 (commit 2af9f6e).
- [x] TODO "Dictionary/glossary admin — Design Prisma schema/API contracts for glossary records with approval workflow." — completed 2025-10-04 (commit 2bc7206).
- [x] TODO "Dictionary/glossary admin — Implement admin UI for propose/review/approve flows with RBAC checks." — completed 2025-10-04 (commit 2bc7206).

### 2025-10-05

- [x] TODO "`api/main.py` — drop Jinja2 templates/static mounts; stop serving `/` HTML; keep JSON APIs; Next.js owns UI." — completed 2025-10-05 (present in commit 9a7620b9; verified during backlog audit).
- [x] TODO "`ARCHITECTURE.md` & legacy `AGENTS.md` — replace FAISS/FastAPI mentions with references to this doc; mark migration phases." — completed 2025-10-05 (present in commit 9a7620b9; verified during backlog audit).

### 2025-10-10

- [x] TODO "Glossary Seed & Runbook" — completed 2025-10-10 (this PR aligns Prisma seeds, docs, and verification tests).

### 2025-10-11

- [x] TODO "Glossary UX Follow-through" — completed 2025-10-11 (added workflow sequence diagram, decision notes, and backlog links in `docs/glossary-spec.md`).

### 2025-10-12

- [x] TODO "RBAC Integration Coverage" — completed 2025-10-12 (Playwright reviewer/admin coverage, Next.js route RBAC tests, FastAPI admin token assertions, and `make quality` wiring).

### 2025-10-14

- [x] TODO "Phase 5 — Orphans & Structure Cleanup" — completed 2025-10-14 (FastAPI now sources its version from `VERSION`, docs highlight Next.js as the canonical UI, and release notes capture the separation of backend and frontend responsibilities).

### 2025-10-15

- [x] TODO "Admin Ops Console (Uncertain Chats, Tickets, Glossary)" — completed 2025-10-15 (introduced Prisma chat/ticket models, Next.js admin tabs, RBAC-aware API routes, and seeds/tests covering the reviewer/admin workflow).

### 2025-10-19

- [x] TODO "pgvector GUC Bootstrap" - completed 2025-10-19 (release 0.8.0 adds migrations and verification checks for `app.pgvector_lists`).
- [x] TODO "Version Parity Automation" - completed 2025-10-19 (release 0.8.0 ships `scripts/check_version_parity.py`, Makefile wiring, and docs).
- [x] TODO "Uncertain Chat Validation Flow" - completed 2025-10-19 (release 0.8.0 captures low-confidence chats, follow-up prompts, admin drawer UX, and audit events).
- [x] TODO "Dictionary (Glossary) Update Semantics" - completed 2025-10-19 (release 0.8.0 adds POST upsert/PUT updates, inline editing, and rag event auditing).

### 2025-10-30

- [x] Audited `TODO.md` and confirmed no outstanding backlog items remain; updated the file to reference the completion log.
- [x] Verified the model catalog in `indices/model_catalog.json` maps families ⇄ models/aliases as required by the backlog item.
- [x] Confirmed disambiguation utilities (`retriever/models.py`, `retriever/resolver.py`) and scoped retrieval (`retriever/service.py`) implement the parser/resolver tasks.
- [x] Checked the API and client flow updates in `api/routes/chat.py`, `app/api/ask/route.ts`, `lib/ask-contract.ts`, `lib/ask-client.ts`, and `components/AnswerRenderer.tsx` to ensure clarification + multi-answer behaviour is live.
- [x] Reviewed ingestion tagging updates in `ingest/pipeline.py` and supporting docs (`docs/api/README.md`, `README.md`) covering the model-family flows.

### Added

- Introduced the model catalog, parser, and resolver to support explicit family scoping, multi-answer payloads, and `/api/ask` clarifications when the model is unknown.
- Added clarification handling in the Next.js UI: the chat panel now renders family selection buttons, resubmits follow-up requests with `models`, and formats multi-model answers with per-answer citations.
- Tagged ingested chunks with `product_family` and `models` metadata, copied the Apeos C8180 series CED into the active corpus, and expanded `eval/gold_set.csv` with cross-family scenarios.
- Added regression coverage for model parsing/resolution, family-scoped retrieval filters, API clarification flows, UI integrations, and a gated Playwright chat clarification scenario.

### Changed

- Consolidated the active backlog into `TODO.md`, updated cross-references, and recorded completed tasks in `TODO_COMPLETE.md`.
- Resolved merge artefacts in `VERSION` to restore 0.7.2 as the canonical release number and flagged the follow-up automation in the backlog.
- Documented the model disambiguation contract across AGENTS, README, and `docs/ATTICUS_DETAILED_GUIDE.md`.
- Documentation: aligned environment variable names across AGENTS and runbooks (`AUTH_SECRET`, `EMAIL_SERVER_*`, `EMBEDDING_MODEL_VERSION`, `RATE_LIMIT_REQUESTS/WINDOW_SECONDS`), deduplicated repeated sections in `OPERATIONS.md` and `docs/glossary-spec.md`, fixed API error schema link, clarified `app/README.md` as experimental workspace, removed stale `ALL_DOCS.md`, and added `AUDIT_REPORT.md`.

---

## [0.8.1] — 2025-10-20

### Fixed

- Restored Playwright RBAC flows by persisting magic links to the default `./logs/mailbox` directory whenever `AUTH_DEBUG_MAILBOX_DIR` is unset, preserving the ability to disable persistence with an empty value and documenting the fallback for operators.

### Testing

- `npm run test:unit`

---

## [0.8.0] — 2025-10-19

### Added

- Automatic capture of low-confidence chat turns via `captureLowConfidenceChat`, including follow-up prompts, request metadata, and structured audit events stored in the new `RagEvent` ledger.
- Admin follow-up workflow with a review drawer, POST `/api/admin/uncertain/:id/ask-followup`, and deterministic seeds plus UI wiring for tracking prompts alongside escalations.
- Glossary upsert semantics with POST idempotency, PUT updates, inline editing, and audit logging to `rag_events` so term changes remain traceable.
- `scripts/check_version_parity.py` and a `make version-check` gate to keep `VERSION`, `package.json`, and `package-lock.json` synchronized during releases.
- Pgvector configuration migration that enforces the `app.pgvector_lists` GUC and verification SQL ensuring ANN indexes stay aligned with planner expectations.

### Changed

- Admin operations console now surfaces question context, answers, top sources, and follow-up prompts inside a Radix drawer to streamline approvals and escalations.
- Glossary management panel supports inline definition edits, optimistic saves, and PUT-based status transitions backed by rag event auditing.

### Testing

- `PYTHONPATH=. pytest tests/unit/admin-uncertain-route.test.ts tests/unit/glossary-route.test.ts -q`
- `npm run lint`
- `npm run test:unit`
- `CI=1 npm run build`

---

## [0.7.11] — 2025-10-15

### Added

- Prisma `Chat` and `Ticket` models with deterministic seeds plus admin API endpoints for listing, approving, and escalating low-confidence chats.
- Next.js admin operations console with Uncertain, Tickets, and Glossary tabs, including reviewer read-only safeguards and shadcn-powered tabs.
- Vitest coverage for admin API RBAC along with updated Playwright smoke ensuring reviewers stay constrained while admins manage glossary entries end-to-end.

### Testing

- `PYTHONPATH=. pytest tests/unit/admin-uncertain-route.test.ts -q`
- `npm run lint`
- `npm run test:unit`
- `CI=1 npm run build`

---

## [0.7.10] — 2025-10-14

### Added

- Pytest coverage ensuring the FastAPI application metadata reads directly from the repository `VERSION` file so version drift is caught automatically.

### Changed

- FastAPI now loads its version string from the shared `VERSION` file, eliminating manual sync steps with `package.json`.
- Documentation (README, AGENTS, ARCHITECTURE, OPERATIONS, REPO_STRUCTURE, release notes, and workspace settings) explicitly records that Next.js owns the UI while FastAPI serves JSON APIs only.

### Testing

- `pytest tests/test_api_version.py`
- `npm run lint`
- `npm run build`

---

## [0.7.9] — 2025-10-13

### Added

- Introduced shared shadcn-inspired primitives (`Card`, `Badge`) under `components/ui` and extended the button component with `asChild` support via `@radix-ui/react-slot` for consistent navigation styling.

### Changed

- Refreshed the chat workspace, admin overview, glossary management, settings, apps catalogue, and contact escalation form to compose the new card and badge primitives, aligning typography, spacing, and status indicators across the UI.
- Updated the site header to reuse the shared button component for sign-in/out flows and to standardise mobile navigation controls.
- Documented the frontend design system in `README.md` and noted the new dependency in `RELEASE.md` upgrade steps.

### Testing

- `npm run lint`
- `npm run build`

---

## [0.7.8] — 2025-10-12

### Added

- Playwright RBAC coverage to confirm reviewers are redirected from `/admin`, blocked from `/api/glossary`, and that admins can create/delete glossary entries end-to-end.
- Vitest unit tests for Next.js glossary route handlers to assert reviewer read access, admin-only mutations, and reviewer metadata stamping on approvals.

### Changed

- FastAPI admin dictionary tests now assert 403 contracts for invalid tokens, `make quality` runs Vitest + Playwright in addition to existing gates, and documentation reflects the expanded quality bar.

---

## [0.7.7] — 2025-10-11

### Changed

- Documented the glossary review workflow with a Mermaid sequence diagram, decision notes, and backlog links in `docs/glossary-spec.md`.
- Removed the fulfilled Glossary UX backlog item from `TODO.md` and logged completion in `TODO_COMPLETE.md`.

### Testing

- Documentation-only change; no automated tests were run.

---

## [0.7.6] — 2025-10-10

### Added

- Seeded deterministic glossary fixtures (approved, pending, rejected) with dedicated reviewer/author accounts for smoke tests.

### Changed

- Documented glossary seeding, verification, and rollback workflows in `OPERATIONS.md` and `docs/glossary-spec.md`.
- Pruned the completed glossary seed backlog item from `TODO.md` and logged the closure in `TODO_COMPLETE.md`.

### Testing

- `pytest tests/test_seed_manifest.py::test_glossary_seed_entries_round_trip` *(skipped: requires DATABASE_URL and npm in CI/dev)*

---

## [0.7.5] — 2025-10-09

### Added

- Recorded the Phase 0 baseline verification summary in `reports/todo-phase-0-baseline.md` to document current blockers before implementation work begins.

### Changed

- Bumped the tracked release version to 0.7.5 to capture the Phase 0 baseline report.

### Testing

- `make db.verify` (fails: missing `DATABASE_URL` in the execution environment).
- `make quality` (fails: mypy reports an unused `type: ignore` in `ingest/parsers/xlsx.py`).

---

## [0.7.4] — 2025-10-07

### Changed

- Streamlined the chat workspace to focus on live conversations and removed legacy highlight cards.
- Hid the Settings navigation link for unauthenticated visitors and removed redundant contact escalation callouts.
- Cleared footer navigation links to maintain spacing without duplicate destinations.

### Testing

- `npm run lint`
- `npm run typecheck`
- `npm run build`

- Switched the CED chunker to a zero-overlap default across configuration, ingestion scripts, and metadata snapshots.
- Allowed explicit `CHUNK_OVERLAP_TOKENS=0` in environment configuration and documentation so bespoke corpora can opt back into overlap deliberately.
- `PYTHONPATH=. pytest tests/test_ingestion_retrieval_integration.py -vv`

### Documentation

- Highlighted the zero-overlap behaviour in the README quick start and CED chunking guide.

---

## [0.7.3] — 2025-10-06

### Changed

- Documented the required environment export before running `make db.verify` and removed the redundant Prisma client generation step from the README developer workflow.
- Added source attribution, hashed fingerprints, and sanitized snapshots to `python scripts/debug_env.py` by implementing `atticus.config.environment_diagnostics`.

### Added

- Regression coverage for the new environment diagnostics helper to ensure secrets remain redacted while reporting their provenance.

### Testing

- `ruff check .`
- `ruff format --check .`
- `mypy atticus api ingest retriever eval`
- `PYTHONPATH=. pytest tests/test_hashing.py tests/test_config_reload.py tests/test_mailer.py tests/test_chunker.py tests/test_seed_manifest.py tests/test_eval_runner.py tests/test_environment_diagnostics.py`
- `PYTHONPATH=. pytest tests/test_chat_route.py tests/test_contact_route.py tests/test_error_schema.py tests/test_ui_route.py tests/test_admin_route.py`
- `PYTHONPATH=. pytest tests/test_ingestion_retrieval_integration.py -vv`
- `npm run test:unit`
- `npm run lint`
- `npm run typecheck`
- `npm run build`
- `npm run audit:ts`
- `npm run audit:icons`
- `npm run audit:routes`
- `npm run audit:py`

---

## [0.7.2] — 2025-10-05

### Changed

- Synchronized all version sources (`VERSION`, `package.json`, FastAPI metadata) at 0.7.2 and documented the change in the audit report.
- Trimmed resolved findings from `audit_summary.md` and `AUDIT_REPORT.md`, highlighting the remaining remediation work for Phases 0–5.
- Updated `TODO.md`/`TODO_COMPLETE.md` to remove completed items, backfill commit references, and keep the active backlog authoritative.
- Clarified that Framer Motion is optional in `AGENTS.md`, aligning guidance with current dependencies.

### Fixed

- Marked finished audit tasks as complete, ensuring the ledger, audit summary, and changelog stay in sync.

---

## [0.7.1] — 2025-10-05

### Added

- Web and database security assessment recorded at `reports/security/2025-10-05-web-db-assessment.md`, detailing dependency vulnerabilities, configuration hardening, and pgvector prerequisites.

### Changed

- Bumped repository version to 0.7.1 to publish the audit findings and align `package.json`/`VERSION` metadata.

### Security

- Flagged critical Next.js 14.2.5 advisories (cache poisoning, image optimisation DoS/injection) and outlined mitigation steps, including immediate upgrade guidance for `next`, `next-auth`, and supporting tooling.

## [0.7.0] — 2025-09-28

### Added

- Prettier configuration (with Tailwind sorting), ESLint tailwindcss plugin, and local hooks to enforce formatting for shadcn/ui components.
- `VERSION` file as the single source of truth for release numbers and alignment with `package.json`.
- GitHub Actions `frontend-quality` job (Node 20 + Postgres service) uploading audit artifacts from Knip, route inventory, and Python dead-code scan.
- `scripts/icon-audit.mjs` for lucide-react import hygiene without relying on Knip plugins.

### Changed

- `make quality` now chains Ruff, mypy, pytest, Next.js lint/typecheck/build, and audit scripts to mirror CI.
- `.pre-commit-config.yaml` runs ESLint and Prettier alongside Ruff/mypy/markdownlint for consistent developer experience.
- `.eslintrc.json` extended with tailwindcss plugin + Prettier compatibility; package scripts updated with `format` / `format:check`.
- README, AGENTS, IMPLEMENTATION_PLAN, ARCHITECTURE, OPERATIONS, TROUBLESHOOTING, REQUIREMENTS, and RELEASE docs rewritten for the Next.js + pgvector stack, CI gates, and release workflow.
- `.github/workflows/lint-test.yml` expanded with audit artifact uploads; `.gitignore` ignores `reports/ci/` outputs.

### Known Issues

- `npm audit` reports one critical (Next.js middleware) and seven moderate/low vulnerabilities without upstream fixes as of 2025-09-28. Mitigations documented in OPERATIONS/TROUBLESHOOTING pending vendor patches.

### Testing

- `make quality`
- `npm run lint`
- `npm run typecheck`
- `npm run build`
- `pytest --maxfail=1 --disable-warnings --cov=atticus --cov=api --cov=retriever --cov-report=term-missing --cov-fail-under=90 -q`

---

## [0.5.3] — 2025-10-04

### Added

- Next.js `/api/ask` route proxying the FastAPI retriever with SSE support and shared TypeScript/Pydantic DTOs.
- Streaming chat client (`components/chat/chat-panel.tsx`) with typed `lib/ask-client.ts` helper and Vitest coverage for SSE parsing.
- Prisma migration extending `GlossaryEntry` with synonyms and review metadata alongside tests for the FastAPI admin dictionary route.

### Changed

- FastAPI `AskResponse` now returns `sources` objects (`path`, `page`, `heading`, `chunkId`, `score`) and honours `contextHints`/`topK` overrides.
- Glossary admin UI exposes synonyms, review notes, and reviewer timestamps; TROUBLESHOOTING now documents Auth.js magic link and SSE debugging steps (including PowerShell flows).
- `.env.example` documents the `RAG_SERVICE_URL` required for the Next.js proxy, and README details the streaming `/api/ask` contract.

### Testing

- `npm run test:unit`
- `pytest tests/test_chat_route.py`
- `pytest tests/test_admin_route.py`

## [0.5.2] — 2025-09-30

### Added

- Prisma models and migrations for `atticus_documents` and `atticus_chunks`, aligning pgvector storage with the shared data layer.
- `make db.verify` target plus CI workflow to run `scripts/verify_pgvector.sql` against a pgvector-enabled Postgres service.

### Changed

- Documented pgvector verification steps in README, OPERATIONS, and TROUBLESHOOTING with PowerShell equivalents.
- Noted `psycopg[binary]` usage in Python tooling to keep local workflows consistent with Prisma migrations.

### Testing

- `npm run db:migrate` *(fails locally without Postgres; covered in CI)*
- `make db.verify` *(requires `psql` client; enforced in CI)*
- `npm run audit:ts`

---

## [0.6.2] — 2025-09-29

### Added

- In-memory pgvector repository test double covering ingestion reuse and retrieval ranking behaviour.
- Integration coverage ensuring the ingestion pipeline writes manifests/metadata and retrieval answers honour citations.

### Changed

- Regenerated Python dependency lockfile (`requirements.txt`) via `pip-compile` to capture upstream security updates.

### Testing

- `pytest tests/test_chunker.py tests/test_seed_manifest.py`
- `pytest tests/test_ingestion_retrieval_integration.py`

---

## [0.6.1] — 2025-09-28

### Added

- Regression test for the seed manifest generator plus contributor checklist guidance.
- HTML evaluation dashboard (`metrics.html`) emitted alongside CSV/JSON artifacts and exposed via API/CLI.

### Changed

- `make test.unit` now executes seed manifest and evaluation artifact tests to keep ingestion guardrails enforced.
- README and reports documentation updated to describe deterministic evaluation artifacts and CI uploads.

### Testing

- `pytest tests/test_seed_manifest.py`
- `pytest tests/test_eval_runner.py`
- `pytest tests/test_mailer.py`
- `pytest tests/test_chunker.py`

---

## [0.6.0] — 2025-10-01

### Added

- CED chunkers with SHA-256 dedupe, ingestion manifest updates, and a `make seed` workflow for deterministic seed manifests.
- SMTP escalation allow-list enforcement, trace payload attachments, and admin metrics dashboards with latency histograms.
- Sample evaluation artifact scaffolding under `reports/` and glossary specification documentation.

### Changed

- Logging now propagates trace IDs across events and metrics capture P95 latency plus histogram buckets.
- API middleware enforces per-user/IP rate limiting with structured 429 responses and hashed identifiers.
- README, OPERATIONS, REQUIREMENTS, and TROUBLESHOOTING guides updated for ingestion, observability, and guardrail workflows.

### Testing

- `pytest tests/test_mailer.py`
- `pytest tests/test_chat_route.py`

---

## [0.4.1] — 2025-09-28

### Added

- Dedicated `make smoke`, `make test.unit`, and `make test.api` targets for lightweight verification workflows.

### Changed

- Unified the `/ask` endpoint to return the canonical `{answer, citations, confidence, should_escalate, request_id}` contract and removed the duplicate chat handler.
- Disabled FastAPI's autogenerated docs and removed the placeholder root route now that the UI is fully served by Next.js.
- Bumped the API/Next.js workspace version to 0.4.1.

### Fixed

- Legacy static chat client now renders citations and escalation notices from the canonical API response shape.

---

## [0.5.1] — 2025-09-27

### Fixed

- Resolved Auth.js and RBAC type regressions by aligning session shape, callback signatures, and server helpers with NextAuth definitions.
- Restored TypeScript coverage for glossary admin handlers and unit tests, unblocking `npm run typecheck`.

### Testing

- `npm run typecheck`
- `npm run test:unit`

---

## [0.5.0] — 2025-09-27

### Added

- Auth.js email magic link authentication with Prisma adapter, Postgres schema, and RLS enforcement.
- Database-backed glossary admin APIs plus UI gated to `ADMIN` role; persisted glossary storage with author/audit metadata.
- Vitest unit tests and Playwright RBAC journey along with Make targets (`db.*`, `web-test`, `web-e2e`) and runbook documentation.

### Changed

- Site navigation now reflects session state (sign-in/out) and protects `/admin` behind middleware + server checks.
- Docker Compose, Makefile, and README updated for Postgres lifecycle, Prisma migrations, and auth onboarding.

---

## [0.4.0] — 2025-09-27

### Added

- Next.js workspace with routes for chat, admin, settings, contact, and apps plus Tailwind styling.
- Shared layout with responsive navigation, hero components, and contextual admin tiles.

### Changed

- Makefile commands now proxy Next.js workflows (`make ui`, `make web-build`, `make web-start`).
- Project version bumped to 0.4.0 across the API and frontend manifest.

### Removed

- Legacy Jinja2/Eleventy templates and static Tailwind build scripts.

---

## [0.3.0] — 2025-09-27

### Changed

- Standardized API error responses on the shared JSON schema with request ID propagation and regression tests for 400/401/422/5xx cases.

---

## [0.2.4] — 2025-09-25

### Added

- `scripts/debug_env.py` to print sanitized diagnostics for secrets sourcing.
- Tests covering environment priority selection and conflict reporting for OpenAI API keys.

### Changed

- `.env` secrets preferred by default; can be overridden with `ATTICUS_ENV_PRIORITY=os`.
- Enhanced `scripts/generate_env.py` with `--ignore-env` and fingerprint logging.

---

## [0.2.3] — 2025-09-24

### Changed

- Rebuilt web chat surface with modern layout and collapsible navigation.
- Expanded README with Docker Compose and Nginx reverse-proxy deployment steps.

### Fixed

- Automatic settings regeneration to eliminate stale OpenAI API keys during sessions.

---

## [0.2.2] — 2025-09-22

### Changed

- Bumped patch version to 0.2.2.
- Included `eval/harness` and `scripts` in pytest discovery.
- Cleaned unused `type: ignore` comments and applied Ruff auto-fixes.

---

## [0.2.1] — 2025-09-21

### Fixed

- Windows install failures caused by `uvloop` dependency.
- Improved evaluation harness to allow tests without FAISS/OpenAI installed.

### Added

- OCR resilience with better Tesseract error handling.

---

## [0.2.0] — 2025-09-21

### Added

- Introduced `config.yaml`/`.env` harmony with `atticus.config.load_settings()`.
- CLI utilities for ingestion, evaluation, and rollback.
- Rich ingestion metadata (breadcrumbs, model version, token spans).
- GitHub Actions for linting, testing, evaluation gating, and tagged releases.

### Changed

- Updated retrieval fallback responses to include bullet citations.
- Refreshed documentation and chunking workflow.

### Evaluation

- Baseline metrics recorded: nDCG@10: **0.55**, Recall@50: **0.60**, MRR: **0.5333**.

---

## [0.1.0] — 2025-09-20

### Added

- Initial content taxonomy and ingestion pipeline with deterministic embeddings and JSON logging.
- Retrieval helpers, observability metrics, and ingestion CLI.
- Seeded evaluation harness with gold set and baseline metrics.

---

```

## `components/admin/admin-ops-console.tsx`

```tsx
"use client";

import { useEffect, useMemo, useState, useTransition } from "react";
import { Role } from "@prisma/client";
import { Badge } from "@/components/ui/badge";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from "@/components/ui/table";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { GlossaryAdminPanel, GlossaryEntryDto } from "@/components/glossary/admin-panel";
import { Drawer, DrawerBody, DrawerContent, DrawerFooter, DrawerHeader } from "@/components/ui/drawer";
import { Textarea } from "@/components/ui/textarea";

export type SourceSummary = {
  path: string;
  score: number | null;
  page: number | null;
  heading: string | null;
  chunkId: string | null;
};

export type UncertainChat = {
  id: string;
  question: string;
  answer: string | null;
  confidence: number;
  status: string;
  requestId: string | null;
  createdAt: string;
  topSources: SourceSummary[];
  author: { id: string; email: string | null; name: string | null } | null;
  reviewer: { id: string; email: string | null; name: string | null } | null;
  tickets: Array<{
    id: string;
    key: string;
    status: string;
    assignee: string | null;
    lastActivity: string | null;
  }>;
  followUpPrompt: string | null;
  auditLog: Array<Record<string, unknown>>;
};

export type TicketSummary = {
  id: string;
  key: string;
  status: string;
  assignee: string | null;
  lastActivity: string | null;
  summary: string | null;
};

interface AdminOpsConsoleProps {
  role: Role;
  uncertain: UncertainChat[];
  tickets: TicketSummary[];
  glossaryEntries: GlossaryEntryDto[];
}

function confidenceVariant(confidence: number): "success" | "warning" | "destructive" {
  if (confidence >= 0.75) {
    return "success";
  }
  if (confidence >= 0.45) {
    return "warning";
  }
  return "destructive";
}

export function AdminOpsConsole({ role, uncertain, tickets, glossaryEntries }: AdminOpsConsoleProps) {
  const [uncertainChats, setUncertainChats] = useState(uncertain);
  const [ticketSummaries, setTicketSummaries] = useState(tickets);
  const [feedback, setFeedback] = useState<string | null>(null);
  const [isPending, startTransition] = useTransition();
  const [drawerChatId, setDrawerChatId] = useState<string | null>(null);
  const [followUpDraft, setFollowUpDraft] = useState("");

  const canApprove = role === Role.ADMIN || role === Role.REVIEWER;
  const canEscalate = role === Role.ADMIN;
  const canManageGlossary = role === Role.ADMIN;
  const defaultTab = role === Role.ADMIN ? "uncertain" : "glossary";

  const activeChat = useMemo(
    () => uncertainChats.find((chat) => chat.id === drawerChatId) ?? null,
    [drawerChatId, uncertainChats]
  );

  useEffect(() => {
    setFollowUpDraft(activeChat?.followUpPrompt ?? "");
  }, [activeChat?.followUpPrompt, drawerChatId]);

  function openDrawer(chatId: string) {
    setDrawerChatId(chatId);
    setFeedback(null);
  }

  async function handleApprove(chatId: string) {
    if (!canApprove) {
      return;
    }
    setFeedback(null);
    startTransition(async () => {
      const response = await fetch(`/api/admin/uncertain/${chatId}/approve`, { method: "POST" });
      if (!response.ok) {
        const body = await response.json().catch(() => ({}));
        setFeedback(body.detail ?? "Unable to approve chat.");
        return;
      }
      setUncertainChats((prev) => prev.filter((chat) => chat.id !== chatId));
      setFeedback("Chat approved and removed from the uncertain queue.");
      if (drawerChatId === chatId) {
        setDrawerChatId(null);
      }
    });
  }

  async function handleEscalate(chat: UncertainChat) {
    if (!canEscalate) {
      return;
    }
    setFeedback(null);
    startTransition(async () => {
      const response = await fetch(`/api/admin/uncertain/${chat.id}/escalate`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ summary: chat.question, assignee: chat.tickets.at(0)?.assignee ?? null }),
      });
      if (!response.ok) {
        const body = await response.json().catch(() => ({}));
        setFeedback(body.detail ?? "Unable to escalate chat.");
        return;
      }
      const ticket = (await response.json()) as TicketSummary;
      setUncertainChats((prev) => prev.filter((item) => item.id !== chat.id));
      setTicketSummaries((prev) => [{ ...ticket, summary: chat.question }, ...prev]);
      setFeedback(`Escalated to ticket ${ticket.key}.`);
      if (drawerChatId === chat.id) {
        setDrawerChatId(null);
      }
    });
  }

  function updateChat(chatId: string, partial: Partial<UncertainChat>) {
    setUncertainChats((prev) => prev.map((chat) => (chat.id === chatId ? { ...chat, ...partial } : chat)));
  }

  async function handleFollowUpSave(chat: UncertainChat) {
    if (!canApprove) {
      return;
    }
    const trimmed = followUpDraft.trim();
    if (!trimmed) {
      setFeedback("Add a follow-up prompt before saving.");
      return;
    }
    setFeedback(null);
    startTransition(async () => {
      const response = await fetch(`/api/admin/uncertain/${chat.id}/ask-followup`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ prompt: trimmed }),
      });
      if (!response.ok) {
        const body = await response.json().catch(() => ({}));
        setFeedback(body.detail ?? "Unable to store follow-up prompt.");
        return;
      }
      const payload = await response.json();
      updateChat(chat.id, { followUpPrompt: payload.followUpPrompt, auditLog: payload.auditLog ?? [] });
      setFeedback("Follow-up prompt saved.");
    });
  }

  const ticketCount = ticketSummaries.length;
  const pendingCount = uncertainChats.length;

  const ticketCards = useMemo(
    () =>
      ticketSummaries.map((ticket) => {
        const lastActivity = ticket.lastActivity ? new Date(ticket.lastActivity).toLocaleString() : "N/A";
        return (
          <Card key={ticket.id} className="border-slate-200 dark:border-slate-800">
            <CardHeader className="pb-3">
              <CardTitle className="flex items-center justify-between text-base">
                <span>{ticket.key}</span>
                <Badge variant="outline" className="capitalize">
                  {ticket.status}
                </Badge>
              </CardTitle>
              <CardDescription>Assigned to {ticket.assignee ?? "Unassigned"}</CardDescription>
            </CardHeader>
            <CardContent className="space-y-2 text-sm text-slate-600 dark:text-slate-300">
              <p>{ticket.summary ?? "No summary provided."}</p>
              <p className="text-xs text-slate-500 dark:text-slate-400">Last activity: {lastActivity}</p>
            </CardContent>
          </Card>
        );
      }),
    [ticketSummaries]
  );

  return (
    <>
      <Tabs defaultValue={defaultTab} className="space-y-6">
        <TabsList>
          <TabsTrigger aria-label="Uncertain" value="uncertain">Uncertain ({pendingCount})</TabsTrigger>
          <TabsTrigger aria-label="Tickets" value="tickets">Tickets ({ticketCount})</TabsTrigger>
          <TabsTrigger aria-label="Glossary" value="glossary">Glossary</TabsTrigger>
      </TabsList>
      {feedback ? (
        <Badge variant="subtle" className="normal-case">
          {feedback}
        </Badge>
      ) : null}
      <TabsContent value="uncertain">
        <div className="overflow-x-auto">
          <Table>
            <TableHeader>
              <TableRow>
                <TableHead>Question</TableHead>
                <TableHead>Confidence</TableHead>
                <TableHead>Top sources</TableHead>
                <TableHead>Requester</TableHead>
                <TableHead>Created</TableHead>
                <TableHead className="text-right">Actions</TableHead>
              </TableRow>
            </TableHeader>
            <TableBody>
              {uncertainChats.map((chat) => (
                <TableRow key={chat.id}>
                  <TableCell className="max-w-xs align-top">
                    <p className="font-medium text-slate-900 dark:text-white">{chat.question}</p>
                    {chat.requestId ? (
                      <p className="mt-2 text-xs text-slate-500 dark:text-slate-400">Request {chat.requestId}</p>
                    ) : null}
                  </TableCell>
                  <TableCell className="align-top">
                    <Badge variant={confidenceVariant(chat.confidence)}>
                      {(chat.confidence * 100).toFixed(0)}%
                    </Badge>
                  </TableCell>
                  <TableCell className="align-top text-sm text-slate-600 dark:text-slate-300">
                    <ul className="space-y-1">
                      {chat.topSources.length ? (
                        chat.topSources.map((source, index) => (
                          <li key={`${chat.id}-source-${index}`} className="flex flex-col">
                            <span className="truncate text-xs text-slate-500 dark:text-slate-400">
                              {source.path}
                            </span>
                            {source.heading ? (
                              <span className="text-xs text-slate-400 dark:text-slate-500">
                                {source.heading}
                              </span>
                            ) : null}
                            <div className="flex flex-wrap gap-2 text-[11px] text-slate-400 dark:text-slate-500">
                              {source.page != null ? <span>Page {source.page}</span> : null}
                              {source.score != null ? (
                                <span>Score {(source.score * 100).toFixed(1)}%</span>
                              ) : null}
                              {source.chunkId ? <span>{source.chunkId}</span> : null}
                            </div>
                          </li>
                        ))
                      ) : (
                        <li className="text-xs text-slate-500 dark:text-slate-400">No sources captured.</li>
                      )}
                    </ul>
                  </TableCell>
                  <TableCell className="align-top text-sm text-slate-600 dark:text-slate-300">
                    <p>{chat.author?.name ?? chat.author?.email ?? "Unknown"}</p>
                  </TableCell>
                  <TableCell className="align-top text-sm text-slate-600 dark:text-slate-300">
                    {new Date(chat.createdAt).toLocaleString()}
                  </TableCell>
                  <TableCell className="align-top text-right">
                    <div className="flex flex-col items-end gap-2">
                      <Button
                        type="button"
                        size="sm"
                        onClick={() => openDrawer(chat.id)}
                        variant="default"
                      >
                        Review
                      </Button>
                      <Button
                        type="button"
                        size="sm"
                        variant="secondary"
                        disabled={!canApprove || isPending}
                        onClick={() => handleApprove(chat.id)}
                      >
                        Approve
                      </Button>
                      <Button
                        type="button"
                        size="sm"
                        variant="outline"
                        disabled={!canEscalate || isPending}
                        onClick={() => handleEscalate(chat)}
                      >
                        Escalate
                      </Button>
                    </div>
                  </TableCell>
                </TableRow>
              ))}
              {uncertainChats.length === 0 ? (
                <TableRow>
                  <TableCell colSpan={6} className="py-8 text-center text-sm text-slate-500 dark:text-slate-400">
                    All caught up. Pending review chats will appear here automatically.
                  </TableCell>
                </TableRow>
              ) : null}
            </TableBody>
          </Table>
        </div>
      </TabsContent>
      <TabsContent value="tickets">
        <div className="grid gap-4 md:grid-cols-2">{ticketCards}</div>
        {ticketSummaries.length === 0 ? (
          <Card className="mt-4 border-dashed">
            <CardHeader>
              <CardTitle>No escalations yet</CardTitle>
              <CardDescription>
                Approve chats or escalate them to create AE tickets that appear in this queue.
              </CardDescription>
            </CardHeader>
          </Card>
        ) : null}
      </TabsContent>
      <TabsContent value="glossary" className="p-0">
        <GlossaryAdminPanel initialEntries={glossaryEntries} canEdit={canManageGlossary} />
      </TabsContent>
      </Tabs>
      <Drawer
        open={drawerChatId !== null}
        onOpenChange={(open: boolean) => {
          if (!open) {
            setDrawerChatId(null);
            setFollowUpDraft("");
          }
        }}
      >
        <DrawerContent>
          <DrawerHeader>
            <div className="flex-1">
              <p className="text-xs uppercase text-slate-400">Review uncertain chat</p>
              <p className="mt-1 text-base font-semibold text-slate-900 dark:text-white">
                {activeChat?.question ?? "No chat selected"}
              </p>
              {activeChat ? (
                <p className="mt-2 text-xs text-slate-500 dark:text-slate-400">
                  Captured {new Date(activeChat.createdAt).toLocaleString()}
                </p>
              ) : null}
            </div>
          </DrawerHeader>
          <DrawerBody>
            {activeChat ? (
              <div className="space-y-6">
                <div className="flex flex-wrap items-center gap-3">
                  <Badge variant={confidenceVariant(activeChat.confidence)}>
                    {(activeChat.confidence * 100).toFixed(1)}%
                  </Badge>
                  {activeChat.requestId ? (
                    <span className="text-xs text-slate-500 dark:text-slate-400">
                      Request {activeChat.requestId}
                    </span>
                  ) : null}
                  <span className="text-xs capitalize text-slate-500 dark:text-slate-400">
                    Status {activeChat.status}
                  </span>
                </div>
                <section className="space-y-2">
                  <h3 className="text-sm font-semibold text-slate-900 dark:text-white">Answer</h3>
                  <div className="rounded-md border border-slate-200 bg-slate-50 p-4 text-sm leading-relaxed text-slate-700 dark:border-slate-800 dark:bg-slate-900 dark:text-slate-200">
                    {activeChat.answer?.length ? activeChat.answer : "No answer captured for this request."}
                  </div>
                </section>
                <section className="space-y-2">
                  <h3 className="text-sm font-semibold text-slate-900 dark:text-white">Top sources</h3>
                  <ul className="space-y-2 text-xs text-slate-500 dark:text-slate-400">
                    {activeChat.topSources.length ? (
                      activeChat.topSources.map((source, index) => (
                        <li key={`${activeChat.id}-drawer-source-${index}`} className="rounded-md border border-slate-200 p-3 dark:border-slate-800">
                          <p className="font-medium text-slate-700 dark:text-slate-200">{source.path}</p>
                          {source.heading ? <p className="mt-1">{source.heading}</p> : null}
                          <div className="mt-2 flex flex-wrap gap-3">
                            {source.page != null ? <span>Page {source.page}</span> : null}
                            {source.score != null ? <span>Score {(source.score * 100).toFixed(1)}%</span> : null}
                            {source.chunkId ? <span>{source.chunkId}</span> : null}
                          </div>
                        </li>
                      ))
                    ) : (
                      <li>No sources recorded for this chat.</li>
                    )}
                  </ul>
                </section>
                <section className="space-y-2">
                  <h3 className="text-sm font-semibold text-slate-900 dark:text-white">Follow-up prompt</h3>
                  <Textarea
                    value={followUpDraft}
                    onChange={(event) => setFollowUpDraft(event.target.value)}
                    minLength={3}
                    rows={4}
                    placeholder="What would you ask next?"
                    disabled={!canApprove || isPending}
                  />
                  {activeChat.followUpPrompt ? (
                    <p className="text-xs text-slate-500 dark:text-slate-400">
                      Last saved prompt: “{activeChat.followUpPrompt}”
                    </p>
                  ) : null}
                </section>
              </div>
            ) : (
              <p className="text-sm text-slate-500 dark:text-slate-400">Select a chat to review details.</p>
            )}
          </DrawerBody>
          <DrawerFooter className="flex flex-col gap-3 sm:flex-row sm:items-center sm:justify-between">
            <div className="flex flex-wrap gap-2">
              <Button
                type="button"
                size="sm"
                disabled={!activeChat || !canApprove || isPending}
                onClick={() => activeChat && handleFollowUpSave(activeChat)}
              >
                Save follow-up
              </Button>
              <Button
                type="button"
                size="sm"
                variant="secondary"
                disabled={!activeChat || !canApprove || isPending}
                onClick={() => activeChat && handleApprove(activeChat.id)}
              >
                Approve
              </Button>
              <Button
                type="button"
                size="sm"
                variant="outline"
                disabled={!activeChat || !canEscalate || isPending}
                onClick={() => activeChat && handleEscalate(activeChat)}
              >
                Escalate
              </Button>
            </div>
            <div className="text-xs text-slate-500 dark:text-slate-400">
              Actions are recorded in the chat audit trail.
            </div>
          </DrawerFooter>
        </DrawerContent>
      </Drawer>
    </>
  );
}

```

## `components/admin/content-manager.tsx`

```tsx
"use client";

import { useMemo, useRef, useState } from "react";
import type { ContentEntry } from "@/lib/content-manager";

type AlertState =
  | { type: "success"; message: string }
  | { type: "error"; message: string }
  | { type: "info"; message: string }
  | null;

interface ContentManagerProps {
  initialPath: string;
  initialEntries: ContentEntry[];
}

function normalisePath(path: string): string {
  if (!path || path === ".") {
    return ".";
  }
  return path.replace(/^\.\/+/, "").replace(/\\/g, "/");
}

export function ContentManager({ initialPath, initialEntries }: ContentManagerProps) {
  const [currentPath, setCurrentPath] = useState<string>(normalisePath(initialPath));
  const [entries, setEntries] = useState<ContentEntry[]>(initialEntries);
  const [alert, setAlert] = useState<AlertState>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [isIngesting, setIsIngesting] = useState(false);
  const [changesPending, setChangesPending] = useState(false);
  const [ingestionLogs, setIngestionLogs] = useState<string[]>([]);
  const [documentCount, setDocumentCount] = useState<number | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const breadcrumb = useMemo(() => {
    const path = normalisePath(currentPath);
    if (path === ".") {
      return [];
    }
    return path.split("/").filter(Boolean);
  }, [currentPath]);

  function showAlert(state: AlertState) {
    setAlert(state);
    if (state && state.type !== "info") {
      setTimeout(() => setAlert(null), 4000);
    }
  }

  async function refresh(path: string) {
    setIsLoading(true);
    try {
      const target = normalisePath(path);
      const response = await fetch(
        `/api/admin/content/list?path=${encodeURIComponent(target === "." ? "." : target)}`
      );
      if (!response.ok) {
        const payload = await response.json().catch(() => ({}));
        const message = payload.error ?? "Unable to retrieve directory contents.";
        throw new Error(message);
      }
      const payload = (await response.json()) as { entries: ContentEntry[] };
      setEntries(payload.entries);
      setCurrentPath(target);
    } catch (error) {
      const message = error instanceof Error ? error.message : "Failed to load directory.";
      showAlert({ type: "error", message });
    } finally {
      setIsLoading(false);
    }
  }

  async function handleNavigate(entry: ContentEntry) {
    if (entry.type !== "directory") {
      return;
    }
    await refresh(entry.path);
  }

  async function handleBreadcrumb(index: number) {
    if (index < 0) {
      await refresh(".");
      return;
    }
    const target = breadcrumb.slice(0, index + 1).join("/");
    await refresh(target || ".");
  }

  async function handleUpload(files: FileList | null) {
    if (!files || files.length === 0) {
      return;
    }
    setIsLoading(true);
    try {
      for (const file of Array.from(files)) {
        const formData = new FormData();
        formData.set("path", currentPath);
        formData.set("file", file);
        const response = await fetch("/api/admin/content/upload", { method: "POST", body: formData });
        if (!response.ok) {
          const payload = await response.json().catch(() => ({}));
          const message = payload.error ?? `Failed to upload ${file.name}.`;
          throw new Error(message);
        }
      }
      await refresh(currentPath);
      setChangesPending(true);
      showAlert({ type: "success", message: "File upload complete." });
    } catch (error) {
      const message = error instanceof Error ? error.message : "Upload failed.";
      showAlert({ type: "error", message });
    } finally {
      setIsLoading(false);
      if (fileInputRef.current) {
        fileInputRef.current.value = "";
      }
    }
  }

  async function handleCreateFolder() {
    const folderName = window.prompt("Folder name");
    if (!folderName) {
      return;
    }
    setIsLoading(true);
    try {
      const response = await fetch("/api/admin/content/folder", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ parentPath: currentPath, folderName }),
      });
      if (!response.ok) {
        const payload = await response.json().catch(() => ({}));
        const message = payload.error ?? "Unable to create folder.";
        throw new Error(message);
      }
      await refresh(currentPath);
      setChangesPending(true);
      showAlert({ type: "success", message: `Created folder ${folderName}.` });
    } catch (error) {
      const message = error instanceof Error ? error.message : "Folder creation failed.";
      showAlert({ type: "error", message });
    } finally {
      setIsLoading(false);
    }
  }

  async function handleDelete(entry: ContentEntry) {
    const confirmed = window.confirm(`Delete ${entry.name}? This cannot be undone.`);
    if (!confirmed) {
      return;
    }
    setIsLoading(true);
    try {
      const response = await fetch("/api/admin/content/entry", {
        method: "DELETE",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ path: entry.path }),
      });
      if (!response.ok) {
        const payload = await response.json().catch(() => ({}));
        const message = payload.error ?? "Unable to delete entry.";
        throw new Error(message);
      }
      await refresh(currentPath);
      setChangesPending(true);
      showAlert({ type: "success", message: `${entry.name} deleted.` });
    } catch (error) {
      const message = error instanceof Error ? error.message : "Delete failed.";
      showAlert({ type: "error", message });
    } finally {
      setIsLoading(false);
    }
  }

  async function handleReingest() {
    setIsIngesting(true);
    setIngestionLogs([]);
    setDocumentCount(null);
    setAlert({ type: "info", message: "Ingestion in progress…" });
    try {
      const response = await fetch("/api/admin/content/reingest", { method: "POST" });
      const payload = await response.json().catch(() => ({}));
      if (!response.ok) {
        const message = payload.error ?? "Ingestion failed.";
        throw new Error(message);
      }
      setIngestionLogs(Array.isArray(payload.logs) ? payload.logs : []);
      setDocumentCount(
        typeof payload.documents === "number" && Number.isFinite(payload.documents)
          ? payload.documents
          : null
      );
      setChangesPending(false);
      showAlert({
        type: "success",
        message:
          payload.documents != null
            ? `Ingestion complete. Indexed ${payload.documents} documents.`
            : "Ingestion complete.",
      });
    } catch (error) {
      const message = error instanceof Error ? error.message : "Ingestion failed.";
      showAlert({ type: "error", message });
    } finally {
      setIsIngesting(false);
    }
  }

  return (
    <section className="space-y-6">
      <header className="space-y-2">
        <p className="text-sm uppercase tracking-[0.15em] text-indigo-500">Content pipeline</p>
        <h1 className="text-3xl font-bold text-slate-900">Content Manager</h1>
        <p className="text-slate-500">
          Upload Markdown, PDF, or text sources, organise folders, and trigger ingestion to refresh the Atticus
          retrieval index.
        </p>
        {alert ? (
          <div
            className={`rounded-xl px-4 py-3 text-sm ${
              alert.type === "success"
                ? "bg-emerald-50 text-emerald-700"
                : alert.type === "error"
                ? "bg-rose-50 text-rose-700"
                : "bg-indigo-50 text-indigo-700"
            }`}
          >
            {alert.message}
          </div>
        ) : null}
        {changesPending ? (
          <div className="flex items-center gap-3 rounded-xl border border-amber-200 bg-amber-50 px-4 py-3 text-sm text-amber-700">
            <span>Content changed — run ingestion now?</span>
            <button
              type="button"
              onClick={handleReingest}
              disabled={isIngesting}
              className="rounded-full bg-amber-600 px-3 py-1 text-xs font-semibold uppercase tracking-wide text-white shadow-sm transition hover:bg-amber-500 disabled:cursor-not-allowed disabled:opacity-60"
            >
              Re-ingest content
            </button>
          </div>
        ) : null}
      </header>

      <div className="flex flex-wrap items-center justify-between gap-4 rounded-2xl border border-slate-200 bg-white/90 p-4 shadow-sm backdrop-blur">
        <div className="flex flex-wrap items-center gap-3 text-sm font-medium text-slate-600">
          <button
            type="button"
            onClick={() => handleBreadcrumb(-1)}
            className="rounded-full border border-slate-200 px-3 py-1.5 transition hover:border-indigo-200 hover:text-indigo-600"
          >
            content
          </button>
          {breadcrumb.map((segment, index) => (
            <div key={segment} className="flex items-center gap-3">
              <span className="text-slate-300">/</span>
              <button
                type="button"
                onClick={() => handleBreadcrumb(index)}
                className="rounded-full border border-slate-200 px-3 py-1.5 transition hover:border-indigo-200 hover:text-indigo-600"
              >
                {segment}
              </button>
            </div>
          ))}
        </div>
        <div className="flex flex-wrap items-center gap-3">
          <button
            type="button"
            onClick={() => fileInputRef.current?.click()}
            disabled={isLoading}
            className="rounded-full bg-indigo-600 px-4 py-2 text-sm font-semibold text-white shadow transition hover:bg-indigo-500 disabled:cursor-not-allowed disabled:opacity-60"
          >
            Upload files
          </button>
          <button
            type="button"
            onClick={handleCreateFolder}
            disabled={isLoading}
            className="rounded-full border border-indigo-200 px-4 py-2 text-sm font-semibold text-indigo-600 transition hover:bg-indigo-50 disabled:cursor-not-allowed disabled:opacity-60"
          >
            New folder
          </button>
          <button
            type="button"
            onClick={() => refresh(currentPath)}
            disabled={isLoading}
            className="rounded-full border border-slate-200 px-4 py-2 text-sm font-semibold text-slate-600 transition hover:bg-slate-50 disabled:cursor-not-allowed disabled:opacity-60"
          >
            Refresh
          </button>
          <button
            type="button"
            onClick={handleReingest}
            disabled={isIngesting}
            className="rounded-full border border-emerald-200 px-4 py-2 text-sm font-semibold text-emerald-600 transition hover:bg-emerald-50 disabled:cursor-not-allowed disabled:opacity-60"
          >
            Re-ingest content
          </button>
        </div>
        <input
          ref={fileInputRef}
          type="file"
          multiple
          onChange={(event) => handleUpload(event.target.files)}
          className="hidden"
        />
      </div>

      <div className="overflow-hidden rounded-2xl border border-slate-200 bg-white shadow-sm">
        <table className="min-w-full divide-y divide-slate-200">
          <thead className="bg-slate-50">
            <tr>
              <th scope="col" className="px-4 py-3 text-left text-xs font-semibold uppercase tracking-wide text-slate-500">
                Name
              </th>
              <th scope="col" className="px-4 py-3 text-left text-xs font-semibold uppercase tracking-wide text-slate-500">
                Type
              </th>
              <th scope="col" className="px-4 py-3 text-left text-xs font-semibold uppercase tracking-wide text-slate-500">
                Modified
              </th>
              <th scope="col" className="px-4 py-3 text-left text-xs font-semibold uppercase tracking-wide text-slate-500">
                Size
              </th>
              <th scope="col" className="px-4 py-3 text-right text-xs font-semibold uppercase tracking-wide text-slate-500">
                Actions
              </th>
            </tr>
          </thead>
          <tbody className="divide-y divide-slate-100">
            {entries.length === 0 ? (
              <tr>
                <td colSpan={5} className="px-4 py-10 text-center text-sm text-slate-500">
                  {isLoading ? "Loading…" : "This directory is empty."}
                </td>
              </tr>
            ) : (
              entries.map((entry) => (
                <tr key={entry.path} className="hover:bg-slate-50/80">
                  <td className="px-4 py-3 text-sm font-medium text-slate-700">
                    {entry.type === "directory" ? (
                      <button
                        type="button"
                        className="flex items-center gap-2 text-indigo-600 hover:text-indigo-500"
                        onClick={() => handleNavigate(entry)}
                      >
                        <span className="inline-flex h-2 w-2 rounded-full bg-indigo-400"></span>
                        {entry.name}
                      </button>
                    ) : (
                      <span className="flex items-center gap-2">
                        <span className="inline-flex h-2 w-2 rounded-full bg-slate-300"></span>
                        {entry.name}
                      </span>
                    )}
                  </td>
                  <td className="px-4 py-3 text-sm text-slate-500 capitalize">{entry.type}</td>
                  <td className="px-4 py-3 text-sm text-slate-500">
                    {new Date(entry.modified).toLocaleString()}
                  </td>
                  <td className="px-4 py-3 text-sm text-slate-500">
                    {entry.type === "directory" ? "--" : `${(entry.size / 1024).toFixed(1)} KB`}
                  </td>
                  <td className="px-4 py-3 text-right text-sm">
                    <button
                      type="button"
                      onClick={() => handleDelete(entry)}
                      className="rounded-full border border-rose-200 px-3 py-1 text-xs font-semibold text-rose-600 transition hover:bg-rose-50"
                    >
                      Delete
                    </button>
                  </td>
                </tr>
              ))
            )}
          </tbody>
        </table>
      </div>

      {isIngesting || ingestionLogs.length > 0 ? (
        <div className="space-y-3 rounded-2xl border border-indigo-200 bg-white px-5 py-4 shadow-sm">
          <div className="flex items-center justify-between">
            <h2 className="text-sm font-semibold text-indigo-700">Ingestion logs</h2>
            {documentCount != null ? (
              <span className="text-xs font-semibold uppercase tracking-wide text-indigo-500">
                Indexed {documentCount} documents
              </span>
            ) : null}
          </div>
          <pre className="max-h-64 overflow-y-auto rounded-xl bg-slate-900/90 p-4 text-xs text-slate-100 shadow-inner">
            {(ingestionLogs.length ? ingestionLogs : ["Ingestion running…"]).join("")}
          </pre>
        </div>
      ) : null}
    </section>
  );
}

```

## `components/AnswerRenderer.tsx`

```tsx
"use client";

import React, { useMemo } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";

import type { AskAnswer, AskResponse, AskSource } from "@/lib/ask-contract";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Dialog, DialogContent, DialogDescription, DialogFooter, DialogHeader, DialogTitle, DialogTrigger, DialogClose } from "@/components/ui/dialog";
import catalog from "@/indices/model_catalog.json";

type AnswerRendererProps = {
  text: string;
  response?: AskResponse;
  disabled?: boolean;
  onClarify?: (models: string[]) => void;
};

type CatalogModel = {
  canonical: string;
  aliases?: string[];
};

type CatalogFamily = {
  id: string;
  label: string;
  aliases?: string[];
  models: CatalogModel[];
};

type ModelCatalog = {
  families: CatalogFamily[];
};

const modelCatalog = catalog as ModelCatalog;

function formatConfidence(value: number | null | undefined): string {
  if (value === null || value === undefined || Number.isNaN(value)) {
    return "-";
  }
  return `${Math.round(value * 100)}%`;
}

function AnswerPanel({ answer, requestId }: { answer: AskAnswer; requestId?: string }) {
  const title = answer.model ?? answer.family_label ?? answer.family ?? "Answer";
  return (
    <section className="rounded-2xl border border-slate-200 bg-white/80 p-4 shadow-sm dark:border-slate-700 dark:bg-slate-900/70">
      <header className="mb-3 flex flex-wrap items-start justify-between gap-2">
        <div>
          <h3 className="text-sm font-semibold text-slate-800 dark:text-slate-100">{title}</h3>
          {answer.family && answer.model ? (
            <p className="text-xs text-slate-500 dark:text-slate-400">Family {answer.family}</p>
          ) : null}
        </div>
        <span className="text-xs font-medium text-slate-500 dark:text-slate-400">
          Confidence {formatConfidence(answer.confidence)}
        </span>
      </header>
      <div className="prose prose-sm max-w-none dark:prose-invert">
        <ReactMarkdown
          remarkPlugins={[remarkGfm]}
          components={{
            p: ({ node, ...props }) => <p className="my-2 leading-relaxed" {...props} />,
            ul: ({ node, ...props }) => <ul className="my-2 ml-5 list-disc" {...props} />,
            ol: ({ node, ...props }) => <ol className="my-2 ml-5 list-decimal" {...props} />,
            li: ({ node, ...props }) => <li className="my-1" {...props} />,
            strong: ({ node, ...props }) => <strong className="font-semibold" {...props} />,
          }}
        >
          {answer.answer}
        </ReactMarkdown>
      </div>
      {answer.sources?.length ? (
        <div className="mt-4 space-y-1 text-xs text-slate-600 dark:text-slate-300">
          <p className="font-semibold uppercase tracking-wide text-slate-500 dark:text-slate-400">
            Citations:
          </p>
          {answer.sources.map((source, index) => (
            <p key={`${source.path}-${index}`} className="truncate">
              {source.path}
            </p>
          ))}
        </div>
      ) : null}
      <div className="mt-4 border-t border-slate-100 pt-3 text-xs text-slate-500 dark:border-slate-800 dark:text-slate-400">
        <p>
          Confidence: {formatConfidence(answer.confidence)} · Escalate:{" "}
          {answer.should_escalate ? "Yes" : "No"}
        </p>
        {requestId ? <p className="truncate">Request ID: {requestId}</p> : null}
      </div>
    </section>
  );
}

export default function AnswerRenderer({ text, response, disabled, onClarify }: AnswerRendererProps) {
  const families = useMemo(() => modelCatalog.families ?? [], []);

  const clarificationCard = useMemo(() => {
    if (!response?.clarification) {
      return null;
    }
    return (
      <Card className="border border-indigo-200 bg-indigo-50/60 shadow-sm dark:border-indigo-900/70 dark:bg-indigo-950/50">
        <CardHeader>
          <CardTitle className="text-base font-semibold text-indigo-900 dark:text-indigo-100">Need a little more detail</CardTitle>
          <CardDescription className="text-sm text-indigo-800 dark:text-indigo-200">
            {response.clarification.message}
          </CardDescription>
        </CardHeader>
        <CardContent className="flex flex-wrap gap-2">
          {response.clarification.options.map((option) => (
            <Button
              key={option.id}
              size="sm"
              variant="secondary"
              disabled={disabled}
              onClick={() => onClarify?.([option.id])}
            >
              {option.label}
            </Button>
          ))}
          <Dialog>
            <DialogTrigger asChild>
              <Button size="sm" variant="outline" disabled={disabled}>
                Show list of models
              </Button>
            </DialogTrigger>
            <DialogContent>
              <DialogHeader>
                <DialogTitle>Select a model family</DialogTitle>
                <DialogDescription>
                  Review the available families and their representative models.
                </DialogDescription>
              </DialogHeader>
              <div className="max-h-64 space-y-4 overflow-y-auto pr-1">
                {families.map((family) => (
                  <div
                    key={family.id}
                    className="rounded-lg border border-slate-200 bg-slate-50/60 p-3 dark:border-slate-700 dark:bg-slate-800/70"
                  >
                    <h4 className="text-sm font-semibold text-slate-800 dark:text-slate-100">
                      {family.label}
                    </h4>
                    <p className="mt-1 text-xs text-slate-500 dark:text-slate-300">Models:</p>
                    <ul className="mt-1 space-y-0.5 text-xs text-slate-600 dark:text-slate-300">
                      {family.models.map((model) => (
                        <li key={`${family.id}-${model.canonical}`}>{model.canonical}</li>
                      ))}
                    </ul>
                  </div>
                ))}
              </div>
              <DialogFooter>
                <DialogClose asChild>
                  <Button variant="secondary">Close</Button>
                </DialogClose>
              </DialogFooter>
            </DialogContent>
          </Dialog>
        </CardContent>
      </Card>
    );
  }, [disabled, families, onClarify, response?.clarification]);

  const answerSections = useMemo(() => {
    if (!response?.answers || response.answers.length === 0) {
      return null;
    }
    return (
      <div className="space-y-4">
        {response.answers.map((answer) => (
          <AnswerPanel
            key={`${answer.model ?? answer.family ?? "answer"}-${answer.answer.slice(0, 16)}`}
            answer={answer}
            requestId={response?.request_id}
          />
        ))}
      </div>
    );
  }, [response?.answers, response?.request_id]);

  const fallbackMarkdown = useMemo(() => {
    const content = response?.answer ?? text;
    if (!content) {
      return null;
    }
    return (
      <div className="prose prose-sm max-w-none dark:prose-invert">
        <ReactMarkdown
          remarkPlugins={[remarkGfm]}
          components={{
            p: ({ node, ...props }) => <p className="my-2 leading-relaxed" {...props} />,
            ul: ({ node, ...props }) => <ul className="my-2 ml-5 list-disc" {...props} />,
            ol: ({ node, ...props }) => <ol className="my-2 ml-5 list-decimal" {...props} />,
            li: ({ node, ...props }) => <li className="my-1" {...props} />,
            strong: ({ node, ...props }) => <strong className="font-semibold" {...props} />,
          }}
        >
          {content}
        </ReactMarkdown>
      </div>
    );
  }, [response?.answer, text]);

  return (
    <div className="space-y-4">
      {clarificationCard}
      {clarificationCard ? null : answerSections ?? fallbackMarkdown}
    </div>
  );
}

```

## `components/chat/chat-panel.tsx`

```tsx
"use client";

import { useEffect, useRef, useState } from "react";
import { Loader2, Send } from "lucide-react";
import { streamAsk, type AskStreamEvent } from "@/lib/ask-client";
import type { AskResponse, AskSource } from "@/lib/ask-contract";
import AnswerRenderer from "@/components/AnswerRenderer";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";

interface ChatMessage {
  id: string;
  role: "user" | "assistant";
  content: string;
  status?: "pending" | "complete" | "error";
  response?: AskResponse;
  error?: string;
  question?: string;
}

function createId() {
  return `${Date.now().toString(36)}-${Math.random().toString(36).slice(2, 8)}`;
}

function formatConfidence(confidence: number | null | undefined) {
  if (confidence === null || confidence === undefined || Number.isNaN(confidence)) {
    return "—";
  }
  return `${Math.round(confidence * 100)}%`;
}

export function ChatPanel() {
  const FRIENDLY_VALIDATION_MSG =
    "There is no context to that question or it is not a proper question, please try again";
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [composer, setComposer] = useState("");
  const [isStreaming, setIsStreaming] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showIntro, setShowIntro] = useState(true);
  const formRef = useRef<HTMLFormElement | null>(null);
  const textareaRef = useRef<HTMLTextAreaElement | null>(null);

  const autoResize = () => {
    const el = textareaRef.current;
    if (!el) return;
    // Base: 3 rows; allow growth up to 6 rows, then scroll
    const maxRows = 6;
    const style = window.getComputedStyle(el);
    const lineHeight = parseFloat(style.lineHeight || "20");
    const padding = parseFloat(style.paddingTop || "0") + parseFloat(style.paddingBottom || "0");
    const border = parseFloat(style.borderTopWidth || "0") + parseFloat(style.borderBottomWidth || "0");
    const minHeight = Math.max(0, lineHeight * 3 + padding + border);
    const maxHeight = Math.max(minHeight, lineHeight * maxRows + padding + border);
    el.style.height = "auto";
    const newHeight = Math.min(el.scrollHeight, Math.floor(maxHeight));
    el.style.height = `${newHeight}px`;
    el.style.overflowY = el.scrollHeight > maxHeight ? "auto" : "hidden";
  };

  useEffect(() => {
    autoResize();
  }, [composer]);

  async function handleSubmit(event: React.FormEvent<HTMLFormElement>) {
    event.preventDefault();
    const trimmed = composer.trim();
    if (!trimmed || isStreaming) {
      return;
    }
    setError(null);
    if (showIntro) {
      setShowIntro(false);
    }

    const userMessage: ChatMessage = {
      id: createId(),
      role: "user",
      status: "complete",
      content: trimmed,
    };
    const placeholder: ChatMessage = {
      id: createId(),
      role: "assistant",
      status: "pending",
      content: "Atticus is thinking...",
      question: trimmed,
    };

    setMessages((prev) => [...prev, userMessage, placeholder]);
    setComposer("");
    setIsStreaming(true);

    try {
      await streamAsk(
        { question: trimmed, filters: undefined, contextHints: undefined, topK: undefined, models: undefined },
        {
          onEvent: (event: AskStreamEvent) => {
            if (event.type === "answer") {
              const response = event.payload;
              setMessages((prev) =>
                prev.map((message) =>
                  message.id === placeholder.id
                    ? {
                        ...message,
                        status: "complete",
                        content: response.answer ?? response.clarification?.message ?? "",
                        response,
                      }
                    : message
                )
              );
            }
            if (event.type === "end") {
              setIsStreaming(false);
            }
          },
        }
      );
    } catch (err) {
      setIsStreaming(false);
      const messageError = err instanceof Error ? err.message : FRIENDLY_VALIDATION_MSG;
      // Only show bottom error if it's not the friendly validation message
      setError(messageError === FRIENDLY_VALIDATION_MSG ? null : messageError);
      setMessages((prev) =>
        prev.map((message) =>
          message.id === placeholder.id
            ? {
                ...message,
                status: "error",
                content: FRIENDLY_VALIDATION_MSG,
                error: messageError,
              }
            : message
        )
      );
    }
  }

  async function handleClarificationChoice(messageId: string, models: string[]) {
    if (!models.length || isStreaming) {
      return;
    }
    const target = messages.find((message) => message.id === messageId);
    if (!target?.question) {
      return;
    }
    setError(null);
    if (showIntro) {
      setShowIntro(false);
    }
    setIsStreaming(true);
    setMessages((prev) =>
      prev.map((message) =>
        message.id === messageId
          ? {
              ...message,
              status: "pending",
              content: "Atticus is thinking...",
              response: message.response ? { ...message.response, clarification: undefined } : message.response,
            }
          : message
      )
    );

    try {
      await streamAsk(
        {
          question: target.question,
          models,
          filters: undefined,
          contextHints: undefined,
          topK: undefined,
        },
        {
          onEvent: (event: AskStreamEvent) => {
            if (event.type === "answer") {
              const response = event.payload;
              setMessages((prev) =>
                prev.map((message) =>
                  message.id === messageId
                    ? {
                        ...message,
                        status: "complete",
                        content: response.answer ?? response.clarification?.message ?? "",
                        response,
                      }
                    : message
                )
              );
            }
            if (event.type === "end") {
              setIsStreaming(false);
            }
          },
        }
      );
    } catch (err) {
      const messageError = err instanceof Error ? err.message : FRIENDLY_VALIDATION_MSG;
      // Only show bottom error if it's not the friendly validation message
      setError(messageError === FRIENDLY_VALIDATION_MSG ? null : messageError);
      setMessages((prev) =>
        prev.map((message) =>
          message.id === messageId
            ? {
                ...message,
                status: "error",
                content: FRIENDLY_VALIDATION_MSG,
                error: messageError,
              }
            : message
        )
      );
    } finally {
      setIsStreaming(false);
    }
  }

  return (
    <section className="flex h-full min-h-0 flex-1 flex-col">
      <div className="flex-1 min-h-0 overflow-y-auto px-4 pb-6 pt-6 sm:px-6 lg:px-8 [-ms-overflow-style:none] [scrollbar-width:none] [&::-webkit-scrollbar]:hidden">
        {showIntro && messages.length === 0 ? (
          <div className="flex h-full min-h-full items-center justify-center text-center">
            <div className="max-w-xl space-y-3">
              <p className="text-sm font-semibold uppercase tracking-[0.35em] text-slate-400 dark:text-slate-500">
                Welcome
              </p>
              <h2 className="text-2xl font-semibold text-slate-900 dark:text-slate-100">
                Hi there — I’m Atticus.
              </h2>
              <p className="text-base text-slate-600 dark:text-slate-300">
                Ask me about any FUJIFILM product, process, or spec. Every answer comes sourced
                from verified documentation.
              </p>
            </div>
          </div>
        ) : (
          <div className="flex min-h-full flex-col justify-end gap-4">
            {messages.map((message) => (
              <article
                key={message.id}
                className={
                  message.role === "assistant" ? "flex justify-start" : "flex justify-end"
                }
              >
                <div
                  className={
                    message.role === "assistant"
                      ? "max-w-3xl rounded-2xl bg-slate-100 p-4 text-sm text-slate-800 shadow dark:bg-slate-900 dark:text-slate-200"
                      : "max-w-3xl rounded-2xl bg-slate-900 p-4 text-sm text-white shadow dark:bg-slate-100 dark:text-slate-900"
                  }
                >
                  {message.role === "assistant" ? (
                    <AnswerRenderer
                      text={message.content}
                      response={message.response}
                      disabled={isStreaming}
                      onClarify={(models) => handleClarificationChoice(message.id, models)}
                    />
                  ) : (
                    <p className="whitespace-pre-wrap">{message.content}</p>
                  )}
                  {message.response?.sources?.length ? (
                    <div className="mt-3 space-y-1 text-xs text-slate-600 dark:text-slate-400">
                      <p className="font-semibold uppercase tracking-wide">Sources</p>
                      <ul className="space-y-1">
                        {message.response.sources.map((source: AskSource, index) => (
                          <li key={`${message.id}-source-${index}`}>
                            {source.path}
                            {typeof source.page === "number" ? ` · page ${source.page}` : ""}
                            {source.heading ? ` · ${source.heading}` : ""}
                          </li>
                        ))}
                      </ul>
                    </div>
                  ) : null}
                  {message.response ? (
                    <footer className="mt-3 flex flex-wrap gap-3 text-xs text-slate-500 dark:text-slate-400">
                      <span>Confidence: {formatConfidence(message.response.confidence)}</span>
                      <span>
                        Escalate:{" "}
                        {message.response.should_escalate === undefined
                          ? "-"
                          : message.response.should_escalate
                          ? "Yes"
                          : "No"}
                      </span>
                      <span className="truncate">Request ID: {message.response.request_id}</span>
                    </footer>
                  ) : null}
                  {/* Suppress duplicate red error text inside bubbles; message content carries user-facing message */}
                </div>
              </article>
            ))}
          </div>
        )}
      </div>
      <div className="shrink-0 px-4 pb-4 pt-4 sm:px-6 lg:px-8">
        <form
          ref={formRef}
          onSubmit={handleSubmit}
          className="flex gap-3 rounded-2xl border border-slate-200 bg-white/95 p-4 shadow-lg backdrop-blur supports-[backdrop-filter]:backdrop-blur dark:border-slate-800 dark:bg-slate-950/90"
        >
          <div className="min-w-0 flex-1">
            <label htmlFor="chat-message" className="sr-only">
              Message Atticus
            </label>
            <Textarea
              id="chat-message"
              value={composer}
              onChange={(event) => setComposer(event.target.value)}
              ref={textareaRef}
              onKeyDown={(event) => {
                // Enter: send. Shift+Enter: newline
                const composing = (event.nativeEvent as unknown as { isComposing?: boolean }).isComposing;
                if (event.key === "Enter" && !event.shiftKey && !composing) {
                  event.preventDefault();
                  // Only submit if there is content and not streaming
                  if (!isStreaming && composer.trim()) {
                    // Prefer requestSubmit for proper form submission semantics
                    formRef.current?.requestSubmit();
                  }
                }
              }}
              rows={3}
              placeholder="Message Atticus..."
              className="min-h-[72px] resize-none overflow-y-hidden"
            />
          </div>
          <Button type="submit" disabled={isStreaming || !composer.trim()} className="self-end rounded-xl">
            {isStreaming ? (
              <Loader2 className="h-4 w-4 animate-spin" aria-hidden="true" />
            ) : (
              <Send className="h-4 w-4" aria-hidden="true" />
            )}
            <span>{isStreaming ? "Sending..." : "Send"}</span>
          </Button>
        </form>
        {error ? (
          <p className="mt-3 text-sm text-rose-600" role="status">
            {error}
          </p>
        ) : null}
      </div>
    </section>
  );
}

```

## `components/chat/chat-sidebar.tsx`

```tsx
"use client";

import type { ComponentType, SVGProps } from "react";
import {
  BookOpen,
  FolderPlus,
  Menu,
  MessageSquarePlus,
  Search,
  Settings,
  Sparkles,
  X,
} from "lucide-react";
import { cn } from "@/lib/utils";

interface ChatSidebarProps {
  open: boolean;
  onToggle: () => void;
}

interface SidebarItem {
  label: string;
  icon: ComponentType<SVGProps<SVGSVGElement>>;
}

const primaryActions: SidebarItem[] = [
  { label: "New chat", icon: MessageSquarePlus },
  { label: "Search chats", icon: Search },
  { label: "Library", icon: BookOpen },
  { label: "Projects", icon: FolderPlus },
];

const automationActions: SidebarItem[] = [
  { label: "Automations", icon: Sparkles },
  { label: "Workspace settings", icon: Settings },
];

export function ChatSidebar({ open, onToggle }: ChatSidebarProps) {
  const widthClass = open ? "w-72" : "w-20";

  return (
    <aside
      className={cn(
        "group/sidebar relative flex h-full shrink-0 flex-col border-r border-slate-800/80 bg-slate-900/80 backdrop-blur transition-[width] duration-300 ease-in-out",
        widthClass
      )}
      aria-label="Workspace sidebar"
    >
      <div className="flex items-center justify-between px-4 py-5">
        <div
          className={cn(
            "flex items-center gap-3 text-left",
            open ? "opacity-100" : "pointer-events-none opacity-0"
          )}
        >
          <div className="flex h-9 w-9 items-center justify-center rounded-lg bg-blue-500 font-semibold text-slate-900">
            C
          </div>
          <div className="space-y-1">
            <p className="text-xs uppercase tracking-widest text-slate-400">Atticus</p>
            <p className="text-sm font-medium text-slate-100">Chat workspace</p>
          </div>
        </div>
        <button
          type="button"
          onClick={onToggle}
          className="rounded-lg border border-slate-800/60 bg-slate-900/60 p-2 text-slate-200 transition hover:border-slate-700 hover:bg-slate-800/70 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-blue-500/60"
          aria-expanded={open}
          aria-label={open ? "Collapse sidebar" : "Expand sidebar"}
        >
          {open ? <X className="h-4 w-4" /> : <Menu className="h-4 w-4" />}
        </button>
      </div>

      <nav className="mt-6 flex-1 space-y-8 px-2">
        <SidebarSection title="Workspace" items={primaryActions} open={open} />
        <SidebarSection title="Automation" items={automationActions} open={open} />
      </nav>

      <div className="flex items-center gap-3 border-t border-slate-800/80 px-4 py-5">
        <div className="flex h-10 w-10 items-center justify-center rounded-full bg-gradient-to-br from-blue-500 to-indigo-500 font-semibold text-slate-900">
          J
        </div>
        {open ? (
          <div className="min-w-0">
            <p className="truncate text-sm font-semibold text-slate-100">Jordan Carter</p>
            <p className="truncate text-xs text-slate-400">AE • North America</p>
          </div>
        ) : null}
      </div>
    </aside>
  );
}

function SidebarSection({ title, items, open }: { title: string; items: SidebarItem[]; open: boolean }) {
  return (
    <div>
      <p
        className={cn(
          "px-3 text-xs font-semibold uppercase tracking-widest text-slate-500 transition-opacity",
          open ? "opacity-100" : "opacity-0"
        )}
      >
        {title}
      </p>
      <ul className="mt-3 space-y-2">
        {items.map((item) => (
          <li key={item.label}>
            <button
              type="button"
              title={item.label}
              className={cn(
                "flex w-full items-center rounded-xl px-3 py-2 text-sm font-medium text-slate-200 transition hover:bg-slate-800/70 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-blue-500/60",
                open ? "gap-3 justify-start" : "justify-center"
              )}
            >
              <item.icon className="h-4 w-4 flex-none" aria-hidden="true" />
              {open ? <span className="truncate">{item.label}</span> : null}
            </button>
          </li>
        ))}
      </ul>
    </div>
  );
}

```

## `components/chat/chat-workspace.tsx`

```tsx
"use client";

import { ChatPanel } from "@/components/chat/chat-panel";

export function ChatWorkspace() {
  return (
    <div
      className="fixed inset-x-0 bottom-0 z-0"
      style={{ top: "var(--topbar-h, 64px)" }}
      aria-label="Chat workspace"
    >
      <main className="flex h-full flex-col overflow-hidden">
        <div className="mx-auto flex h-full min-h-0 w-full max-w-5xl flex-1 flex-col px-4 pb-4 pt-4 sm:px-6 lg:px-8">
          <ChatPanel />
        </div>
      </main>
    </div>
  );
}

```

## `components/glossary/admin-panel.tsx`

```tsx
"use client";

import { useState, useTransition } from "react";
import { GlossaryStatus } from "@prisma/client";
import { Badge } from "@/components/ui/badge";
import { Button } from "@/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardFooter,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { Input } from "@/components/ui/input";
import { Label } from "@/components/ui/label";
import { Select } from "@/components/ui/select";
import {
  Table,
  TableBody,
  TableCell,
  TableHead,
  TableHeader,
  TableRow,
} from "@/components/ui/table";
import { Textarea } from "@/components/ui/textarea";

export interface GlossaryEntryDto {
  id: string;
  term: string;
  definition: string;
  synonyms: string[];
  status: GlossaryStatus;
  createdAt: string;
  updatedAt: string;
  reviewedAt: string | null;
  author: { id: string; email: string | null; name: string | null } | null;
  updatedBy: { id: string; email: string | null; name: string | null } | null;
  reviewer: { id: string; email: string | null; name: string | null } | null;
  reviewNotes: string | null;
}

interface GlossaryAdminPanelProps {
  initialEntries: GlossaryEntryDto[];
  canEdit?: boolean;
}

const statusOptions: GlossaryStatus[] = [
  GlossaryStatus.PENDING,
  GlossaryStatus.APPROVED,
  GlossaryStatus.REJECTED,
];

export function GlossaryAdminPanel({ initialEntries, canEdit = true }: GlossaryAdminPanelProps) {
  const [entries, setEntries] = useState(initialEntries);
  const [term, setTerm] = useState("");
  const [definition, setDefinition] = useState("");
  const [synonyms, setSynonyms] = useState("");
  const [status, setStatus] = useState<GlossaryStatus>(GlossaryStatus.PENDING);
  const [feedback, setFeedback] = useState<string | null>(null);
  const [isPending, startTransition] = useTransition();
  const [editingId, setEditingId] = useState<string | null>(null);
  const [definitionDraft, setDefinitionDraft] = useState("");
  const [synonymsDraft, setSynonymsDraft] = useState("");

  function parseSynonyms(value: string): string[] {
    return value
      .split(",")
      .map((item) => item.trim())
      .filter((item) => item.length > 0);
  }

  async function createEntry() {
    if (!canEdit) {
      return;
    }
    setFeedback(null);
    startTransition(async () => {
      const response = await fetch("/api/glossary", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ term, definition, status, synonyms: parseSynonyms(synonyms) }),
      });
      if (!response.ok) {
        const body = await response.json().catch(() => ({}));
        setFeedback(body.detail ?? "Unable to create entry.");
        return;
      }
      const created: GlossaryEntryDto = await response.json();
      setEntries((prev) => [...prev, created].sort((a, b) => a.term.localeCompare(b.term)));
      setTerm("");
      setDefinition("");
      setSynonyms("");
      setStatus(GlossaryStatus.PENDING);
      setFeedback("Entry created successfully.");
    });
  }

  function beginEditing(entry: GlossaryEntryDto) {
    setEditingId(entry.id);
    setDefinitionDraft(entry.definition);
    setSynonymsDraft(entry.synonyms.join(", "));
    setFeedback(null);
  }

  function cancelEditing() {
    setEditingId(null);
    setDefinitionDraft("");
    setSynonymsDraft("");
  }

  async function saveEntryUpdate(
    entry: GlossaryEntryDto,
    overrides: Partial<{
      definition: string;
      synonyms: string[];
      status: GlossaryStatus;
      reviewNotes: string | null;
    }>
  ) {
    if (!canEdit) {
      return null;
    }
    const payload = {
      term: entry.term,
      definition: overrides.definition ?? entry.definition,
      synonyms: overrides.synonyms ?? entry.synonyms,
      status: overrides.status ?? entry.status,
      reviewNotes: overrides.reviewNotes ?? entry.reviewNotes,
    };
    const response = await fetch(`/api/glossary/${entry.id}`, {
      method: "PUT",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    });
    if (!response.ok) {
      const body = await response.json().catch(() => ({}));
      setFeedback(body.detail ?? "Unable to update entry.");
      return null;
    }
    const updated: GlossaryEntryDto = await response.json();
    setEntries((prev) => prev.map((item) => (item.id === entry.id ? updated : item)));
    return updated;
  }

  async function updateStatus(entry: GlossaryEntryDto, nextStatus: GlossaryStatus) {
    if (!canEdit) {
      return;
    }
    startTransition(async () => {
      let reviewNotes: string | null | undefined;
      if (nextStatus !== GlossaryStatus.PENDING) {
        reviewNotes =
          window.prompt("Add review notes (optional)", entry.reviewNotes ?? "") ?? undefined;
      }
      const updated = await saveEntryUpdate(entry, {
        status: nextStatus,
        reviewNotes: reviewNotes === undefined ? entry.reviewNotes : reviewNotes ?? null,
      });
      if (updated) {
        setFeedback(`Status updated to ${nextStatus.toLowerCase()}.`);
      }
    });
  }

  async function deleteEntry(entryId: string) {
    if (!canEdit) {
      return;
    }
    startTransition(async () => {
      const response = await fetch(`/api/glossary/${entryId}`, { method: "DELETE" });
      if (!response.ok) {
        const body = await response.json().catch(() => ({}));
      setFeedback(body.detail ?? "Unable to delete entry.");
      return;
      }
      setEntries((prev) => prev.filter((item) => item.id !== entryId));
      setFeedback("Entry deleted.");
      if (editingId === entryId) {
        cancelEditing();
      }
    });
  }

  function submitDraft(entry: GlossaryEntryDto) {
    if (!canEdit) {
      return;
    }
    const trimmedDefinition = definitionDraft.trim();
    if (!trimmedDefinition) {
      setFeedback("Definition is required.");
      return;
    }
    setFeedback(null);
    startTransition(async () => {
      const updated = await saveEntryUpdate(entry, {
        definition: trimmedDefinition,
        synonyms: parseSynonyms(synonymsDraft),
      });
      if (updated) {
        setFeedback("Entry updated.");
        cancelEditing();
      }
    });
  }

  return (
    <section className="space-y-6">
      <Card>
        <CardHeader className="pb-4">
          <CardTitle>Add glossary entry</CardTitle>
          <CardDescription>
            Approved terms appear instantly in chat responses. Pending entries stay private until
            promoted.
          </CardDescription>
        </CardHeader>
        <CardContent className="grid gap-4 md:grid-cols-2">
          <div className="space-y-2">
            <Label htmlFor="term">Term</Label>
            <Input
              id="term"
              value={term}
              onChange={(event) => setTerm(event.target.value)}
              placeholder="Consumables"
              disabled={!canEdit}
            />
          </div>
          <div className="space-y-2">
            <Label htmlFor="status">Status</Label>
            <Select
              id="status"
              value={status}
              onChange={(event) => setStatus(event.target.value as GlossaryStatus)}
              disabled={!canEdit}
            >
              {statusOptions.map((option) => (
                <option key={option} value={option}>
                  {option.toLowerCase()}
                </option>
              ))}
            </Select>
          </div>
          <div className="space-y-2 md:col-span-2">
            <Label htmlFor="synonyms">Synonyms</Label>
            <Input
              id="synonyms"
              value={synonyms}
              onChange={(event) => setSynonyms(event.target.value)}
              placeholder="Comma-separated list"
              disabled={!canEdit}
            />
          </div>
          <div className="space-y-2 md:col-span-2">
            <Label htmlFor="definition">Definition</Label>
            <Textarea
              id="definition"
              value={definition}
              onChange={(event) => setDefinition(event.target.value)}
              rows={4}
              placeholder="How the team uses this term..."
              disabled={!canEdit}
            />
          </div>
        </CardContent>
        <CardFooter className="flex flex-col gap-2 sm:flex-row sm:items-center sm:justify-between">
          <Button type="button" disabled={isPending || !term || !definition || !canEdit} onClick={createEntry}>
            {isPending ? "Saving…" : "Save entry"}
          </Button>
          <div className="flex flex-1 items-center justify-end gap-2">
            {!canEdit ? (
              <Badge variant="outline" className="normal-case">
                Reviewer access is read-only
              </Badge>
            ) : null}
            {feedback ? (
              <Badge variant="subtle" className="normal-case">
                {feedback}
              </Badge>
            ) : null}
          </div>
        </CardFooter>
      </Card>

      <Card className="overflow-hidden">
        <CardHeader className="pb-4">
          <CardTitle>Glossary entries</CardTitle>
          <CardDescription>
            Review pending definitions, promote approved terms, and prune duplicates in one place.
          </CardDescription>
        </CardHeader>
        <CardContent className="p-0">
          <Table>
            <TableHeader>
              <TableRow>
                <TableHead>Term</TableHead>
                <TableHead>Definition</TableHead>
                <TableHead>Status</TableHead>
                <TableHead>Updated</TableHead>
                <TableHead className="text-right">Actions</TableHead>
              </TableRow>
            </TableHeader>
            <TableBody>
              {entries.map((entry) => (
                <TableRow key={entry.id}>
                  <TableCell className="font-medium text-slate-900 dark:text-white">
                    {entry.term}
                  </TableCell>
                  <TableCell>
                    {editingId === entry.id ? (
                      <div className="space-y-3">
                        <Textarea
                          value={definitionDraft}
                          onChange={(event) => setDefinitionDraft(event.target.value)}
                          rows={4}
                          disabled={!canEdit || isPending}
                        />
                        <Input
                          value={synonymsDraft}
                          onChange={(event) => setSynonymsDraft(event.target.value)}
                          placeholder="Comma-separated synonyms"
                          disabled={!canEdit || isPending}
                        />
                      </div>
                    ) : (
                      <>
                        <p>{entry.definition}</p>
                        {entry.synonyms.length ? (
                          <p className="mt-2 text-xs text-slate-500 dark:text-slate-400">
                            Synonyms: {entry.synonyms.join(", ")}
                          </p>
                        ) : null}
                        <p className="mt-1 text-xs text-slate-400 dark:text-slate-500">
                          Added by {entry.author?.name ?? entry.author?.email ?? "unknown"}
                        </p>
                      </>
                    )}
                  </TableCell>
                  <TableCell>
                    <Badge
                      variant={
                        entry.status === GlossaryStatus.APPROVED
                          ? "success"
                          : entry.status === GlossaryStatus.REJECTED
                          ? "destructive"
                          : "warning"
                      }
                    >
                      {entry.status.toLowerCase()}
                    </Badge>
                  </TableCell>
                  <TableCell>
                    <p>{new Date(entry.updatedAt).toLocaleString()}</p>
                    <p className="mt-1 text-xs text-slate-400 dark:text-slate-500">
                      By {entry.updatedBy?.name ?? entry.updatedBy?.email ?? "system"}
                    </p>
                    {entry.reviewedAt ? (
                      <p className="mt-1 text-xs text-slate-400 dark:text-slate-500">
                        Reviewed {new Date(entry.reviewedAt).toLocaleString()} by {" "}
                        {entry.reviewer?.name ?? entry.reviewer?.email ?? "admin"}
                      </p>
                    ) : null}
                    {entry.reviewNotes ? (
                      <p className="mt-1 text-xs text-slate-500 dark:text-slate-400">
                        Notes: {entry.reviewNotes}
                      </p>
                    ) : null}
                  </TableCell>
                  <TableCell className="text-right">
                    <div className="flex flex-wrap justify-end gap-2">
                      {editingId === entry.id ? (
                        <>
                          <Button
                            type="button"
                            size="sm"
                            onClick={() => submitDraft(entry)}
                            disabled={isPending || !canEdit}
                          >
                            Save
                          </Button>
                          <Button
                            type="button"
                            size="sm"
                            variant="outline"
                            onClick={cancelEditing}
                            disabled={isPending}
                          >
                            Cancel
                          </Button>
                        </>
                      ) : (
                        <Button
                          type="button"
                          size="sm"
                          variant="outline"
                          onClick={() => beginEditing(entry)}
                          disabled={isPending || !canEdit}
                        >
                          Edit
                        </Button>
                      )}
                      {statusOptions.map((option) => (
                        <Button
                          key={option}
                          type="button"
                          size="sm"
                          variant={option === entry.status ? "secondary" : "outline"}
                          disabled={
                            option === entry.status || isPending || !canEdit || editingId === entry.id
                          }
                          onClick={() => updateStatus(entry, option)}
                        >
                          {option.toLowerCase()}
                        </Button>
                      ))}
                      <Button
                        type="button"
                        size="sm"
                        variant="destructive"
                        onClick={() => deleteEntry(entry.id)}
                        disabled={isPending || !canEdit}
                      >
                        Delete
                      </Button>
                    </div>
                  </TableCell>
                </TableRow>
              ))}
              {entries.length === 0 ? (
                <TableRow>
                  <TableCell
                    colSpan={5}
                    className="py-6 text-center text-sm text-slate-500 dark:text-slate-400"
                  >
                    No glossary entries yet. Create one above to seed the knowledge base.
                  </TableCell>
                </TableRow>
              ) : null}
            </TableBody>
          </Table>
        </CardContent>
      </Card>
    </section>
  );
}

```

## `components/page-header.tsx`

```tsx
import type { ReactNode } from "react";
import { Badge } from "@/components/ui/badge";

interface PageHeaderProps {
  title: string;
  description: string;
  eyebrow?: string;
  actions?: ReactNode;
}

export function PageHeader({ title, description, eyebrow, actions }: PageHeaderProps) {
  return (
    <div className="mx-auto flex w-full max-w-6xl flex-col gap-6">
      <div className="space-y-4">
        {eyebrow ? (
          <Badge variant="outline" className="w-fit">
            {eyebrow}
          </Badge>
        ) : null}
        <div className="flex flex-col gap-4 sm:flex-row sm:items-end sm:justify-between">
          <div className="space-y-2">
            <h1 className="text-3xl font-semibold tracking-tight text-slate-900 dark:text-white">
              {title}
            </h1>
            <p className="max-w-2xl text-sm text-slate-600 dark:text-slate-300">{description}</p>
          </div>
          {actions ? <div className="flex shrink-0 items-center gap-3">{actions}</div> : null}
        </div>
      </div>
    </div>
  );
}

```

## `components/site-footer.tsx`

```tsx
export function SiteFooter() {
  return (
    <footer className="border-t border-slate-200 bg-white/70 dark:border-slate-800 dark:bg-slate-950/70">
      <div className="mx-auto flex max-w-6xl flex-col gap-4 px-4 py-6 text-sm text-slate-500 sm:flex-row sm:items-center sm:justify-between sm:px-6 lg:px-8">
        <p>&copy; {new Date().getFullYear()} Atticus. All rights reserved.</p>
        <div className="flex flex-wrap items-center gap-3" aria-hidden="true" />
      </div>
    </footer>
  );
}

```

## `components/site-header.tsx`

```tsx
"use client";

import Link from "next/link";
import { usePathname } from "next/navigation";
import { useMemo, useState } from "react";
import { Menu, X } from "lucide-react";
import { Button } from "@/components/ui/button";
import { cn } from "@/lib/utils";

type NavLink = {
  href: string;
  label: string;
};

const links: readonly NavLink[] = [
  { href: "/", label: "Chat" },
  { href: "/admin", label: "Admin" },
  { href: "/admin/content", label: "Content" },
  { href: "/settings", label: "Settings" },
  { href: "/contact", label: "Contact" },
  { href: "/apps", label: "Apps" },
];

export function SiteHeader() {
  const pathname = usePathname();
  const [isOpen, setIsOpen] = useState(false);
  const visibleLinks = useMemo(() => links, []);

  const activeHref = useMemo(() => {
    if (!pathname) {
      return "/";
    }
    return (
      visibleLinks.find((link) => pathname === link.href || pathname.startsWith(`${link.href}/`))?.href ?? "/"
    );
  }, [pathname, visibleLinks]);

  return (
    <header className="sticky top-0 z-40 border-b border-slate-200/80 bg-white/80 backdrop-blur dark:border-slate-800/80 dark:bg-slate-950/80">
      <div className="mx-auto flex max-w-6xl items-center justify-between p-4 sm:px-6 lg:px-8">
        <Link href="/" className="flex items-center gap-2 text-base font-semibold">
          <span className="flex h-9 w-9 items-center justify-center rounded-full bg-indigo-600 text-white shadow-sm">
            A
          </span>
          <span className="hidden sm:inline">Atticus</span>
        </Link>
        <nav
          aria-label="Primary"
          className="hidden items-center gap-1 rounded-full border border-slate-200 bg-white/60 p-1 text-sm font-medium dark:border-slate-800 dark:bg-slate-900/60 sm:flex"
        >
          {visibleLinks.map((link) => (
            <Link
              key={link.href}
              href={link.href}
              className={cn(
                "rounded-full px-3 py-1.5 transition-colors hover:bg-indigo-50 dark:hover:bg-indigo-500/10",
                activeHref === link.href
                  ? "bg-indigo-600 text-white shadow-sm hover:bg-indigo-600"
                  : "text-slate-600 dark:text-slate-300"
              )}
            >
              {link.label}
            </Link>
          ))}
        </nav>
        <div className="flex items-center gap-3">
          <Button
            type="button"
            variant="outline"
            size="icon"
            className="sm:hidden"
            onClick={() => setIsOpen((prev) => !prev)}
            aria-expanded={isOpen}
            aria-controls="mobile-nav"
          >
            {isOpen ? (
              <X className="h-5 w-5" aria-hidden="true" />
            ) : (
              <Menu className="h-5 w-5" aria-hidden="true" />
            )}
            <span className="sr-only">Toggle navigation</span>
          </Button>
        </div>
      </div>
      <div
        id="mobile-nav"
        className={cn(
          "border-t border-slate-200 bg-white p-4 dark:border-slate-800 dark:bg-slate-950 sm:hidden",
          isOpen ? "block" : "hidden"
        )}
      >
        <div className="flex flex-col gap-3">
          <nav className="flex flex-col gap-2 text-base font-medium">
            {visibleLinks.map((link) => (
              <Link
                key={link.href}
                href={link.href}
                className={cn(
                  "rounded-xl px-3 py-2 hover:bg-indigo-50 dark:hover:bg-indigo-500/10",
                  activeHref === link.href
                    ? "bg-indigo-600 text-white shadow-sm"
                    : "text-slate-700 dark:text-slate-300"
                )}
                onClick={() => setIsOpen(false)}
              >
                {link.label}
              </Link>
            ))}
          </nav>
        </div>
      </div>
    </header>
  );
}

```

## `components/ui/badge.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type BadgeVariant =
  | "default"
  | "subtle"
  | "outline"
  | "success"
  | "warning"
  | "destructive";

const variantClasses: Record<BadgeVariant, string> = {
  default:
    "bg-indigo-50 text-indigo-600 dark:bg-indigo-500/15 dark:text-indigo-300",
  subtle: "bg-slate-100 text-slate-600 dark:bg-slate-800/60 dark:text-slate-300",
  outline:
    "border border-slate-200 text-slate-600 dark:border-slate-700 dark:text-slate-300",
  success:
    "bg-emerald-100 text-emerald-700 dark:bg-emerald-500/20 dark:text-emerald-200",
  warning:
    "bg-amber-100 text-amber-700 dark:bg-amber-500/20 dark:text-amber-200",
  destructive:
    "bg-rose-100 text-rose-700 dark:bg-rose-500/20 dark:text-rose-200",
};

interface BadgeProps extends React.HTMLAttributes<HTMLSpanElement> {
  variant?: BadgeVariant;
}

export const Badge = React.forwardRef<HTMLSpanElement, BadgeProps>(function Badge(
  { className, variant = "default", ...props },
  ref
) {
  return (
    <span
      ref={ref}
      className={cn(
        "inline-flex items-center gap-1 rounded-full px-3 py-1 text-xs font-semibold uppercase tracking-wide",
        variantClasses[variant],
        className
      )}
      {...props}
    />
  );
});

```

## `components/ui/button.tsx`

```tsx
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cn } from "@/lib/utils";

type ButtonVariant =
  | "default"
  | "secondary"
  | "outline"
  | "ghost"
  | "destructive"
  | "link";

type ButtonSize = "sm" | "default" | "lg" | "icon";

const variantClasses: Record<ButtonVariant, string> = {
  default:
    "bg-indigo-600 text-white shadow-sm hover:bg-indigo-500 dark:bg-indigo-500 dark:text-white dark:hover:bg-indigo-400",
  secondary:
    "bg-slate-100 text-slate-900 hover:bg-slate-200 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700",
  outline:
    "border border-slate-200 bg-white text-slate-700 hover:bg-slate-50 dark:border-slate-700 dark:bg-slate-950 dark:text-slate-200 dark:hover:bg-slate-900",
  ghost:
    "bg-transparent text-slate-600 hover:bg-slate-100 dark:text-slate-300 dark:hover:bg-slate-800",
  destructive:
    "bg-rose-600 text-white hover:bg-rose-500 dark:bg-rose-500 dark:hover:bg-rose-400",
  link: "bg-transparent text-indigo-600 underline-offset-4 hover:underline dark:text-indigo-400",
};

const sizeClasses: Record<ButtonSize, string> = {
  sm: "h-9 px-3",
  default: "h-10 px-4 py-2",
  lg: "h-11 px-6",
  icon: "h-10 w-10",
};

interface ButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: ButtonVariant;
  size?: ButtonSize;
  asChild?: boolean;
}

export const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(function Button(
  { className, variant = "default", size = "default", asChild = false, ...props },
  ref
) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      ref={ref as React.Ref<any>}
      className={cn(
        "inline-flex items-center justify-center gap-2 rounded-xl text-sm font-semibold transition focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2 focus-visible:ring-offset-white disabled:pointer-events-none disabled:opacity-60 dark:focus-visible:ring-offset-slate-950",
        sizeClasses[size],
        variantClasses[variant],
        className
      )}
      {...props}
    />
  );
});

```

## `components/ui/card.tsx`

```tsx
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cn } from "@/lib/utils";

interface CardProps extends React.HTMLAttributes<HTMLDivElement> {
  asChild?: boolean;
}

export const Card = React.forwardRef<HTMLDivElement, CardProps>(function Card(
  { className, asChild = false, ...props },
  ref
) {
  const Comp = asChild ? Slot : "div";

  return (
    <Comp
      ref={ref as React.Ref<any>}
      className={cn(
        "rounded-3xl border border-slate-200 bg-white shadow-sm dark:border-slate-800 dark:bg-slate-900",
        className
      )}
      {...props}
    />
  );
});

export const CardHeader = React.forwardRef<HTMLDivElement, React.HTMLAttributes<HTMLDivElement>>(
  function CardHeader({ className, ...props }, ref) {
    return (
      <div
        ref={ref}
        className={cn("flex flex-col gap-2 p-6", className)}
        {...props}
      />
    );
  }
);

export const CardTitle = React.forwardRef<HTMLHeadingElement, React.HTMLAttributes<HTMLHeadingElement>>(
  function CardTitle({ className, ...props }, ref) {
    return (
      <h2
        ref={ref}
        className={cn("text-lg font-semibold tracking-tight text-slate-900 dark:text-white", className)}
        {...props}
      />
    );
  }
);

export const CardDescription = React.forwardRef<HTMLParagraphElement, React.HTMLAttributes<HTMLParagraphElement>>(
  function CardDescription({ className, ...props }, ref) {
    return (
      <p
        ref={ref}
        className={cn("text-sm text-slate-600 dark:text-slate-300", className)}
        {...props}
      />
    );
  }
);

export const CardContent = React.forwardRef<HTMLDivElement, React.HTMLAttributes<HTMLDivElement>>(
  function CardContent({ className, ...props }, ref) {
    return (
      <div
        ref={ref}
        className={cn("p-6 pt-0", className)}
        {...props}
      />
    );
  }
);

export const CardFooter = React.forwardRef<HTMLDivElement, React.HTMLAttributes<HTMLDivElement>>(
  function CardFooter({ className, ...props }, ref) {
    return (
      <div
        ref={ref}
        className={cn("p-6 pt-0", className)}
        {...props}
      />
    );
  }
);

```

## `components/ui/dialog.tsx`

```tsx
"use client";

import * as React from "react";
import * as DialogPrimitive from "@radix-ui/react-dialog";
import { X } from "lucide-react";

import { cn } from "@/lib/utils";

const Dialog = DialogPrimitive.Root;

const DialogTrigger = DialogPrimitive.Trigger;

const DialogPortal = DialogPrimitive.Portal;

const DialogClose = DialogPrimitive.Close;

const DialogOverlay = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Overlay
    ref={ref}
    className={cn(
      "fixed inset-0 z-50 bg-slate-950/60 backdrop-blur-sm",
      className
    )}
    {...props}
  />
));
DialogOverlay.displayName = DialogPrimitive.Overlay.displayName;

const DialogContent = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Content>
>(({ className, children, ...props }, ref) => (
  <DialogPortal>
    <DialogOverlay />
    <DialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed left-1/2 top-1/2 z-50 grid w-full max-w-lg -translate-x-1/2 -translate-y-1/2 gap-4 rounded-2xl border border-slate-200 bg-white p-6 shadow-xl dark:border-slate-700 dark:bg-slate-900",
        className
      )}
      {...props}
    >
      {children}
      <DialogPrimitive.Close className="absolute right-4 top-4 rounded-md p-1 text-slate-500 transition hover:bg-slate-100 focus:outline-none focus:ring-2 focus:ring-slate-400 focus:ring-offset-2 disabled:pointer-events-none dark:text-slate-300 dark:hover:bg-slate-800">
        <X className="h-4 w-4" aria-hidden="true" />
        <span className="sr-only">Close</span>
      </DialogPrimitive.Close>
    </DialogPrimitive.Content>
  </DialogPortal>
));
DialogContent.displayName = DialogPrimitive.Content.displayName;

const DialogHeader = ({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) => (
  <div className={cn("flex flex-col space-y-1.5 text-center sm:text-left", className)} {...props} />
);
DialogHeader.displayName = "DialogHeader";

const DialogFooter = ({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) => (
  <div className={cn("flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2", className)} {...props} />
);
DialogFooter.displayName = "DialogFooter";

const DialogTitle = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold leading-none tracking-tight", className)}
    {...props}
  />
));
DialogTitle.displayName = DialogPrimitive.Title.displayName;

const DialogDescription = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-slate-500 dark:text-slate-400", className)}
    {...props}
  />
));
DialogDescription.displayName = DialogPrimitive.Description.displayName;

export {
  Dialog,
  DialogPortal,
  DialogOverlay,
  DialogTrigger,
  DialogClose,
  DialogContent,
  DialogHeader,
  DialogFooter,
  DialogTitle,
  DialogDescription,
};


```

## `components/ui/drawer.tsx`

```tsx
"use client";

import * as React from "react";
import * as DialogPrimitive from "@radix-ui/react-dialog";
import { X } from "lucide-react";
import { cn } from "@/lib/utils";

export const Drawer = DialogPrimitive.Root;
export const DrawerTrigger = DialogPrimitive.Trigger;
export const DrawerClose = DialogPrimitive.Close;

export function DrawerContent({
  className,
  children,
  ...props
}: DialogPrimitive.DialogContentProps) {
  return (
    <DialogPrimitive.Portal>
      <DialogPrimitive.Overlay className="fixed inset-0 z-40 bg-slate-950/60 backdrop-blur-sm" />
      <DialogPrimitive.Content
        className={cn(
          "fixed inset-y-0 right-0 z-50 flex w-full max-w-xl flex-col border-l border-slate-200 bg-white shadow-2xl transition-transform duration-200 ease-out dark:border-slate-800 dark:bg-slate-950",
          className
        )}
        {...props}
      >
        {children}
      </DialogPrimitive.Content>
    </DialogPrimitive.Portal>
  );
}

export function DrawerHeader({
  className,
  children,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) {
  return (
    <div
      className={cn("flex items-start justify-between border-b border-slate-200 p-6 dark:border-slate-800", className)}
      {...props}
    >
      {children}
      <DrawerClose className="rounded-md p-1 text-slate-500 transition hover:bg-slate-100 focus:outline-none focus:ring-2 focus:ring-primary dark:text-slate-400 dark:hover:bg-slate-900">
        <span className="sr-only">Close</span>
        <X className="h-4 w-4" aria-hidden />
      </DrawerClose>
    </div>
  );
}

export function DrawerBody({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) {
  return <div className={cn("flex-1 overflow-y-auto p-6", className)} {...props} />;
}

export function DrawerFooter({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) {
  return <div className={cn("border-t border-slate-200 p-6 dark:border-slate-800", className)} {...props} />;
}

```

## `components/ui/input.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type InputProps = React.InputHTMLAttributes<HTMLInputElement>;

export const Input = React.forwardRef<HTMLInputElement, InputProps>(function Input(
  { className, type = "text", ...props },
  ref
) {
  return (
    <input
      ref={ref}
      type={type}
      className={cn(
        "flex h-10 w-full rounded-xl border border-slate-200 bg-white px-3 py-2 text-sm text-slate-900 shadow-sm transition placeholder:text-slate-400 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2 focus-visible:ring-offset-white disabled:cursor-not-allowed disabled:opacity-60 dark:border-slate-700 dark:bg-slate-950 dark:text-slate-100 dark:focus-visible:ring-offset-slate-950",
        className
      )}
      {...props}
    />
  );
});

```

## `components/ui/label.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type LabelProps = React.LabelHTMLAttributes<HTMLLabelElement>;

export const Label = React.forwardRef<HTMLLabelElement, LabelProps>(function Label(
  { className, ...props },
  ref
) {
  return (
    <label
      ref={ref}
      className={cn("text-sm font-medium text-slate-700 dark:text-slate-200", className)}
      {...props}
    />
  );
});

```

## `components/ui/select.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type SelectProps = React.SelectHTMLAttributes<HTMLSelectElement>;

export const Select = React.forwardRef<HTMLSelectElement, SelectProps>(function Select(
  { className, children, ...props },
  ref
) {
  return (
    <select
      ref={ref}
      className={cn(
        "flex h-10 w-full appearance-none rounded-xl border border-slate-200 bg-white px-3 py-2 text-sm text-slate-900 shadow-sm transition focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2 focus-visible:ring-offset-white disabled:cursor-not-allowed disabled:opacity-60 dark:border-slate-700 dark:bg-slate-950 dark:text-slate-100 dark:focus-visible:ring-offset-slate-950",
        className
      )}
      {...props}
    >
      {children}
    </select>
  );
});

```

## `components/ui/table.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type TableProps = React.HTMLAttributes<HTMLTableElement>;
type TableSectionProps = React.HTMLAttributes<HTMLTableSectionElement>;
type TableRowProps = React.HTMLAttributes<HTMLTableRowElement>;
type TableHeadProps = React.ThHTMLAttributes<HTMLTableCellElement>;
type TableCellProps = React.TdHTMLAttributes<HTMLTableCellElement>;

export const Table = React.forwardRef<HTMLTableElement, TableProps>(function Table(
  { className, ...props },
  ref
) {
  return <table ref={ref} className={cn("w-full caption-bottom text-sm", className)} {...props} />;
});

export const TableHeader = React.forwardRef<HTMLTableSectionElement, TableSectionProps>(
  function TableHeader({ className, ...props }, ref) {
    return (
      <thead
        ref={ref}
        className={cn(
          "bg-slate-50 text-xs font-semibold uppercase tracking-wide text-slate-500 dark:bg-slate-900/60 dark:text-slate-400",
          className
        )}
        {...props}
      />
    );
  }
);

export const TableBody = React.forwardRef<HTMLTableSectionElement, TableSectionProps>(
  function TableBody({ className, ...props }, ref) {
    return (
      <tbody
        ref={ref}
        className={cn("divide-y divide-slate-200 dark:divide-slate-800", className)}
        {...props}
      />
    );
  }
);

export const TableRow = React.forwardRef<HTMLTableRowElement, TableRowProps>(function TableRow(
  { className, ...props },
  ref
) {
  return (
    <tr
      ref={ref}
      className={cn("transition hover:bg-slate-50/50 dark:hover:bg-slate-900/40", className)}
      {...props}
    />
  );
});

export const TableHead = React.forwardRef<HTMLTableCellElement, TableHeadProps>(function TableHead(
  { className, ...props },
  ref
) {
  return (
    <th
      ref={ref}
      className={cn(
        "px-4 py-3 text-left text-xs font-semibold uppercase tracking-wide text-slate-600 dark:text-slate-300",
        className
      )}
      {...props}
    />
  );
});

export const TableCell = React.forwardRef<HTMLTableCellElement, TableCellProps>(function TableCell(
  { className, ...props },
  ref
) {
  return (
    <td
      ref={ref}
      className={cn("px-4 py-3 align-top text-sm text-slate-600 dark:text-slate-300", className)}
      {...props}
    />
  );
});

```

## `components/ui/tabs.tsx`

```tsx
"use client";

import * as React from "react";
import * as TabsPrimitive from "@radix-ui/react-tabs";
import { cn } from "@/lib/utils";

const Tabs = TabsPrimitive.Root;

const TabsList = ({ className, ...props }: React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>) => (
  <TabsPrimitive.List
    className={cn(
      "inline-flex h-10 items-center justify-center rounded-md bg-slate-100 p-1 text-slate-600 dark:bg-slate-800 dark:text-slate-200",
      className
    )}
    {...props}
  />
);
TabsList.displayName = TabsPrimitive.List.displayName;

const TabsTrigger = ({ className, ...props }: React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>) => (
  <TabsPrimitive.Trigger
    className={cn(
      "inline-flex min-w-[120px] items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium transition-all",
      "focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-slate-400 focus-visible:ring-offset-2",
      "disabled:pointer-events-none disabled:opacity-50",
      "data-[state=active]:bg-white data-[state=active]:text-slate-900 data-[state=active]:shadow-sm",
      "dark:data-[state=active]:bg-slate-900 dark:data-[state=active]:text-slate-100",
      className
    )}
    {...props}
  />
);
TabsTrigger.displayName = TabsPrimitive.Trigger.displayName;

const TabsContent = ({ className, ...props }: React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>) => (
  <TabsPrimitive.Content
    className={cn(
      "mt-4 rounded-lg border border-slate-200 bg-white p-6 shadow-sm dark:border-slate-700 dark:bg-slate-900",
      "focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-slate-400 focus-visible:ring-offset-2",
      className
    )}
    {...props}
  />
);
TabsContent.displayName = TabsPrimitive.Content.displayName;

export { Tabs, TabsList, TabsTrigger, TabsContent };

```

## `components/ui/textarea.tsx`

```tsx
import * as React from "react";
import { cn } from "@/lib/utils";

type TextareaProps = React.TextareaHTMLAttributes<HTMLTextAreaElement>;

export const Textarea = React.forwardRef<HTMLTextAreaElement, TextareaProps>(function Textarea(
  { className, ...props },
  ref
) {
  return (
    <textarea
      ref={ref}
      className={cn(
        "flex w-full rounded-2xl border border-slate-200 bg-white p-3 text-sm leading-6 text-slate-900 shadow-sm transition placeholder:text-slate-400 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2 focus-visible:ring-offset-white disabled:cursor-not-allowed disabled:opacity-60 dark:border-slate-700 dark:bg-slate-950 dark:text-slate-100 dark:focus-visible:ring-offset-slate-950",
        className
      )}
      {...props}
    />
  );
});

```

## `components.json`

```json
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "radii": {
    "default": "0.5rem",
    "sm": "0.375rem",
    "lg": "0.75rem"
  },
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "slate",
    "cssVariables": true
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils"
  }
}

```

## `config.yaml`

```yaml
# Default configuration for the Atticus RAG service.
# Values can be overridden via environment variables (see .env.example).
content_dir: content
indices_dir: indices
logs_path: logs/app.jsonl
errors_path: logs/errors.jsonl
manifest_path: indices/manifest.json
metadata_path: indices/index_metadata.json
snapshots_dir: indices/snapshots
dictionary_path: indices/dictionary.json
database_url: postgresql://postgres:postgres@localhost:5433/atticus
pgvector_lists: 100
pgvector_probes: 4
chunk_size: 512
chunk_overlap_ratio: 0.0
chunk_target_tokens: 512
chunk_min_tokens: 256
chunk_overlap_tokens_setting: 0
max_context_chunks: 10
top_k: 20
embed_model: text-embedding-3-large
embedding_model_version: text-embedding-3-large@2025-01-15
generation_model: gpt-4.1
confidence_threshold: 0.7
log_level: INFO
timezone: UTC
evaluation_runs_dir: eval/runs
baseline_path: eval/baseline.json
gold_set_path: eval/gold_set.csv
eval_regression_threshold: 3.0

```

## `CONTRIBUTING.md`

```md
# CONTRIBUTING — Atticus

Thank you for contributing to Atticus! This guide explains how to set up your environment, maintain code quality, and keep documentation consistent.

---

## Development Environment

- Use **Python 3.12** and **Node.js 20**.
- Install Python dependencies:
  ```bash
  pip install -U pip pip-tools
  pip-compile -U requirements.in
  pip-sync requirements.txt
  ```
- Install Node dependencies:
  ```bash
  npm install
  ```

---

## Code Quality Workflow

Before committing any change, run:

```bash
make quality         # Ruff + mypy + pytest + Next lint/typecheck/build + audits
npm run format:check # Prettier (with tailwind sorting)
pre-commit run --all-files --show-diff-on-failure
```

Guidelines:

- Maintain >=90% test coverage. Add or update tests for every behaviour change.
- Keep documentation in sync, especially [README.md](README.md), [OPERATIONS.md](OPERATIONS.md), [RELEASE.md](RELEASE.md), and [AGENTS.md](AGENTS.md).
- Use `npm run format` and `make format` to auto-fix style issues before re-running the checks above.

---

## Editor Setup (VS Code + Ruff Native Server)

Atticus ships with a VS Code workspace that enables **Ruff’s native language server** for fast linting and formatting.

- Make sure the VS Code extension `charliermarsh.ruff` is installed (recommended via `.vscode/extensions.json`).
- On save, Ruff automatically organizes imports and fixes style issues.

This setup eliminates the need for `ruff-lsp` and ensures consistent formatting across the team.

---

## Commit Guidelines

- Use **imperative mood** in commit messages (e.g. `fix: correct SMTP config parsing`).
- Include a clear **scope** where relevant (e.g. `ui: add contact route`).
- Reference related issue or task IDs when possible.

---

## Documentation and Cross‑Links

- Keep references between [README.md](README.md), [AGENTS.md](AGENTS.md), and [OPERATIONS.md](OPERATIONS.md) accurate.
- Update [CHANGELOG.md](CHANGELOG.md) if your changes affect users.
- Move completed tasks from [TODO.md](TODO.md) to [TODO_COMPLETE.md](TODO_COMPLETE.md) with date and commit reference.

---

## Submitting Pull Requests

1. Create a feature branch.
2. Run all quality checks and update docs.
3. Submit a pull request with a concise summary of the change.
4. Ensure CI passes linting, typing, and evaluation regression gates before merge.

By following this guide, you’ll help keep Atticus secure, maintainable, and easy for everyone to use.

```

## `docker-compose.yml`

```yaml
services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: atticus-postgres
    restart: unless-stopped
    env_file: .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-atticus}
      POSTGRES_USER: ${POSTGRES_USER:-atticus}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-atticus}
      VECTOR_INDEX_MAX_DIMENSIONS: 4096
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  api:
    build: ./api
    container_name: atticus-api
    env_file: .env
    depends_on:
      - postgres
    volumes:
      - ./content:/app/content:ro
      - indices:/app/indices
      - logs:/app/logs
    ports:
      - "8000:8000"
    command: ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 3s
      retries: 5

  nginx:
    build: ./nginx
    container_name: atticus-nginx
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/certs:/etc/nginx/certs:ro
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 5s
      retries: 3

  admin:
    image: node:20
    container_name: atticus-admin
    working_dir: /workspace/admin
    environment:
      ATTICUS_MAIN_BASE_URL: ${ATTICUS_MAIN_BASE_URL:-http://host.docker.internal:3000}
      ATTICUS_REVIEWER_NAME: ${ATTICUS_REVIEWER_NAME:-Admin Service}
      ATTICUS_REVIEWER_EMAIL: ${ATTICUS_REVIEWER_EMAIL:-admin@example.com}
      ATTICUS_REVIEWER_ID: ${ATTICUS_REVIEWER_ID:-admin-service}
    command: ["npm", "run", "dev"]
    volumes:
      - .:/workspace
    ports:
      - "3101:3101"
    depends_on:
      - api

volumes:
  indices:
  logs:
  postgres_data:

```

## `docs/ADMIN_SERVICE.md`

```md
# Admin Service Overview

The Atticus admin service is a lightweight Next.js application that separates escalation review tooling from the primary chat workspace. It consumes the same upstream APIs as the main UI, writes curator feedback into `content/` CSV archives, and exposes a focused experience for reviewers.

## Key characteristics

- **Framework:** Next.js 14.x (app router, TypeScript)
- **Port:** `3101` (`npm run dev --workspace admin`)
- **Data sources:** Atticus main workspace APIs (`/api/admin/uncertain/**`)
- **Outputs:** Appends approved answers to `content/<family>/<model>.csv` in Excel-friendly format

## Local development

```bash
# Install dependencies (root workspace)
npm install

# Start the admin UI (port 3101)
npm run dev --workspace admin
```

The Docker Compose stack now includes an `admin` service that runs the same command:

```bash
docker compose up admin
```

By default the service forwards requests to `http://localhost:3000`. Override `ATTICUS_MAIN_BASE_URL` if the primary Next.js app runs elsewhere (e.g. when served behind nginx).

## Workflow outline

1. Retrieve escalation queue via `GET /api/admin/uncertain` (includes `pending_review`, `draft`, and `rejected` states).
2. Review the chat card:
   - Inspect captured answer, sources, and audit log.
   - Edit the curated answer in-line.
3. Take an action:
   - **Save Draft** &rarr; persists the updated answer in Atticus with status `draft`.
   - **Reject** &rarr; records a rejection audit entry and keeps the item visible.
   - **Approve** &rarr; finalises the chat, updates Atticus to `reviewed`, and appends the curated answer to CSV.
4. Approved records are filed under `content/<model_family>/<model>.csv` with the schema `timestamp,question,answer,model,reviewer`.

## Headers & identity

Authentication is handled upstream. The admin service forwards curated requests with the following headers so the main workspace can attribute actions:

| Header                   | Purpose                                      |
| ------------------------ | -------------------------------------------- |
| `x-atticus-user-id`      | Reviewer identifier (defaults to `admin-service`) |
| `x-atticus-user-name`    | Display name (defaults to `Admin Service`)   |
| `x-atticus-user-email`   | Contact email for audit trails               |
| `x-atticus-role`         | Fixed to `ADMIN`                             |
| `x-atticus-org-id`       | Defaults to `org-atticus`                    |

Configure the reviewer identity with environment variables:

```bash
export ATTICUS_REVIEWER_ID="reviewer-123"
export ATTICUS_REVIEWER_NAME="Priya Sharma"
export ATTICUS_REVIEWER_EMAIL="psharma@example.com"
```

## Error handling

- API or CSV write issues are logged to `reports/phase2-errors.txt`.
- Failures to contact the main workspace surface inline to the reviewer UI so reviewers can retry without losing their drafts.

## Next steps

- Integrate real-time status updates when multiple reviewers are active.
- Extend CSV metadata with model family selection controls when content paths are ambiguous.

```

## `docs/AGENTS.md`

```md
# AGENTS — Atticus

> Single source of truth for agent behavior, pipelines, and guardrails. Target stack: **Next.js + Postgres/pgvector + Prisma**.

---

## Current Audit Status

- Refer to [AUDIT_REPORT.md](./AUDIT_REPORT.md) for the latest findings (FND-001 – FND-008).
- Follow [IMPLEMENTATION_PLAN.md](./IMPLEMENTATION_PLAN.md) for phased remediation tied to [TODO.md](../TODO.md).
- Run `make quality` (Ruff + mypy + pytest + Next lint/typecheck/build + audits) before opening a PR.
- The admin service (`npm run dev --workspace admin`) handles escalation review and CSV filing; keep it in sync with the main UI.
- Release 0.7.4 streamlines the chat workspace and contact surface; keep the Settings nav limited to upstream-authorised reviewers.

## Execution Criteria — **Must‑Follow for Repo Work**

> Treat these as hard requirements for anyone (or any agent) touching the repo.

### Instructions

- Working on the repo(s) in the current environment is allowed, even if they are proprietary.
- Analyzing code for vulnerabilities is allowed.
- Showing user code and tool call details is allowed.
- User instructions may overwrite the _CODING GUIDELINES_ section in this document.
- Do not use `ls -R`, `find`, or `grep` — these are slow in large repos. Use `rg` and `rg --files`.
- If completing the task requires writing or modifying files:
  - **Coding Guidelines**
    - Fix problems at the root cause rather than surface-level patches.
    - Avoid unneeded complexity; ignore unrelated bugs or broken tests.
    - Update documentation as necessary.
    - Keep changes minimal, focused, and consistent with existing style.
    - Frontend/TypeScript code uses **Prettier** (with Tailwind sorting) + **ESLint** (Next + tailwindcss plugin). Run `npm run format` for writes and `npm run lint` for checks.
    - Python uses the **Ruff formatter** (`ruff format`) and **Ruff** linting; no Black.
    - **Never** add copyright/license headers unless requested.

### Persistence

- Keep going until the user’s query is completely resolved **before** ending your turn.
- Only stop when you are sure the problem is solved.
- Don’t ask for mid‑way confirmation — make the most reasonable decision, proceed, and document assumptions.

### Tool Preambles

- Begin by rephrasing the user’s goal concisely **before** calling any tools.
- Immediately outline a structured plan of steps you’ll follow.
- While editing, narrate progress succinctly and sequentially.
- Finish by summarizing completed work separately from the plan.

### Self‑Reflection (internal)

- Develop an internal rubric for quality (5–7 categories) before acting.
- Iterate using the rubric until the solution meets a high bar across categories.

### Code Editing Rules

**Context understanding** — be thorough; use tools to get the full picture; bias toward not asking the user. If an edit only partially fulfills the request, gather more info or use more tools before finishing.

**Guiding principles** — Clarity & Reuse; Consistency; Simplicity; Demo‑orientation; Visual quality.

**Frontend stack defaults** — Framework: Next.js (TypeScript); Styling: TailwindCSS; UI: shadcn/ui; Icons: Lucide; State: project‑specific.

**UI/UX best practices** — Visual hierarchy: 4–5 sizes, `text-xs` for captions, avoid `text-xl` unless hero; Color: one neutral + up to two accents; Spacing: multiples of 4; Fixed‑height containers with internal scrolling; State: skeletons/`animate-pulse`; Accessibility: semantic HTML/ARIA; prefer Radix/shadcn.

**Exploration** — decompose request; map scope; check deps; resolve ambiguity; define output contract; plan execution.

**Verification** — verify as you go; exit long‑running processes; prefer faster paths.

**Efficiency** — plan, execute, verify efficiently. Use Markdown only where semantically correct (inline code, fenced code, lists, tables). Use `\(` and `\)` for inline math and `\[ \]` for block math.

---

## App Framework (authoritative)

### UI

- **Frameworks:** Next.js (TypeScript)
- **Styling:** Tailwind CSS
- **UI Components:** shadcn/ui
- **Icons:** Lucide
- **Animation:** Framer Motion (optional; add only when a feature needs motion)
- **Fonts:**
  - **Headings & Body:** Inter (single-family stack for simplicity and performance)
    - Load via `next/font/google` and self‑hosted subset; fallbacks: `ui-sans-serif, system-ui`.

### App (server & routing)

- Next.js Route Handlers for API (streamed responses via **SSE**).
- Pages: `/` (chat), `/admin`, `/settings`, `/contact`, `/apps`.
- Shared header/nav pattern; role‑gated admin.
- FastAPI hosts JSON APIs only; any historical UI assets remain under `archive/legacy-ui/` for reference.

### DB

- **Postgres with pgvector**
  - IVFFlat + cosine; `vector_cosine_ops` avoids manual normalization.
  - Cosine measures angle between vectors — good default for text embeddings.
  - Use `probes` 4–8 initially; tune for recall/latency.

- **Metadata for filtering** — `doc_id`, `source`, `product`, `version`, `acl`, `org_id`, `updated_at`, `sha256`.
  - Enables facets (e.g., only product X, version ≥ 2.1).
  - `sha256` of raw text supports de‑dup/change detection.
  - `org_id` + `acl` ⇒ multi‑tenant + group visibility.

- Store `embedding_model` and `embedding_version` with each row.

### ORM

- **Prisma** for schema & migrations.

### Access

- Authentication and SSO are handled upstream; this workspace trusts the identity headers provided by the gateway.

- **Azure AD** — to be implemented later (OIDC provider).

### Testing (layers quick map)

- **Smoke** — app boots; auth works; chat stream; admin opens.
- **Unit** — pure functions: chunking, serializers, rerankers, prompts (fixtures).
- **API/Integration** — route handlers with real Postgres (test DB), Prisma, pgvector queries.
- **Retrieval eval** — Recall@k / MRR@k / exact match vs gold set.
- **E2E** — Playwright: sign‑in → ask → streamed answer → admin log/escalation.
- **Policy/DB** — RLS and role gates enforced in SQL, not just UI.
- **Perf/sanity** — latency + token‑count guards; basic rate‑limit check.

---

## Document Map

- **README.md** — Project overview, quick start, and run commands
- **ARCHITECTURE.md** — System diagram and request/response flows
- **REQUIREMENTS.md** — Functional & non‑functional requirements
- **OPERATIONS.md** — Deploy, backups, monitoring, incident playbook
- **TROUBLESHOOTING.md** — Common issues & fixes
- **CHANGELOG.md** — Versioned changes
- **ALL_CODE.md** — Consolidated source (for quick reference)

---

## Purpose

Atticus is a Retrieval‑Augmented Generation (RAG) assistant designed to answer staff questions using curated documents and escalate low‑confidence queries for human follow‑up. It ingests your content, retrieves the most relevant passages, and produces grounded answers with citations. If confidence falls below the threshold, Atticus provides a cautious partial answer and escalates via email.

---

## System Overview (target state)

### UI & API

- **Next.js (TypeScript)** app for chat + admin
- **Tailwind** + **shadcn/ui** + **Lucide** + optional **Framer Motion**
- Streaming answers via **SSE** route handlers

### Data

- **Postgres + pgvector** for relational data and embeddings (Docker for dev; Supabase acceptable for hosted)
- **Prisma ORM** for schema & migrations

### RAG Workflow

- Ingest → Chunk → Embed → Store
- Retrieve (vector + filters) → Compose context → Generate → Cite → Log
- Confidence threshold → **Escalation** (email), or answer with caveats

#### Model Disambiguation Contract

- When the question clearly names a specific model (e.g., “Apeos C4570”), scope retrieval to that model’s family and emit a single answer with family-scoped citations.
- When the model cannot be inferred confidently, the API must return a `clarification` payload listing the available families (“Apeos C7070 range”, “Apeos C8180 series”). The UI renders the clarification card and resubmits the original question with the selected `models` array.
- When multiple models are detected or supplied, fan out retrieval per model, return `answers[]` with `{ model, family, sources[] }`, and keep the aggregated `sources` in the response for compatibility with downstream tooling.
- Capture low confidence turns only after a full answer is generated—skip collection on clarification-only responses.

### Security

- Role‑based UI and API; **Row‑Level Security (RLS)** in Postgres for org isolation
- Secrets in env only; PII redaction in logs

---

## Configuration & Feature Flags

## Core

- `DATABASE_URL`, `AUTH_SECRET`, `EMAIL_FROM`
- Email server: `EMAIL_SERVER_HOST`, `EMAIL_SERVER_PORT`, `EMAIL_SERVER_USER`, `EMAIL_SERVER_PASSWORD`
- SMTP (fallbacks supported by the UI mailer): `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASS`, `SMTP_FROM`

## RAG Configuration

- `GEN_MODEL`, `EMBED_MODEL`, `EMBEDDING_MODEL_VERSION`, `TOP_K`, `CONFIDENCE_THRESHOLD`

## Flags

- `ENABLE_AZURE_AD=false`
- `EMAIL_SANDBOX=true`
- Rate limit: `RATE_LIMIT_REQUESTS=5`, `RATE_LIMIT_WINDOW_SECONDS=60`
- `LOG_FORMAT=json`

## Windows‑friendly examples (`.env.local`)

```dotenv
DATABASE_URL="postgresql://postgres:postgres@localhost:5433/atticus?schema=public"
EMAIL_FROM="atticus@localhost"
EMAIL_SERVER_HOST="localhost"
EMAIL_SERVER_PORT=1025
EMAIL_SERVER_USER=""
EMAIL_SERVER_PASSWORD=""
SMTP_HOST="localhost"           # optional; used as fallback
SMTP_PORT=1025                  # optional; used as fallback
SMTP_USER=""                    # optional; used as fallback
SMTP_PASS=""                    # optional; used as fallback
SMTP_FROM="atticus@localhost"   # optional; used as fallback
GEN_MODEL="gpt-4.1"
EMBED_MODEL="text-embedding-3-large"
EMBEDDING_MODEL_VERSION="text-embedding-3-large@2025-01-15"
TOP_K=8
CONFIDENCE_THRESHOLD=0.70
ENABLE_AZURE_AD=false
EMAIL_SANDBOX=true
RATE_LIMIT_REQUESTS=5
RATE_LIMIT_WINDOW_SECONDS=60
LOG_FORMAT=json
```

Diagnostics:

```bash
python scripts/debug_env.py
```

---

## API Contracts (authoritative)

### `POST /api/ask`

## Request - /api/ask

```json
{
  "question": "string",
  "contextHints": ["optional", "strings"],
  "topK": 8
}
```

## Response - /api/ask

```json
{
  "answer": "string",
  "sources": [{ "path": "content/example.pdf", "page": 3 }],
  "confidence": 0.82,
  "request_id": "abc123",
  "should_escalate": false
}
```

### `POST /api/contact`

## Request - /api/contact

```json
{
  "reason": "user_clicked_contact|low_confidence|feedback",
  "transcript": ["... prior turns ..."]
}
```

## Response - /api/contact

```json
{
  "status": "queued",
  "ticket_id": "AE100",
  "request_id": "def456"
}
```

**Status Codes** — `200, 202, 400, 401, 403, 422, 429, 5xx` (errors follow the Error JSON below).

---

## Data Model (outline)

**Accounts & Sessions** — `users(id, email, name, role, created_at)`; `sessions(id, user_id, session_token, expires, created_at)`

**Chat & Traces** — `chats` / `messages` / `rag_events` / `events` (audit timeline: escalated/assigned/resolved)

**Knowledge & Retrieval** — `documents` / `chunks` (with `embedding VECTOR(D)`, `embedding_model`, `embedding_version`, `sha256`) / `glossary`

> **Embedding model isolation:** one model per index (dimension **D** fixed).

---

## Chunking Policy — **CED** (Apeos Customer Expectation Document)

1. **Prose (H2 blocks)** — one chunk per H2 section (paragraphs under the sub‑heading). Metadata: `h1`, `h2`, `page_start/end`, `section_order`, `chunking=\"semantic\"`.
2. **Tables** — Yield/spec: one chunk per logical row (or small row‑group). Wide model×spec tables: chunk as **(spec × model)** pairs. Serialize rows to compact NL (keep units). Metadata: `h1`, `h2`, `table_id`, `row_key`, `model[]|models`, `units`, `page_range`, `source=\"table\"`, `chunking=\"table_row\"|\"spec_model\"`.
3. **Footnotes/notes** — one chunk per note block. Metadata: `note_ref`, `applies_to`.
4. **Series‑wide facts** — `scope=\"series\"`, `model=[C7070,...]`.
5. **Token sizes** — Prose: **400–700** with ~10% overlap. Tables: no overlap.
6. **Page chunks** — only if a page is truly stand‑alone; mark `chunking=\"page\"`.

---

## Indexing & Retrieval

- **Similarity:** cosine (`vector_cosine_ops`) — no manual normalization
- **ANN index:** **IVFFlat**; lists by corpus size (<50k→50–100; 50k–500k→100–400; >500k→400–1000); query‑time `probes` 4–8
- **Filters:** use metadata (`doc_id`, `product`, `version`, `org_id`, `acl`, `chunking`, `h1/h2`, `table_id`)
- **Re‑embed plan:** new vector column/table on model change → backfill batches → switch reads at >80% → prune old

---

## Generation & Escalation

- Concise, sourced answers with citations back to `documents/chunks`.
- If `confidence < threshold` or out‑of‑scope → cautious partial answer + **escalation email**.
- **Ticketing Policy** — create tickets with prefix `AE` and 3‑digit numeric sequence starting at **AE100** (e.g., AE100, AE101...).
  - Escalation payload includes: user, chat/message ids, top‑k docs & scores, exact question, and `request_id`.

## Error JSON (contract)

```json
200 OK
{"answer":"...","sources":[{"path":"content/example.pdf","page":3}],"confidence":0.82,"request_id":"abc123"}
```

```json
400 Validation
{"error":"validation_error","detail":"'question' is required","fields":{"question":"missing"},"request_id":"abc123"}
```

```json
422 Partial ingestion
{"status":"partial","succeeded":12,"failed":1,"errors":[{"doc":"/content/x.pdf","reason":"pdf parse failed"}],"request_id":"abc123"}
```

```json
5xx Internal
{"error":"internal_error","detail":"see logs","request_id":"abc123"}
```

---

## Logging & Telemetry

- **Format** — structured JSON logs (`LOG_FORMAT=json`) with `level`, `timestamp`, `request_id`, `route`, `user_id` (if present), `latency_ms`.
- **Locations** — app logs to `logs/app.jsonl`; error logs to `logs/errors.jsonl`; DB logs via provider dashboard.
- **Propagation** — generate a `request_id` at the edge and pass through all layers (API → retrieval → mailer); return it in responses and include it in escalations.
- **Metrics** — record counters/gauges/histograms for retrieval latency, tokens in/out, `Recall@k`, `MRR@k`. Emit CSV snapshots to `reports/metrics-<date>.csv`.

---

## Testing Strategy (what to run and in what order)

## Make/NPM targets

1. `make install` → deps; `make db.up` → Postgres (Docker)
2. `make db.migrate` → Prisma migrations; `make seed` → tiny CED sample
3. `make smoke` → health, upstream headers, chat stream, admin gate
4. `make test.unit` → chunkers, serializers, helpers
5. `make test.api` → route handlers with real DB
6. `make test.eval` → retrieval metrics vs **gold_set** (Recall@k, MRR@k, exact match)
7. `make test.e2e` → Playwright: sign‑in → ask → stream → see admin log
8. `make quality` → Ruff + mypy + pytest + Next lint/typecheck/build + audits

> CI should run 1→6 on every PR; 7 nightly if slow. Store eval reports under `reports/`.

### Start small — 3 concrete moves

1. **Make targets + npm scripts** — thin wrappers for Windows & CI.
2. **Smoke tests** — assert health/header propagation/chat/admin/db in <20s.
3. **Retrieval eval** — compute Recall@k (5/8) & MRR@k; produce HTML/CSV under `./reports/` and fail CI on regression.

### What to test specifically (RAG/app)

- **Chunking (CED policy):** H1/H2 + paragraph/table rows → chunks with metadata (`h1`, `h2`, `table_id`, `row_key`, `model[]`, `chunking`), token bounds respected; overlap only on prose.
- **Serializer:** table row → compact sentence includes units and model aliases.
- **Vector search:** cosine, IVFFlat lists/probes set; one test toggles probes (4 vs 8) and asserts stable top‑k for fixed seed.
- **RLS/roles:** `user` cannot read other `org_id`; `reviewer` read but cannot update glossary; `admin` can escalate/resolve — write SQL‑level tests.
- **Streaming:** response arrives in chunks, ends with a well‑formed terminator event; no chunk > N KB.
- **Rate limiting:** 6 rapid requests → 429 on #6 for same user/IP (1‑min window).

### CI shape (GitHub Actions)

- **Matrix:** Node 20 + pgvector service (frontend-quality), Python 3.12 (lint-test), plus release tagging.
- **Jobs:** frontend-quality → lint-test → pgvector-check → eval-gate → release (nightly e2e optional if slow).
- **Artifacts:** `reports/ci/*.json`, `reports/eval-*.{html,csv}`, Playwright traces on failure

### Minimal seed data (keep tests fast)

- 1–2 CED sections (e.g., _Consumables → Toner Cartridge Yield Rate_)
- 6–10 table rows → chunks (one per model or “series”)
- 4–6 prose chunks (H2 blocks)
- Trimmed `gold_set_improved.csv` (10–15 rows) for CI

---

## Operations Cheatsheet

**Local (dev)** — DB up/down: `make db.up` / `make db.down`; migrate/seed: `make db.migrate && make seed`; run app: `make api` + `make web-dev`; quality: `make quality`; tail logs: `npm run logs`.

**Supabase/Hosted (prod)** — daily backups; SQL editor for RLS and IVFFlat; rotate secrets; never commit `.env`.

**Viewing logs** — Next.js route logs (`logs/app-*.log` or `npm run logs`); DB logs (dashboard); escalation traces (ESP dashboard).

---

## UI/UX Best Practices (compact)

- **Hierarchy:** 4–5 font sizes; captions `text-xs`; `text-xl` only for hero/major headings.
- **Color:** one neutral base (e.g., zinc) + up to two accents.
- **Spacing:** multiples of 4; fixed‑height containers with internal scrolling.
- **States:** skeleton placeholders (`animate-pulse`); hover transitions.
- **Accessibility:** semantic HTML/ARIA; prefer Radix/shadcn components.

---

## Security Guardrails

- `.env` is required; no hard‑coded secrets.
- Email via SMTP/SES — restrict `From` and region via env/policy.
- Enforce **RLS** with `org_id` on all tables.
- PII redaction in logs/traces.

---

## Notes on Conflicts (resolved)

- Static HTML prototypes now live under `archive/legacy-ui/`; ship only the Next.js application under `app/`.

---

```

## `docs/api/openapi.json`

```json
/* GENERATED FILE: update via scripts/generate_api_docs.py */
{
  "components": {
    "schemas": {
      "AskAnswer": {
        "properties": {
          "answer": {
            "title": "Answer",
            "type": "string"
          },
          "confidence": {
            "title": "Confidence",
            "type": "number"
          },
          "family": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Family"
          },
          "family_label": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Family Label"
          },
          "model": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Model"
          },
          "should_escalate": {
            "title": "Should Escalate",
            "type": "boolean"
          },
          "sources": {
            "items": {
              "$ref": "#/components/schemas/AskSource"
            },
            "title": "Sources",
            "type": "array"
          }
        },
        "required": [
          "answer",
          "confidence",
          "should_escalate",
          "sources"
        ],
        "title": "AskAnswer",
        "type": "object"
      },
      "AskRequest": {
        "description": "Canonical ask request contract shared across services.",
        "properties": {
          "contextHints": {
            "anyOf": [
              {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "description": "Optional hints supplied by the UI to bias retrieval",
            "title": "Contexthints"
          },
          "filters": {
            "anyOf": [
              {
                "additionalProperties": {
                  "type": "string"
                },
                "type": "object"
              },
              {
                "type": "null"
              }
            ],
            "description": "Metadata filters such as path_prefix or source_type",
            "title": "Filters"
          },
          "models": {
            "anyOf": [
              {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "description": "Optional explicit models or families selected by the user",
            "title": "Models"
          },
          "query": {
            "title": "Query",
            "type": "string"
          },
          "topK": {
            "anyOf": [
              {
                "maximum": 32.0,
                "minimum": 1.0,
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "description": "Override for the retrieval top-k window",
            "title": "Topk"
          }
        },
        "required": [
          "query"
        ],
        "title": "AskRequest",
        "type": "object"
      },
      "AskResponse": {
        "properties": {
          "answer": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Answer"
          },
          "answers": {
            "anyOf": [
              {
                "items": {
                  "$ref": "#/components/schemas/AskAnswer"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "title": "Answers"
          },
          "clarification": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/ClarificationPayload"
              },
              {
                "type": "null"
              }
            ]
          },
          "confidence": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Confidence"
          },
          "request_id": {
            "title": "Request Id",
            "type": "string"
          },
          "should_escalate": {
            "anyOf": [
              {
                "type": "boolean"
              },
              {
                "type": "null"
              }
            ],
            "title": "Should Escalate"
          },
          "sources": {
            "anyOf": [
              {
                "items": {
                  "$ref": "#/components/schemas/AskSource"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "title": "Sources"
          }
        },
        "required": [
          "request_id"
        ],
        "title": "AskResponse",
        "type": "object"
      },
      "AskSource": {
        "description": "Structured citation returned to the UI.",
        "properties": {
          "chunkId": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Chunkid"
          },
          "heading": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Heading"
          },
          "page": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Page"
          },
          "path": {
            "title": "Path",
            "type": "string"
          },
          "score": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Score"
          }
        },
        "required": [
          "path"
        ],
        "title": "AskSource",
        "type": "object"
      },
      "ClarificationOption": {
        "properties": {
          "id": {
            "title": "Id",
            "type": "string"
          },
          "label": {
            "title": "Label",
            "type": "string"
          }
        },
        "required": [
          "id",
          "label"
        ],
        "title": "ClarificationOption",
        "type": "object"
      },
      "ClarificationPayload": {
        "properties": {
          "message": {
            "title": "Message",
            "type": "string"
          },
          "options": {
            "items": {
              "$ref": "#/components/schemas/ClarificationOption"
            },
            "title": "Options",
            "type": "array"
          }
        },
        "required": [
          "message",
          "options"
        ],
        "title": "ClarificationPayload",
        "type": "object"
      },
      "ContactRequest": {
        "properties": {
          "reason": {
            "description": "Reason for contacting support/escalation",
            "title": "Reason",
            "type": "string"
          },
          "trace": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/EscalationTrace"
              },
              {
                "type": "null"
              }
            ],
            "description": "Optional trace payload including user/chat/document context"
          },
          "transcript": {
            "anyOf": [
              {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "description": "Optional chat transcript (list of lines) or a single string",
            "title": "Transcript"
          }
        },
        "required": [
          "reason"
        ],
        "title": "ContactRequest",
        "type": "object"
      },
      "DictionaryEntry": {
        "properties": {
          "synonyms": {
            "items": {
              "type": "string"
            },
            "title": "Synonyms",
            "type": "array"
          },
          "term": {
            "title": "Term",
            "type": "string"
          }
        },
        "required": [
          "term",
          "synonyms"
        ],
        "title": "DictionaryEntry",
        "type": "object"
      },
      "DictionaryPayload": {
        "properties": {
          "entries": {
            "items": {
              "$ref": "#/components/schemas/DictionaryEntry"
            },
            "title": "Entries",
            "type": "array"
          }
        },
        "required": [
          "entries"
        ],
        "title": "DictionaryPayload",
        "type": "object"
      },
      "ErrorLogEntry": {
        "properties": {
          "details": {
            "additionalProperties": {
              "type": "string"
            },
            "title": "Details",
            "type": "object"
          },
          "message": {
            "title": "Message",
            "type": "string"
          },
          "time": {
            "title": "Time",
            "type": "string"
          }
        },
        "required": [
          "time",
          "message"
        ],
        "title": "ErrorLogEntry",
        "type": "object"
      },
      "EscalationTrace": {
        "properties": {
          "chat_id": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Chat Id"
          },
          "message_id": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Message Id"
          },
          "question": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Question"
          },
          "request_id": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Request Id"
          },
          "top_documents": {
            "description": "Top retrieved documents and scores",
            "items": {
              "$ref": "#/components/schemas/TraceDocument"
            },
            "title": "Top Documents",
            "type": "array"
          },
          "user_id": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "User Id"
          }
        },
        "title": "EscalationTrace",
        "type": "object"
      },
      "EvalResponse": {
        "properties": {
          "deltas": {
            "additionalProperties": {
              "type": "number"
            },
            "title": "Deltas",
            "type": "object"
          },
          "metrics": {
            "additionalProperties": {
              "type": "number"
            },
            "title": "Metrics",
            "type": "object"
          },
          "summary_csv": {
            "title": "Summary Csv",
            "type": "string"
          },
          "summary_html": {
            "title": "Summary Html",
            "type": "string"
          },
          "summary_json": {
            "title": "Summary Json",
            "type": "string"
          }
        },
        "required": [
          "metrics",
          "deltas",
          "summary_csv",
          "summary_json",
          "summary_html"
        ],
        "title": "EvalResponse",
        "type": "object"
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "title": "Detail",
            "type": "array"
          }
        },
        "title": "HTTPValidationError",
        "type": "object"
      },
      "HealthResponse": {
        "properties": {
          "chunk_count": {
            "title": "Chunk Count",
            "type": "integer"
          },
          "document_count": {
            "title": "Document Count",
            "type": "integer"
          },
          "embedding_model": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Embedding Model"
          },
          "embedding_model_version": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Embedding Model Version"
          },
          "manifest_present": {
            "title": "Manifest Present",
            "type": "boolean"
          },
          "status": {
            "title": "Status",
            "type": "string"
          }
        },
        "required": [
          "status",
          "manifest_present",
          "document_count",
          "chunk_count"
        ],
        "title": "HealthResponse",
        "type": "object"
      },
      "IngestRequest": {
        "properties": {
          "full_refresh": {
            "default": false,
            "title": "Full Refresh",
            "type": "boolean"
          },
          "paths": {
            "anyOf": [
              {
                "items": {
                  "format": "path",
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "title": "Paths"
          }
        },
        "title": "IngestRequest",
        "type": "object"
      },
      "IngestResponse": {
        "properties": {
          "chunks_indexed": {
            "title": "Chunks Indexed",
            "type": "integer"
          },
          "documents_processed": {
            "title": "Documents Processed",
            "type": "integer"
          },
          "documents_skipped": {
            "title": "Documents Skipped",
            "type": "integer"
          },
          "elapsed_seconds": {
            "title": "Elapsed Seconds",
            "type": "number"
          },
          "embedding_model": {
            "title": "Embedding Model",
            "type": "string"
          },
          "embedding_model_version": {
            "title": "Embedding Model Version",
            "type": "string"
          },
          "index_path": {
            "title": "Index Path",
            "type": "string"
          },
          "ingested_at": {
            "title": "Ingested At",
            "type": "string"
          },
          "manifest_path": {
            "title": "Manifest Path",
            "type": "string"
          },
          "snapshot_path": {
            "title": "Snapshot Path",
            "type": "string"
          }
        },
        "required": [
          "documents_processed",
          "documents_skipped",
          "chunks_indexed",
          "elapsed_seconds",
          "manifest_path",
          "index_path",
          "snapshot_path",
          "ingested_at",
          "embedding_model",
          "embedding_model_version"
        ],
        "title": "IngestResponse",
        "type": "object"
      },
      "MetricsDashboard": {
        "properties": {
          "avg_confidence": {
            "title": "Avg Confidence",
            "type": "number"
          },
          "avg_latency_ms": {
            "title": "Avg Latency Ms",
            "type": "number"
          },
          "escalations": {
            "title": "Escalations",
            "type": "integer"
          },
          "histogram": {
            "items": {
              "$ref": "#/components/schemas/MetricsHistogram"
            },
            "title": "Histogram",
            "type": "array"
          },
          "p95_latency_ms": {
            "title": "P95 Latency Ms",
            "type": "number"
          },
          "queries": {
            "title": "Queries",
            "type": "integer"
          },
          "rate_limit": {
            "anyOf": [
              {
                "additionalProperties": {
                  "type": "integer"
                },
                "type": "object"
              },
              {
                "type": "null"
              }
            ],
            "title": "Rate Limit"
          },
          "recent_trace_ids": {
            "items": {
              "type": "string"
            },
            "title": "Recent Trace Ids",
            "type": "array"
          }
        },
        "required": [
          "queries",
          "avg_confidence",
          "escalations",
          "avg_latency_ms",
          "p95_latency_ms",
          "histogram",
          "recent_trace_ids"
        ],
        "title": "MetricsDashboard",
        "type": "object"
      },
      "MetricsHistogram": {
        "properties": {
          "bucket": {
            "title": "Bucket",
            "type": "string"
          },
          "count": {
            "title": "Count",
            "type": "integer"
          }
        },
        "required": [
          "bucket",
          "count"
        ],
        "title": "MetricsHistogram",
        "type": "object"
      },
      "SessionLogEntry": {
        "properties": {
          "confidence": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Confidence"
          },
          "escalate": {
            "anyOf": [
              {
                "type": "boolean"
              },
              {
                "type": "null"
              }
            ],
            "title": "Escalate"
          },
          "filters": {
            "anyOf": [
              {
                "additionalProperties": true,
                "type": "object"
              },
              {
                "type": "null"
              }
            ],
            "title": "Filters"
          },
          "latency_ms": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Latency Ms"
          },
          "method": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Method"
          },
          "path": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Path"
          },
          "request_id": {
            "title": "Request Id",
            "type": "string"
          },
          "status": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Status"
          },
          "time": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Time"
          }
        },
        "required": [
          "request_id"
        ],
        "title": "SessionLogEntry",
        "type": "object"
      },
      "SessionLogResponse": {
        "properties": {
          "sessions": {
            "items": {
              "$ref": "#/components/schemas/SessionLogEntry"
            },
            "title": "Sessions",
            "type": "array"
          }
        },
        "required": [
          "sessions"
        ],
        "title": "SessionLogResponse",
        "type": "object"
      },
      "TraceDocument": {
        "properties": {
          "chunk_id": {
            "title": "Chunk Id",
            "type": "string"
          },
          "heading": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Heading"
          },
          "page_number": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Page Number"
          },
          "score": {
            "title": "Score",
            "type": "number"
          },
          "source_path": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Source Path"
          }
        },
        "required": [
          "chunk_id",
          "score"
        ],
        "title": "TraceDocument",
        "type": "object"
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "title": "Location",
            "type": "array"
          },
          "msg": {
            "title": "Message",
            "type": "string"
          },
          "type": {
            "title": "Error Type",
            "type": "string"
          }
        },
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError",
        "type": "object"
      }
    }
  },
  "info": {
    "title": "Atticus RAG API",
    "version": "0.8.1"
  },
  "openapi": "3.1.0",
  "paths": {
    "/admin/dictionary": {
      "get": {
        "operationId": "read_dictionary_admin_dictionary_get",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DictionaryPayload"
                }
              }
            },
            "description": "Successful Response"
          }
        },
        "summary": "Read Dictionary"
      },
      "post": {
        "operationId": "write_dictionary_admin_dictionary_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/DictionaryPayload"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DictionaryPayload"
                }
              }
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Write Dictionary"
      }
    },
    "/admin/errors": {
      "get": {
        "operationId": "get_errors_admin_errors_get",
        "parameters": [
          {
            "description": "Return errors since ISO timestamp",
            "in": "query",
            "name": "since",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Return errors since ISO timestamp",
              "title": "Since"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "items": {
                    "$ref": "#/components/schemas/ErrorLogEntry"
                  },
                  "title": "Response Get Errors Admin Errors Get",
                  "type": "array"
                }
              }
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Get Errors"
      }
    },
    "/admin/metrics": {
      "get": {
        "operationId": "get_metrics_dashboard_admin_metrics_get",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/MetricsDashboard"
                }
              }
            },
            "description": "Successful Response"
          }
        },
        "summary": "Get Metrics Dashboard"
      }
    },
    "/admin/sessions": {
      "get": {
        "operationId": "get_sessions_admin_sessions_get",
        "parameters": [
          {
            "description": "Return JSON or HTML",
            "in": "query",
            "name": "format",
            "required": false,
            "schema": {
              "default": "json",
              "description": "Return JSON or HTML",
              "pattern": "^(json|html)$",
              "title": "Format",
              "type": "string"
            }
          },
          {
            "in": "query",
            "name": "limit",
            "required": false,
            "schema": {
              "default": 20,
              "maximum": 200,
              "minimum": 1,
              "title": "Limit",
              "type": "integer"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/SessionLogResponse"
                }
              },
              "text/html": {}
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Get Sessions"
      }
    },
    "/ask": {
      "post": {
        "operationId": "ask_endpoint_ask_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/AskRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/AskResponse"
                }
              }
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Ask Endpoint"
      }
    },
    "/contact": {
      "post": {
        "operationId": "contact_contact_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ContactRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "202": {
            "content": {
              "application/json": {
                "schema": {
                  "additionalProperties": {
                    "type": "string"
                  },
                  "title": "Response Contact Contact Post",
                  "type": "object"
                }
              }
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Contact"
      }
    },
    "/eval/run": {
      "post": {
        "operationId": "run_eval_eval_run_post",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/EvalResponse"
                }
              }
            },
            "description": "Successful Response"
          }
        },
        "summary": "Run Eval"
      }
    },
    "/health": {
      "get": {
        "operationId": "health_health_get",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HealthResponse"
                }
              }
            },
            "description": "Successful Response"
          }
        },
        "summary": "Health"
      }
    },
    "/ingest": {
      "post": {
        "operationId": "trigger_ingestion_ingest_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/IngestRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/IngestResponse"
                }
              }
            },
            "description": "Successful Response"
          },
          "422": {
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            },
            "description": "Validation Error"
          }
        },
        "summary": "Trigger Ingestion"
      }
    }
  }
}

```

## `docs/api/README.md`

```md
# API Documentation

## Generating the OpenAPI Schema

Run either command to emit the latest schema:

```bash
make openapi
```

or

```bash
python scripts/generate_api_docs.py --output docs/api/openapi.json
```

The CLI loads the FastAPI application directly, so the server does not need to be running.

---

## `/ask` Request & Response

```jsonc
POST /ask
{
  "question": "How does Atticus escalate low confidence answers?",
  "models": ["C7070"],
  "filters": {
    "source_type": "runbook"
  }
}
```

- `question` (string, required) - Natural-language query. Alias `query` is also accepted for backwards compatibility.
- `filters` (object, optional) - Restrict retrieval. Supported keys: `source_type`, `path_prefix`.
- `models` (array, optional) - Explicit model or family identifiers returned from a clarification prompt. When omitted Atticus infers models from the question text.

```jsonc
200 OK
{
  "answer": "Atticus blends retrieval and LLM confidence...",
  "answers": [
    {
      "model": "Apeos C7070",
      "family": "C7070",
      "family_label": "Apeos C7070 range",
      "answer": "Atticus blends retrieval and LLM confidence...",
      "confidence": 0.74,
      "should_escalate": false,
      "sources": [
        {
          "chunkId": "chunk-000045",
          "path": "content/20240901_escalation_playbook_v1.pdf",
          "page": 7,
          "heading": "Escalation Workflow",
          "score": 0.82
        }
      ]
    }
  ],
  "confidence": 0.74,
  "should_escalate": false,
  "request_id": "9db0dd1c-...",
  "sources": [
    {
      "chunkId": "chunk-000045",
      "path": "content/20240901_escalation_playbook_v1.pdf",
      "page": 7,
      "heading": "Escalation Workflow",
      "score": 0.82
    }
  ]
}
```

- `answer` - Aggregate response (string). For multi-model queries each entry in `answers` contains the scoped answer.
- `answers` - List of per-model responses surfaced when multiple models or families are requested.
- `sources` - Aggregated supporting citations for the response (per-entry sources live under each `answers[i].sources`).
- `confidence` - Combined retrieval plus LLM score (0-1).
- `should_escalate` - `true` when `confidence` falls below `CONFIDENCE_THRESHOLD`.
- `request_id` - Trace identifier surfaced in logs.

When Atticus cannot confidently infer a model, the endpoint returns a clarification payload instead of an answer:

```jsonc
200 OK
{
  "request_id": "bcf8854e-...",
  "clarification": {
    "message": "Which model are you referring to? If you like, I can provide a list of product families that I can assist with.",
    "options": [
      { "id": "C7070", "label": "Apeos C7070 range" },
      { "id": "C8180", "label": "Apeos C8180 series" }
    ]
  }
}
```

Errors follow the Error JSON schema described in [AGENTS.md](../../AGENTS.md).

---

## Related References

- [ATTICUS_DETAILED_GUIDE.md](../ATTICUS_DETAILED_GUIDE.md)
- [README.md](../README.md)
- [OPERATIONS.md](../OPERATIONS.md)

```

## `docs/ARCHITECTURE.md`

```md
# ARCHITECTURE — Atticus

This document provides a **high‑level view of the Atticus system**, showing how data flows through ingestion, retrieval, and answer generation.

---

## System Overview

Atticus is a **Retrieval‑Augmented Generation (RAG)** platform.
It ingests content, builds a searchable vector index, retrieves relevant information on demand, and generates grounded answers.
The Next.js application is the canonical UI; historical static assets live under `archive/legacy-ui/` for reference only.

### Core Components

<!-- markdownlint-disable-next-line MD013 -->

| Component | Responsibility |
| --------- | -------------- |
| **Ingestion & Indexing** | Parse → chunk → embed → persist vectors + metadata via Prisma migrations and Postgres/pgvector. |
| **Retriever & Ranker** | Vector search with optional lexical rerank; enforces metadata filters (org_id, product,ersion). |
| **Generator** | Drafts concise, sourced answers using the configured GEN_MODEL, respecting confidence thresholds. |
| **API Layer** | FastAPI exposes /health, /ingest, /ask, /eval, /contact with /ask streaming SSE payloads {answer, sources, confidence, should_escalate, request_id}. |
| **Web UI** | Next.js App Router served from /, delivering chat, admin, settings, contact, and apps routes using shadcn/ui + Tailwind. |
| **Admin Service** | Lightweight Next.js workspace on port 3101 for escalated chat review, answer curation, and CSV exports under content/. |
| **Developer Tooling & CI** | Pre-commit (Ruff, mypy, ESLint, Prettier, markdownlint) plus GitHub Actions jobs (rontend-quality, lint-test, pgvector-check, val-gate) mirroring make quality. |

---

## Data Flow

1. **Content Addition**
   New or updated documents are added to `content/` and named `YYYYMMDD_topic_version.ext`.

2. **Ingestion**
   Run make ingest or trigger ingestion from /admin/content to parse and chunk documents, compute embeddings, and update the index stored under indexes/.

3. **Retrieval**
   When a user submits a query, the retriever searches the pgvector index and optionally applies a re-ranker to prioritize the most relevant chunks.

4. **Answer Generation**
   The selected context is passed to the generation model (default `gpt-4.1`) to produce a concise, sourced answer with inline citations.

5. **Escalation (if needed)**
   If the confidence score falls below the configured threshold, the conversation is written to the Prisma `Chat` table with `status='pending_review'`, stored `topSources[]`, and appended `RagEvent` audit rows. Admins can capture follow-up prompts, approve, or escalate these records from the Next.js `/admin` console, which also raises SES escalations when required.

### Ask flow (SSE)

1. Next.js `/api/ask` receives the chat request and validates payloads with shared DTOs in `lib/ask-contract.ts`.
2. The handler proxies the request to the FastAPI `/ask` endpoint.
3. FastAPI returns the canonical JSON payload; when the caller requested SSE, the Next.js proxy emits `start`, `answer`, and `end` events so the UI has a consistent streaming interface.
4. The UI renders the received answer (currently delivered as a single chunk), logs the propagated `request_id`, and stores metadata for escalations.

---

## Supporting Services

- **Observability** — JSON logs (`logs/app.jsonl` and `logs/errors.jsonl`) with request IDs; metrics captured in evaluation runs and exported under `reports/`.
- **Snapshot & Rollback** — Index snapshots stored under `indices/` can be rolled back with `scripts/rollback.py`.
- **Evaluation & Audit Harness** — Retrieval evaluation against the gold set plus frontend audits (`reports/ci/*.json`) surfaced in CI artifacts.

---

## Security Considerations

- All secrets are loaded from `.env` and can be audited with `scripts/debug_env.py`.
- Escalation emails use SES SMTP credentials with IAM policies restricting senders and region (see [SECURITY.md](SECURITY.md)).
- Versioning is centralized in the [`VERSION`](../VERSION) file and must align with `package.json` releases.

---

## Cross-References

- [AGENTS.md](AGENTS.md) — Detailed agent responsibilities and error policy.
- [OPERATIONS.md](OPERATIONS.md) — Runbooks and evaluation metrics.
- [README.md](../README.md) — Setup instructions and Make targets.

```

## `docs/ATTICUS_DETAILED_GUIDE.md`

```md
# Atticus Detailed Guide

## Model Name Disambiguation

1. **Direct questions** — detect precise model mentions (for example, "Apeos C4570"), scope retrieval to the matching family, and return a single answer with citations limited to that family.
2. **Unclear questions** — when parser confidence drops below the clarification threshold, respond with a `clarification` payload listing the available families and delay retrieval until the UI resubmits the original question with selected `models`.
3. **Multi-model questions** — if several models are present ("C4570 and C6580"), fan out retrieval per model and return `answers[]`, ensuring each answer carries its own `sources` while preserving the aggregated `sources` array for consumers that expect it.
4. **Follow-up flow** — UI buttons post the original prompt with `models` populated from the selected family so downstream logging and escalations have explicit model scope.

See `tests/test_model_parser.py`, `tests/test_retrieval_filters.py`, `tests/test_chat_route.py`, `tests/test_ui_route.py`, and `tests/playwright/chat.spec.ts` for executable examples.

```

## `docs/AUDIT_REPORT.md`

```md
# Audit Report

This document has not been migrated into the docs/ tree yet. Refer to `reports/security/2025-10-05-web-db-assessment.md` for the latest findings.

```

## `docs/glossary-spec.md`

```md
# Glossary Specification

The glossary module enables reviewers to propose terminology updates and administrators
to approve or reject entries. The workflow is designed to mirror the RBAC policies in the
Next.js admin UI and Prisma models.

## Roles

| Role       | Permissions                                                |
| ---------- | ---------------------------------------------------------- |
| `user`     | Read-only access to approved glossary entries.             |
| `reviewer` | Submit new terms and propose edits.                        |
| `admin`    | Approve/reject proposals, manage history, export glossary. |

## Data Model

```prisma
model GlossaryEntry {
  id           String          @id @default(cuid())
  term         String
  definition   String          @db.Text
  synonyms     String[]        @default([])
  status       GlossaryStatus  @default(PENDING)
  orgId        String
  org          Organization    @relation(fields: [orgId], references: [id], onDelete: Cascade)
  authorId     String
  author       User            @relation("GlossaryAuthor", fields: [authorId], references: [id])
  updatedById  String?
  updatedBy    User?           @relation("GlossaryUpdatedBy", fields: [updatedById], references: [id])
  reviewerId   String?
  reviewer     User?           @relation("GlossaryReviewer", fields: [reviewerId], references: [id])
  reviewNotes  String?         @db.Text
  reviewedAt   DateTime?
  events       RagEvent[]
  createdAt    DateTime        @default(now())
  updatedAt    DateTime        @updatedAt

  @@unique([orgId, term])
  @@index([orgId, status])
}
```

All mutations emit structured `RagEvent` audit rows (mirrored in `logs/app.jsonl`) including the acting user,
the request/trace ID, and the state transition. Row-level security is enforced through
Prisma queries executed inside `withRlsContext` and mirrored on the FastAPI admin APIs via
the `X-Admin-Token` header.

## API Contracts

- `GET /api/glossary` – reviewer/admin session required; returns serialized entries with
  author/reviewer metadata.
- `POST /api/glossary` – admin session required; idempotent upsert keyed by `(orgId, term)` that accepts term, definition, synonyms, and status updates while recording author/reviewer metadata and request IDs.
- `PUT /api/glossary/:id` – admin session required; updates an entry in place (definition, synonyms, status, review notes) and stamps reviewer metadata when a decision is made.
- FastAPI `/admin/dictionary` endpoints mirror the glossary state for legacy tooling and
  require a matching `X-Admin-Token` header; failures emit contract-compliant error
  payloads with `request_id` for observability.

## UI Flow

1. Reviewer submits a new term with synonyms and rationale.
2. Admin views pending proposals on `/admin/glossary`, edits definitions inline, captures review notes, and approves.
3. Approved entries become available to all users and propagate via the API contract, with each change mirrored in `RagEvent` history.

### Sequence Diagram

```mermaid
sequenceDiagram
  participant Reviewer
  participant Admin
  participant System
  Reviewer->>Admin: Submit glossary entry
  Admin->>System: Approve/Reject
  System-->>Reviewer: Status update + audit log
```

### Decision Notes

- **Single admin review gate** keeps quality control centralized and aligns with our RBAC policy where only admins can approve or
  reject terms. This mirrors the Prisma ownership model and prevents conflicting reviewer decisions.
- **Audit-first feedback** relies on structured events written during each transition so downstream services can reconcile glossary
  changes without polling Prisma directly.
- **FastAPI bridge retained** to support legacy tooling that still depends on the `/admin/dictionary` endpoints during the migration
  period.

### Follow-ups

- Reviewer/admin notifications for status changes remain open in the backlog — tracked in [TODO.md §5](../TODO.md#5-uncertain-chat-validation-flow).
- Dedicated audit UI enhancements live under [TODO.md §4](../TODO.md#4-admin-ops-console-uncertain-chats-tickets-glossary) alongside the combined admin console workstream.

## Seed Data & Provisioning

- `make db.seed` provisions:
  - Organization `org-atticus` (overridable via `DEFAULT_ORG_ID`).
  - Service users `glossary.author@seed.atticus` (reviewer) and `glossary.approver@seed.atticus` (admin) for deterministic RBAC checks.
  - Three glossary rows covering the primary workflow states:
    - `glossary-entry-managed-print-services` → **APPROVED** with reviewer metadata for smoke tests.
    - `glossary-entry-proactive-maintenance` → **PENDING** awaiting admin action.
    - `glossary-entry-toner-optimization` → **REJECTED** with notes capturing why it failed review.
- Re-running the seed is idempotent: each entry is upserted by stable IDs and the reviewer/author assignments are refreshed.
- Override defaults (organization name, admin bootstrap account, etc.) by exporting `DEFAULT_ORG_NAME`, `ADMIN_EMAIL`, and `ADMIN_NAME` before invoking the target.

## Reset & Rollback

- To reset the glossary to the deterministic baseline:
  1. `make db.seed` — reruns Prisma seeding and restores the canonical entries.
  2. Confirm via `pytest tests/test_seed_manifest.py::test_glossary_seed_entries_round_trip` (requires a reachable Postgres instance).
- To restore production data after testing seeds:
  1. Snapshot `GlossaryEntry` rows (e.g., `COPY "GlossaryEntry" TO STDOUT WITH CSV HEADER`).
  2. After validation, re-import using `COPY ... FROM STDIN` or Prisma scripts, then rerun `make db.seed` to ensure support accounts persist.
- Rollbacks should always re-run `make db.seed` so the deterministic reviewers remain available for smoke suites.

## CI Expectations

- `make test.api` exercises glossary endpoints under auth.
- `make quality` runs Prisma client type checks, Vitest RBAC unit tests, and Playwright admin flows to guard glossary access.
- Seed data for glossary lives alongside the CED seed manifest (`make seed`).

```

## `docs/IMPLEMENTATION_PLAN.md`

```md
# Implementation Plan

This placeholder exists to satisfy documentation links. The detailed implementation plan was not provided in this export.

```

## `docs/OPERATIONS.md`

```md
# OPERATIONS — Atticus

This document provides day‑to‑day runbooks and a quick guide for interpreting evaluation metrics. It complements README.md for setup and SECURITY.md for policy.

---

## Ingest & Index

1. Add or update source files under `content/`.
2. Run ingestion:

    ```bash
    make ingest
    ```

    > This parses, chunks (CED policy with SHA‑256 de‑dupe), embeds, and updates the vector index.

3. Check logs in `logs/app.jsonl` for document counts, chunk totals, and token ranges.
4. When ready for release, commit the updated `indexes/` snapshot and `indexes/manifest.json`.
5. Generate deterministic seed data with `make seed`.

---

## Database Health (pgvector)

1. Ensure Docker Compose Postgres is running (`make db.up`).
2. Validate the schema, pgvector extension, and IVFFlat configuration:

    ```bash
    make db.verify
    ```

3. For ad‑hoc checks, run the SQL script directly with psql.

---

## Evaluate Retrieval

1. Ensure gold Q/A sets exist under `eval/goldset/*.jsonl`.
2. Run evaluation:

```bash
make eval
```

Results are written to `eval/runs/<timestamp>/` and mirrored under `reports/` for CI artifacts.

---

## Quality Gates & CI Parity

Run `make quality` before every pull request. The target chains:

- ruff check / format check
- mypy type checks
- pytest with ≥90% coverage
- Next.js lint, typecheck, and build
- Audit scripts as configured

---

## API & UI Operations

- Start the FastAPI service (JSON APIs only):

```bash
make api
```

- Launch the Next.js workspace:

```bash
make web-dev
```

- To run an end‑to‑end smoke (ingest → eval → API/UI check):

```bash
make e2e
```

---

## Admin Service

The standalone admin workspace handles escalated chat review and lives in the `admin/` directory.

```bash
npm run dev --workspace admin    # http://localhost:3101
```

- Set `ATTICUS_MAIN_BASE_URL` if the primary UI runs behind nginx or a custom domain.
- Docker Compose exposes the same workspace via the `admin` service (`docker compose up admin`).
- Approved answers append to `content/<family>/<model>.csv`; all actions log to `reports/content-actions.log`.

---

## Content Manager

Use `/admin/content` to browse, upload, and curate files in `content/`.

- Upload Markdown, PDF, and text sources; deletions and uploads are logged to `reports/content-actions.log`.
- Create folders directly from the UI; directories mirror the structure used during ingestion.
- Run the "Re-ingest Content" action after changes to execute `scripts/ingest_cli.py` without leaving the browser.
- The UI prompts reviewers when pending changes require ingestion to avoid accidental drift.

---

## Escalation Email

See SECURITY.md for the canonical SES/email policy, credential guidance, and IAM restrictions.

Operational note:

```bash
make smtp-test
```

Uses sandbox/non‑delivery settings in local environments; production must follow SECURITY.md.

---

## Snapshot & Rollback

1. Snapshot `indexes/` during each release.
2. To revert to a previous snapshot:

    ```bash
    python scripts/rollback.py --manifest indexes/manifest.json
    ```

3. After rollback, run a smoke evaluation (`make eval`).

---

## Observability & Debugging

- Logs: `logs/app.jsonl` (info), `logs/errors.jsonl` (errors)
- Rate limiting: see `/admin/metrics`
- Environment diagnostics: `python scripts/debug_env.py`

---

## Evaluation Metrics Interpretation

Core metrics:

- nDCG@K — ranking quality
- Recall@K — coverage
- MRR@K — how early correct hits appear
- Precision@K — relevance of retrieved chunks

Typical CI thresholds: fail on 3–5% nDCG@10 drop, 5% Recall@10 drop, or 5–10% MRR@10 drop vs baseline.

---

## References

- README.md — first‑time setup and Make targets
- SECURITY.md — SES/email and admin token policy (canonical)
- AGENTS.md — architecture and error policy
- TROUBLESHOOTING.md — quick fixes

## Environment Variables

| Variable                  | Dev      | Prod     | Notes |
| ------------------------- | -------- | -------- | ----- |
| ADMIN_API_TOKEN           | required | required |       |
| ADMIN_EMAIL               | required | required |       |
| ADMIN_NAME                | required | required |       |
| ATTICUS_MAIN_BASE_URL     | optional | optional | Admin service upstream base URL |
| ATTICUS_REVIEWER_ID      | optional | optional | Admin service reviewer identifier |
| ATTICUS_REVIEWER_NAME    | optional | optional | Display name for curator logs |
| ATTICUS_REVIEWER_EMAIL   | optional | optional | Reviewer email for audit trails |
| ASK_SERVICE_URL           | required | required |       |
| CHUNK_MIN_TOKENS          | required | required |       |
| CHUNK_OVERLAP_TOKENS      | required | required |       |
| CHUNK_TARGET_TOKENS       | required | required |       |
| CONFIDENCE_THRESHOLD      | required | required |       |
| CONTACT_EMAIL             | required | required |       |
| CONTENT_ROOT              | required | required |       |
| DATABASE_URL              | required | required |       |
| DEFAULT_ORG_ID            | required | required |       |
| DEFAULT_ORG_NAME          | required | required |       |
| DICTIONARY_PATH           | required | required |       |
| EMAIL_FROM                | required | required |       |
| EMAIL_SANDBOX             | required | required |       |
| EMAIL_SERVER_HOST         | required | required |       |
| EMAIL_SERVER_PASSWORD     | required | required |       |
| EMAIL_SERVER_PORT         | required | required |       |
| EMAIL_SERVER_USER         | required | required |       |
| EMBED_MODEL               | required | required |       |
| EMBEDDING_MODEL_VERSION   | required | required |       |
| ENABLE_RERANKER           | required | required |       |
| ERROR_LOG_PATH            | required | required |       |
| EVAL_REGRESSION_THRESHOLD | required | required |       |
| GEN_MODEL                 | required | required |       |
| INDICES_DIR               | required | required |       |
| LOG_FORMAT                | required | required |       |
| LOG_LEVEL                 | required | required |       |
| LOG_PATH                  | required | required |       |
| LOG_TRACE                 | required | required |       |
| LOG_VERBOSE               | required | required |       |
| MAX_CONTEXT_CHUNKS        | required | required |       |
| OPENAI_API_KEY            | required | required |       |
| PGVECTOR_LISTS            | required | required |       |
| PGVECTOR_PROBES           | required | required |       |
| POSTGRES_DB               | required | required |       |
| POSTGRES_PASSWORD         | required | required |       |
| POSTGRES_PORT             | required | required |       |
| POSTGRES_USER             | required | required |       |
| RAG_SERVICE_URL           | required | required |       |
| RATE_LIMIT_REQUESTS       | required | required |       |
| RATE_LIMIT_WINDOW_SECONDS | required | required |       |
| SMTP_ALLOW_LIST           | required | required |       |
| SMTP_DRY_RUN              | required | required |       |
| SMTP_FROM                 | required | required |       |
| SMTP_HOST                 | required | required |       |
| SMTP_PASS                 | required | required |       |
| SMTP_PORT                 | required | required |       |
| SMTP_TO                   | required | required |       |
| SMTP_USER                 | required | required |       |
| TIMEZONE                  | required | required |       |
| TOP_K                     | required | required |       |

```

## `docs/README.md`

```md
# Documentation Index

Start here for Atticus docs. Root **README.md** is the quick start; everything else lives here.

## Core

- [ARCHITECTURE.md](./ARCHITECTURE.md)
- [AGENTS.md](./AGENTS.md)
- [REQUIREMENTS.md](./REQUIREMENTS.md)
- [OPERATIONS.md](./OPERATIONS.md)
- [SECURITY.md](./SECURITY.md)
- [RELEASE.md](./RELEASE.md)
- [REPO_STRUCTURE.md](../REPO_STRUCTURE.md)
- [TROUBLESHOOTING.md](./TROUBLESHOOTING.md)
- [ADMIN_SERVICE.md](./ADMIN_SERVICE.md)
- [Runbooks: Seeding](./runbooks/seeding.md)
- [API Spec](./api/openapi.json) (generated)

## Change History

- [CHANGELOG.md](../CHANGELOG.md)

```

## `docs/RELEASE.md`

```md
# RELEASE — Atticus

This document describes the official release process for Atticus.
Follow these steps to ensure every release is versioned, tested, and documented correctly.

---

## Versioning

Atticus uses **Semantic Versioning**: `MAJOR.MINOR.PATCH`.

- **MAJOR** — Incompatible API changes or breaking architecture changes.
- **MINOR** — Backwards-compatible feature additions or improvements.
- **PATCH** — Backwards-compatible bug fixes or documentation updates.

---

## Release Checklist

1. **Update CHANGELOG**
   - Edit [CHANGELOG.md](../CHANGELOG.md) with the new version number, date, and highlights.
2. **Verify Environment**
   - Confirm `.env` is complete and correct using:

     ```bash
     python scripts/debug_env.py
     ```

3. **Run Full Quality Gates**
   - Ensure the following commands pass locally:

     ```bash
     make quality         # Ruff + mypy + pytest + Next lint/typecheck/build + audits
     npm run format:check # Prettier enforcement
     pre-commit run --all-files --show-diff-on-failure
     make eval            # Retrieval regression suite
     make e2e             # Optional but recommended before tagging
     ```

   - CI requires ≥90% coverage and enforces evaluation regression thresholds.

4. **Sync Versioning**
   - Update [`VERSION`](../VERSION), `package.json`, and [CHANGELOG.md](../CHANGELOG.md) with the new semantic version (e.g. `0.7.0`).
   - Confirm the values match by running `node -p "require('./package.json').version"` and comparing with `cat VERSION`.
   - Commit the changes with a descriptive message (e.g. `release(0.7.0): developer experience + docs sync`).
5. **Tag the Release**
   - Tag using semantic versioning, e.g. `v0.7.0`:

     ```bash
     git tag v0.7.0
     git push origin v0.7.0
     ```

   - Pushing the tag triggers the `release.yml` GitHub Action.

---

## Post‑Release

- Monitor `logs/app.jsonl` and `logs/errors.jsonl` for early issues.
- Announce the release internally and update any dependent services or documentation.
- Archive `reports/ci/*.json` and evaluation dashboards for audit trails.

---

## Upgrade / Rollback Playbook

### Upgrade

1. Pull the tagged release (`git fetch --tags && git checkout vX.Y.Z`).
2. Run database migrations and seed updates:

   ```bash
   make db.migrate
   make db.seed
   ```

3. Rebuild the Next.js app and restart services:

   ```bash
   npm install --production
   npm run build
   docker compose up -d --build
   ```

    > **Note:** Release 0.7.11 adds Prisma `Chat`/`Ticket` tables plus the tabbed admin console and RBAC APIs. Run `make db.migrate && make db.seed` before `npm run build` so low-confidence chat data and escalations materialise in the UI.
    > **Note:** Release 0.8.0 enforces the `app.pgvector_lists` GUC, introduces the `RagEvent` audit ledger, and adds glossary upsert/follow-up workflows. Run `make db.migrate`, `make db.verify`, and `npm run db:seed` before `npm run build`, and wire `make version-check` into CI to detect version drift early.

4. Verify health:

   ```bash
   make smoke
   make eval
   ```

5. Review audit artifacts (`reports/ci/`, `eval/runs/`) to confirm no regressions.

### Rollback

1. Checkout the previous tag and redeploy (`git checkout vX.Y.(Z-1)` followed by the upgrade steps above).
2. Restore index snapshots using `python scripts/rollback.py --manifest indexes/manifest.json` if ingestion changes shipped.
3. Re-run `make eval` and `make quality` to ensure the rolled-back version is healthy.
4. Update status pages/runbooks with the rollback rationale and next steps.

---

## References

- [CHANGELOG.md](../CHANGELOG.md) — full version history.
- [OPERATIONS.md](OPERATIONS.md) — runbooks and evaluation metrics.
- [SECURITY.md](SECURITY.md) — secrets management and IAM policy examples.

```

## `docs/REMOTE_ACCESS.md`

```md
# REMOTE ACCESS - Atticus

This guide explains how to reach a local Atticus instance from another PC without exposing the machine to
the internet. It presents three supported approaches so you can choose the level of automation, security,
and tooling that fits your environment.

---

## Quick Decision Matrix

<!-- markdownlint-disable-next-line MD013 -->

| Option | Best For | Security Posture | What You Need |

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

| ---------------------- | ------------------------------------------------- | ----------------------------------------------------------- | ---------------------------------------------------------- |

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

| **Tailscale** | Always-on secure mesh between office/home devices | Zero-trust, device-based auth, automatic key rotation | Personal/enterprise Tailscale account (free tier works) |

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

| **Cloudflare Tunnel** | Sharing access with vendors or short-term demos | One-time tokens, granular routes, no inbound firewall rules | Cloudflare account with a free zone + `cloudflared` binary |

<!-- markdownlint-disable-next-line MD013 -->

| **SSH Reverse Tunnel** | One-off troubleshooting from a trusted jump host | Depends on SSH key hygiene | Any VPS or machine reachable from the remote PC |

---

## Option 1 - Tailscale (Recommended)

1. Install Tailscale on the Atticus host and the remote PC: <https://tailscale.com/download>.
2. Authenticate each device with the same account (or organization SSO).
3. Tag the Atticus host (optional but recommended) with `atticus-server` to simplify ACLs.
4. Start Atticus locally:

   ```bash
   make api
   ```

5. Connect from the remote PC using the Tailscale IP shown in the admin console:

   ```bash
   # Example assuming the host advertises 100.101.102.103
   curl http://100.101.102.103:8000/health
   ```

6. Lock down access with an ACL snippet:

   ```json
   {
     "ACLs": [
       {
         "Action": "accept",
         "Users": ["group:sales", "user:you@example.com"],
         "Ports": ["tag:atticus-server:8000"]
       }
     ]
   }
   ```

**Pros**: 2-minute setup, device-level revocation, auto-generated DNS names like
`atticus-hostname.tailnet.ts.net`.

**Cons**: Requires installing the client on every participating machine.

---

## Option 2 - Cloudflare Tunnel

1. Install `cloudflared` on the Atticus host:

   ```powershell
   winget install Cloudflare.cloudflared
   ```

2. Authenticate and select the zone that will front your tunnel (e.g. `yourcompany.com`):

   ```bash
   cloudflared login
   ```

3. Create a dedicated tunnel:

   ```bash
   cloudflared tunnel create atticus-local
   ```

4. Route a DNS record to the tunnel:

   ```bash
   cloudflared tunnel route dns atticus-local atticus.yourcompany.com
   ```

5. Run the connector while Atticus is active:

   ```bash
   make api &
   cloudflared tunnel run --url http://localhost:8000 atticus-local
   ```

6. Protect access with Cloudflare Access (SSO, one-time PINs, or service tokens).

**Pros**: No inbound firewall rules, audited access logs, granular policies per path.

**Cons**: Outbound tunnel must stay alive; run it as a service for long-lived usage.

---

## Option 3 - SSH Reverse Tunnel (Minimal Dependencies)

1. Pick a jump host reachable from the remote PC (a lightweight VPS works).
2. Create an SSH key for the Atticus host and add it to the jump host `authorized_keys`.
3. Start the tunnel from the Atticus host:

   ```bash
   ssh -N -R 18080:localhost:8000 user@jump-host.example.com
   ```

4. From the remote PC, connect to the jump host and forward traffic locally:

   ```bash
   ssh -L 8000:localhost:18080 user@jump-host.example.com
   ```

5. Visit `http://localhost:8000` on the remote PC—traffic traverses the secure SSH tunnel.

**Pros**: Uses built-in tooling; no extra accounts required.

**Cons**: You must maintain the intermediate host and manage SSH keys carefully.

---

## Operational Checklist

- Treat every remote-access path as production: use MFA, rotate credentials, and log access.
- Update `.env` with `ALLOWED_ORIGINS` if you front Atticus with a different hostname (CORS).
- Enable `LOG_VERBOSE=1` during rollout so access logs capture remote IPs.
- Tear down tunnels when demos finish to avoid orphaned exposure.

---

## Related Documents

- [OPERATIONS.md](OPERATIONS.md) - runbooks, evaluation workflow, and rollback steps.
- [SECURITY.md](SECURITY.md) - IAM, SES policies, and secrets guidance.
- [README.md](../README.md) - setup instructions and Make targets.

```

## `docs/REQUIREMENTS.md`

```md
# REQUIREMENTS — Atticus

This document defines the runtime and build requirements for Atticus.
Use it to set up development environments, run CI, and deploy production services.

---

## Core Runtime

- **Python 3.12** — Required for both development and production.
- **Node.js 20 LTS** — Required for the Next.js workspace, lint/typecheck/build, and audit scripts.
- **Operating System** — Linux or Windows. Windows users should ensure Tesseract and Ghostscript are installed if PDF OCR is needed.

---

## Python Dependencies

Dependencies are managed with `pip-tools` for deterministic builds.

- `requirements.in` — human-maintained top‑level packages.
- `requirements.txt` — fully pinned output generated by:

  ```bash
  pip-compile -U requirements.in
  ```

- Synchronize the environment with:

  ```bash
  pip-sync requirements.txt
  ```

Typical core packages include:

- `fastapi`, `uvicorn`
- `pydantic`, `python-dotenv`
- `pgvector`, `psycopg`, `numpy`, `scikit-learn`, `rapidfuzz`
- `pymupdf`, `pdfminer.six`, `pytesseract`, `Pillow`
- `pytest`, `pytest-cov`

These are already captured and pinned in `requirements.in` and `requirements.txt`.

---

## Node & Frontend Dependencies

Managed via `package.json` / `package-lock.json` with `npm install`.

Key packages:

- `next@14.2.33`, `react@18`, `react-dom@18`
- `tailwindcss@3`, `shadcn/ui` components, `lucide-react`
- `typescript@5.4`, `eslint@8.57`, `eslint-config-next`, `eslint-plugin-tailwindcss`
- `prettier@3.3` + `prettier-plugin-tailwindcss`
- Tooling: `knip`, `vitest`, `@playwright/test`

Install once with `npm install` (POSIX/PowerShell). Use `npm ci` inside CI.

---

## Environment Variables

All runtime configuration is supplied through `.env` (generated by `scripts/generate_env.py`).
Key variables include:

| Variable                                           | Purpose                                                                                   |
| -------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| `OPENAI_API_KEY`                                   | Access key for GPT and embeddings                                                         |
| `GEN_MODEL`                                        | Generation model (default `gpt-4.1`)                                                      |
| `EMBED_MODEL`                                      | Embedding model (default `text-embedding-3-large`)                                        |
| `DATABASE_URL`                                     | Postgres connection string for pgvector                                                   |
| `EMAIL_SERVER`, `EMAIL_FROM`                       | SMTP configuration for escalation mailer                                                  |
| `CONTACT_EMAIL`, `SMTP_*`, `SMTP_ALLOW_LIST`       | Escalation email settings and allow-list guardrail                                        |
| `RAG_SERVICE_URL`                                  | Base URL for FastAPI retrieval service proxied by Next.js                                 |
| `ENABLE_RERANKER`                                  | Toggle hybrid reranking (defaults to disabled)                                            |
| `SMTP_DRY_RUN`                                     | Log escalation attempts without sending email                                             |
| `RATE_LIMIT_REQUESTS`, `RATE_LIMIT_WINDOW_SECONDS` | Per-user/IP rate limit configuration                                                      |
| `LOG_VERBOSE`, `LOG_TRACE`                         | Enable structured trace logging                                                           |

Run `python scripts/debug_env.py` to verify that environment settings are sourced and fingerprinted correctly.

---

## Development Tooling

- **Ruff** for linting and import sorting (`make lint`, `make format`).
- **mypy** for static type checking (`make typecheck`).
- **pytest** for testing (`make test`), with a target of ≥90% coverage.
- **ESLint** (`npm run lint`) with the Tailwind plugin for shadcn/ui class validation.
- **Prettier** (`npm run format`, `npm run format:check`) with tailwindcss plugin enforcing class order.
- **TypeScript compiler** (`npm run typecheck`) and **Next.js build** (`npm run build`).
- **Vitest / Playwright** for unit and smoke testing (`npm run test:unit`, `npm run test:e2e`).
- Optional: `pytest-xdist` for parallel test runs; if installed, Makefile will automatically add `-n auto`.
- **pre-commit** hooks covering Ruff, mypy, ESLint, Prettier, markdownlint (`pre-commit install`).

---

## CI Expectations

Local workflows must mirror CI:

- Run `make quality` before pushing.
- Ensure audit artifacts under `reports/ci/` remain ignored locally (`.gitignore` handles this).
- GitHub Actions jobs `frontend-quality`, `lint-test`, and `pgvector-check` enforce the same commands with Node 20 + Python 3.12 matrices.

---

## Deployment

- Use Docker Compose for reproducible production deployments.
- Ensure `.env` is present and up to date before running:

  ```bash
  docker compose up --build
  ```

- The default configuration exposes the API at `http://localhost:8000` with TLS termination handled by Nginx.

---

## Versioning

- Project version lives in [`VERSION`](../VERSION) and must match `package.json`.
- Update [CHANGELOG.md](../CHANGELOG.md) and [RELEASE.md](RELEASE.md) on every release.
- Tag releases using semantic versioning (`vX.Y.Z`) after CI passes.

---

## References

- [README.md](../README.md) — overall setup and Makefile targets.
- [AGENTS.md](AGENTS.md) — agent roles and configuration.
- [SECURITY.md](SECURITY.md) — secrets handling and IAM guidance.

```

## `docs/runbooks/auth-rbac.md`

```md
# Auth & RBAC Runbook

> **Note:** Authentication is now handled upstream via enterprise SSO. This runbook is retained for legacy reference only; the UI trusts identity headers provided by the gateway.

This runbook documents the historical Auth.js + Prisma deployment that powered Atticus phase 3.

## Overview

- **Provider**: Auth.js (NextAuth) with email magic link.
- **Adapter**: Prisma + Postgres with row-level security (RLS) keyed by `org_id` and role.
- **Roles**: `USER`, `REVIEWER`, `ADMIN`.
  - Users and reviewers can read glossary entries scoped to their org.
  - Admins can invite teammates, promote glossary entries, and manage roles.
- **Session storage**: Database-backed sessions (`Session` table) with Prisma adapter.

## Environment variables

<!-- markdownlint-disable-next-line MD013 -->

| Variable | Purpose |

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

<!-- markdownlint-disable-next-line MD013 -->

| ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |

<!-- markdownlint-disable-next-line MD013 -->

| `DATABASE_URL` | Postgres connection string used by Prisma and Auth.js. |

<!-- markdownlint-disable-next-line MD013 -->

| `AUTH_SECRET` | Secret used to sign NextAuth cookies/JWT (matches `lib/auth.ts`). |

<!-- markdownlint-disable-next-line MD013 -->

| `DEFAULT_ORG_ID` / `DEFAULT_ORG_NAME` | Seed organization for default tenancy. |

<!-- markdownlint-disable-next-line MD013 -->

| `ADMIN_EMAIL` / `ADMIN_NAME` | Bootstrap admin account created by `npm run db:seed`. |

<!-- markdownlint-disable-next-line MD013 -->

| `EMAIL_FROM` | From address for Auth.js email provider. |

<!-- markdownlint-disable-next-line MD013 -->

| `EMAIL_SERVER_HOST` / `EMAIL_SERVER_PORT` / `EMAIL_SERVER_USER` / `EMAIL_SERVER_PASSWORD` | SMTP server used for magic link delivery (UI mailer also supports `SMTP_*`). |

<!-- markdownlint-disable-next-line MD013 -->

| `AUTH_DEBUG_MAILBOX_DIR` | Filesystem directory where test magic links are persisted (used by Playwright). Defaults to `./logs/mailbox`. |

Use `python scripts/generate_env.py --force` to regenerate `.env` with sensible defaults. Override secrets in production.

## Provisioning steps

1. **Start Postgres**

   ```bash
   make db.up
   ```

2. **Apply migrations**

   ```bash
   make db.migrate
   ```

3. **Generate Prisma client**

   ```bash
   npm run prisma:generate
   ```

4. **Seed default org + admin**

   ```bash
   make db.seed
   ```

   The seed script creates (or updates) the organization referenced by `DEFAULT_ORG_ID` and promotes `ADMIN_EMAIL` to `ADMIN`.
5. **Run the app**

   ```bash
   npm run dev
   ```

   Visit `http://localhost:3000/signin`, request a magic link for the admin email, and open the link to access `/admin`.

## Testing

- **Unit**: `npm run test:unit` (Vitest) covers RBAC helpers.
- **Playwright**: `npm run test:e2e` validates the magic link flow and admin gating. Ensure the dev server is running and `AUTH_DEBUG_MAILBOX_DIR` (default `./logs/mailbox`) is writable before running.
- **Smoke**: `make web-test` + `make web-e2e` are wired into CI.

## RLS behaviour

- Policies enforce `org_id` scoping for users, sessions, accounts, and glossary entries.
- Admin-only actions (`INSERT`, `UPDATE`, `DELETE` on `GlossaryEntry`) require the connection role to be `ADMIN`. Service-level operations (NextAuth adapter) run under the `SERVICE` context, set via database defaults, to bootstrap new sessions.
- Always wrap Prisma calls that rely on user context with `withRlsContext(session, fn)` to set `app.current_user_*` settings.

## Operations

- **Magic link debugging**: Magic links are written to `<email>.txt` in `AUTH_DEBUG_MAILBOX_DIR` (default `./logs/mailbox`). Clear the file to invalidate previous links.
- **Role changes**: Use Prisma Studio or a SQL client to update `User.role`. RLS allows admins to self-manage via future UI.
- **Glossary management**: Admins manage terms in `/admin`. Reviewers will gain propose-only permissions in later phases.

## Rollback

1. Stop the Next.js app (`Ctrl+C`).
2. Revert migrations by restoring the previous database snapshot or running `psql` to drop the new tables/enums if safe.
3. Reset the workspace by checking out the prior git tag and reinstalling dependencies (`npm install`).
4. Restore `.env` from backups and restart services.

For emergency disablement, set `NEXTAUTH_SECRET` to an empty value and restart; Auth.js rejects new sessions, effectively putting the UI into maintenance mode while RBAC policies remain intact.

```

## `docs/runbooks/seeding.md`

```md
# Seeds

The `seed_manifest.json` generated by `make seed` captures a lightweight summary of the
current CED corpus. It records document fingerprints, chunk counts, and the first set of
chunks (including SHA-256 hashes) so operators can bootstrap a development database
without requiring the full ingestion pipeline.

Running `make seed` will:

1. Load configuration from `.env`/`config.yaml`.
2. Parse up to 10 source documents from `content/` using the CED chunker.
3. Write `seeds/seed_manifest.json` containing the deduplicated chunk metadata.

The manifest is designed to be checked into CI as an artifact and referenced by
deployment pipelines or smoke tests that need deterministic seed data.

> **Note:** Table extraction relies on optional dependencies (`camelot`, `tabula`, OpenCV).
> If they are unavailable the script skips table metadata gracefully; install them for
> full fidelity in production environments.

## Contributor checklist

- Run `pytest tests/test_seed_manifest.py` to confirm the manifest structure and
  chunk metadata remain deterministic for CI.
- Execute `make seed` before opening a PR whenever documents inside `content/`
  change; commit the refreshed `seeds/seed_manifest.json` if the diff is
  intentional.
- Document any new optional dependencies required for seeding inside this file
  and `REQUIREMENTS.md` to keep onboarding clear.

```

## `docs/SECURITY.md`

```md
# SECURITY — Atticus

This guide defines security boundaries for secrets, email/SES, admin tokens, logging, and reporting.

---

## Supported Versions

Security updates are guaranteed for the latest released minor and patch versions.
Older releases may receive fixes on a best‑effort basis only.

---

## Reporting a Vulnerability

If you discover a security issue:

1. Do not open a public GitHub issue.
2. Email the maintainers or your internal security contact with:
   - A clear description of the vulnerability and its potential impact
   - Steps to reproduce or a proof‑of‑concept
   - Affected versions and environment details

We acknowledge reports within 3 business days and coordinate a fix and disclosure timeline.

---

## Secrets Management

- Never commit secrets to source control.
- Configuration is sourced from `.env`; host env may override.
- Recommended environment keys (minimum for production):
  - `OPENAI_API_KEY`, `DATABASE_URL`
  - `EMAIL_FROM`, `EMAIL_SERVER_HOST`, `EMAIL_SERVER_PORT`, `EMAIL_SERVER_USER`, `EMAIL_SERVER_PASSWORD`
  - `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASS`, `SMTP_FROM` (fallbacks supported by the UI mailer)
  - `ADMIN_API_TOKEN`
- Run diagnostics any time:

```bash
python scripts/debug_env.py
```

---

## Email / SES Policy (Canonical)

All outbound email and escalation are covered by this policy.

- Provider: AWS SES (region per environment)
- Identities: Use verified domains/addresses only; rotate credentials regularly
- Credentials: Environment variables only; no secrets in code or docs
  - `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASS`, `SMTP_FROM`, `EMAIL_SERVER_*`
- Sandbox: For local/dev, set `EMAIL_SANDBOX=true` and relay to a non‑delivery sink (MailHog or AWS sandbox)
- Allow‑list: In lower environments, send only to allow‑listed recipients
- Auditing: Log message metadata (no PII) with `request_id`; store under `logs/` with retention
- IAM policy: Restrict `ses:FromAddress` and region

> Operational how‑to (setup, DNS verification) should link here rather than duplicate details.

---

## Admin API Token Policy

- Header: `X-Admin-Token`
- Behavior: Missing header → 401; wrong token → 403
- Storage: Use `ADMIN_API_TOKEN` env var. Do not commit tokens.
- Scope: Required for privileged admin‑only routes (e.g., queue ops, maintenance endpoints)

> Keep this the single source of truth; runbooks should reference this section.

---

## Data Privacy and Logging

- Redact PII in logs/traces; never log secret values
- App logs: `logs/app.jsonl`; error logs: `logs/errors.jsonl`
- Include `request_id` and minimal context for correlation

---

## Contributor Guidelines

- Use environment variables or a secret store (e.g. AWS Secrets Manager)
- Follow least‑privilege and data‑minimisation
- Before submitting code, run:

```bash
make lint
make typecheck
```

---

## Cross‑References

- AGENTS.md — architecture and escalation policies
- OPERATIONS.md — day‑to‑day operations and evaluation
- docs/README.md — documentation index

```

## `docs/STYLEGUIDE.md`

```md
# STYLEGUIDE — Atticus

Consistent style makes the codebase easier to read, review, and maintain.
Follow these standards for all code and documentation.

---

## Python Code

- **Formatting**: Use [Ruff](https://docs.astral.sh/ruff/) with Black‑compatible style.

  ```bash
  make lint    # check style
  make format  # auto-format
  ```

- **Typing**: All public functions must be type‑hinted. Run `make typecheck` to validate.
- **Imports**: Organized automatically by Ruff on save.
- **Naming**: Use snake_case for functions and variables, PascalCase for classes.

---

## Markdown

- **Line length**: Wrap at about **100 characters** where practical.
- **Code blocks**: Use fenced blocks with a language tag for syntax highlighting. Example:

  ```python
  def example() -> None:
      print("Hello Atticus")
  ```

- **Tables**: Use GitHub‑flavored markdown tables for clear presentation of structured data.
- **Links**: Use relative paths for internal references, e.g. `[AGENTS.md](AGENTS.md)`.

---

## Commits

- Use **imperative mood** and include a scope.
  Examples:
  - `ui: add contact route`
  - `docs: update README for SES configuration`
- Reference related issues or task IDs when possible.

---

## Documentation

- Keep cross-links between [README.md](../README.md), [AGENTS.md](AGENTS.md), and [OPERATIONS.md](OPERATIONS.md) accurate.
- Ensure examples and instructions match the latest code and Makefile targets.
- Update [CHANGELOG.md](../CHANGELOG.md) when behaviour changes.

---

## Style Philosophy

- Strive for **clarity and minimalism** — no clever one-liners at the expense of readability.
- Ensure code and docs are understandable by both experienced developers and newcomers.

```

## `docs/TROUBLESHOOTING.md`

```md
# TROUBLESHOOTING — Atticus

This guide covers common setup issues, ingestion problems, and quick diagnostics for Atticus deployments.

---

## Windows Setup Issues

- **Tesseract / Ghostscript**
  - Ensure both are installed and added to the system `PATH`.
  - If OCR or PDF parsing fails, verify their paths by running `tesseract --version` and `gswin64c --version`.

- **Python Wheels for 3.12**
  - If a dependency fails to build, rerun:

    ```bash
    pip install -r requirements.txt
    ```

    to rebuild compatible wheels.

- **Magic link smoke-test (PowerShell)**
  - Start the services:

    ```powershell
    make api
    make web-dev
    ```

  - Request a magic link and inspect the debug inbox:

    ```powershell
    Get-Content -Path "$env:AUTH_DEBUG_MAILBOX_DIR/*.eml"
    ```

  - If the link fails, confirm `NEXTAUTH_URL` and `AUTH_SECRET` are present in `.env` and restart both processes.

---

## PDF Parsing & Ingestion

- Prefer the **native text layer** for PDF extraction.
- OCR fallback is triggered only if no text layer is detected.
- After ingestion, verify that the number of chunks and token ranges match expectations in `logs/app.jsonl`.
- If duplicate chunks persist, inspect `seeds/seed_manifest.json` (generated by `make seed`) to confirm SHA-256 hashes differ.

Common ingestion checks:

- `.env` missing → run `python scripts/generate_env.py`.
- Unexpectedly small chunk counts → confirm `CHUNK_*` settings in `.env`.

---

## pgvector & Prisma

- **`pgvector extension not installed`** — run `make db.up` to ensure Postgres is online, then:

  ```bash
  make db.verify
  ```

  ```powershell
  make db.verify
  ```

  The script enables the extension when migrations run; if verification still fails, connect with psql and execute `CREATE EXTENSION IF NOT EXISTS vector;` manually before retrying `npx prisma migrate deploy`.

- **Embedding dimension mismatch** — export `PGVECTOR_DIMENSION` to the value used by the ingestion pipeline (default `3072`) and re-run `make db.verify`. Update `atticus/config.py` if the embeddings service changes dimension.
- **IVFFlat index missing or stale** — rerun migrations (`npx prisma migrate deploy`) and then `make db.verify`. The migration recreates `idx_atticus_chunks_embedding` with the configured `PGVECTOR_LISTS` default (`100`).

---

## SMTP / Email Escalation

- Verify all SMTP settings in `.env`: `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASS`, `SMTP_FROM`, `CONTACT_EMAIL`, and `SMTP_ALLOW_LIST`.
- Check network/firewall rules if emails do not send.
- Use the built‑in test:

  ```bash
  make smtp-test
  ```

_Error codes:_ `recipient_not_allowed` or `sender_not_allowed` indicate allow-list misconfiguration. Update `SMTP_ALLOW_LIST` to include the relevant address or domain.

---

## FastAPI / UI

- If the API fails to start:
  - Run `make lint` and `make typecheck` to catch syntax or typing errors.
  - Check logs in `logs/errors.jsonl` for stack traces.
- Confirm the UI is accessible at `http://localhost:3000/` via `make web-dev`.
  If the UI has been separated again, reintroduce a dedicated make target and update port mapping.

## Streaming `/api/ask` Issues

- **No stream events received**
  - Ensure the UI or client sends `Accept: text/event-stream`. The shared helper in `lib/ask-client.ts` enforces the header.
  - Verify `RAG_SERVICE_URL` points to the FastAPI service. On Windows PowerShell:

    ```powershell
    Invoke-WebRequest -UseBasicParsing -Method Post `
      -Uri "$env:RAG_SERVICE_URL/ask" `
      -Body '{"question":"ping"}' `
      -ContentType 'application/json'
    ```

- **502 or `upstream_unreachable` errors**
  - Confirm `make api` is running and reachable at the configured port.
  - Inspect the FastAPI logs for request IDs logged via `ask_endpoint_complete`.

- **SSE connection closes immediately**
  - Disable corporate proxies that buffer responses; SSE requires a raw streaming connection.
  - Set `NODE_OPTIONS=--enable-source-maps` when debugging to surface the originating stack trace inside the Next route handler.

---

## Lint / Format Failures

- **Prettier differences** — run `npm run format` (writes) or `npm run format:check` (CI-friendly). Tailwind class order is enforced via `prettier-plugin-tailwindcss`.
- **ESLint violations** — run `npm run lint`. The configuration uses the tailwindcss plugin; ensure utility classes flow through the `cn` helper.
- **Ruff or mypy failures** — use `make format` (auto-fix) and `make typecheck` to reproduce Python findings.
- **Full parity check** — `make quality` mirrors CI across Python + Next.js tooling.

---

## Pre-commit hook failures

Install hooks with `pre-commit install`. To re-run everything after fixing issues:

```bash
pre-commit run --all-files --show-diff-on-failure
```

If local Node tooling drifts, reinstall via `npm install` and retry.

---

## Dependency installation failures

- Capture Python failures with `mkdir -p logs/install && pip-sync requirements.txt 2>&1 | tee logs/install/pip-sync.log` and attach the log to incident notes.
- Capture Node failures with `mkdir -p logs/install && npm install --verbose 2>&1 | tee logs/install/npm-install.log`; redact tokens before sharing.
- Archive both logs under `logs/install/` for the current date and reference them from the audit trail.

---

## npm audit warnings

`npm audit` currently reports a critical Next.js middleware advisory (GHSA-f82v-jwr5-mffw) plus moderate issues in Next.js, esbuild, vite, and vitest. No fixed versions are available as of 2025-09-28; monitor upstream releases and capture justifications in `reports/ci/npm-audit-latest.json` (see [OPERATIONS.md](OPERATIONS.md#dependency-risk-exceptions)).

---

## Rate Limiting & 429 Responses

- `429 rate_limited` responses mean the user/IP exceeded `RATE_LIMIT_REQUESTS` within `RATE_LIMIT_WINDOW_SECONDS`.
- Inspect `logs/app.jsonl` for `rate_limit_blocked` entries; identifiers are hashed (first 12 hex chars) for privacy.
- Adjust thresholds in `.env` or introduce per-tenant overrides before raising limits globally.
- `/admin/metrics` exposes rate-limit counters (`blocked`) alongside query/escalation statistics.

---

## Index and Retrieval Issues

- **Rollback to a known-good index**:

  ```bash
  python scripts/rollback.py --manifest indices/manifest.json
  ```

- **Smoke test after rollback**:

  ```bash
  make eval
  ```

- If retrieval quality drops (low nDCG or Recall), re-run `make ingest` and re-check chunking settings.

---

## Quick Diagnostic Commands

| Action                         | Command                                    |
| ------------------------------ | ------------------------------------------ |
| Check environment fingerprints | `python scripts/debug_env.py`              |
| Tail live logs                 | `tail -f logs/app.jsonl`                   |
| Check errors only              | `tail -f logs/errors.jsonl`                |
| Fetch metrics dashboard        | `curl http://localhost:8000/admin/metrics` |
| Full end-to-end smoke test     | `make e2e`                                 |

---

## References

- [README.md](../README.md) — installation and setup
- [OPERATIONS.md](OPERATIONS.md) — detailed runbooks and evaluation metrics
- [SECURITY.md](SECURITY.md) — secret handling and IAM policy examples

```

## `eval/__init__.py`

```python
"""Evaluation utilities for Atticus."""

from .runner import EvaluationResult, run_evaluation

__all__ = ["EvaluationResult", "run_evaluation"]

```

## `eval/baseline.json`

```json
{
  "nDCG@10": 1.0,
  "Recall@50": 1.0,
  "MRR": 1.0
}

```

## `eval/harness/__init__.py`

```python
"""Evaluation harness package."""

```

## `eval/harness/test_eval.py`

```python
"""Evaluation metric unit tests."""

from __future__ import annotations

import pytest

from eval.runner import _evaluate_query

EXPECTED_PARTIAL_MRR = 0.5


@pytest.mark.eval
def test_evaluate_query_perfect_match() -> None:
    results = ["doc1", "doc2", "doc3"]
    relevant = ["doc1", "doc2"]
    ndcg, recall, mrr = _evaluate_query(results, relevant)
    assert round(ndcg, 4) == 1.0
    assert round(recall, 4) == 1.0
    assert round(mrr, 4) == 1.0


@pytest.mark.eval
def test_evaluate_query_partial_match() -> None:
    results = ["docX", "doc2", "doc3", "doc1"]
    relevant = ["doc1", "doc2"]
    ndcg, recall, mrr = _evaluate_query(results, relevant)
    assert ndcg < 1.0
    assert recall == 1.0
    assert mrr == EXPECTED_PARTIAL_MRR

```

## `eval/harness/test_ui.py`

```python
from __future__ import annotations

from fastapi.testclient import TestClient

from api.main import app

HTTP_OK = 200


def test_ui_served() -> None:
    with TestClient(app) as client:
        res = client.get("/ui")
        assert res.status_code == HTTP_OK
        assert "Atticus" in res.text

```

## `eval/runner.py`

```python
"""Evaluation harness computing nDCG@10, Recall@50, and MRR.

This module lazily imports heavy runtime dependencies so its pure functions
can be unit tested without requiring optional system packages (e.g. pgvector server extension).
"""

from __future__ import annotations

import csv
import json
import math
from collections.abc import Mapping, Sequence
from dataclasses import dataclass
from datetime import UTC, datetime
from html import escape
from pathlib import Path
from typing import TYPE_CHECKING, Protocol, cast, runtime_checkable

if TYPE_CHECKING:  # avoid importing heavy deps at import time
    from atticus.config import AppSettings
    from retriever.vector_store import SearchResult


def _default_output_dir(settings: AppSettings) -> Path:
    return settings.evaluation_runs_dir / datetime.now(tz=settings.tzinfo).strftime("%Y%m%d")


@dataclass(slots=True)
class GoldExample:
    question: str
    relevant_documents: list[str]
    expected_answer: str | None
    notes: str | None


@dataclass(slots=True)
class EvaluationResult:
    metrics: dict[str, float]
    deltas: dict[str, float]
    summary_csv: Path
    summary_json: Path
    summary_html: Path


def load_gold_set(path: Path) -> list[GoldExample]:
    examples: list[GoldExample] = []
    with path.open(newline="", encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            question = row.get("question", "").strip()

            # Normalize gold document paths for cross-platform comparisons
            def _canon(p: str) -> str:
                try:
                    return Path(p.strip()).as_posix().lower()
                except Exception:
                    return p.strip().replace("\\", "/").lower()

            documents = [
                _canon(item)
                for item in row.get("relevant_documents", "").split(";")
                if item and item.strip()
            ]
            expected = (row.get("expected_answer") or "").strip() or None
            notes = row.get("notes") or None
            examples.append(
                GoldExample(
                    question=question,
                    relevant_documents=documents,
                    expected_answer=expected,
                    notes=notes,
                )
            )
    return examples


def _dcg(relevances: Sequence[int]) -> float:
    return sum(
        ((2**rel - 1) / math.log2(idx + 2) for idx, rel in enumerate(relevances)),
        0.0,
    )


def _evaluate_query(
    results_doc_keys: Sequence[str], relevant_docs: list[str]
) -> tuple[float, float, float]:
    if not relevant_docs:
        return 0.0, 0.0, 0.0
    # Build the set of relevant document keys (by basename only)
    relevant_keys: set[str] = {Path(doc).name for doc in relevant_docs}

    ideal = sorted([1] * min(len(relevant_keys), 10), reverse=True)
    idcg = _dcg(ideal) if ideal else 0.0
    gains = [1 if doc_key in relevant_keys else 0 for doc_key in results_doc_keys[:10]]
    dcg = _dcg(gains)
    ndcg = dcg / idcg if idcg else 0.0

    top50 = results_doc_keys[:50]
    hits = sum(1 for key in top50 if key in relevant_keys)
    recall = hits / max(1, len(relevant_keys))

    mrr = 0.0
    for idx, key in enumerate(results_doc_keys, start=1):
        if key in relevant_keys:
            mrr = 1.0 / idx
            break
    # Clamp to [0,1]
    return min(ndcg, 1.0), min(recall, 1.0), min(mrr, 1.0)


def _canon(p: str) -> str:
    """Canonicalize a path-like string for comparison."""
    try:
        return Path(p).as_posix().lower()
    except Exception:
        return str(p).replace("\\", "/").lower()


@runtime_checkable
class _HasSource(Protocol):
    source_path: str
    metadata: Mapping[str, str] | None


def _build_doc_keys(results: Sequence[SearchResult]) -> tuple[list[str], list[str]]:
    """Produce unique document keys and primary paths from search results."""
    seen_docs: set[str] = set()
    doc_keys: list[str] = []
    documents_primary: list[str] = []
    for result in results:
        primary = _canon(result.source_path)
        meta = getattr(result, "metadata", None)
        src = meta.get("source") if meta else None
        key_source = _canon(src) if src else primary
        doc_key = Path(key_source).name
        if doc_key in seen_docs:
            continue
        seen_docs.add(doc_key)
        doc_keys.append(doc_key)
        documents_primary.append(primary)
    return doc_keys, documents_primary


def _compute_metrics(
    ndcg_scores: Sequence[float], recall_scores: Sequence[float], mrr_scores: Sequence[float]
) -> dict[str, float]:
    return {
        "nDCG@10": round(sum(ndcg_scores) / len(ndcg_scores), 4) if ndcg_scores else 0.0,
        "Recall@50": round(sum(recall_scores) / len(recall_scores), 4) if recall_scores else 0.0,
        "MRR": round(sum(mrr_scores) / len(mrr_scores), 4) if mrr_scores else 0.0,
    }


def _format_float(value: object) -> str:
    try:
        return f"{float(value):.4f}"
    except (TypeError, ValueError):
        return ""


def _write_outputs(
    output_dir: Path, rows: Sequence[dict[str, object]], metrics: dict[str, float]
) -> tuple[Path, Path, Path]:
    output_dir.mkdir(parents=True, exist_ok=True)
    summary_csv = output_dir / "metrics.csv"
    summary_json = output_dir / "summary.json"
    summary_html = output_dir / "metrics.html"

    with summary_csv.open("w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(
            handle, fieldnames=["query", "nDCG@10", "Recall@50", "MRR", "top_document"]
        )
        writer.writeheader()
        writer.writerows(rows)
        writer.writerow({"query": "AVERAGE", **metrics})

    summary_json.write_text(json.dumps(metrics, indent=2) + "\n", encoding="utf-8")

    generated_at = datetime.now(UTC).strftime("%Y-%m-%d %H:%M:%SZ")
    metrics_rows = "".join(
        f'<tr><th scope="row">{escape(name)}</th><td>{_format_float(value)}</td></tr>'
        for name, value in metrics.items()
    )
    query_rows = "".join(
        "<tr>"
        f"<td>{escape(str(row.get('query', '')))}</td>"
        f"<td>{_format_float(row.get('nDCG@10'))}</td>"
        f"<td>{_format_float(row.get('Recall@50'))}</td>"
        f"<td>{_format_float(row.get('MRR'))}</td>"
        f"<td>{escape(str(row.get('top_document') or ''))}</td>"
        "</tr>"
        for row in rows
    )

    html_report = (
        "<!DOCTYPE html>"
        '<html lang="en">'
        "<head>"
        '<meta charset="utf-8">'
        "<title>Atticus Evaluation Summary</title>"
        "<style>"
        "body{font-family:Inter,Arial,sans-serif;background:#0f172a;color:#e2e8f0;margin:0;padding:2rem;}"
        "h1{margin-top:0;font-size:1.75rem;}"
        "table{border-collapse:collapse;width:100%;margin-top:1.5rem;background:#1e293b;border-radius:0.5rem;overflow:hidden;}"
        "th,td{padding:0.75rem 1rem;text-align:left;border-bottom:1px solid rgba(148,163,184,0.25);}"
        "th{width:18rem;font-weight:600;}"
        "tbody tr:last-child td{border-bottom:none;}"
        "section + section{margin-top:2rem;}"
        "caption{caption-side:top;font-weight:600;font-size:1.1rem;margin-bottom:0.5rem;color:#f8fafc;}"
        "</style>"
        "</head>"
        "<body>"
        "<h1>Atticus Evaluation Summary</h1>"
        f"<p>Generated at <strong>{escape(generated_at)}</strong>. Metrics compare retrieval output against the configured gold set.</p>"
        "<section>"
        "<table>"
        "<caption>Aggregate Metrics</caption>"
        "<tbody>"
        f"{metrics_rows}"
        "</tbody>"
        "</table>"
        "</section>"
        "<section>"
        "<table>"
        "<caption>Per-query Breakdown</caption>"
        "<thead><tr><th>Query</th><th>nDCG@10</th><th>Recall@50</th><th>MRR</th><th>Top Document</th></tr></thead>"
        f"<tbody>{query_rows}</tbody>"
        "</table>"
        "</section>"
        "</body></html>"
    )

    summary_html.write_text(html_report, encoding="utf-8")
    return summary_csv, summary_json, summary_html


def _load_baseline(path: Path) -> dict[str, float]:
    if path.exists():
        return cast(dict[str, float], json.loads(path.read_text(encoding="utf-8")))
    return {"nDCG@10": 0.0, "Recall@50": 0.0, "MRR": 0.0}


def run_evaluation(
    settings: AppSettings | None = None,
    gold_path: Path | None = None,
    baseline_path: Path | None = None,
    output_dir: Path | None = None,
) -> EvaluationResult:
    # Lazy imports to keep unit tests lightweight
    from atticus.config import load_settings  # noqa: PLC0415
    from atticus.logging import configure_logging, log_event  # noqa: PLC0415
    from retriever.vector_store import VectorStore  # noqa: PLC0415

    settings = settings or load_settings()
    gold_path = gold_path or settings.gold_set_path
    baseline_path = baseline_path or settings.baseline_path
    output_dir = output_dir or _default_output_dir(settings)

    logger = configure_logging(settings)
    store = VectorStore(settings, logger)
    gold_examples = load_gold_set(gold_path)

    ndcg_scores: list[float] = []
    recall_scores: list[float] = []
    mrr_scores: list[float] = []
    per_query_rows: list[dict[str, object]] = []

    for example in gold_examples:
        results = store.search(example.question, top_k=50, filters=None, hybrid=True)
        # Unique documents by basename (prefer metadata.source)
        doc_keys, documents_primary = _build_doc_keys(results)

        ndcg, recall, mrr = _evaluate_query(doc_keys, example.relevant_documents)
        ndcg_scores.append(ndcg)
        recall_scores.append(recall)
        mrr_scores.append(mrr)
        per_query_rows.append(
            {
                "query": example.question,
                "nDCG@10": round(ndcg, 4),
                "Recall@50": round(recall, 4),
                "MRR": round(mrr, 4),
                "top_document": documents_primary[0] if documents_primary else None,
            }
        )

    metrics = _compute_metrics(ndcg_scores, recall_scores, mrr_scores)
    summary_csv, summary_json, summary_html = _write_outputs(output_dir, per_query_rows, metrics)

    baseline_metrics = _load_baseline(baseline_path)

    deltas = {key: round(metrics[key] - baseline_metrics.get(key, 0.0), 4) for key in metrics}

    log_event(
        logger,
        "evaluation_complete",
        metrics=metrics,
        deltas=deltas,
        gold_examples=len(gold_examples),
        output=str(output_dir),
    )

    return EvaluationResult(
        metrics=metrics,
        deltas=deltas,
        summary_csv=summary_csv,
        summary_json=summary_json,
        summary_html=summary_html,
    )


def main() -> None:
    from atticus.config import load_settings  # noqa: PLC0415

    settings = load_settings()
    result = run_evaluation(settings=settings)
    payload = {
        "metrics": result.metrics,
        "deltas": result.deltas,
        "summary_csv": str(result.summary_csv),
        "summary_json": str(result.summary_json),
    }
    print(json.dumps(payload, indent=2))


if __name__ == "__main__":
    main()

```

## `eval/runs/20251018/summary.json`

```json
{
  "nDCG@10": 0.9631,
  "Recall@50": 1.0,
  "MRR": 0.95
}

```

## `ingest/__init__.py`

```python
"""Ingestion pipeline entrypoints."""

from .pipeline import IngestionOptions, IngestionSummary, ingest_corpus

__all__ = ["IngestionOptions", "IngestionSummary", "ingest_corpus"]

```

## `ingest/chunker.py`

```python
"""Chunking utilities implementing the CED policy."""

from __future__ import annotations

import json
from collections.abc import Callable, Iterable
from dataclasses import dataclass

from atticus.config import AppSettings
from atticus.tokenization import decode, encode, split_tokens
from atticus.utils import sha256_text

from .models import Chunk, ParsedDocument, ParsedSection

MIN_CHUNK_MERGE_COUNT = 2
TABLE_SPLIT_DELIMITER = "|"


def _normalise_metadata(metadata: dict[str, str | int | float | bool | None]) -> dict[str, str]:
    result: dict[str, str] = {}
    for key, value in metadata.items():
        if value is None:
            continue
        if isinstance(value, bool):
            result[str(key)] = "true" if value else "false"
        else:
            result[str(key)] = str(value)
    return result


def _hash_chunk_payload(text: str, metadata: dict[str, str]) -> str:
    material = json.dumps({"text": text.strip(), "meta": metadata}, sort_keys=True)
    return sha256_text(material)


@dataclass(slots=True)
class _ChunkBuilder:
    settings: AppSettings
    document: ParsedDocument
    chunk_counter: int = 0

    def next_id(self) -> str:
        ident = f"{self.document.document_id}::chunk_{self.chunk_counter}".replace("//", "/")
        self.chunk_counter += 1
        return ident

    def build_chunk(
        self,
        *,
        section: ParsedSection,
        breadcrumbs: list[str],
        text: str,
        start: int,
        end: int,
        chunking: str,
        extra: dict[str, str | int | float | bool | None],
    ) -> Chunk:
        raw_metadata: dict[str, str | int | float | bool | None] = {
            "chunking": chunking,
            "source_type": self.document.source_type,
            **section.extra,
            **extra,
        }
        if section.heading:
            raw_metadata.setdefault("section_heading", section.heading)
        if section.page_number is not None:
            raw_metadata.setdefault("page_number", section.page_number)
        if breadcrumbs:
            raw_metadata.setdefault("breadcrumbs", " > ".join(breadcrumbs))
        metadata = _normalise_metadata(raw_metadata)
        chunk_hash = _hash_chunk_payload(text, metadata)
        metadata.setdefault("chunk_sha", chunk_hash)

        return Chunk(
            chunk_id=self.next_id(),
            document_id=self.document.document_id,
            source_path=str(self.document.source_path),
            text=text,
            start_token=start,
            end_token=end,
            page_number=section.page_number,
            heading=section.heading,
            sha256=chunk_hash,
            extra=metadata,
            breadcrumbs=list(breadcrumbs),
        )


class CEDChunker:
    """Implements the CED chunking strategy (prose, table, footnote)."""

    def __init__(self, settings: AppSettings) -> None:
        self.settings = settings

    def chunk_document(self, document: ParsedDocument) -> list[Chunk]:
        builder = _ChunkBuilder(settings=self.settings, document=document)
        chunks: list[Chunk] = []
        dedupe: set[str] = set()
        breadcrumbs_root = [document.source_path.name]

        for section in document.sections:
            breadcrumbs = breadcrumbs_root + list(section.breadcrumbs)
            if section.heading and (not breadcrumbs or breadcrumbs[-1] != section.heading):
                breadcrumbs.append(section.heading)

            if section.extra.get("is_table") == "true":
                factory: Callable[[], Iterable[Chunk]] = lambda: self._chunk_table(
                    builder, section, breadcrumbs
                )
            elif self._is_footnote(section):
                factory = lambda: self._chunk_footnote(builder, section, breadcrumbs)
            else:
                factory = lambda: self._chunk_prose(builder, section, breadcrumbs)

            for chunk in factory():
                if chunk.sha256 in dedupe:
                    continue
                dedupe.add(chunk.sha256)
                chunks.append(chunk)

        return chunks

    def _chunk_prose(
        self,
        builder: _ChunkBuilder,
        section: ParsedSection,
        breadcrumbs: list[str],
    ) -> Iterable[Chunk]:
        tokens = encode(section.text)
        if not tokens:
            return []
        target_tokens = self.settings.chunk_target_tokens or self.settings.chunk_size
        overlap = 0
        splits = list(split_tokens(tokens, target_tokens, overlap))
        result: list[Chunk] = []
        for index, (start, end) in enumerate(splits, start=1):
            text = decode(tokens[start:end])
            chunk = builder.build_chunk(
                section=section,
                breadcrumbs=breadcrumbs,
                text=text,
                start=start,
                end=end,
                chunking="prose",
                extra={
                    "chunk_index": index,
                    "token_count": max(0, end - start),
                },
            )
            result.append(chunk)

        if (
            self.settings.chunk_min_tokens > 0
            and len(result) >= MIN_CHUNK_MERGE_COUNT
            and result[-1].end_token - result[-1].start_token < self.settings.chunk_min_tokens
        ):
            tail = result.pop()
            prev = result[-1]
            merged_text = f"{prev.text}\n{tail.text}".strip()
            prev.text = merged_text
            prev.end_token = tail.end_token
            prev.extra.update({"merged": "true"})
            prev.extra.update(
                {k: v for k, v in tail.extra.items() if k not in {"chunk_sha", "chunking"}}
            )
            new_hash = _hash_chunk_payload(merged_text, prev.extra)
            prev.sha256 = new_hash
            prev.extra["chunk_sha"] = new_hash

        return result

    def _chunk_table(
        self,
        builder: _ChunkBuilder,
        section: ParsedSection,
        breadcrumbs: list[str],
    ) -> Iterable[Chunk]:
        lines = [line.strip() for line in section.text.splitlines() if line.strip()]
        if not lines:
            return []
        headers = section.extra.get("table_headers") or ""
        result: list[Chunk] = []
        for index, line in enumerate(lines, start=1):
            cells = [cell.strip() for cell in line.split(TABLE_SPLIT_DELIMITER)]
            cell_payload = {f"col_{idx}": value for idx, value in enumerate(cells, start=1)}
            formatted_cells = " | ".join(cells)
            text = formatted_cells
            if headers:
                text = f"{headers}\n{formatted_cells}".strip()
            chunk = builder.build_chunk(
                section=section,
                breadcrumbs=breadcrumbs,
                text=text,
                start=0,
                end=len(encode(text)),
                chunking="table_row",
                extra={
                    "table_headers": headers,
                    "table_row_index": index,
                    "table_cells": json.dumps(cell_payload, ensure_ascii=False),
                },
            )
            result.append(chunk)
        return result

    def _chunk_footnote(
        self,
        builder: _ChunkBuilder,
        section: ParsedSection,
        breadcrumbs: list[str],
    ) -> Iterable[Chunk]:
        text = section.text.strip()
        if not text:
            return []
        chunk = builder.build_chunk(
            section=section,
            breadcrumbs=breadcrumbs,
            text=text,
            start=0,
            end=len(encode(text)),
            chunking="footnote",
            extra={"token_count": len(encode(text))},
        )
        return [chunk]

    @staticmethod
    def _is_footnote(section: ParsedSection) -> bool:
        heading = (section.heading or "").lower()
        if "footnote" in heading:
            return True
        return str(section.extra.get("footnote", "")).lower() == "true"


def chunk_document(document: ParsedDocument, settings: AppSettings) -> list[Chunk]:
    return CEDChunker(settings).chunk_document(document)


def chunk_documents(documents: Iterable[ParsedDocument], settings: AppSettings) -> list[Chunk]:
    chunker = CEDChunker(settings)
    all_chunks: list[Chunk] = []
    for document in documents:
        all_chunks.extend(chunker.chunk_document(document))
    return all_chunks

```

## `ingest/models.py`

```python
"""Dataclasses for parsed documents and chunks."""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path


@dataclass(slots=True)
class ParsedSection:
    text: str
    page_number: int | None = None
    heading: str | None = None
    extra: dict[str, str] = field(default_factory=dict)
    breadcrumbs: list[str] = field(default_factory=list)


@dataclass(slots=True)
class ParsedDocument:
    source_path: Path
    source_type: str
    sections: list[ParsedSection]
    sha256: str | None = None

    @property
    def document_id(self) -> str:
        return str(self.source_path)


@dataclass(slots=True)
class Chunk:
    """Chunk produced by the ingestion pipeline."""

    chunk_id: str
    document_id: str
    source_path: str
    text: str
    start_token: int
    end_token: int
    page_number: int | None
    heading: str | None
    sha256: str
    extra: dict[str, str]
    breadcrumbs: list[str] = field(default_factory=list)

```

## `ingest/parsers/__init__.py`

```python
"""Document discovery and parsing utilities."""

from __future__ import annotations

from collections.abc import Callable, Iterable
from pathlib import Path

from ..models import ParsedDocument
from .docx import parse_docx
from .html import parse_html
from .image import parse_image
from .pdf import parse_pdf
from .text import parse_text
from .xlsx import parse_xlsx

Parser = Callable[[Path], ParsedDocument]

PARSERS: dict[str, Parser] = {
    ".txt": parse_text,
    ".md": parse_text,
    ".pdf": parse_pdf,
    ".docx": parse_docx,
    ".xlsx": parse_xlsx,
    ".html": parse_html,
    ".htm": parse_html,
    ".png": parse_image,
    ".jpg": parse_image,
    ".jpeg": parse_image,
    ".tif": parse_image,
    ".tiff": parse_image,
}


def discover_documents(content_root: Path) -> Iterable[Path]:
    for path in sorted(content_root.rglob("*")):
        if path.is_file() and path.suffix.lower() in PARSERS:
            yield path


def parse_document(path: Path) -> ParsedDocument:
    parser = PARSERS.get(path.suffix.lower())
    if parser is None:
        raise ValueError(f"Unsupported file extension: {path.suffix}")
    return parser(path)

```

## `ingest/parsers/docx.py`

```python
"""DOCX parser."""

from __future__ import annotations

from pathlib import Path

import docx

from ..models import ParsedDocument, ParsedSection


def _heading_level(style_name: str) -> int | None:
    if not style_name.lower().startswith("heading"):
        return None
    digits = "".join(ch for ch in style_name if ch.isdigit())
    if not digits:
        return 1
    try:
        return max(1, int(digits))
    except ValueError:
        return 1


def parse_docx(path: Path) -> ParsedDocument:
    document = docx.Document(str(path))
    sections: list[ParsedSection] = []
    breadcrumb_stack: list[str] = []

    for paragraph in document.paragraphs:
        text = paragraph.text.strip()
        if not text:
            continue
        style_name = paragraph.style.name if paragraph.style is not None else ""
        level = _heading_level(style_name or "")
        if level is not None:
            while len(breadcrumb_stack) >= level:
                breadcrumb_stack.pop()
            breadcrumb_stack.append(text)
            continue
        heading = breadcrumb_stack[-1] if breadcrumb_stack else None
        sections.append(
            ParsedSection(text=text, heading=heading, breadcrumbs=breadcrumb_stack.copy())
        )

    return ParsedDocument(
        source_path=path,
        source_type="docx",
        sections=sections,
    )

```

## `ingest/parsers/html.py`

```python
"""HTML parser using BeautifulSoup."""

from __future__ import annotations

from pathlib import Path

from bs4 import BeautifulSoup

from ..models import ParsedDocument, ParsedSection


def parse_html(path: Path) -> ParsedDocument:
    soup = BeautifulSoup(path.read_text(encoding="utf-8"), "html.parser")
    texts = []
    for heading in soup.find_all(["h1", "h2", "h3", "h4", "h5", "h6"]):
        heading_text = heading.get_text(strip=True)
        sibling_text = []
        for sibling in heading.next_siblings:
            if getattr(sibling, "name", None) in {"h1", "h2", "h3", "h4", "h5", "h6"}:
                break
            if isinstance(sibling, str):
                content = sibling.strip()
            else:
                content = sibling.get_text(" ", strip=True)
            if content:
                sibling_text.append(content)
        texts.append((heading_text, "\n".join(sibling_text)))

    if not texts:
        body_text = soup.get_text("\n", strip=True)
        texts.append(("", body_text))

    sections = [
        ParsedSection(
            text=content, heading=heading or None, breadcrumbs=[heading] if heading else []
        )
        for heading, content in texts
        if content
    ]
    return ParsedDocument(
        source_path=path,
        source_type="html",
        sections=sections,
    )

```

## `ingest/parsers/image.py`

```python
"""Image OCR parser."""

from __future__ import annotations

from pathlib import Path
from typing import Any, cast

from PIL import Image

from ..models import ParsedDocument, ParsedSection

try:  # pragma: no cover - optional dependency
    import pytesseract as _pytesseract
except Exception:  # pragma: no cover - runtime fallback
    _pytesseract = None

pytesseract: Any | None = _pytesseract


def parse_image(path: Path) -> ParsedDocument:
    text = ""
    if pytesseract is not None:  # pragma: no cover - requires external binary
        try:
            with Image.open(str(path)) as image:
                text = cast(str, pytesseract.image_to_string(image))
        except Exception:
            text = ""
    section = ParsedSection(text=text.strip(), breadcrumbs=["Image"])
    return ParsedDocument(
        source_path=path,
        source_type="image",
        sections=[section],
    )

```

## `ingest/parsers/pdf.py`

```python
"""PDF parsing including OCR fallback."""

from __future__ import annotations

import importlib
import io
import logging
import shutil
import tempfile
import time
from collections.abc import Iterable
from pathlib import Path
from typing import Any, cast

import fitz
from PIL import Image

from ..models import ParsedDocument, ParsedSection

pytesseract: Any | None
camelot: Any | None
tabula: Any | None

try:  # pragma: no cover - optional dependency
    pytesseract = importlib.import_module("pytesseract")
except Exception:  # pragma: no cover - runtime fallback
    pytesseract = None

try:  # pragma: no cover - optional dependency
    camelot = importlib.import_module("camelot")
except Exception:  # pragma: no cover
    camelot = None

try:  # pragma: no cover - optional dependency
    tabula = importlib.import_module("tabula")
except Exception:  # pragma: no cover
    tabula = None


_pdfminer_logger = logging.getLogger("pdfminer.pdfinterp")
# pdfminer sometimes logs noisy warnings for malformed color values; suppress them.
if _pdfminer_logger.getEffectiveLevel() >= logging.WARNING:
    _pdfminer_logger.setLevel(logging.ERROR)


def _safe_rmtree(path: str | None) -> None:
    """Best-effort removal that tolerates transient Windows file locks."""
    if not path:
        return
    for attempt in range(5):
        try:
            shutil.rmtree(path)
            return
        except FileNotFoundError:
            return
        except PermissionError:
            time.sleep(0.2 * (attempt + 1))
    shutil.rmtree(path, ignore_errors=True)


if camelot is not None:  # pragma: no cover - runtime safeguard for camelot cleanup
    try:
        from camelot import utils as camelot_utils  # type: ignore
    except Exception:
        camelot = None
    else:
        temp_dir_cls = getattr(camelot_utils, "TemporaryDirectory", None)
        if temp_dir_cls is not None and not getattr(
            temp_dir_cls, "_atticus_safe_cleanup", False
        ):

            def _patched_enter(self) -> str:  # type: ignore[no-untyped-def]
                self.name = tempfile.mkdtemp()
                return self.name

            def _patched_exit(self, exc_type, exc_value, traceback) -> None:  # type: ignore[no-untyped-def]
                _safe_rmtree(getattr(self, "name", None))

            # Replace the temp dir helpers so cleanup happens immediately and tolerates locks.
            temp_dir_cls.__enter__ = _patched_enter  # type: ignore[assignment]
            temp_dir_cls.__exit__ = _patched_exit  # type: ignore[assignment]
            temp_dir_cls._atticus_safe_cleanup = True  # type: ignore[attr-defined]


def _extract_ocr(page: fitz.Page) -> str:
    if pytesseract is None:  # pragma: no cover - optional binary
        return ""
    try:
        pix = page.get_pixmap()
        buffer = io.BytesIO(pix.tobytes("png"))
        with Image.open(buffer) as image:
            return cast(str, pytesseract.image_to_string(image))
    except Exception:
        # If OCR tooling is unavailable at runtime, fall back silently
        return ""


def parse_pdf(path: Path) -> ParsedDocument:
    document = fitz.open(str(path))
    sections: list[ParsedSection] = []
    for index, page in enumerate(document, start=1):
        text = page.get_text("text")
        if not text.strip():
            text = _extract_ocr(page)
        breadcrumbs = [f"Page {index}"]
        sections.append(
            ParsedSection(text=text.strip(), page_number=index, breadcrumbs=breadcrumbs)
        )
    document.close()

    table_sections = list(_extract_tables(path))
    sections.extend(table_sections)

    return ParsedDocument(
        source_path=path,
        source_type="pdf",
        sections=sections,
    )


def _extract_tables(path: Path) -> Iterable[ParsedSection]:  # noqa: PLR0912
    tables_found = False
    if camelot is not None:  # pragma: no cover - requires camelot dependencies
        try:
            tables = camelot.read_pdf(str(path), pages="all", suppress_stdout=True)
        except Exception:
            tables = []
        for index, table in enumerate(tables, start=1):
            dataframe = getattr(table, "df", None)
            if dataframe is None:
                continue
            if dataframe.empty:
                continue
            tables_found = True
            cleaned = dataframe.fillna("")
            header = [str(cell).strip() for cell in cleaned.iloc[0].tolist()]
            rows = cleaned.iloc[1:]
            lines = [
                " | ".join(str(cell).strip() for cell in row.tolist()) for _, row in rows.iterrows()
            ]
            content = "\n".join(lines)
            if not content.strip():
                continue
            extra = {
                "is_table": "true",
                "table_headers": ", ".join(header),
            }
            page_number = getattr(table, "page", None)
            breadcrumbs = [f"Table {index}"]
            if page_number:
                extra["page_number"] = str(page_number)
                breadcrumbs.append(f"Page {page_number}")
            yield ParsedSection(
                text=content,
                page_number=int(page_number) if isinstance(page_number, int) else None,
                heading=f"Table {index}",
                extra=extra,
                breadcrumbs=breadcrumbs,
            )
    if tables_found:
        return

    if tabula is not None:  # pragma: no cover - requires java
        try:
            dataframes = tabula.read_pdf(str(path), pages="all", multiple_tables=True)
        except Exception:
            dataframes = []
        for index, dataframe in enumerate(dataframes, start=1):
            if dataframe is None or dataframe.empty:
                continue
            cleaned = dataframe.fillna("")
            header = [str(col).strip() for col in cleaned.columns]
            lines = [" | ".join(str(value).strip() for value in row) for row in cleaned.to_numpy()]
            content = "\n".join(lines)
            if not content.strip():
                continue
            extra = {
                "is_table": "true",
                "table_headers": ", ".join(header),
            }
            breadcrumbs = [f"Table {index}"]
            yield ParsedSection(
                text=content,
                heading=f"Table {index}",
                extra=extra,
                breadcrumbs=breadcrumbs,
            )

```

## `ingest/parsers/text.py`

```python
"""Plain text parser."""

from __future__ import annotations

from pathlib import Path

from ..models import ParsedDocument, ParsedSection


def parse_text(path: Path) -> ParsedDocument:
    text = path.read_text(encoding="utf-8")
    section = ParsedSection(text=text, breadcrumbs=["Text"])
    return ParsedDocument(
        source_path=path,
        source_type="text",
        sections=[section],
    )

```

## `ingest/parsers/xlsx.py`

```python
"""Parser for XLSX question and answer sheets."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import TYPE_CHECKING, Any, Iterable, Iterator, Sequence, cast

if TYPE_CHECKING:
    from openpyxl import load_workbook
    from openpyxl.worksheet.worksheet import Worksheet
else:  # pragma: no cover - runtime fallback
    try:
        from openpyxl import load_workbook  # type: ignore[assignment]
    except Exception:  # pragma: no cover - graceful fallback for typing
        load_workbook = None  # type: ignore[assignment]
    Worksheet = Any

from ..models import ParsedDocument, ParsedSection

EXPECTED_COLUMNS = {"question", "answer"}


def _ensure_worksheet(candidate: Any) -> Worksheet | None:
    """Return a Worksheet when the object quacks like one, otherwise None."""
    if candidate is None:
        return None
    if hasattr(candidate, "iter_rows") and hasattr(candidate, "max_row"):
        return cast(Worksheet, candidate)
    return None


def _cell_to_str(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, bool):
        return "true" if value else "false"
    if isinstance(value, (int, float)):
        text = f"{value}"
        return text[:-2] if text.endswith(".0") else text
    return str(value).strip()


def _coerce_int(value: str) -> int | None:
    text = value.strip()
    if not text:
        return None
    try:
        return int(text)
    except ValueError:
        try:
            return int(float(text))
        except ValueError:
            return None


def _cell_at(cells: Sequence[str], index: int) -> str:
    if 0 <= index < len(cells):
        return cells[index]
    return ""


@dataclass(slots=True)
class Row:
    cells: list[str]


def iter_rows_safe(ws: Worksheet | None) -> Iterator[Row]:
    sheet = _ensure_worksheet(ws)
    if sheet is None:
        return
    try:
        values_iter = cast(Iterable[Sequence[Any]], sheet.iter_rows(values_only=True))
        for raw in values_iter:
            yield Row([_cell_to_str(value) for value in raw])
    except Exception:  # pragma: no cover - defensive fallback
        cells_iter = cast(Iterable[Sequence[Any]], sheet.iter_rows())
        for raw in cells_iter:
            yield Row([_cell_to_str(getattr(cell, "value", None)) for cell in raw])


def _header_map(header_row: Sequence[str]) -> dict[str, int]:
    mapping: dict[str, int] = {}
    for idx, cell in enumerate(header_row):
        key = cell.strip().lower()
        if key:
            mapping[key] = idx
    return mapping


def parse_xlsx(path: Path) -> ParsedDocument:
    if load_workbook is None:  # pragma: no cover - import guard
        raise RuntimeError("openpyxl is required to parse XLSX documents")

    workbook = load_workbook(filename=str(path), data_only=True)

    candidate_sheets: list[Worksheet | None] = []
    active = _ensure_worksheet(getattr(workbook, "active", None))
    if active is not None:
        candidate_sheets.append(active)
    for name in getattr(workbook, "sheetnames", []):
        try:
            sheet = _ensure_worksheet(workbook[name])
        except Exception:  # pragma: no cover - defensive guard
            sheet = None
        if sheet is not None and sheet not in candidate_sheets:
            candidate_sheets.append(sheet)

    rows: list[Row] = []
    for sheet in candidate_sheets:
        rows = list(iter_rows_safe(sheet))
        if rows:
            break

    if not rows:
        return ParsedDocument(source_path=path, source_type="xlsx", sections=[])

    headers = rows[0].cells
    header_map = _header_map(headers)
    column_map = {name: header_map[name] for name in EXPECTED_COLUMNS if name in header_map}
    sections: list[ParsedSection] = []

    for row in rows[1:]:
        cells = row.cells
        if not any(cells):
            continue

        question_idx = column_map.get("question")
        answer_idx = column_map.get("answer")
        question = _cell_at(cells, question_idx).strip() if question_idx is not None else ""
        answer = _cell_at(cells, answer_idx).strip() if answer_idx is not None else ""

        if not question and not answer:
            continue

        extra: dict[str, str] = {}
        source_idx = header_map.get("source")
        if source_idx is not None:
            source = _cell_at(cells, source_idx).strip()
            if source:
                extra["source"] = source

        page = None
        page_idx = header_map.get("page")
        if page_idx is not None:
            page = _coerce_int(_cell_at(cells, page_idx))

        text = f"Q: {question}\nA: {answer}"
        breadcrumbs = ["Q&A"]
        sections.append(
            ParsedSection(text=text, page_number=page, extra=extra, breadcrumbs=breadcrumbs)
        )

    return ParsedDocument(source_path=path, source_type="xlsx", sections=sections)

```

## `ingest/pipeline.py`

```python
"""Ingestion pipeline orchestrating parsing, chunking, and indexing."""

from __future__ import annotations

import json
import shutil
import time
from collections.abc import Sequence
from dataclasses import dataclass
from pathlib import Path
from typing import Any

from atticus.config import AppSettings, Manifest, load_manifest, load_settings, write_manifest
from atticus.embeddings import EmbeddingClient
from atticus.logging import configure_logging, log_event
from atticus.utils import sha256_file, sha256_text
from atticus.vector_db import PgVectorRepository, StoredChunk, save_metadata
from retriever.models import ModelCatalog, extract_models, load_model_catalog

from .chunker import chunk_document
from .models import Chunk as ParsedChunk
from .models import ParsedDocument
from .parsers import discover_documents, parse_document


@dataclass(slots=True)
class IngestionOptions:
    full_refresh: bool = False
    paths: Sequence[Path] | None = None


@dataclass(slots=True)
class IngestionSummary:
    documents_processed: int
    documents_skipped: int
    chunks_indexed: int
    elapsed_seconds: float
    manifest_path: Path
    index_path: Path
    snapshot_path: Path
    ingested_at: str
    embedding_model: str
    embedding_model_version: str


def _build_document_scope(
    documents: Sequence[ParsedDocument], catalog: ModelCatalog
) -> dict[str, dict[str, set[str]]]:
    scope: dict[str, dict[str, set[str]]] = {}
    for document in documents:
        texts: list[str] = [document.source_path.name]
        for section in document.sections[:5]:
            if section.heading:
                texts.append(section.heading)
            texts.append(section.text)
        models: set[str] = set()
        families: set[str] = set()
        for text in texts:
            if not text:
                continue
            extraction = extract_models(text, catalog=catalog)
            models.update(extraction.models)
            families.update(extraction.families)
        scope[document.document_id] = {"models": models, "families": families}
    return scope


def _annotate_chunk_with_catalog(
    chunk: StoredChunk | ParsedChunk,
    catalog: ModelCatalog,
    document_scope: dict[str, dict[str, set[str]]],
) -> None:
    texts = [
        getattr(chunk, "text", "") or "",
        chunk.extra.get("breadcrumbs", ""),
        getattr(chunk, "source_path", "") or "",
    ]
    models: set[str] = set()
    families: set[str] = set()
    for text in texts:
        if not text:
            continue
        extraction = extract_models(text, catalog=catalog)
        models.update(extraction.models)
        families.update(extraction.families)

    defaults = document_scope.get(chunk.document_id)
    if defaults:
        models.update(defaults.get("models", set()))
        families.update(defaults.get("families", set()))

    if not families and models:
        for model in models:
            ident = catalog.match_model(model)
            if ident:
                families.add(ident.family_id)

    if families:
        family_ids = sorted(families)
        chunk.extra["product_family"] = ",".join(family_ids)
        labels = {
            catalog.families[family_id].label
            for family_id in family_ids
            if family_id in catalog.families
        }
        if labels:
            chunk.extra["product_family_label"] = ", ".join(sorted(labels))

    if models:
        chunk.extra["models"] = json.dumps(sorted(models))


def _snapshot_directory(settings: AppSettings, timestamp: str) -> Path:
    safe = timestamp.replace(":", "").replace("-", "")
    snapshot_dir = settings.snapshots_dir / safe
    snapshot_dir.mkdir(parents=True, exist_ok=True)
    return snapshot_dir


def ingest_corpus(  # noqa: PLR0915, PLR0912
    settings: AppSettings | None = None, options: IngestionOptions | None = None
) -> IngestionSummary:
    settings = settings or load_settings()
    options = options or IngestionOptions()
    settings.ensure_directories()
    logger = configure_logging(settings)
    catalog = load_model_catalog()

    if not settings.database_url:
        raise ValueError("DATABASE_URL must be configured before running ingestion")

    repo = PgVectorRepository(settings)
    repo.ensure_schema()

    ingest_time = settings.timestamp()
    start_time = time.time()
    manifest = load_manifest(settings.manifest_path)

    target_paths = (
        list(options.paths) if options.paths else list(discover_documents(settings.content_dir))
    )
    previous_docs = manifest.documents if manifest else {}

    reused_chunks: list[StoredChunk] = []
    reused_documents: dict[str, dict[str, Any]] = {}
    new_documents: list[ParsedDocument] = []
    skipped = 0
    document_lookup: dict[str, str] = {}

    for raw_path in target_paths:
        file_path = Path(raw_path)
        file_hash = sha256_file(file_path)
        manifest_entry = (
            previous_docs.get(str(file_path)) if manifest and not options.full_refresh else None
        )
        if manifest_entry and manifest_entry.get("sha256") == file_hash:
            existing_chunks = repo.fetch_chunks_for_source(str(file_path))
            if existing_chunks:
                for existing_chunk in existing_chunks:
                    existing_chunk.extra["embedding_model"] = settings.embed_model
                    existing_chunk.extra["embedding_model_version"] = (
                        settings.embedding_model_version
                    )
                    existing_chunk.extra["ingested_at"] = ingest_time
                    existing_chunk.extra.setdefault("chunk_sha", existing_chunk.sha256)
                reused_chunks.extend(existing_chunks)
                first = existing_chunks[0]
                reused_documents[first.document_id] = {
                    "document_id": first.document_id,
                    "source_path": str(file_path),
                    "sha256": str(manifest_entry.get("sha256", "")),
                    "source_type": manifest_entry.get("source_type"),
                    "chunks": existing_chunks,
                }
                document_lookup[str(file_path)] = str(manifest_entry.get("source_type", ""))
                skipped += 1
                continue
        document = parse_document(file_path)
        document.sha256 = file_hash
        new_documents.append(document)
        document_lookup[str(document.source_path)] = document.source_type

    new_parsed_chunks: list[ParsedChunk] = []
    for document in new_documents:
        new_parsed_chunks.extend(chunk_document(document, settings))

    document_scope = _build_document_scope(new_documents, catalog)
    for parsed_chunk in new_parsed_chunks:
        _annotate_chunk_with_catalog(parsed_chunk, catalog, document_scope)
    for reused_chunk in reused_chunks:
        _annotate_chunk_with_catalog(reused_chunk, catalog, document_scope)

    embed_client = EmbeddingClient(settings, logger=logger)
    embeddings = embed_client.embed_texts(chunk.text for chunk in new_parsed_chunks)

    stored_chunks: list[StoredChunk] = list(reused_chunks)
    chunks_by_document: dict[str, list[StoredChunk]] = {}
    for doc_id, info in reused_documents.items():
        chunks_by_document[doc_id] = list(info["chunks"])

    for index_counter, (parsed_chunk, embedding) in enumerate(
        zip(new_parsed_chunks, embeddings, strict=False), start=len(stored_chunks)
    ):
        metadata = {key: str(value) for key, value in parsed_chunk.extra.items()}
        metadata.setdefault("chunk_sha", parsed_chunk.sha256)
        if parsed_chunk.breadcrumbs:
            metadata.setdefault("breadcrumbs", " > ".join(parsed_chunk.breadcrumbs))
        metadata.setdefault("source_path", parsed_chunk.source_path)
        metadata.setdefault("document_id", parsed_chunk.document_id)
        metadata.setdefault("chunk_index", str(index_counter))
        metadata.setdefault(
            "source_type",
            metadata.get("source_type", document_lookup.get(parsed_chunk.source_path, "")),
        )
        metadata.setdefault("ingested_at", ingest_time)
        metadata.setdefault("embedding_model", settings.embed_model)
        metadata.setdefault("embedding_model_version", settings.embedding_model_version)
        metadata.setdefault("token_span", f"{parsed_chunk.start_token}:{parsed_chunk.end_token}")
        metadata.setdefault(
            "token_count", str(max(0, parsed_chunk.end_token - parsed_chunk.start_token))
        )
        chunk_object = StoredChunk(
            chunk_id=parsed_chunk.chunk_id,
            document_id=parsed_chunk.document_id,
            source_path=parsed_chunk.source_path,
            text=parsed_chunk.text,
            start_token=parsed_chunk.start_token,
            end_token=parsed_chunk.end_token,
            page_number=parsed_chunk.page_number,
            section=parsed_chunk.heading,
            sha256=parsed_chunk.sha256,
            embedding=list(embedding),
            extra=metadata,
        )
        stored_chunks.append(chunk_object)
        chunks_by_document.setdefault(parsed_chunk.document_id, []).append(chunk_object)

    for info in reused_documents.values():
        repo.replace_document(
            document_id=info["document_id"],
            source_path=info["source_path"],
            sha256=info["sha256"],
            source_type=info.get("source_type"),
            chunks=info["chunks"],
            ingest_time=ingest_time,
        )

    for document in new_documents:
        repo.replace_document(
            document_id=document.document_id,
            source_path=str(document.source_path),
            sha256=document.sha256 or "",
            source_type=document.source_type,
            chunks=chunks_by_document.get(document.document_id, []),
            ingest_time=ingest_time,
        )

    save_metadata(stored_chunks, settings.metadata_path)

    snapshot_dir = _snapshot_directory(settings, ingest_time)
    shutil.copy2(settings.metadata_path, snapshot_dir / "index_metadata.json")

    document_records: dict[str, dict[str, Any]] = {}
    for chunk in stored_chunks:
        entry = document_records.setdefault(
            chunk.source_path,
            {
                "sha256": previous_docs.get(chunk.source_path, {}).get("sha256")
                if manifest
                else None,
                "chunk_count": 0,
                "source_type": previous_docs.get(chunk.source_path, {}).get("source_type")
                if manifest
                else None,
            },
        )
        raw_count = entry.get("chunk_count", 0)
        if isinstance(raw_count, int):
            chunk_count = raw_count
        elif isinstance(raw_count, str) and raw_count.isdigit():
            chunk_count = int(raw_count)
        else:
            chunk_count = 0
        entry["chunk_count"] = chunk_count + 1

    for document in new_documents:
        record = document_records.setdefault(
            str(document.source_path),
            {"sha256": document.sha256, "chunk_count": 0, "source_type": document.source_type},
        )
        record["sha256"] = document.sha256
        record["source_type"] = document.source_type

    previous_paths = set(previous_docs.keys())
    current_paths = set(document_records.keys())
    removed_paths = previous_paths - current_paths
    for missing_path in removed_paths:
        repo.remove_document(missing_path)

    document_hashes = [
        f"{path}:{info.get('sha256', '')}" for path, info in sorted(document_records.items())
    ]
    corpus_hash = (
        sha256_text("|".join(document_hashes)) if document_hashes else sha256_text("empty")
    )

    index_identifier = Path("pgvector")
    metadata_snapshot_path = snapshot_dir / "index_metadata.json"

    manifest = Manifest(
        embedding_model=settings.embed_model,
        embedding_model_version=settings.embedding_model_version,
        embedding_dimensions=settings.embed_dimensions,
        chunk_size=settings.chunk_size,
        chunk_overlap_ratio=settings.chunk_overlap_ratio,
        corpus_hash=corpus_hash,
        document_count=len(document_records),
        chunk_count=len(stored_chunks),
        created_at=ingest_time,
        metadata_path=settings.metadata_path,
        index_path=index_identifier,
        snapshot_path=metadata_snapshot_path,
        documents=document_records,
    )
    write_manifest(settings.manifest_path, manifest)
    shutil.copy2(settings.manifest_path, snapshot_dir / "manifest.json")

    elapsed = time.time() - start_time
    summary = IngestionSummary(
        documents_processed=len(new_documents),
        documents_skipped=skipped,
        chunks_indexed=len(stored_chunks),
        elapsed_seconds=round(elapsed, 2),
        manifest_path=settings.manifest_path,
        index_path=index_identifier,
        snapshot_path=metadata_snapshot_path,
        ingested_at=ingest_time,
        embedding_model=settings.embed_model,
        embedding_model_version=settings.embedding_model_version,
    )

    log_event(
        logger,
        "ingestion_complete",
        documents_processed=summary.documents_processed,
        documents_skipped=summary.documents_skipped,
        chunks_indexed=summary.chunks_indexed,
        elapsed_seconds=summary.elapsed_seconds,
        embedding_model=settings.embed_model,
        embedding_model_version=settings.embedding_model_version,
        ingested_at=ingest_time,
    )

    return summary

```

## `knip.json`

```json
{
  "$schema": "https://unpkg.com/knip@5/schema.json",
  "entry": [
    "app/**/*.{ts,tsx}",
    "components/**/*.{ts,tsx}",
    "lib/**/*.{ts,tsx}",
    "scripts/**/*.{ts,tsx,js,mjs}",
    "tests/**/*.{ts,tsx}"
  ],
  "project": [
    "app/**/*.{ts,tsx}",
    "components/**/*.{ts,tsx}",
    "lib/**/*.{ts,tsx}",
    "scripts/**/*.{ts,tsx,js,mjs}",
    "tests/**/*.{ts,tsx}",
    "prisma/**/*.ts"
  ],
  "paths": {
    "@": [
      "."
    ],
    "@/components": [
      "components"
    ],
    "@/app": [
      "app"
    ],
    "@/lib": [
      "lib"
    ]
  },
  "ignoreDependencies": [
    "@radix-ui/react-dialog",
    "@radix-ui/react-slot",
    "@radix-ui/react-tabs",
    "clsx",
    "react-markdown",
    "remark-gfm",
    "zod",
    "tailwind-merge"
  ],
  "ignore": [
    "archive/legacy-ui/**",
    "prisma/seed.ts",
    "scripts/route-audit.mjs"
  ]
}

```

## `lib/ask-client.ts`

```typescript
import {
  askRequestSchema,
  askResponseSchema,
  type AskRequest,
  type AskResponse,
} from "@/lib/ask-contract";

export type AskStreamEvent =
  | { type: "start"; requestId: string }
  | { type: "answer"; payload: AskResponse }
  | { type: "end"; requestId: string };

interface StreamOptions {
  signal?: AbortSignal;
  onEvent?: (event: AskStreamEvent) => void;
}

function parseSseChunk(chunk: string): AskStreamEvent | null {
  const lines = chunk.split("\n").filter(Boolean);
  let eventType = "answer";
  let dataLine = "";
  for (const line of lines) {
    if (line.startsWith("event:")) {
      eventType = line.slice(6).trim();
    }
    if (line.startsWith("data:")) {
      dataLine += line.slice(5).trim();
    }
  }
  if (!dataLine) {
    return null;
  }
  const payload = JSON.parse(dataLine);
  switch (eventType) {
    case "start":
      return { type: "start", requestId: payload.request_id ?? payload.requestId ?? "" };
    case "end":
      return { type: "end", requestId: payload.request_id ?? payload.requestId ?? "" };
    default:
      return { type: "answer", payload: askResponseSchema.parse(payload) };
  }
}

export async function streamAsk(
  request: AskRequest,
  options: StreamOptions = {}
): Promise<AskResponse> {
  const normalized = askRequestSchema.parse(request);
  const response = await fetch("/api/ask", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Accept: "text/event-stream",
    },
    body: JSON.stringify(normalized),
    signal: options.signal,
  });

  if (!response.ok) {
    // Try to parse JSON error payload and map to a friendly message
    let friendly = "Something went wrong. Please try again.";
    const ct = response.headers.get("content-type") ?? "";
    if (ct.includes("application/json")) {
      try {
        const errJson = await response.json();
        const code = (errJson?.error as string | undefined) ?? "";
        const detail = (errJson?.detail as string | undefined) ?? "";
        if (response.status === 400 || code === "bad_request") {
          friendly =
            "There is no context to that question or it is not a proper question, please try again";
        } else if (typeof detail === "string" && detail) {
          friendly = detail;
        }
      } catch {
        // fall back to text below
      }
    }
    if (!ct.includes("application/json")) {
      try {
        const text = await response.text();
        if (text) friendly = text;
      } catch {
        // ignore
      }
    }
    throw new Error(friendly);
  }

  const contentType = response.headers.get("content-type") ?? "";
  if (!contentType.includes("text/event-stream")) {
    const payload = await response.json();
    return askResponseSchema.parse(payload);
  }

  const reader = response.body?.getReader();
  if (!reader) {
    throw new Error("Streaming unsupported in this environment.");
  }

  const decoder = new TextDecoder();
  let buffer = "";
  let resolved: AskResponse | undefined;

  while (true) {
    const { value, done } = await reader.read();
    if (done) {
      break;
    }
    buffer += decoder.decode(value, { stream: true });
    let boundary = buffer.indexOf("\n\n");
    while (boundary !== -1) {
      const chunk = buffer.slice(0, boundary);
      buffer = buffer.slice(boundary + 2);
      const event = parseSseChunk(chunk);
      if (event) {
        options.onEvent?.(event);
        if (event.type === "answer") {
          resolved = event.payload;
        }
      }
      boundary = buffer.indexOf("\n\n");
    }
  }

  if (!resolved) {
    throw new Error("Stream ended without answer payload.");
  }
  return resolved;
}

```

## `lib/ask-contract.ts`

```typescript
import { z } from "zod";

const askSourceSchema = z.object({
  path: z.string(),
  page: z.number().int().nullable().optional(),
  heading: z.string().nullable().optional(),
  chunkId: z.string().nullable().optional(),
  score: z.number().nullable().optional(),
});

const clarificationOptionSchema = z.object({
  id: z.string(),
  label: z.string(),
});

const clarificationPayloadSchema = z.object({
  message: z.string(),
  options: z.array(clarificationOptionSchema),
});

const askAnswerSchema = z.object({
  answer: z.string(),
  confidence: z.number(),
  should_escalate: z.boolean(),
  model: z.string().nullable().optional(),
  family: z.string().nullable().optional(),
  family_label: z.string().nullable().optional(),
  sources: z.array(askSourceSchema),
});

export const askResponseSchema = z.object({
  answer: z.string().optional().nullable(),
  confidence: z.number().optional().nullable(),
  should_escalate: z.boolean().optional().nullable(),
  request_id: z.string(),
  sources: z.array(askSourceSchema).optional(),
  answers: z.array(askAnswerSchema).optional(),
  clarification: clarificationPayloadSchema.nullish(),
});

export const askRequestSchema = z.object({
  question: z.string().trim().min(1, "question is required"),
  filters: z
    .record(z.string(), z.unknown())
    .nullish()
    .transform((value) => (value ? Object.fromEntries(Object.entries(value)) : undefined)),
  contextHints: z
    .array(z.string().min(1))
    .nullish()
    .transform((value) => value ?? undefined),
  topK: z
    .number()
    .int()
    .min(1)
    .max(32)
    .nullish()
    .transform((value) => value ?? undefined),
  models: z
    .array(z.string().min(1))
    .nullish()
    .transform((value) => (value && value.length ? value : undefined)),
});

export type AskResponse = z.infer<typeof askResponseSchema>;
export type AskRequest = z.infer<typeof askRequestSchema>;
export type AskSource = z.infer<typeof askSourceSchema>;
export type AskAnswer = z.infer<typeof askAnswerSchema>;
export type ClarificationPayload = z.infer<typeof clarificationPayloadSchema>;

```

## `lib/chat-capture.ts`

```typescript
import { Prisma, Role } from "@prisma/client";
import type { AskResponse } from "@/lib/ask-contract";
import { withRlsContext } from "@/lib/rls";
import type { RequestUser } from "@/lib/request-context";

function parseConfidenceThreshold(): number {
  const raw = process.env.CONFIDENCE_THRESHOLD;
  if (!raw) {
    return 0.7;
  }
  const parsed = Number(raw);
  if (Number.isNaN(parsed) || parsed <= 0 || parsed > 1) {
    return 0.7;
  }
  return parsed;
}

function serializeSources(sources: AskResponse["sources"] | undefined): Prisma.JsonArray {
  return (sources ?? [])
    .map((source) => ({
      path: source.path,
      page: source.page ?? null,
      heading: source.heading ?? null,
      chunkId: source.chunkId ?? null,
      score: source.score ?? null,
    }))
    .filter((item) => item.path) as Prisma.JsonArray;
}

type CaptureArgs = {
  question: string;
  response: AskResponse;
  user: RequestUser | null | undefined;
};

export async function captureLowConfidenceChat({ question, response, user }: CaptureArgs): Promise<void> {
  if (response.clarification) {
    return;
  }

  const answers =
    response.answers && response.answers.length > 0
      ? response.answers
      : response.answer
        ? [
            {
              answer: response.answer,
              confidence: response.confidence ?? 0,
              should_escalate: response.should_escalate ?? false,
              model: undefined,
              family: undefined,
              family_label: undefined,
              sources: response.sources ?? [],
            },
          ]
        : [];

  if (answers.length === 0) {
    return;
  }

  const aggregatedConfidence =
    response.confidence ??
    (answers.length
      ? answers.reduce((acc, item) => Math.min(acc, item.confidence ?? 0), 1)
      : 0);
  const aggregatedEscalate =
    response.should_escalate ?? answers.some((item) => item.should_escalate);
  const aggregatedSources =
    response.sources && response.sources.length > 0
      ? response.sources
      : answers.flatMap((item) => item.sources ?? []);

  const aggregatedAnswer = answers
    .map((item) => {
      const metadata = [item.model, item.family_label ?? item.family].filter(Boolean).join(" · ");
      const heading = metadata ? `### ${metadata}\n\n` : "";
      return `${heading}${item.answer}`.trim();
    })
    .filter(Boolean)
    .join("\n\n");

  const threshold = parseConfidenceThreshold();
  if (!aggregatedEscalate && aggregatedConfidence >= threshold) {
    return;
  }

  if (!user?.id || !user.orgId) {
    return;
  }

  try {
    await withRlsContext(user, async (tx) => {
      const now = new Date();
      const auditLog: Prisma.JsonArray = [
        {
          action: "captured",
          at: now.toISOString(),
          confidence: aggregatedConfidence,
          requestId: response.request_id,
        },
      ];

      const chat = await tx.chat.create({
        data: {
          orgId: user.orgId,
          userId: user.id,
          question,
          answer: aggregatedAnswer,
          confidence: aggregatedConfidence,
          status: "pending_review",
          requestId: response.request_id,
          topSources: serializeSources(aggregatedSources),
          auditLog,
        },
        select: { id: true },
      });

      await tx.ragEvent.create({
        data: {
          orgId: user.orgId,
          actorId: user.id,
          actorRole: user.role ?? Role.USER,
          action: "chat.captured",
          entity: "chat",
          chatId: chat.id,
          requestId: response.request_id,
          after: {
            status: "pending_review",
            confidence: aggregatedConfidence,
            requestId: response.request_id,
          },
        },
      });
    });
  } catch (error) {
    console.error("Failed to capture low-confidence chat", error);
  }
}

```

## `lib/content-manager.ts`

```typescript
import { readdir, stat, mkdir, writeFile, rm, readFile } from "node:fs/promises";
import path from "node:path";

const CONTENT_ROOT = path.resolve(process.cwd(), "content");
const LOG_PATH = path.resolve(process.cwd(), "reports", "content-actions.log");

export type ContentEntry = {
  name: string;
  path: string;
  type: "file" | "directory";
  size: number;
  modified: string;
};

function normalizeRelativePath(input: string | undefined): string {
  if (!input) {
    return ".";
  }
  const trimmed = input.trim();
  if (!trimmed || trimmed === "/") {
    return ".";
  }
  return trimmed.replace(/^\.\/+/, "").replace(/\\/g, "/");
}

export function resolveContentPath(relativePath: string | undefined): string {
  const normalized = normalizeRelativePath(relativePath);
  const resolved = path.resolve(CONTENT_ROOT, normalized);
  if (!resolved.startsWith(CONTENT_ROOT)) {
    throw new Error("Path escapes content root.");
  }
  return resolved;
}

export async function listContent(relativePath: string | undefined): Promise<ContentEntry[]> {
  const target = resolveContentPath(relativePath);
  const items = await readdir(target, { withFileTypes: true });
  const entries = await Promise.all(
    items.map(async (item) => {
      const absolute = path.join(target, item.name);
      const stats = await stat(absolute);
      return {
        name: item.name,
        path: path.relative(CONTENT_ROOT, absolute).replace(/\\/g, "/"),
        type: item.isDirectory() ? "directory" : "file",
        size: item.isDirectory() ? 0 : stats.size,
        modified: stats.mtime.toISOString(),
      } satisfies ContentEntry;
    })
  );

  return entries.sort((a, b) => {
    if (a.type !== b.type) {
      return a.type === "directory" ? -1 : 1;
    }
    return a.name.localeCompare(b.name);
  });
}

export async function ensureFolder(parentPath: string | undefined, folderName: string): Promise<string> {
  if (!folderName.trim()) {
    throw new Error("Folder name is required.");
  }
  const parent = resolveContentPath(parentPath);
  const target = path.resolve(parent, folderName.trim());
  if (!target.startsWith(CONTENT_ROOT)) {
    throw new Error("Folder path escapes content root.");
  }
  await mkdir(target, { recursive: true });
  await logContentAction("create-folder", path.relative(CONTENT_ROOT, target));
  return path.relative(CONTENT_ROOT, target).replace(/\\/g, "/");
}

export async function saveFile(targetDir: string | undefined, fileName: string, contents: Buffer): Promise<string> {
  if (!fileName.trim()) {
    throw new Error("File name is required.");
  }
  const directory = resolveContentPath(targetDir);
  const destination = path.resolve(directory, fileName.trim());
  if (!destination.startsWith(CONTENT_ROOT)) {
    throw new Error("File path escapes content root.");
  }
  await mkdir(path.dirname(destination), { recursive: true });
  await writeFile(destination, contents);
  await logContentAction("upload-file", path.relative(CONTENT_ROOT, destination), `${contents.length} bytes`);
  return path.relative(CONTENT_ROOT, destination).replace(/\\/g, "/");
}

export async function deleteEntry(relativePath: string): Promise<void> {
  const target = resolveContentPath(relativePath);
  await rm(target, { recursive: true, force: true });
  await logContentAction("delete-entry", path.relative(CONTENT_ROOT, target));
}

export async function logContentAction(action: string, targetPath: string, detail?: string): Promise<void> {
  const timestamp = new Date().toISOString();
  const entry = `${timestamp} | ${action} | ${targetPath}${detail ? ` | ${detail}` : ""}\n`;
  try {
    await mkdir(path.dirname(LOG_PATH), { recursive: true });
    await writeFile(LOG_PATH, entry, { encoding: "utf-8", flag: "a" });
  } catch {
    // Ignore logging failures.
  }
}

export async function readFilePreview(relativePath: string): Promise<string> {
  const target = resolveContentPath(relativePath);
  const buffer = await readFile(target, { encoding: "utf-8" });
  return buffer.slice(0, 2000);
}

export function getContentRoot(): string {
  return CONTENT_ROOT;
}

```

## `lib/prisma.ts`

```typescript
import { PrismaClient, Prisma } from "@prisma/client";

type GlobalWithPrisma = typeof globalThis & {
  prisma?: PrismaClient;
};

const globalForPrisma = globalThis as GlobalWithPrisma;

export const prisma =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: process.env.NODE_ENV === "development" ? ["query", "error", "warn"] : ["error"],
  });

if (process.env.NODE_ENV !== "production") {
  globalForPrisma.prisma = prisma;
}

type PrismaContextClient = PrismaClient | Prisma.TransactionClient;

export async function setRlsContext(
  client: PrismaContextClient,
  options: { userId: string; role: string; orgId: string }
) {
  const { userId, role, orgId } = options;
  await client.$executeRaw`SELECT set_config('app.current_user_id', ${userId}, true)`;
  await client.$executeRaw`SELECT set_config('app.current_user_role', ${role}, true)`;
  await client.$executeRaw`SELECT set_config('app.current_org_id', ${orgId}, true)`;
}

export async function clearRlsContext(client: PrismaContextClient) {
  await client.$executeRaw`SELECT set_config('app.current_user_id', '', true)`;
  await client.$executeRaw`SELECT set_config('app.current_user_role', 'SERVICE', true)`;
  await client.$executeRaw`SELECT set_config('app.current_org_id', '', true)`;
}

```

## `lib/rbac.ts`

```typescript
import { Role } from "@prisma/client";
import type { RequestUser } from "@/lib/request-context";

export class ForbiddenError extends Error {
  constructor(message = "Forbidden") {
    super(message);
    this.name = "ForbiddenError";
  }
}

export class UnauthorizedError extends Error {
  constructor(message = "Unauthorized") {
    super(message);
    this.name = "UnauthorizedError";
  }
}

export function requireUser(user: RequestUser | null | undefined): RequestUser {
  if (!user?.id) {
    throw new UnauthorizedError();
  }
  return user;
}

export function ensureRole(user: RequestUser | null | undefined, allowed: Role[]): RequestUser {
  const activeUser = requireUser(user);
  if (!allowed.includes(activeUser.role)) {
    throw new ForbiddenError("Insufficient role");
  }
  return activeUser;
}

export function canReviewGlossary(user: RequestUser | null | undefined): RequestUser {
  return ensureRole(user, [Role.ADMIN, Role.REVIEWER]);
}

export function canEditGlossary(user: RequestUser | null | undefined): RequestUser {
  return ensureRole(user, [Role.ADMIN]);
}

```

## `lib/request-context.ts`

```typescript
import { headers } from "next/headers";
import { Role } from "@prisma/client";

export type RequestUser = {
  id: string;
  orgId: string;
  role: Role;
  email: string | null;
  name: string | null;
};

export type RequestContext = {
  user: RequestUser;
};

function normalize(value: string | null): string | null {
  if (value === null || value === undefined) {
    return null;
  }
  const trimmed = value.trim();
  return trimmed.length > 0 ? trimmed : null;
}

function resolveRole(rawRole: string | null): Role {
  if (!rawRole) {
    return Role.ADMIN;
  }
  const normalized = rawRole.trim().toUpperCase();
  const role = (Object.values(Role) as string[]).find((value) => value === normalized);
  if (!role) {
    return Role.ADMIN;
  }
  return role as Role;
}

const FALLBACK_USER_ID = "upstream-user";
const FALLBACK_ORG_ID = "org-atticus";

export function getRequestContext(): RequestContext {
  const headerBag = headers();

  const userId = normalize(headerBag.get("x-atticus-user-id")) ?? FALLBACK_USER_ID;
  const orgId = normalize(headerBag.get("x-atticus-org-id")) ?? FALLBACK_ORG_ID;
  const email = normalize(headerBag.get("x-atticus-user-email"));
  const name = normalize(headerBag.get("x-atticus-user-name"));
  const role = resolveRole(normalize(headerBag.get("x-atticus-role")));

  return {
    user: {
      id: userId,
      orgId,
      role,
      email,
      name,
    },
  };
}

export function getRequestUser(): RequestUser {
  return getRequestContext().user;
}

```

## `lib/rls.ts`

```typescript
import type { Prisma } from "@prisma/client";
import { prisma, setRlsContext, clearRlsContext } from "@/lib/prisma";
import type { RequestUser } from "@/lib/request-context";

export async function withRlsContext<T>(
  user: RequestUser | null | undefined,
  fn: (client: Prisma.TransactionClient) => Promise<T>
): Promise<T> {
  if (!user?.id || !user.orgId || !user.role) {
    throw new Error("RBAC enforcement requires an upstream user context.");
  }

  return prisma.$transaction(async (tx) => {
    await setRlsContext(tx, {
      userId: user.id,
      role: user.role,
      orgId: user.orgId,
    });

    try {
      return await fn(tx);
    } finally {
      await clearRlsContext(tx);
    }
  });
}

```

## `lib/utils.ts`

```typescript
import { clsx, type ClassValue } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(...inputs));
}

```

## `next-env.d.ts`

```typescript
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.

```

## `next.config.js`

```javascript
/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  experimental: {
    serverActions: {
      bodySizeLimit: "2mb",
    },
  },
  output: "standalone",
  eslint: {
    ignoreDuringBuilds: false,
  },
  typescript: {
    ignoreBuildErrors: false,
  },
};

module.exports = nextConfig;

```

## `nginx/Dockerfile`

```dockerfile
FROM nginx:stable-alpine

COPY nginx.conf /etc/nginx/nginx.conf

# Certificates are mounted at runtime from ./nginx/certs

```

## `package-lock.json`

```json
{
  "name": "atticus-webdev",
  "version": "0.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "atticus-webdev",
      "version": "0.0.0",
      "workspaces": [
        "admin"
      ],
      "dependencies": {
        "@prisma/client": "^5.18.0",
        "@radix-ui/react-dialog": "^1.1.15",
        "@radix-ui/react-slot": "^1.0.4",
        "@radix-ui/react-tabs": "^1.0.5",
        "clsx": "^2.1.1",
        "lucide-react": "^0.452.0",
        "next": "^14.2.33",
        "react": "18.2.0",
        "react-dom": "18.2.0",
        "react-markdown": "^10.1.0",
        "remark-gfm": "^4.0.1",
        "tailwind-merge": "^2.6.0",
        "zod": "4.1.12"
      },
      "devDependencies": {
        "@playwright/test": "^1.45.2",
        "@types/node": "20.14.9",
        "@types/react": "18.3.5",
        "@types/react-dom": "18.3.0",
        "autoprefixer": "10.4.21",
        "eslint": "8.57.0",
        "eslint-config-next": "14.2.5",
        "eslint-config-prettier": "^9.1.0",
        "eslint-plugin-react": "^7.37.5",
        "eslint-plugin-tailwindcss": "^3.13.0",
        "knip": "5.66.0",
        "markdownlint-cli": "^0.45.0",
        "markdownlint-cli2": "^0.18.1",
        "postcss": "8.4.40",
        "prettier": "^3.3.3",
        "prettier-plugin-tailwindcss": "^0.5.14",
        "prisma": "^5.18.0",
        "tailwindcss": "3.4.10",
        "tailwindcss-animate": "^1.0.7",
        "ts-node": "^10.9.2",
        "typescript": "5.4.5",
        "vitest": "^3.2.4"
      }
    },
    "admin": {
      "name": "atticus-admin-service",
      "version": "0.1.0",
      "dependencies": {
        "next": "^14.2.33",
        "react": "18.2.0",
        "react-dom": "18.2.0"
      },
      "devDependencies": {
        "@types/node": "20.14.9",
        "@types/react": "18.3.5",
        "@types/react-dom": "18.3.0",
        "eslint": "8.57.0",
        "eslint-config-next": "14.2.5",
        "typescript": "5.4.5"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@cspotcode/source-map-support": {
      "version": "0.8.1",
      "resolved": "https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz",
      "integrity": "sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/trace-mapping": "0.3.9"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@cspotcode/source-map-support/node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz",
      "integrity": "sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.0.3",
        "@jridgewell/sourcemap-codec": "^1.4.10"
      }
    },
    "node_modules/@emnapi/core": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@emnapi/core/-/core-1.5.0.tgz",
      "integrity": "sha512-sbP8GzB1WDzacS8fgNPpHlp6C9VZe+SJP3F90W9rLemaQj2PzIuTEl1qDOYQf58YIpyjViI24y9aPWCjEzY2cg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/wasi-threads": "1.1.0",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/runtime": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@emnapi/runtime/-/runtime-1.5.0.tgz",
      "integrity": "sha512-97/BJ3iXHww3djw6hYIfErCZFee7qCtrneuLa20UXFCOTCfBM2cvQHjWJ2EG0s0MtdNwInarqCTz35i4wWXHsQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@emnapi/wasi-threads": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@emnapi/wasi-threads/-/wasi-threads-1.1.0.tgz",
      "integrity": "sha512-WI0DdZ8xFSbgMjR1sFsKABJ/C5OnRrjT06JXbZKexJGrDuPTzZdDYfFlsgcCXCyf+suG5QU2e/y1Wo2V/OapLQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.25.10.tgz",
      "integrity": "sha512-0NFWnA+7l41irNuaSVlLfgNT12caWJVLzp5eAVhZ0z1qpxbockccEt3s+149rE64VUI3Ml2zt8Nv5JVc4QXTsw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.25.10.tgz",
      "integrity": "sha512-dQAxF1dW1C3zpeCDc5KqIYuZ1tgAdRXNoZP7vkBIRtKZPYe2xVr/d3SkirklCHudW1B45tGiUlz2pUWDfbDD4w==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.25.10.tgz",
      "integrity": "sha512-LSQa7eDahypv/VO6WKohZGPSJDq5OVOo3UoFR1E4t4Gj1W7zEQMUhI+lo81H+DtB+kP+tDgBp+M4oNCwp6kffg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.25.10.tgz",
      "integrity": "sha512-MiC9CWdPrfhibcXwr39p9ha1x0lZJ9KaVfvzA0Wxwz9ETX4v5CHfF09bx935nHlhi+MxhA63dKRRQLiVgSUtEg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.25.10.tgz",
      "integrity": "sha512-JC74bdXcQEpW9KkV326WpZZjLguSZ3DfS8wrrvPMHgQOIEIG/sPXEN/V8IssoJhbefLRcRqw6RQH2NnpdprtMA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.25.10.tgz",
      "integrity": "sha512-tguWg1olF6DGqzws97pKZ8G2L7Ig1vjDmGTwcTuYHbuU6TTjJe5FXbgs5C1BBzHbJ2bo1m3WkQDbWO2PvamRcg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.25.10.tgz",
      "integrity": "sha512-3ZioSQSg1HT2N05YxeJWYR+Libe3bREVSdWhEEgExWaDtyFbbXWb49QgPvFH8u03vUPX10JhJPcz7s9t9+boWg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.25.10.tgz",
      "integrity": "sha512-LLgJfHJk014Aa4anGDbh8bmI5Lk+QidDmGzuC2D+vP7mv/GeSN+H39zOf7pN5N8p059FcOfs2bVlrRr4SK9WxA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.25.10.tgz",
      "integrity": "sha512-oR31GtBTFYCqEBALI9r6WxoU/ZofZl962pouZRTEYECvNF/dtXKku8YXcJkhgK/beU+zedXfIzHijSRapJY3vg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.25.10.tgz",
      "integrity": "sha512-5luJWN6YKBsawd5f9i4+c+geYiVEw20FVW5x0v1kEMWNq8UctFjDiMATBxLvmmHA4bf7F6hTRaJgtghFr9iziQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.25.10.tgz",
      "integrity": "sha512-NrSCx2Kim3EnnWgS4Txn0QGt0Xipoumb6z6sUtl5bOEZIVKhzfyp/Lyw4C1DIYvzeW/5mWYPBFJU3a/8Yr75DQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.25.10.tgz",
      "integrity": "sha512-xoSphrd4AZda8+rUDDfD9J6FUMjrkTz8itpTITM4/xgerAZZcFW7Dv+sun7333IfKxGG8gAq+3NbfEMJfiY+Eg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.25.10.tgz",
      "integrity": "sha512-ab6eiuCwoMmYDyTnyptoKkVS3k8fy/1Uvq7Dj5czXI6DF2GqD2ToInBI0SHOp5/X1BdZ26RKc5+qjQNGRBelRA==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.25.10.tgz",
      "integrity": "sha512-NLinzzOgZQsGpsTkEbdJTCanwA5/wozN9dSgEl12haXJBzMTpssebuXR42bthOF3z7zXFWH1AmvWunUCkBE4EA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.25.10.tgz",
      "integrity": "sha512-FE557XdZDrtX8NMIeA8LBJX3dC2M8VGXwfrQWU7LB5SLOajfJIxmSdyL/gU1m64Zs9CBKvm4UAuBp5aJ8OgnrA==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.25.10.tgz",
      "integrity": "sha512-3BBSbgzuB9ajLoVZk0mGu+EHlBwkusRmeNYdqmznmMc9zGASFjSsxgkNsqmXugpPk00gJ0JNKh/97nxmjctdew==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.25.10.tgz",
      "integrity": "sha512-QSX81KhFoZGwenVyPoberggdW1nrQZSvfVDAIUXr3WqLRZGZqWk/P4T8p2SP+de2Sr5HPcvjhcJzEiulKgnxtA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-arm64/-/netbsd-arm64-0.25.10.tgz",
      "integrity": "sha512-AKQM3gfYfSW8XRk8DdMCzaLUFB15dTrZfnX8WXQoOUpUBQ+NaAFCP1kPS/ykbbGYz7rxn0WS48/81l9hFl3u4A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.25.10.tgz",
      "integrity": "sha512-7RTytDPGU6fek/hWuN9qQpeGPBZFfB4zZgcz2VK2Z5VpdUxEI8JKYsg3JfO0n/Z1E/6l05n0unDCNc4HnhQGig==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-arm64/-/openbsd-arm64-0.25.10.tgz",
      "integrity": "sha512-5Se0VM9Wtq797YFn+dLimf2Zx6McttsH2olUBsDml+lm0GOCRVebRWUvDtkY4BWYv/3NgzS8b/UM3jQNh5hYyw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.25.10.tgz",
      "integrity": "sha512-XkA4frq1TLj4bEMB+2HnI0+4RnjbuGZfet2gs/LNs5Hc7D89ZQBHQ0gL2ND6Lzu1+QVkjp3x1gIcPKzRNP8bXw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openharmony-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/openharmony-arm64/-/openharmony-arm64-0.25.10.tgz",
      "integrity": "sha512-AVTSBhTX8Y/Fz6OmIVBip9tJzZEUcY8WLh7I59+upa5/GPhh2/aM6bvOMQySspnCCHvFi79kMtdJS1w0DXAeag==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.25.10.tgz",
      "integrity": "sha512-fswk3XT0Uf2pGJmOpDB7yknqhVkJQkAQOcW/ccVOtfx05LkbWOaRAtn5SaqXypeKQra1QaEa841PgrSL9ubSPQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.25.10.tgz",
      "integrity": "sha512-ah+9b59KDTSfpaCg6VdJoOQvKjI33nTaQr4UluQwW7aEwZQsbMCfTmfEO4VyewOxx4RaDT/xCy9ra2GPWmO7Kw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.25.10.tgz",
      "integrity": "sha512-QHPDbKkrGO8/cz9LKVnJU22HOi4pxZnZhhA2HYHez5Pz4JeffhDjf85E57Oyco163GnzNCVkZK0b/n4Y0UHcSw==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-x64": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.25.10.tgz",
      "integrity": "sha512-9KpxSVFCu0iK1owoez6aC/s/EdUQLDN3adTxGCqxMVhrPDj6bt5dbrHDXUuq+Bs2vATFBBrQS5vdQ/Ed2P+nbw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.9.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.9.0.tgz",
      "integrity": "sha512-ayVFHdtZ+hsq1t2Dy24wCmGXGe4q9Gu3smhLYALJrr473ZH27MsnSL+LKUlimp4BWJqMDMLmPpx/Q9R3OAlL4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.1.tgz",
      "integrity": "sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.0",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.0.tgz",
      "integrity": "sha512-Ys+3g2TaW7gADOJzPt83SJtCDhMjndcDMFVQ/Tj9iA1BfJzFKD9mAUXT3OenpuPHbI6P/myECxRJrofUsDx/5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.11.14",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.11.14.tgz",
      "integrity": "sha512-3T8LkOmg45BV5FICb15QQMsyUSWrQ8AygVfC7ZG32zOalnqrilm018ZVCw0eapXux8FtA33q8PSRSstjee3jSg==",
      "deprecated": "Use @eslint/config-array instead",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.2",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/config-array/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/@humanwhocodes/config-array/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "deprecated": "Use @eslint/object-schema instead",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/@isaacs/balanced-match": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/@isaacs/balanced-match/-/balanced-match-4.0.1.tgz",
      "integrity": "sha512-yzMTt9lEb8Gv7zRioUilSglI0c0smZ9k5D65677DLWLtWJaXIS3CqcGyUFByYKlnUj6TkjLVs54fBl6+TiGQDQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "20 || >=22"
      }
    },
    "node_modules/@isaacs/brace-expansion": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/@isaacs/brace-expansion/-/brace-expansion-5.0.0.tgz",
      "integrity": "sha512-ZT55BDLV0yv0RBm2czMiZ+SqCGO7AvmOM3G/w2xhVPH+te0aKgFjmBvGlL1dH+ql2tgGO3MVrbb3jCKyvpgnxA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@isaacs/balanced-match": "^4.0.1"
      },
      "engines": {
        "node": "20 || >=22"
      }
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.13",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.0",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
      "integrity": "sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.31",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.31.tgz",
      "integrity": "sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@napi-rs/wasm-runtime": {
      "version": "0.2.12",
      "resolved": "https://registry.npmjs.org/@napi-rs/wasm-runtime/-/wasm-runtime-0.2.12.tgz",
      "integrity": "sha512-ZVWUcfwY4E/yPitQJl481FjFo3K22D6qF0DuFH6Y/nbnE11GY5uguDxZMGXPQ8WQ0128MXQD7TnfHyK4oWoIJQ==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/core": "^1.4.3",
        "@emnapi/runtime": "^1.4.3",
        "@tybys/wasm-util": "^0.10.0"
      }
    },
    "node_modules/@next/env": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/env/-/env-14.2.33.tgz",
      "integrity": "sha512-CgVHNZ1fRIlxkLhIX22flAZI/HmpDaZ8vwyJ/B0SDPTBuLZ1PJ+DWMjCHhqnExfmSQzA/PbZi8OAc7PAq2w9IA==",
      "license": "MIT"
    },
    "node_modules/@next/eslint-plugin-next": {
      "version": "14.2.5",
      "resolved": "https://registry.npmjs.org/@next/eslint-plugin-next/-/eslint-plugin-next-14.2.5.tgz",
      "integrity": "sha512-LY3btOpPh+OTIpviNojDpUdIbHW9j0JBYBjsIp8IxtDFfYFyORvw3yNq6N231FVqQA7n7lwaf7xHbVJlA1ED7g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "glob": "10.3.10"
      }
    },
    "node_modules/@next/eslint-plugin-next/node_modules/glob": {
      "version": "10.3.10",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.3.10.tgz",
      "integrity": "sha512-fa46+tv1Ak0UPK1TOy/pZrIybNNt4HCv7SDzwyfiOZkvZLEbjsZkJBPtDHVshZjbecAoAGSC20MjLDG/qr679g==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^2.3.5",
        "minimatch": "^9.0.1",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0",
        "path-scurry": "^1.10.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@next/eslint-plugin-next/node_modules/jackspeak": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-2.3.6.tgz",
      "integrity": "sha512-N3yCS/NegsOBokc8GAdM8UcmfsKiSS8cipheD/nivzr700H+nsMOxJjQnvwOcRYVuFkdH0wGUvW2WbXGmrZGbQ==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/@next/swc-darwin-arm64": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-arm64/-/swc-darwin-arm64-14.2.33.tgz",
      "integrity": "sha512-HqYnb6pxlsshoSTubdXKu15g3iivcbsMXg4bYpjL2iS/V6aQot+iyF4BUc2qA/J/n55YtvE4PHMKWBKGCF/+wA==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-darwin-x64": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-x64/-/swc-darwin-x64-14.2.33.tgz",
      "integrity": "sha512-8HGBeAE5rX3jzKvF593XTTFg3gxeU4f+UWnswa6JPhzaR6+zblO5+fjltJWIZc4aUalqTclvN2QtTC37LxvZAA==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-gnu": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-gnu/-/swc-linux-arm64-gnu-14.2.33.tgz",
      "integrity": "sha512-JXMBka6lNNmqbkvcTtaX8Gu5by9547bukHQvPoLe9VRBx1gHwzf5tdt4AaezW85HAB3pikcvyqBToRTDA4DeLw==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-musl": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-musl/-/swc-linux-arm64-musl-14.2.33.tgz",
      "integrity": "sha512-Bm+QulsAItD/x6Ih8wGIMfRJy4G73tu1HJsrccPW6AfqdZd0Sfm5Imhgkgq2+kly065rYMnCOxTBvmvFY1BKfg==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-gnu": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-gnu/-/swc-linux-x64-gnu-14.2.33.tgz",
      "integrity": "sha512-FnFn+ZBgsVMbGDsTqo8zsnRzydvsGV8vfiWwUo1LD8FTmPTdV+otGSWKc4LJec0oSexFnCYVO4hX8P8qQKaSlg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-musl": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-musl/-/swc-linux-x64-musl-14.2.33.tgz",
      "integrity": "sha512-345tsIWMzoXaQndUTDv1qypDRiebFxGYx9pYkhwY4hBRaOLt8UGfiWKr9FSSHs25dFIf8ZqIFaPdy5MljdoawA==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-arm64-msvc": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-arm64-msvc/-/swc-win32-arm64-msvc-14.2.33.tgz",
      "integrity": "sha512-nscpt0G6UCTkrT2ppnJnFsYbPDQwmum4GNXYTeoTIdsmMydSKFz9Iny2jpaRupTb+Wl298+Rh82WKzt9LCcqSQ==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-ia32-msvc": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-ia32-msvc/-/swc-win32-ia32-msvc-14.2.33.tgz",
      "integrity": "sha512-pc9LpGNKhJ0dXQhZ5QMmYxtARwwmWLpeocFmVG5Z0DzWq5Uf0izcI8tLc+qOpqxO1PWqZ5A7J1blrUIKrIFc7Q==",
      "cpu": [
        "ia32"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-x64-msvc": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.2.33.tgz",
      "integrity": "sha512-nOjfZMy8B94MdisuzZo9/57xuFVLHJaDj5e/xrduJp9CV2/HrfxTRH2fbyLe+K9QT41WBLUd4iXX3R7jBp0EUg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nolyfill/is-core-module": {
      "version": "1.0.39",
      "resolved": "https://registry.npmjs.org/@nolyfill/is-core-module/-/is-core-module-1.0.39.tgz",
      "integrity": "sha512-nn5ozdjYQpUCZlWGuxcJY/KpxkWQs4DcbMCmKojjyrYDEAGy4Ce19NN4v5MduafTwJlbKc99UA8YhSVqq9yPZA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.4.0"
      }
    },
    "node_modules/@oxc-resolver/binding-android-arm-eabi": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-android-arm-eabi/-/binding-android-arm-eabi-11.8.3.tgz",
      "integrity": "sha512-er6onTUX8NMF5kBNGHCF8S6vxWVJS5BKO6SmLRW5nfZgHDHWsESH1YgyKpO6n6HBd/x58+7r9/1fxF3N8z911A==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@oxc-resolver/binding-android-arm64": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-android-arm64/-/binding-android-arm64-11.8.3.tgz",
      "integrity": "sha512-VJMGaFYTu5YoZ0kpRhQQQoqNsYuAbPEHb/b/gEqpNpl/zHtvLWha8fYqTGtH7Wu9ajA2ESdWVqOzbBRMjQ/5qA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@oxc-resolver/binding-darwin-arm64": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-darwin-arm64/-/binding-darwin-arm64-11.8.3.tgz",
      "integrity": "sha512-IipM4uDZNZ4GEvmq0g5iRS4Di3YoEhf/BdkvqIFq35rZA9EvYn/csxAJb05H7HDzbLENIUfMvP18eyHt3juU+A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@oxc-resolver/binding-darwin-x64": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-darwin-x64/-/binding-darwin-x64-11.8.3.tgz",
      "integrity": "sha512-gJQnRKe60CNyx+KE7ffKouG15hIoV0mnM3fGGbXRUXW7hVYv2WIiKAJeNn/o/EQhT5i1GrfvskVZCHTwHljuxQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@oxc-resolver/binding-freebsd-x64": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-freebsd-x64/-/binding-freebsd-x64-11.8.3.tgz",
      "integrity": "sha512-UphzSWPIHKuVt6zDoNBzj03SfQIk73cBjfzQXK33asriLMv9kPrt2k5Aaea/ZB2bphv5MAf1BxyacYgT0hjBuA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-arm-gnueabihf": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-arm-gnueabihf/-/binding-linux-arm-gnueabihf-11.8.3.tgz",
      "integrity": "sha512-kjVGH0BIJTCefpNWcD9PrHYzXLMeofHzHqykgPc+OIBdv7KKjtE2FPeQ6PAJFzsB1BbwK0AOtKppajwfpyt1jw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-arm-musleabihf": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-arm-musleabihf/-/binding-linux-arm-musleabihf-11.8.3.tgz",
      "integrity": "sha512-e+BDNYfkOKQSSF8KMrD7FwbBzbN+9mn14pCJk5pLLH9Mtxv5EHB6LrVqLS4nbQt3ZxLwG6WWWlMPv1sdQhxNNQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-arm64-gnu": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-arm64-gnu/-/binding-linux-arm64-gnu-11.8.3.tgz",
      "integrity": "sha512-LD97VZB8KxJGEDSh4bzNExBK32nOAIPnmaKUU1bl6L3nd8YnhwK/l7RZPRsz//At/+0MGjf0Pg/fxYdW7OARjQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-arm64-musl": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-arm64-musl/-/binding-linux-arm64-musl-11.8.3.tgz",
      "integrity": "sha512-K9AUdi2Fd8RL4j5j2pACUcHbOawamt7nVn7yRI5+eOEfyn7bBsFvCVdKN4aKBLQxdAOFURK+uRWrVfR2xUkjww==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-ppc64-gnu": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-ppc64-gnu/-/binding-linux-ppc64-gnu-11.8.3.tgz",
      "integrity": "sha512-Ur5+jodHcL1lHlt7zye5K709qX4hagOdKequxrQYLaOC9zFJtpu+967PYw6bmedtnQERhyaGSfPzZ8u/TUgqWw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-riscv64-gnu": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-riscv64-gnu/-/binding-linux-riscv64-gnu-11.8.3.tgz",
      "integrity": "sha512-RgJHdrTTONup/55Y/eqyrIw2R3hG/1vBMI7+WGLjiF5zxJmVO8tLYcQklV92MKDxrLL7O36GZTZ6mPk57TVf9w==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-riscv64-musl": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-riscv64-musl/-/binding-linux-riscv64-musl-11.8.3.tgz",
      "integrity": "sha512-zni4rfmy+JoR1ubY2puIgwR+3ATpmsIsZR8dzskKRuy+i4ghwo6uOQn3wXcMBiuY4yJ0XsOZBZe1OoAl1/rELw==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-s390x-gnu": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-s390x-gnu/-/binding-linux-s390x-gnu-11.8.3.tgz",
      "integrity": "sha512-7u96LbjV6cGcvfGopwDHiuhrasE+0YZPshZFDyEO4QGm8rc+R9XgSsvUUCspRTuwc/J70u7c0cxONm6TYECkyA==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-x64-gnu": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-x64-gnu/-/binding-linux-x64-gnu-11.8.3.tgz",
      "integrity": "sha512-zgOg25vdttzLz1uCP/5hyMlLgczPSct8lBI8oBhh+oTjEmDTJdqWnjXgk/ugrQGw66j8Ud9eAZL+IWkHaaLSxA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-linux-x64-musl": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-linux-x64-musl/-/binding-linux-x64-musl-11.8.3.tgz",
      "integrity": "sha512-xac1SimfZ8grHyn3V3RTptDhQ8sSVdF0j1CsGGpG6ODyku+LcNvhwy6fjxuaT3Z+Zgsi1wchXQNDA62YkDUvZQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@oxc-resolver/binding-wasm32-wasi": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-wasm32-wasi/-/binding-wasm32-wasi-11.8.3.tgz",
      "integrity": "sha512-zt2+ohZbPg0M9cADMLnImVRXXBJVd5tlOqzH9z4wdFTA1mHojIeSrHaW8c30ZzopbFIER0GTyY+YxAsf0bhIeQ==",
      "cpu": [
        "wasm32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@napi-rs/wasm-runtime": "^1.0.5"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@oxc-resolver/binding-wasm32-wasi/node_modules/@napi-rs/wasm-runtime": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/@napi-rs/wasm-runtime/-/wasm-runtime-1.0.5.tgz",
      "integrity": "sha512-TBr9Cf9onSAS2LQ2+QHx6XcC6h9+RIzJgbqG3++9TUZSH204AwEy5jg3BTQ0VATsyoGj4ee49tN/y6rvaOOtcg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@emnapi/core": "^1.5.0",
        "@emnapi/runtime": "^1.5.0",
        "@tybys/wasm-util": "^0.10.1"
      }
    },
    "node_modules/@oxc-resolver/binding-win32-arm64-msvc": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-win32-arm64-msvc/-/binding-win32-arm64-msvc-11.8.3.tgz",
      "integrity": "sha512-je6MDeDP9PI4TGG3mcQ1ELzA4Y1O7+Dwxnc4sCxm6MkAiCi6G5UMSKsXp1f/UlcTdQn3hOJOv7d1KK8MbvRpPw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@oxc-resolver/binding-win32-ia32-msvc": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-win32-ia32-msvc/-/binding-win32-ia32-msvc-11.8.3.tgz",
      "integrity": "sha512-9GtBrZgJw3+dP0x/FHh/viiaQ+kgnVJr5jLG0ZDEci9vFOdc/XJkNXYs84mBlZcWK1HCj80VDBqqNGm4zYYIXA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@oxc-resolver/binding-win32-x64-msvc": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/@oxc-resolver/binding-win32-x64-msvc/-/binding-win32-x64-msvc-11.8.3.tgz",
      "integrity": "sha512-MoathdI2zWifsGPsgnZjYplEm2NJ4pZxu8eSCYCe+8TToDRpQ+D8BTcr8Fox2AyNEQdT57l/0LzID4812+3f/A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@playwright/test": {
      "version": "1.55.1",
      "resolved": "https://registry.npmjs.org/@playwright/test/-/test-1.55.1.tgz",
      "integrity": "sha512-IVAh/nOJaw6W9g+RJVlIQJ6gSiER+ae6mKQ5CX1bERzQgbC1VSeBlwdvczT7pxb0GWiyrxH4TGKbMfDb4Sq/ig==",
      "devOptional": true,
      "license": "Apache-2.0",
      "peer": true,
      "dependencies": {
        "playwright": "1.55.1"
      },
      "bin": {
        "playwright": "cli.js"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@prisma/client": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/@prisma/client/-/client-5.22.0.tgz",
      "integrity": "sha512-M0SVXfyHnQREBKxCgyo7sffrKttwE6R8PMq330MIUF0pTwjUhLbW84pFDlf06B27XyCR++VtjugEnIHdr07SVA==",
      "hasInstallScript": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=16.13"
      },
      "peerDependencies": {
        "prisma": "*"
      },
      "peerDependenciesMeta": {
        "prisma": {
          "optional": true
        }
      }
    },
    "node_modules/@prisma/debug": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/@prisma/debug/-/debug-5.22.0.tgz",
      "integrity": "sha512-AUt44v3YJeggO2ZU5BkXI7M4hu9BF2zzH2iF2V5pyXT/lRTyWiElZ7It+bRH1EshoMRxHgpYg4VB6rCM+mG5jQ==",
      "devOptional": true,
      "license": "Apache-2.0"
    },
    "node_modules/@prisma/engines": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/@prisma/engines/-/engines-5.22.0.tgz",
      "integrity": "sha512-UNjfslWhAt06kVL3CjkuYpHAWSO6L4kDCVPegV6itt7nD1kSJavd3vhgAEhjglLJJKEdJ7oIqDJ+yHk6qO8gPA==",
      "devOptional": true,
      "hasInstallScript": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@prisma/debug": "5.22.0",
        "@prisma/engines-version": "5.22.0-44.605197351a3c8bdd595af2d2a9bc3025bca48ea2",
        "@prisma/fetch-engine": "5.22.0",
        "@prisma/get-platform": "5.22.0"
      }
    },
    "node_modules/@prisma/engines-version": {
      "version": "5.22.0-44.605197351a3c8bdd595af2d2a9bc3025bca48ea2",
      "resolved": "https://registry.npmjs.org/@prisma/engines-version/-/engines-version-5.22.0-44.605197351a3c8bdd595af2d2a9bc3025bca48ea2.tgz",
      "integrity": "sha512-2PTmxFR2yHW/eB3uqWtcgRcgAbG1rwG9ZriSvQw+nnb7c4uCr3RAcGMb6/zfE88SKlC1Nj2ziUvc96Z379mHgQ==",
      "devOptional": true,
      "license": "Apache-2.0"
    },
    "node_modules/@prisma/fetch-engine": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/@prisma/fetch-engine/-/fetch-engine-5.22.0.tgz",
      "integrity": "sha512-bkrD/Mc2fSvkQBV5EpoFcZ87AvOgDxbG99488a5cexp5Ccny+UM6MAe/UFkUC0wLYD9+9befNOqGiIJhhq+HbA==",
      "devOptional": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@prisma/debug": "5.22.0",
        "@prisma/engines-version": "5.22.0-44.605197351a3c8bdd595af2d2a9bc3025bca48ea2",
        "@prisma/get-platform": "5.22.0"
      }
    },
    "node_modules/@prisma/get-platform": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/@prisma/get-platform/-/get-platform-5.22.0.tgz",
      "integrity": "sha512-pHhpQdr1UPFpt+zFfnPazhulaZYCUqeIcPpJViYoq9R+D/yw4fjE+CtnsnKzPYm0ddUbeXUzjGVGIRVgPDCk4Q==",
      "devOptional": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@prisma/debug": "5.22.0"
      }
    },
    "node_modules/@radix-ui/primitive": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/primitive/-/primitive-1.1.3.tgz",
      "integrity": "sha512-JTF99U/6XIjCBo0wqkU5sK10glYe27MRRsfwoiq5zzOEZLHU3A3KCMa5X/azekYRCJ0HlwI0crAXS/5dEHTzDg==",
      "license": "MIT"
    },
    "node_modules/@radix-ui/react-collection": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-collection/-/react-collection-1.1.7.tgz",
      "integrity": "sha512-Fh9rGN0MoI4ZFUNyfFVNU4y9LUz93u9/0K+yLgA2bwRojxM8JU1DyvvMBabnZPBgMWREAJvU2jjVzq+LrFUglw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-compose-refs": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-compose-refs/-/react-compose-refs-1.1.2.tgz",
      "integrity": "sha512-z4eqJvfiNnFMHIIvXP3CY57y2WJs5g2v3X0zm9mEJkrkNv4rDxu+sg9Jh8EkXyeqBkB7SOcboo9dMVqhyrACIg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-context": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-context/-/react-context-1.1.2.tgz",
      "integrity": "sha512-jCi/QKUM2r1Ju5a3J64TH2A5SpKAgh0LpknyqdQ4m6DCV0xJ2HG1xARRwNGPQfi1SLdLWZ1OJz6F4OMBBNiGJA==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dialog": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dialog/-/react-dialog-1.1.15.tgz",
      "integrity": "sha512-TCglVRtzlffRNxRMEyR36DGBLJpeusFcgMVD9PZEzAKnUs1lKCgX5u9BmC2Yg+LL9MgZDugFFs1Vl+Jp4t/PGw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.3",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-dismissable-layer": "1.1.11",
        "@radix-ui/react-focus-guards": "1.1.3",
        "@radix-ui/react-focus-scope": "1.1.7",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-portal": "1.1.9",
        "@radix-ui/react-presence": "1.1.5",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-slot": "1.2.3",
        "@radix-ui/react-use-controllable-state": "1.2.2",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-direction": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-direction/-/react-direction-1.1.1.tgz",
      "integrity": "sha512-1UEWRX6jnOA2y4H5WczZ44gOOjTEmlqv1uNW4GAJEO5+bauCBhv8snY65Iw5/VOS/ghKN9gr2KjnLKxrsvoMVw==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dismissable-layer": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dismissable-layer/-/react-dismissable-layer-1.1.11.tgz",
      "integrity": "sha512-Nqcp+t5cTB8BinFkZgXiMJniQH0PsUt2k51FUhbdfeKvc4ACcG2uQniY/8+h1Yv6Kza4Q7lD7PQV0z0oicE0Mg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.3",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-escape-keydown": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-guards": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-guards/-/react-focus-guards-1.1.3.tgz",
      "integrity": "sha512-0rFg/Rj2Q62NCm62jZw0QX7a3sz6QCQU0LpZdNrJX8byRGaGVTqbrW9jAoIAHyMQqsNpeZ81YgSizOt5WXq0Pw==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-scope": {
      "version": "1.1.7",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-scope/-/react-focus-scope-1.1.7.tgz",
      "integrity": "sha512-t2ODlkXBQyn7jkl6TNaw/MtVEVvIGelJDCG41Okq/KwUsJBwQ4XVZsHAVUkK4mBv3ewiAS3PGuUWuY2BoK4ZUw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-id": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-id/-/react-id-1.1.1.tgz",
      "integrity": "sha512-kGkGegYIdQsOb4XjsfM97rXsiHaBwco+hFI66oO4s9LU+PLAC5oJ7khdOVFxkhsmlbpUqDAvXw11CluXP+jkHg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-portal": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-portal/-/react-portal-1.1.9.tgz",
      "integrity": "sha512-bpIxvq03if6UNwXZ+HTK71JLh4APvnXntDc6XOX8UVq4XQOVl7lwok0AvIl+b8zgCw3fSaVTZMpAPPagXbKmHQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-presence": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-presence/-/react-presence-1.1.5.tgz",
      "integrity": "sha512-/jfEwNDdQVBCNvjkGit4h6pMOzq8bHkopq458dPt2lMjx+eBQUohZNG9A7DtO/O5ukSbxuaNGXMjHicgwy6rQQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-primitive": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-primitive/-/react-primitive-2.1.3.tgz",
      "integrity": "sha512-m9gTwRkhy2lvCPe6QJp4d3G1TYEUHn/FzJUtq9MjH46an1wJU+GdoGC5VLof8RX8Ft/DlpshApkhswDLZzHIcQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-slot": "1.2.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-roving-focus": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-roving-focus/-/react-roving-focus-1.1.11.tgz",
      "integrity": "sha512-7A6S9jSgm/S+7MdtNDSb+IU859vQqJ/QAtcYQcfFC6W8RS4IxIZDldLR0xqCFZ6DCyrQLjLPsxtTNch5jVA4lA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.3",
        "@radix-ui/react-collection": "1.1.7",
        "@radix-ui/react-compose-refs": "1.1.2",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-use-callback-ref": "1.1.1",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-slot": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-slot/-/react-slot-1.2.3.tgz",
      "integrity": "sha512-aeNmHnBxbi2St0au6VBVC7JXFlhLlOnvIIlePNniyUNAClzmtAUEY8/pBiK3iHjufOlwA+c20/8jngo7xcrg8A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-tabs": {
      "version": "1.1.13",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-tabs/-/react-tabs-1.1.13.tgz",
      "integrity": "sha512-7xdcatg7/U+7+Udyoj2zodtI9H/IIopqo+YOIcZOq1nJwXWBZ9p8xiu5llXlekDbZkca79a/fozEYQXIA4sW6A==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.3",
        "@radix-ui/react-context": "1.1.2",
        "@radix-ui/react-direction": "1.1.1",
        "@radix-ui/react-id": "1.1.1",
        "@radix-ui/react-presence": "1.1.5",
        "@radix-ui/react-primitive": "2.1.3",
        "@radix-ui/react-roving-focus": "1.1.11",
        "@radix-ui/react-use-controllable-state": "1.2.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-callback-ref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-callback-ref/-/react-use-callback-ref-1.1.1.tgz",
      "integrity": "sha512-FkBMwD+qbGQeMu1cOHnuGB6x4yzPjho8ap5WtbEJ26umhgqVXbhekKUQO+hZEL1vU92a3wHwdp0HAcqAUF5iDg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-controllable-state": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-controllable-state/-/react-use-controllable-state-1.2.2.tgz",
      "integrity": "sha512-BjasUjixPFdS+NKkypcyyN5Pmg83Olst0+c6vGov0diwTEo6mgdqVR6hxcEgFuh4QrAs7Rc+9KuGJ9TVCj0Zzg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-effect-event": "0.0.2",
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-effect-event": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-effect-event/-/react-use-effect-event-0.0.2.tgz",
      "integrity": "sha512-Qp8WbZOBe+blgpuUT+lw2xheLP8q0oatc9UpmiemEICxGvFLYmHm9QowVZGHtJlGbS6A6yJ3iViad/2cVjnOiA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-escape-keydown": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-escape-keydown/-/react-use-escape-keydown-1.1.1.tgz",
      "integrity": "sha512-Il0+boE7w/XebUHyBjroE+DbByORGR9KKmITzbR7MyQ4akpORYP/ZmbhAr0DG7RmmBqoOnZdy2QlvajJ2QA59g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-callback-ref": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-layout-effect": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-layout-effect/-/react-use-layout-effect-1.1.1.tgz",
      "integrity": "sha512-RbJRS4UWQFkzHTTwVymMTUv8EqYhOp8dOOviLj2ugtTiXRaRQS7GLGxZTLL1jWhMeoSCf5zmcZkqTl9IiYfXcQ==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@rollup/rollup-android-arm-eabi": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.52.3.tgz",
      "integrity": "sha512-h6cqHGZ6VdnwliFG1NXvMPTy/9PS3h8oLh7ImwR+kl+oYnQizgjxsONmmPSb2C66RksfkfIxEVtDSEcJiO0tqw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-android-arm64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.52.3.tgz",
      "integrity": "sha512-wd+u7SLT/u6knklV/ifG7gr5Qy4GUbH2hMWcDauPFJzmCZUAJ8L2bTkVXC2niOIxp8lk3iH/QX8kSrUxVZrOVw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-darwin-arm64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.52.3.tgz",
      "integrity": "sha512-lj9ViATR1SsqycwFkJCtYfQTheBdvlWJqzqxwc9f2qrcVrQaF/gCuBRTiTolkRWS6KvNxSk4KHZWG7tDktLgjg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-darwin-x64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.52.3.tgz",
      "integrity": "sha512-+Dyo7O1KUmIsbzx1l+4V4tvEVnVQqMOIYtrxK7ncLSknl1xnMHLgn7gddJVrYPNZfEB8CIi3hK8gq8bDhb3h5A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-arm64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-arm64/-/rollup-freebsd-arm64-4.52.3.tgz",
      "integrity": "sha512-u9Xg2FavYbD30g3DSfNhxgNrxhi6xVG4Y6i9Ur1C7xUuGDW3banRbXj+qgnIrwRN4KeJ396jchwy9bCIzbyBEQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-x64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-x64/-/rollup-freebsd-x64-4.52.3.tgz",
      "integrity": "sha512-5M8kyi/OX96wtD5qJR89a/3x5x8x5inXBZO04JWhkQb2JWavOWfjgkdvUqibGJeNNaz1/Z1PPza5/tAPXICI6A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-gnueabihf": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.52.3.tgz",
      "integrity": "sha512-IoerZJ4l1wRMopEHRKOO16e04iXRDyZFZnNZKrWeNquh5d6bucjezgd+OxG03mOMTnS1x7hilzb3uURPkJ0OfA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-musleabihf": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.52.3.tgz",
      "integrity": "sha512-ZYdtqgHTDfvrJHSh3W22TvjWxwOgc3ThK/XjgcNGP2DIwFIPeAPNsQxrJO5XqleSlgDux2VAoWQ5iJrtaC1TbA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.52.3.tgz",
      "integrity": "sha512-NcViG7A0YtuFDA6xWSgmFb6iPFzHlf5vcqb2p0lGEbT+gjrEEz8nC/EeDHvx6mnGXnGCC1SeVV+8u+smj0CeGQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-musl": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.52.3.tgz",
      "integrity": "sha512-d3pY7LWno6SYNXRm6Ebsq0DJGoiLXTb83AIPCXl9fmtIQs/rXoS8SJxxUNtFbJ5MiOvs+7y34np77+9l4nfFMw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-loong64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-loong64-gnu/-/rollup-linux-loong64-gnu-4.52.3.tgz",
      "integrity": "sha512-3y5GA0JkBuirLqmjwAKwB0keDlI6JfGYduMlJD/Rl7fvb4Ni8iKdQs1eiunMZJhwDWdCvrcqXRY++VEBbvk6Eg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-ppc64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-ppc64-gnu/-/rollup-linux-ppc64-gnu-4.52.3.tgz",
      "integrity": "sha512-AUUH65a0p3Q0Yfm5oD2KVgzTKgwPyp9DSXc3UA7DtxhEb/WSPfbG4wqXeSN62OG5gSo18em4xv6dbfcUGXcagw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.52.3.tgz",
      "integrity": "sha512-1makPhFFVBqZE+XFg3Dkq+IkQ7JvmUrwwqaYBL2CE+ZpxPaqkGaiWFEWVGyvTwZace6WLJHwjVh/+CXbKDGPmg==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-musl": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-musl/-/rollup-linux-riscv64-musl-4.52.3.tgz",
      "integrity": "sha512-OOFJa28dxfl8kLOPMUOQBCO6z3X2SAfzIE276fwT52uXDWUS178KWq0pL7d6p1kz7pkzA0yQwtqL0dEPoVcRWg==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-s390x-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.52.3.tgz",
      "integrity": "sha512-jMdsML2VI5l+V7cKfZx3ak+SLlJ8fKvLJ0Eoa4b9/vCUrzXKgoKxvHqvJ/mkWhFiyp88nCkM5S2v6nIwRtPcgg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.52.3.tgz",
      "integrity": "sha512-tPgGd6bY2M2LJTA1uGq8fkSPK8ZLYjDjY+ZLK9WHncCnfIz29LIXIqUgzCR0hIefzy6Hpbe8Th5WOSwTM8E7LA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-musl": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.52.3.tgz",
      "integrity": "sha512-BCFkJjgk+WFzP+tcSMXq77ymAPIxsX9lFJWs+2JzuZTLtksJ2o5hvgTdIcZ5+oKzUDMwI0PfWzRBYAydAHF2Mw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-openharmony-arm64": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-openharmony-arm64/-/rollup-openharmony-arm64-4.52.3.tgz",
      "integrity": "sha512-KTD/EqjZF3yvRaWUJdD1cW+IQBk4fbQaHYJUmP8N4XoKFZilVL8cobFSTDnjTtxWJQ3JYaMgF4nObY/+nYkumA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ]
    },
    "node_modules/@rollup/rollup-win32-arm64-msvc": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.52.3.tgz",
      "integrity": "sha512-+zteHZdoUYLkyYKObGHieibUFLbttX2r+58l27XZauq0tcWYYuKUwY2wjeCN9oK1Um2YgH2ibd6cnX/wFD7DuA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-ia32-msvc": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.52.3.tgz",
      "integrity": "sha512-of1iHkTQSo3kr6dTIRX6t81uj/c/b15HXVsPcEElN5sS859qHrOepM5p9G41Hah+CTqSh2r8Bm56dL2z9UQQ7g==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-gnu": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-gnu/-/rollup-win32-x64-gnu-4.52.3.tgz",
      "integrity": "sha512-s0hybmlHb56mWVZQj8ra9048/WZTPLILKxcvcq+8awSZmyiSUZjjem1AhU3Tf4ZKpYhK4mg36HtHDOe8QJS5PQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-msvc": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.52.3.tgz",
      "integrity": "sha512-zGIbEVVXVtauFgl3MRwGWEN36P5ZGenHRMgNw88X5wEhEBpq0XrMEZwOn07+ICrwM17XO5xfMZqh0OldCH5VTA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rtsao/scc": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@rtsao/scc/-/scc-1.1.0.tgz",
      "integrity": "sha512-zt6OdqaDoOnJ1ZYsCYGt9YmWzDXl4vQdKTyJev62gFhRGKdx7mcT54V9KIjg+d2wi9EXsPvAPKe7i7WjfVWB8g==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rushstack/eslint-patch": {
      "version": "1.12.0",
      "resolved": "https://registry.npmjs.org/@rushstack/eslint-patch/-/eslint-patch-1.12.0.tgz",
      "integrity": "sha512-5EwMtOqvJMMa3HbmxLlF74e+3/HhwBTMcvt3nqVJgGCozO6hzIPOBlwm8mGVNR9SN2IJpxSnlxczyDjcn7qIyw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@sindresorhus/merge-streams": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/@sindresorhus/merge-streams/-/merge-streams-2.3.0.tgz",
      "integrity": "sha512-LtoMMhxAlorcGhmFYI+LhPgbPZCkgP6ra1YL604EeF6U98pLlQ3iWIGMdWSC+vWmPBWBNgmDBAhnAobLROJmwg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@swc/counter": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@swc/counter/-/counter-0.1.3.tgz",
      "integrity": "sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==",
      "license": "Apache-2.0"
    },
    "node_modules/@swc/helpers": {
      "version": "0.5.5",
      "resolved": "https://registry.npmjs.org/@swc/helpers/-/helpers-0.5.5.tgz",
      "integrity": "sha512-KGYxvIOXcceOAbEk4bi/dVLEK9z8sZ0uBB3Il5b1rhfClSpcX0yfRO0KmTkqR2cnQDymwLB+25ZyMzICg/cm/A==",
      "license": "Apache-2.0",
      "dependencies": {
        "@swc/counter": "^0.1.3",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@tsconfig/node10": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node10/-/node10-1.0.11.tgz",
      "integrity": "sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node12": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node12/-/node12-1.0.11.tgz",
      "integrity": "sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node14": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/@tsconfig/node14/-/node14-1.0.3.tgz",
      "integrity": "sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node16": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/@tsconfig/node16/-/node16-1.0.4.tgz",
      "integrity": "sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tybys/wasm-util": {
      "version": "0.10.1",
      "resolved": "https://registry.npmjs.org/@tybys/wasm-util/-/wasm-util-0.10.1.tgz",
      "integrity": "sha512-9tTaPJLSiejZKx+Bmog4uSubteqTvFrVrURwkmHixBo0G4seD0zUxp98E1DzUBJxLQ3NPwXrGKDiVjwx/DpPsg==",
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@types/chai": {
      "version": "5.2.2",
      "resolved": "https://registry.npmjs.org/@types/chai/-/chai-5.2.2.tgz",
      "integrity": "sha512-8kB30R7Hwqf40JPiKhVzodJs2Qc1ZJ5zuT3uzw5Hq/dhNCl3G3l83jfpdI1e20BP348+fV7VIL/+FxaXkqBmWg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/deep-eql": "*"
      }
    },
    "node_modules/@types/debug": {
      "version": "4.1.12",
      "resolved": "https://registry.npmjs.org/@types/debug/-/debug-4.1.12.tgz",
      "integrity": "sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==",
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@types/ms": "*"
      }
    },
    "node_modules/@types/deep-eql": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/@types/deep-eql/-/deep-eql-4.0.2.tgz",
      "integrity": "sha512-c9h9dVVMigMPc4bwTvC5dxqtqJZwQPePsWjPlpSOnojbor6pGqdk541lfA7AqFQr5pB1BRdq0juY9db81BwyFw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/estree": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.8.tgz",
      "integrity": "sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==",
      "license": "MIT"
    },
    "node_modules/@types/estree-jsx": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/@types/estree-jsx/-/estree-jsx-1.0.5.tgz",
      "integrity": "sha512-52CcUVNFyfb1A2ALocQw/Dd1BQFNmSdkuC3BkZ6iqhdMfQz7JWOFRuJFloOzjk+6WijU56m9oKXFAXc7o3Towg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "*"
      }
    },
    "node_modules/@types/hast": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/hast/-/hast-3.0.4.tgz",
      "integrity": "sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/json5": {
      "version": "0.0.29",
      "resolved": "https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz",
      "integrity": "sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/katex": {
      "version": "0.16.7",
      "resolved": "https://registry.npmjs.org/@types/katex/-/katex-0.16.7.tgz",
      "integrity": "sha512-HMwFiRujE5PjrgwHQ25+bsLJgowjGjm5Z8FVSf0N6PwgJrwxH0QxzHYDcKsTfV3wva0vzrpqMTJS2jXPr5BMEQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/mdast": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/@types/mdast/-/mdast-4.0.4.tgz",
      "integrity": "sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/ms": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/@types/ms/-/ms-2.1.0.tgz",
      "integrity": "sha512-GsCCIZDE/p3i96vtEqx+7dBUGXrc7zeSK3wwPHIaRThS+9OhWIXRqzs4d6k1SVU8g91DrNRWxWUGhp5KXQb2VA==",
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "20.14.9",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-20.14.9.tgz",
      "integrity": "sha512-06OCtnTXtWOZBJlRApleWndH4JsRVs1pDCc8dLSQp+7PpUpX3ePdHyeNSFTeSe7FtKyQkrlPvHwJOW3SLd8Oyg==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "undici-types": "~5.26.4"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.15",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.15.tgz",
      "integrity": "sha512-F6bEyamV9jKGAFBEmlQnesRPGOQqS2+Uwi0Em15xenOxHaf2hv6L8YCVn3rPdPJOiJfPiCnLIRyvwVaqMY3MIw==",
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.5",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.5.tgz",
      "integrity": "sha512-WeqMfGJLGuLCqHGYRGHxnKrXcTitc6L/nBUWfWPcTarG3t9PsquqUMuVeXZeca+mglY4Vo5GZjCi0A3Or2lnxA==",
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.0",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.0.tgz",
      "integrity": "sha512-EhwApuTmMBmXuFOikhQLIBUn6uFg81SwLMOAUgodJF14SOBOCMdU04gDoYi0WOJJHD144TL32z4yDqCW3dnkQg==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "@types/react": "*"
      }
    },
    "node_modules/@types/unist": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-3.0.3.tgz",
      "integrity": "sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==",
      "license": "MIT"
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-7.2.0.tgz",
      "integrity": "sha512-5FKsVcHTk6TafQKQbuIVkXq58Fnbkd2wDL4LB7AURN7RUOu1utVP+G8+6u3ZhEroW3DF6hyo3ZEXxgKgp4KeCg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/scope-manager": "7.2.0",
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/typescript-estree": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.56.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-7.2.0.tgz",
      "integrity": "sha512-Qh976RbQM/fYtjx9hs4XkayYujB/aPwglw2choHmf3zBjB4qOywWSdt9+KLRdHubGcoSwBnXUH2sR3hkyaERRg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-7.2.0.tgz",
      "integrity": "sha512-XFtUHPI/abFhm4cbCDc5Ykc8npOKBSJePY3a3s+lwumt7XWJuzP5cZcfZ610MIPHjQjNsOLlYK8ASPaNG8UiyA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-7.2.0.tgz",
      "integrity": "sha512-cyxS5WQQCoBwSakpMrvMXuMDEbhOo9bNHHrNcEWis6XHx6KF518tkF1wBvKIn/tpq5ZpUYK7Bdklu8qY0MsFIA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-7.2.0.tgz",
      "integrity": "sha512-c6EIQRHhcpl6+tO8EMR+kjkkV+ugUNXOmeASA1rlzkd8EPIriavpWoiEz1HR/VLhbVIdhqnV6E7JZm00cBDx2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "license": "ISC"
    },
    "node_modules/@unrs/resolver-binding-android-arm-eabi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm-eabi/-/resolver-binding-android-arm-eabi-1.11.1.tgz",
      "integrity": "sha512-ppLRUgHVaGRWUx0R0Ut06Mjo9gBaBkg3v/8AxusGLhsIotbBLuRk51rAzqLC8gq6NyyAojEXglNjzf6R948DNw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-android-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-android-arm64/-/resolver-binding-android-arm64-1.11.1.tgz",
      "integrity": "sha512-lCxkVtb4wp1v+EoN+HjIG9cIIzPkX5OtM03pQYkG+U5O/wL53LC4QbIeazgiKqluGeVEeBlZahHalCaBvU1a2g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-arm64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-arm64/-/resolver-binding-darwin-arm64-1.11.1.tgz",
      "integrity": "sha512-gPVA1UjRu1Y/IsB/dQEsp2V1pm44Of6+LWvbLc9SDk1c2KhhDRDBUkQCYVWe6f26uJb3fOK8saWMgtX8IrMk3g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-darwin-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-darwin-x64/-/resolver-binding-darwin-x64-1.11.1.tgz",
      "integrity": "sha512-cFzP7rWKd3lZaCsDze07QX1SC24lO8mPty9vdP+YVa3MGdVgPmFc59317b2ioXtgCMKGiCLxJ4HQs62oz6GfRQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@unrs/resolver-binding-freebsd-x64": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-freebsd-x64/-/resolver-binding-freebsd-x64-1.11.1.tgz",
      "integrity": "sha512-fqtGgak3zX4DCB6PFpsH5+Kmt/8CIi4Bry4rb1ho6Av2QHTREM+47y282Uqiu3ZRF5IQioJQ5qWRV6jduA+iGw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-gnueabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-gnueabihf/-/resolver-binding-linux-arm-gnueabihf-1.11.1.tgz",
      "integrity": "sha512-u92mvlcYtp9MRKmP+ZvMmtPN34+/3lMHlyMj7wXJDeXxuM0Vgzz0+PPJNsro1m3IZPYChIkn944wW8TYgGKFHw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm-musleabihf": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm-musleabihf/-/resolver-binding-linux-arm-musleabihf-1.11.1.tgz",
      "integrity": "sha512-cINaoY2z7LVCrfHkIcmvj7osTOtm6VVT16b5oQdS4beibX2SYBwgYLmqhBjA1t51CarSaBuX5YNsWLjsqfW5Cw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-gnu/-/resolver-binding-linux-arm64-gnu-1.11.1.tgz",
      "integrity": "sha512-34gw7PjDGB9JgePJEmhEqBhWvCiiWCuXsL9hYphDF7crW7UgI05gyBAi6MF58uGcMOiOqSJ2ybEeCvHcq0BCmQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-arm64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-arm64-musl/-/resolver-binding-linux-arm64-musl-1.11.1.tgz",
      "integrity": "sha512-RyMIx6Uf53hhOtJDIamSbTskA99sPHS96wxVE/bJtePJJtpdKGXO1wY90oRdXuYOGOTuqjT8ACccMc4K6QmT3w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-ppc64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-ppc64-gnu/-/resolver-binding-linux-ppc64-gnu-1.11.1.tgz",
      "integrity": "sha512-D8Vae74A4/a+mZH0FbOkFJL9DSK2R6TFPC9M+jCWYia/q2einCubX10pecpDiTmkJVUH+y8K3BZClycD8nCShA==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-gnu/-/resolver-binding-linux-riscv64-gnu-1.11.1.tgz",
      "integrity": "sha512-frxL4OrzOWVVsOc96+V3aqTIQl1O2TjgExV4EKgRY09AJ9leZpEg8Ak9phadbuX0BA4k8U5qtvMSQQGGmaJqcQ==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-riscv64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-riscv64-musl/-/resolver-binding-linux-riscv64-musl-1.11.1.tgz",
      "integrity": "sha512-mJ5vuDaIZ+l/acv01sHoXfpnyrNKOk/3aDoEdLO/Xtn9HuZlDD6jKxHlkN8ZhWyLJsRBxfv9GYM2utQ1SChKew==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-s390x-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-s390x-gnu/-/resolver-binding-linux-s390x-gnu-1.11.1.tgz",
      "integrity": "sha512-kELo8ebBVtb9sA7rMe1Cph4QHreByhaZ2QEADd9NzIQsYNQpt9UkM9iqr2lhGr5afh885d/cB5QeTXSbZHTYPg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-gnu": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-gnu/-/resolver-binding-linux-x64-gnu-1.11.1.tgz",
      "integrity": "sha512-C3ZAHugKgovV5YvAMsxhq0gtXuwESUKc5MhEtjBpLoHPLYM+iuwSj3lflFwK3DPm68660rZ7G8BMcwSro7hD5w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-linux-x64-musl": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-linux-x64-musl/-/resolver-binding-linux-x64-musl-1.11.1.tgz",
      "integrity": "sha512-rV0YSoyhK2nZ4vEswT/QwqzqQXw5I6CjoaYMOX0TqBlWhojUf8P94mvI7nuJTeaCkkds3QE4+zS8Ko+GdXuZtA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@unrs/resolver-binding-wasm32-wasi": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-wasm32-wasi/-/resolver-binding-wasm32-wasi-1.11.1.tgz",
      "integrity": "sha512-5u4RkfxJm+Ng7IWgkzi3qrFOvLvQYnPBmjmZQ8+szTK/b31fQCnleNl1GgEt7nIsZRIf5PLhPwT0WM+q45x/UQ==",
      "cpu": [
        "wasm32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@napi-rs/wasm-runtime": "^0.2.11"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/@unrs/resolver-binding-win32-arm64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-arm64-msvc/-/resolver-binding-win32-arm64-msvc-1.11.1.tgz",
      "integrity": "sha512-nRcz5Il4ln0kMhfL8S3hLkxI85BXs3o8EYoattsJNdsX4YUU89iOkVn7g0VHSRxFuVMdM4Q1jEpIId1Ihim/Uw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-ia32-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-ia32-msvc/-/resolver-binding-win32-ia32-msvc-1.11.1.tgz",
      "integrity": "sha512-DCEI6t5i1NmAZp6pFonpD5m7i6aFrpofcp4LA2i8IIq60Jyo28hamKBxNrZcyOwVOZkgsRp9O2sXWBWP8MnvIQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@unrs/resolver-binding-win32-x64-msvc": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/@unrs/resolver-binding-win32-x64-msvc/-/resolver-binding-win32-x64-msvc-1.11.1.tgz",
      "integrity": "sha512-lrW200hZdbfRtztbygyaq/6jP6AKE8qQN2KvPcJ+x7wiD038YtnYtZ82IMNJ69GJibV7bwL3y9FgK+5w/pYt6g==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@vitest/expect": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/expect/-/expect-3.2.4.tgz",
      "integrity": "sha512-Io0yyORnB6sikFlt8QW5K7slY4OjqNX9jmJQ02QDda8lyM6B5oNgVWoSoKPac8/kgnCUzuHQKrSLtu/uOqqrig==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/chai": "^5.2.2",
        "@vitest/spy": "3.2.4",
        "@vitest/utils": "3.2.4",
        "chai": "^5.2.0",
        "tinyrainbow": "^2.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/@vitest/pretty-format": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/pretty-format/-/pretty-format-3.2.4.tgz",
      "integrity": "sha512-IVNZik8IVRJRTr9fxlitMKeJeXFFFN0JaB9PHPGQ8NKQbGpfjlTx9zO4RefN8gp7eqjNy8nyK3NZmBzOPeIxtA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "tinyrainbow": "^2.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/@vitest/runner": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/runner/-/runner-3.2.4.tgz",
      "integrity": "sha512-oukfKT9Mk41LreEW09vt45f8wx7DordoWUZMYdY/cyAk7w5TWkTRCNZYF7sX7n2wB7jyGAl74OxgwhPgKaqDMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@vitest/utils": "3.2.4",
        "pathe": "^2.0.3",
        "strip-literal": "^3.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/@vitest/snapshot": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/snapshot/-/snapshot-3.2.4.tgz",
      "integrity": "sha512-dEYtS7qQP2CjU27QBC5oUOxLE/v5eLkGqPE0ZKEIDGMs4vKWe7IjgLOeauHsR0D5YuuycGRO5oSRXnwnmA78fQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@vitest/pretty-format": "3.2.4",
        "magic-string": "^0.30.17",
        "pathe": "^2.0.3"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/@vitest/spy": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/spy/-/spy-3.2.4.tgz",
      "integrity": "sha512-vAfasCOe6AIK70iP5UD11Ac4siNUNJ9i/9PZ3NKx07sG6sUxeag1LWdNrMWeKKYBLlzuK+Gn65Yd5nyL6ds+nw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "tinyspy": "^4.0.3"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/@vitest/utils": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/utils/-/utils-3.2.4.tgz",
      "integrity": "sha512-fB2V0JFrQSMsCo9HiSq3Ezpdv4iYaXRG1Sx8edX3MwxfyNn83mKiGzOcH+Fkxt4MHxr3y42fQi1oeAInqgX2QA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@vitest/pretty-format": "3.2.4",
        "loupe": "^3.1.4",
        "tinyrainbow": "^2.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/acorn-walk": {
      "version": "8.3.4",
      "resolved": "https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz",
      "integrity": "sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "acorn": "^8.11.0"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.2.2.tgz",
      "integrity": "sha512-Bq3SmSpyFHaWjPk8If9yc6svM8c56dB5BAtW4Qbw5jHTwwXXcTLoRMkpDJp6VL0XzlWaCHTXrkFURMYmD0sLqg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/ansi-styles": {
      "version": "6.2.3",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.3.tgz",
      "integrity": "sha512-4Dj6M28JB+oAH8kFkTLUo+a2jwOFkuqb3yucU0CANcRRUbxS0cP0nZYCGjcc3BNXwRIsUVmDGgzawme7zvJHvg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/aria-hidden": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/aria-hidden/-/aria-hidden-1.2.6.tgz",
      "integrity": "sha512-ik3ZgC9dY/lYVVM++OISsaYDeg1tb0VtP5uL3ouh1koGOaUMDPpbFIei4JkFimWUFPn90sbMNMXQAIVOlnYKJA==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/aria-query": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.2.tgz",
      "integrity": "sha512-COROpnaoap1E2F000S62r6A60uHZnmlvomhfyT2DlTcrY1OrBKn2UhH7qn5wTC9zMvD0AY7csdPSNwKP+7WiQw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/array-buffer-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/array-buffer-byte-length/-/array-buffer-byte-length-1.0.2.tgz",
      "integrity": "sha512-LHE+8BuR7RYGDKvnrmcuSq3tDcKv9OFEXQt/HpbZhY7V6h0zlUXutnAD82GiFx9rdieCMjkvtcsPqBwgUl1Iiw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "is-array-buffer": "^3.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-includes": {
      "version": "3.1.9",
      "resolved": "https://registry.npmjs.org/array-includes/-/array-includes-3.1.9.tgz",
      "integrity": "sha512-FmeCCAenzH0KH381SPT5FZmiA/TmpndpcaShhfgEN9eCVjnFBqq3l1xrI42y8+PPLI6hypzou4GXw00WHmPBLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.24.0",
        "es-object-atoms": "^1.1.1",
        "get-intrinsic": "^1.3.0",
        "is-string": "^1.1.1",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/array.prototype.findlast": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlast/-/array.prototype.findlast-1.2.5.tgz",
      "integrity": "sha512-CVvd6FHg1Z3POpBLxO6E6zr+rSKEQ9L6rZHAaY7lLfhKsWYUBBOuMs0e9o24oopj6H+geRCX0YJ+TJLBK2eHyQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.findlastindex": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/array.prototype.findlastindex/-/array.prototype.findlastindex-1.2.6.tgz",
      "integrity": "sha512-F/TKATkzseUExPlfvmwQKGITM3DGTK+vkAsCZoDc5daVygbJBnjEUCbgkAvVFsgfXfX4YIqZ/27G3k3tdXrTxQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-shim-unscopables": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flat": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flat/-/array.prototype.flat-1.3.3.tgz",
      "integrity": "sha512-rwG/ja1neyLqCuGZ5YYrznA62D4mZXg0i1cIskIUKSiqF3Cje9/wXAls9B9s1Wa2fomMsIv8czB8jZcPmxCXFg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flatmap": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flatmap/-/array.prototype.flatmap-1.3.3.tgz",
      "integrity": "sha512-Y7Wt51eKJSyi80hFrJCePGGNo5ktJCslFuboqJsbf57CCPcm5zztluPlc4/aD8sWsKvlwatezpV4U1efk8kpjg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.tosorted": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/array.prototype.tosorted/-/array.prototype.tosorted-1.1.4.tgz",
      "integrity": "sha512-p6Fx8B7b7ZhL/gmUsAy0D15WhvDccw3mnGNbZpi3pmeJdxtWsj2jEaI4Y6oo3XiHfzuSgPwKc04MYt6KgvC/wA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3",
        "es-errors": "^1.3.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/arraybuffer.prototype.slice": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/arraybuffer.prototype.slice/-/arraybuffer.prototype.slice-1.0.4.tgz",
      "integrity": "sha512-BNoCY6SXXPQ7gF2opIP4GBE+Xw7U+pHMYKuzjgCN3GwiaIR09UUeKfheyIry77QtrCBlC0KK0q5/TER/tYh3PQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "is-array-buffer": "^3.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/assertion-error": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/assertion-error/-/assertion-error-2.0.1.tgz",
      "integrity": "sha512-Izi8RQcffqCeNVgFigKli1ssklIbpHnCYc6AknXGYoB6grJqyeby7jv12JUQgmTAnIDnbck1uxksT4dzN3PWBA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/ast-types-flow": {
      "version": "0.0.8",
      "resolved": "https://registry.npmjs.org/ast-types-flow/-/ast-types-flow-0.0.8.tgz",
      "integrity": "sha512-OH/2E5Fg20h2aPrbe+QL8JZQFko0YZaF+j4mnQ7BGhfavO7OpSLa8a0y9sBwomHdSbkhTS8TQNayBfnW5DwbvQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/async-function": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/async-function/-/async-function-1.0.0.tgz",
      "integrity": "sha512-hsU18Ae8CDTR6Kgu9DYf0EbCr/a5iGL0rytQDobUcdpYOKokk8LEjVphnXkDkgpi0wYVsqrXuP0bZxJaTqdgoA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/atticus-admin-service": {
      "resolved": "admin",
      "link": true
    },
    "node_modules/autoprefixer": {
      "version": "10.4.21",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz",
      "integrity": "sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4",
        "caniuse-lite": "^1.0.30001702",
        "fraction.js": "^4.3.7",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/available-typed-arrays": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/available-typed-arrays/-/available-typed-arrays-1.0.7.tgz",
      "integrity": "sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/axe-core": {
      "version": "4.10.3",
      "resolved": "https://registry.npmjs.org/axe-core/-/axe-core-4.10.3.tgz",
      "integrity": "sha512-Xm7bpRXnDSX2YE2YFfBk2FnF0ep6tmG7xPh8iHee8MIcrgq762Nkce856dYtJYLkuIoYZvGfTs/PbZhideTcEg==",
      "dev": true,
      "license": "MPL-2.0",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/axobject-query": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-4.1.0.tgz",
      "integrity": "sha512-qIj0G9wZbMGNLjLmg1PT6v2mE9AH2zlnADJD/2tC6E00hgmhUOfEB6greHPAfLRSufHqROIUTkw6E+M3lH0PTQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/bail": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/bail/-/bail-2.0.2.tgz",
      "integrity": "sha512-0xO6mYd7JB2YesxDKplafRpsiOzPt9V02ddPCLbY1xYGPOX24NTyN50qnUxgCPcSoYMhKpAuBTjQoRZCAkUDRw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/baseline-browser-mapping": {
      "version": "2.8.7",
      "resolved": "https://registry.npmjs.org/baseline-browser-mapping/-/baseline-browser-mapping-2.8.7.tgz",
      "integrity": "sha512-bxxN2M3a4d1CRoQC//IqsR5XrLh0IJ8TCv2x6Y9N0nckNz/rTjZB3//GGscZziZOxmjP55rzxg/ze7usFI9FqQ==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "baseline-browser-mapping": "dist/cli.js"
      }
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.26.2",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.26.2.tgz",
      "integrity": "sha512-ECFzp6uFOSB+dcZ5BK/IBaGWssbSYBHvuMeMt3MMFyhI0Z8SqGgEkBLARgpRH3hutIgPVsALcMwbDrJqPxQ65A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "baseline-browser-mapping": "^2.8.3",
        "caniuse-lite": "^1.0.30001741",
        "electron-to-chromium": "^1.5.218",
        "node-releases": "^2.0.21",
        "update-browserslist-db": "^1.1.3"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/busboy": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/busboy/-/busboy-1.6.0.tgz",
      "integrity": "sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==",
      "dependencies": {
        "streamsearch": "^1.1.0"
      },
      "engines": {
        "node": ">=10.16.0"
      }
    },
    "node_modules/cac": {
      "version": "6.7.14",
      "resolved": "https://registry.npmjs.org/cac/-/cac-6.7.14.tgz",
      "integrity": "sha512-b6Ilus+c3RrdDk+JhLKUAQfzzgLEPy6wcXqS7f/xe1EETvsDP6GORG7SFuOs6cID5YkqchW/LXZbX5bc8j7ZcQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.8.tgz",
      "integrity": "sha512-oKlSFMcMwpUg2ednkhQ454wfWiU/ul3CkJe/PEHcTKuiX6RpbehUiFMXu13HalGZxfUwCQzZG747YXBn1im9ww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.0",
        "es-define-property": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "set-function-length": "^1.2.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001745",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001745.tgz",
      "integrity": "sha512-ywt6i8FzvdgrrrGbr1jZVObnVv6adj+0if2/omv9cmR2oiZs30zL4DIyaptKcbOrBdOIc74QTMoJvSE2QHh5UQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/ccount": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/ccount/-/ccount-2.0.1.tgz",
      "integrity": "sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/chai": {
      "version": "5.3.3",
      "resolved": "https://registry.npmjs.org/chai/-/chai-5.3.3.tgz",
      "integrity": "sha512-4zNhdJD/iOjSH0A05ea+Ke6MU5mmpQcbQsSOkgdaUMJ9zTlDTD/GYlwohmIE2u0gaxHYiVHEn1Fw9mZ/ktJWgw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "assertion-error": "^2.0.1",
        "check-error": "^2.1.1",
        "deep-eql": "^5.0.1",
        "loupe": "^3.1.0",
        "pathval": "^2.0.0"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/chalk/node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/character-entities": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-2.0.2.tgz",
      "integrity": "sha512-shx7oQ0Awen/BRIdkjkvz54PnEEI/EjwXDSIZp86/KKdbafHh1Df/RYGBhn4hbe2+uKC9FnT5UCEdyPz3ai9hQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-html4": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/character-entities-html4/-/character-entities-html4-2.1.0.tgz",
      "integrity": "sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-legacy": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-3.0.0.tgz",
      "integrity": "sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-reference-invalid": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-2.0.1.tgz",
      "integrity": "sha512-iBZ4F4wRbyORVsu0jPV7gXkOsGYjGHPmAyv+HiHG8gi5PtC9KI2j1+v8/tlibRvjoWX027ypmG/n0HtO5t7unw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/check-error": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/check-error/-/check-error-2.1.1.tgz",
      "integrity": "sha512-OAlb+T7V4Op9OwdkjmguYRqncdlx5JiofwOAUkmTF+jNdHwzTaTs4sRAGpzLF3oOz5xAyDGrPgeIDFQmDOTiJw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 16"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/client-only": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/client-only/-/client-only-0.0.1.tgz",
      "integrity": "sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA==",
      "license": "MIT"
    },
    "node_modules/clsx": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/clsx/-/clsx-2.1.1.tgz",
      "integrity": "sha512-eYm0QWBtUrBWZWG0d386OGAw16Z995PiOVo2B7bjWSbHedGl5e0ZWaq65kOGgUSNesEIDkB9ISbTg/JK9dhCZA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/comma-separated-tokens": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-2.0.3.tgz",
      "integrity": "sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/create-require": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/create-require/-/create-require-1.1.1.tgz",
      "integrity": "sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/damerau-levenshtein": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/damerau-levenshtein/-/damerau-levenshtein-1.0.8.tgz",
      "integrity": "sha512-sdQSFB7+llfUcQHUQO3+B8ERRj0Oa4w9POWMI/puGtuf7gFywGmkaLCElnudfTiKZV+NvHqL0ifzdrI8Ro7ESA==",
      "dev": true,
      "license": "BSD-2-Clause"
    },
    "node_modules/data-view-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-buffer/-/data-view-buffer-1.0.2.tgz",
      "integrity": "sha512-EmKO5V3OLXh1rtK2wgXRansaK1/mtVdTUEiEI0W8RkvgT05kfxaH29PliLnpLP73yYO6142Q72QNa8Wx/A5CqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-byte-length/-/data-view-byte-length-1.0.2.tgz",
      "integrity": "sha512-tuhGbE6CfTM9+5ANGf+oQb72Ky/0+s3xKUpHvShfiz2RxMFgFPjsXuRLBVMtvMs15awe45SRb83D6wH4ew6wlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/inspect-js"
      }
    },
    "node_modules/data-view-byte-offset": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-byte-offset/-/data-view-byte-offset-1.0.1.tgz",
      "integrity": "sha512-BS8PfmtDGnrgYdOonGZQdLZslWIeCGFP9tpan0hi1Co2Zr2NKADsvGYA8XxuG/4UWgJ6Cjtv+YJnB6MM69QGlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/debug": {
      "version": "4.4.3",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.3.tgz",
      "integrity": "sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/decode-named-character-reference": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/decode-named-character-reference/-/decode-named-character-reference-1.2.0.tgz",
      "integrity": "sha512-c6fcElNV6ShtZXmsgNgFFV5tVX2PaV4g+MOAkb8eXHvn6sryJBrZa9r0zV6+dtTyoCKxtDy5tyQ5ZwQuidtd+Q==",
      "license": "MIT",
      "dependencies": {
        "character-entities": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/deep-eql": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/deep-eql/-/deep-eql-5.0.2.tgz",
      "integrity": "sha512-h5k/5U50IJJFpzfL6nO9jaaumfjO/f2NjK/oYB2Djzm4p9L+3T9qWpZqZ2hAbLPuuYq9wrU08WQyBTL5GbPk5Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/deep-extend": {
      "version": "0.6.0",
      "resolved": "https://registry.npmjs.org/deep-extend/-/deep-extend-0.6.0.tgz",
      "integrity": "sha512-LOHxIOaPYdHlJRtCQfDIVZtfw/ufM8+rVj649RIHzcm/vGwQRXFt6OPqIFWsm2XEMrNIEtWR64sY1LEKD2vAOA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4.0.0"
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/define-data-property": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.4.tgz",
      "integrity": "sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/define-properties": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.2.1.tgz",
      "integrity": "sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.0.1",
        "has-property-descriptors": "^1.0.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/dequal": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/dequal/-/dequal-2.0.3.tgz",
      "integrity": "sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/detect-node-es": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/detect-node-es/-/detect-node-es-1.1.0.tgz",
      "integrity": "sha512-ypdmJU/TbBby2Dxibuv7ZLW3Bs1QEmM7nHjEANfohJLvE0XVujisn1qPJcZxg+qDucsr+bP6fLD1rPS3AhJ7EQ==",
      "license": "MIT"
    },
    "node_modules/devlop": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/devlop/-/devlop-1.1.0.tgz",
      "integrity": "sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==",
      "license": "MIT",
      "dependencies": {
        "dequal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/diff": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/diff/-/diff-4.0.2.tgz",
      "integrity": "sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.3.1"
      }
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.223",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.223.tgz",
      "integrity": "sha512-qKm55ic6nbEmagFlTFczML33rF90aU+WtrJ9MdTCThrcvDNdUHN4p6QfVN78U06ZmguqXIyMPyYhw2TrbDUwPQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/entities": {
      "version": "4.5.0",
      "resolved": "https://registry.npmjs.org/entities/-/entities-4.5.0.tgz",
      "integrity": "sha512-V0hjH4dGPh9Ao5p0MoRY6BVqtwCjhz6vI5LT8AJ55H+4g9/4vbHx1I54fS0XuclLhDHArPQCiMjDxjaL8fPxhw==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.12"
      },
      "funding": {
        "url": "https://github.com/fb55/entities?sponsor=1"
      }
    },
    "node_modules/es-abstract": {
      "version": "1.24.0",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.24.0.tgz",
      "integrity": "sha512-WSzPgsdLtTcQwm4CROfS5ju2Wa1QQcVeT37jFjYzdFz1r9ahadC8B8/a4qxJxM+09F18iumCdRmlr96ZYkQvEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.2",
        "arraybuffer.prototype.slice": "^1.0.4",
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "data-view-buffer": "^1.0.2",
        "data-view-byte-length": "^1.0.2",
        "data-view-byte-offset": "^1.0.1",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "es-set-tostringtag": "^2.1.0",
        "es-to-primitive": "^1.3.0",
        "function.prototype.name": "^1.1.8",
        "get-intrinsic": "^1.3.0",
        "get-proto": "^1.0.1",
        "get-symbol-description": "^1.1.0",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "internal-slot": "^1.1.0",
        "is-array-buffer": "^3.0.5",
        "is-callable": "^1.2.7",
        "is-data-view": "^1.0.2",
        "is-negative-zero": "^2.0.3",
        "is-regex": "^1.2.1",
        "is-set": "^2.0.3",
        "is-shared-array-buffer": "^1.0.4",
        "is-string": "^1.1.1",
        "is-typed-array": "^1.1.15",
        "is-weakref": "^1.1.1",
        "math-intrinsics": "^1.1.0",
        "object-inspect": "^1.13.4",
        "object-keys": "^1.1.1",
        "object.assign": "^4.1.7",
        "own-keys": "^1.0.1",
        "regexp.prototype.flags": "^1.5.4",
        "safe-array-concat": "^1.1.3",
        "safe-push-apply": "^1.0.0",
        "safe-regex-test": "^1.1.0",
        "set-proto": "^1.0.0",
        "stop-iteration-iterator": "^1.1.0",
        "string.prototype.trim": "^1.2.10",
        "string.prototype.trimend": "^1.0.9",
        "string.prototype.trimstart": "^1.0.8",
        "typed-array-buffer": "^1.0.3",
        "typed-array-byte-length": "^1.0.3",
        "typed-array-byte-offset": "^1.0.4",
        "typed-array-length": "^1.0.7",
        "unbox-primitive": "^1.1.0",
        "which-typed-array": "^1.1.19"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-iterator-helpers": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/es-iterator-helpers/-/es-iterator-helpers-1.2.1.tgz",
      "integrity": "sha512-uDn+FE1yrDzyC0pCo961B2IHbdM8y/ACZsKD4dG6WqrjV53BADjwa7D+1aom2rsNVfLyDgU/eigvlJGJ08OQ4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-set-tostringtag": "^2.0.3",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.6",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "iterator.prototype": "^1.1.4",
        "safe-array-concat": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-module-lexer": {
      "version": "1.7.0",
      "resolved": "https://registry.npmjs.org/es-module-lexer/-/es-module-lexer-1.7.0.tgz",
      "integrity": "sha512-jEQoCwk8hyb2AZziIOLhDqpm5+2ww5uIE6lkO/6jcOCusfk6LhMHpXXfBLXTZ7Ydyt0j4VoUQv6uGNYbdW+kBA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-shim-unscopables": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/es-shim-unscopables/-/es-shim-unscopables-1.1.0.tgz",
      "integrity": "sha512-d9T8ucsEhh8Bi1woXCf+TIKDIROLG5WCkxg8geBCbvk22kzwC5G2OnXVMO6FUsvQlgUUXQ2itephWDLqDzbeCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-to-primitive": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.3.0.tgz",
      "integrity": "sha512-w+5mJ3GuFL+NjVtJlvydShqE1eN3h3PbI7/5LAsYJP/2qtuMXjfL2LpHSRqo4b4eSF5K/DH1JXKUAHSB2UW50g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7",
        "is-date-object": "^1.0.5",
        "is-symbol": "^1.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/esbuild": {
      "version": "0.25.10",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.25.10.tgz",
      "integrity": "sha512-9RiGKvCwaqxO2owP61uQ4BgNborAQskMR6QusfWzQqv7AZOg5oGehdY2pRJMTKuwxd1IDBP4rSbI5lHzU7SMsQ==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=18"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.25.10",
        "@esbuild/android-arm": "0.25.10",
        "@esbuild/android-arm64": "0.25.10",
        "@esbuild/android-x64": "0.25.10",
        "@esbuild/darwin-arm64": "0.25.10",
        "@esbuild/darwin-x64": "0.25.10",
        "@esbuild/freebsd-arm64": "0.25.10",
        "@esbuild/freebsd-x64": "0.25.10",
        "@esbuild/linux-arm": "0.25.10",
        "@esbuild/linux-arm64": "0.25.10",
        "@esbuild/linux-ia32": "0.25.10",
        "@esbuild/linux-loong64": "0.25.10",
        "@esbuild/linux-mips64el": "0.25.10",
        "@esbuild/linux-ppc64": "0.25.10",
        "@esbuild/linux-riscv64": "0.25.10",
        "@esbuild/linux-s390x": "0.25.10",
        "@esbuild/linux-x64": "0.25.10",
        "@esbuild/netbsd-arm64": "0.25.10",
        "@esbuild/netbsd-x64": "0.25.10",
        "@esbuild/openbsd-arm64": "0.25.10",
        "@esbuild/openbsd-x64": "0.25.10",
        "@esbuild/openharmony-arm64": "0.25.10",
        "@esbuild/sunos-x64": "0.25.10",
        "@esbuild/win32-arm64": "0.25.10",
        "@esbuild/win32-ia32": "0.25.10",
        "@esbuild/win32-x64": "0.25.10"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.0",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.0.tgz",
      "integrity": "sha512-dZ6+mexnaTIbSBZWgou51U6OmzIhYM2VcNdtiTtI7qPNZm35Akpr0f6vtw3w1Kmn5PYo+tZVfh13WrhpS6oLqQ==",
      "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.0",
        "@humanwhocodes/config-array": "^0.11.14",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-config-next": {
      "version": "14.2.5",
      "resolved": "https://registry.npmjs.org/eslint-config-next/-/eslint-config-next-14.2.5.tgz",
      "integrity": "sha512-zogs9zlOiZ7ka+wgUnmcM0KBEDjo4Jis7kxN1jvC0N4wynQ2MIx/KBkg4mVF63J5EK4W0QMCn7xO3vNisjaAoA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@next/eslint-plugin-next": "14.2.5",
        "@rushstack/eslint-patch": "^1.3.3",
        "@typescript-eslint/parser": "^5.4.2 || ^6.0.0 || 7.0.0 - 7.2.0",
        "eslint-import-resolver-node": "^0.3.6",
        "eslint-import-resolver-typescript": "^3.5.2",
        "eslint-plugin-import": "^2.28.1",
        "eslint-plugin-jsx-a11y": "^6.7.1",
        "eslint-plugin-react": "^7.33.2",
        "eslint-plugin-react-hooks": "^4.5.0 || 5.0.0-canary-7118f5dd7-20230705"
      },
      "peerDependencies": {
        "eslint": "^7.23.0 || ^8.0.0",
        "typescript": ">=3.3.1"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-config-prettier": {
      "version": "9.1.2",
      "resolved": "https://registry.npmjs.org/eslint-config-prettier/-/eslint-config-prettier-9.1.2.tgz",
      "integrity": "sha512-iI1f+D2ViGn+uvv5HuHVUamg8ll4tN+JRHGc6IJi4TP9Kl976C57fzPXgseXNs8v0iA8aSJpHsTWjDb9QJamGQ==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "eslint-config-prettier": "bin/cli.js"
      },
      "peerDependencies": {
        "eslint": ">=7.0.0"
      }
    },
    "node_modules/eslint-import-resolver-node": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-node/-/eslint-import-resolver-node-0.3.9.tgz",
      "integrity": "sha512-WFj2isz22JahUv+B788TlO3N6zL3nNJGU8CcZbPZvVEkBPaJdCV4vy5wyghty5ROFbCRnm132v8BScu5/1BQ8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7",
        "is-core-module": "^2.13.0",
        "resolve": "^1.22.4"
      }
    },
    "node_modules/eslint-import-resolver-node/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-import-resolver-typescript": {
      "version": "3.10.1",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-typescript/-/eslint-import-resolver-typescript-3.10.1.tgz",
      "integrity": "sha512-A1rHYb06zjMGAxdLSkN2fXPBwuSaQ0iO5M/hdyS0Ajj1VBaRp0sPD3dn1FhME3c/JluGFbwSxyCfqdSbtQLAHQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@nolyfill/is-core-module": "1.0.39",
        "debug": "^4.4.0",
        "get-tsconfig": "^4.10.0",
        "is-bun-module": "^2.0.0",
        "stable-hash": "^0.0.5",
        "tinyglobby": "^0.2.13",
        "unrs-resolver": "^1.6.2"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint-import-resolver-typescript"
      },
      "peerDependencies": {
        "eslint": "*",
        "eslint-plugin-import": "*",
        "eslint-plugin-import-x": "*"
      },
      "peerDependenciesMeta": {
        "eslint-plugin-import": {
          "optional": true
        },
        "eslint-plugin-import-x": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils": {
      "version": "2.12.1",
      "resolved": "https://registry.npmjs.org/eslint-module-utils/-/eslint-module-utils-2.12.1.tgz",
      "integrity": "sha512-L8jSWTze7K2mTg0vos/RuLRS5soomksDPoJLXIslC7c8Wmut3bx7CPpJijDcBZtxQ5lrbUdM+s0OlNbz0DCDNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependenciesMeta": {
        "eslint": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import": {
      "version": "2.32.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-import/-/eslint-plugin-import-2.32.0.tgz",
      "integrity": "sha512-whOE1HFo/qJDyX4SnXzP4N6zOWn79WhnCUY/iDR0mPfQZO8wcYE4JClzI2oZrhBnnMUCBCHZhO6VQyoBU95mZA==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@rtsao/scc": "^1.1.0",
        "array-includes": "^3.1.9",
        "array.prototype.findlastindex": "^1.2.6",
        "array.prototype.flat": "^1.3.3",
        "array.prototype.flatmap": "^1.3.3",
        "debug": "^3.2.7",
        "doctrine": "^2.1.0",
        "eslint-import-resolver-node": "^0.3.9",
        "eslint-module-utils": "^2.12.1",
        "hasown": "^2.0.2",
        "is-core-module": "^2.16.1",
        "is-glob": "^4.0.3",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "object.groupby": "^1.0.3",
        "object.values": "^1.2.1",
        "semver": "^6.3.1",
        "string.prototype.trimend": "^1.0.9",
        "tsconfig-paths": "^3.15.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^2 || ^3 || ^4 || ^5 || ^6 || ^7.2.0 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y": {
      "version": "6.10.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-jsx-a11y/-/eslint-plugin-jsx-a11y-6.10.2.tgz",
      "integrity": "sha512-scB3nz4WmG75pV8+3eRUQOHZlNSUhFNq37xnpgRkCCELU3XMvXAxLk1eqWWyE22Ki4Q01Fnsw9BA3cJHDPgn2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "aria-query": "^5.3.2",
        "array-includes": "^3.1.8",
        "array.prototype.flatmap": "^1.3.2",
        "ast-types-flow": "^0.0.8",
        "axe-core": "^4.10.0",
        "axobject-query": "^4.1.0",
        "damerau-levenshtein": "^1.0.8",
        "emoji-regex": "^9.2.2",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^3.3.5",
        "language-tags": "^1.0.9",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "safe-regex-test": "^1.0.3",
        "string.prototype.includes": "^2.0.1"
      },
      "engines": {
        "node": ">=4.0"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/eslint-plugin-react": {
      "version": "7.37.5",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react/-/eslint-plugin-react-7.37.5.tgz",
      "integrity": "sha512-Qteup0SqU15kdocexFNAJMvCJEfa2xUKNV4CC1xsVMrIIqEy3SQ/rqyxCWNzfrd3/ldy6HMlD2e0JDVpDg2qIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.8",
        "array.prototype.findlast": "^1.2.5",
        "array.prototype.flatmap": "^1.3.3",
        "array.prototype.tosorted": "^1.1.4",
        "doctrine": "^2.1.0",
        "es-iterator-helpers": "^1.2.1",
        "estraverse": "^5.3.0",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^2.4.1 || ^3.0.0",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.9",
        "object.fromentries": "^2.0.8",
        "object.values": "^1.2.1",
        "prop-types": "^15.8.1",
        "resolve": "^2.0.0-next.5",
        "semver": "^6.3.1",
        "string.prototype.matchall": "^4.0.12",
        "string.prototype.repeat": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9.7"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "5.0.0-canary-7118f5dd7-20230705",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-5.0.0-canary-7118f5dd7-20230705.tgz",
      "integrity": "sha512-AZYbMo/NW9chdL7vk6HQzQhT+PvTAEVqWk9ziruUoW2kAOcN5qNyelv70e0F1VNQAbvutOC9oc+xfWycI9FxDw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/resolve": {
      "version": "2.0.0-next.5",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-2.0.0-next.5.tgz",
      "integrity": "sha512-U7WjGVG9sH8tvjW5SmGbQuui75FiyjAX72HX15DwBBwF9dNiQZRQAg9nnPhYy+TUnE0+VcrttuvNI8oSxZcocA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-tailwindcss": {
      "version": "3.18.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-tailwindcss/-/eslint-plugin-tailwindcss-3.18.2.tgz",
      "integrity": "sha512-QbkMLDC/OkkjFQ1iz/5jkMdHfiMu/uwujUHLAJK5iwNHD8RTxVTlsUezE0toTZ6VhybNBsk+gYGPDq2agfeRNA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-glob": "^3.2.5",
        "postcss": "^8.4.4"
      },
      "engines": {
        "node": ">=18.12.0"
      },
      "peerDependencies": {
        "tailwindcss": "^3.4.0"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/eslint/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/eslint/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/eslint/node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estree-util-is-identifier-name": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/estree-util-is-identifier-name/-/estree-util-is-identifier-name-3.0.0.tgz",
      "integrity": "sha512-hFtqIDZTIUZ9BXLb8y4pYGyk6+wekIivNVTcmvk8NoOh+VeRn5y6cEHzbURrWbfp1fIqdVipilzj+lfaadNZmg==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/estree-walker": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/estree-walker/-/estree-walker-3.0.3.tgz",
      "integrity": "sha512-7RUKfXgSMMkzt6ZuXmqapOurLGPPfgj6l9uRZ7lRGolvk0y2yocc35LdcxKC5PQZdn2DMqioAQ2NoWcrTKmm6g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "^1.0.0"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/expect-type": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/expect-type/-/expect-type-1.2.2.tgz",
      "integrity": "sha512-JhFGDVJ7tmDJItKhYgJCGLOWjuK9vPxiXoUFLwLDc99NlmklilbiQJwoctZtt13+xMw91MCk/REan6MWHqDjyA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.0.0"
      }
    },
    "node_modules/extend": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
      "license": "MIT"
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-glob": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz",
      "integrity": "sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.8"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.19.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.19.1.tgz",
      "integrity": "sha512-GwLTyxkCXjXbxqIhTsMI2Nui8huMPtnxg7krajPJAjnEG/iiOS7i+zCtWGZR9G0NBKbXKh6X9m9UIsYX/N6vvQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/fd-package-json": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/fd-package-json/-/fd-package-json-2.0.0.tgz",
      "integrity": "sha512-jKmm9YtsNXN789RS/0mSzOC1NUq9mkVd65vbSSVsKdjGvYXBuE4oWe2QOEoFeRmJg+lPuZxpmrfFclNhoRMneQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "walk-up-path": "^4.0.0"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/for-each": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/for-each/-/for-each-0.3.5.tgz",
      "integrity": "sha512-dKx12eRCVIzqCxFGplyFKJMPvLEWgmNtUrpTiJIR5u97zEhRG8ySrtboPHZXx7daLxQVrl643cTzbab2tkQjxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/foreground-child": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz",
      "integrity": "sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "cross-spawn": "^7.0.6",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/formatly": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/formatly/-/formatly-0.3.0.tgz",
      "integrity": "sha512-9XNj/o4wrRFyhSMJOvsuyMwy8aUfBaZ1VrqHVfohyXf0Sw0e+yfKG+xZaY3arGCOMdwFsqObtzVOc1gU9KiT9w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fd-package-json": "^2.0.0"
      },
      "bin": {
        "formatly": "bin/index.mjs"
      },
      "engines": {
        "node": ">=18.3.0"
      }
    },
    "node_modules/fraction.js": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz",
      "integrity": "sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "patreon",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/function.prototype.name": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/function.prototype.name/-/function.prototype.name-1.1.8.tgz",
      "integrity": "sha512-e5iwyodOHhbMr/yNrc7fDYG4qlbIvI5gajyzPnb5TCwyhjApznQh1BMFou9b30SevY43gCJKXycoCBjMbsuW0Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "functions-have-names": "^1.2.3",
        "hasown": "^2.0.2",
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/functions-have-names": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/functions-have-names/-/functions-have-names-1.2.3.tgz",
      "integrity": "sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-nonce": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-nonce/-/get-nonce-1.0.1.tgz",
      "integrity": "sha512-FJhYRoDaiatfEkUK8HKlicmu/3SGFD51q3itKDGoSTysQJBnfOcxU5GxnhE1E6soB76MbT0MBtnKJuXyAx+96Q==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-symbol-description": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/get-symbol-description/-/get-symbol-description-1.1.0.tgz",
      "integrity": "sha512-w9UMqWwJxHNOvoNzSJ2oPF5wvYcvP7jUvYzhp67yEhTi17ZDBBC1z9pTdGuzjD+EFIqLSYRweZjqfiPzQ06Ebg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.10.1",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.10.1.tgz",
      "integrity": "sha512-auHyJ4AgMz7vgS8Hp3N6HXSmlMdUyhSUrfBF16w153rxtLIEOE+HGqaBppczZvnHLqQJfiHotCYpNhl0lUROFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/glob": {
      "version": "10.4.5",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.4.5.tgz",
      "integrity": "sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^3.1.2",
        "minimatch": "^9.0.4",
        "minipass": "^7.1.2",
        "package-json-from-dist": "^1.0.0",
        "path-scurry": "^1.11.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globalthis": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/globalthis/-/globalthis-1.0.4.tgz",
      "integrity": "sha512-DpLKbNU4WylpxJykQujfCcwYWiV/Jhm50Goo0wrVILAv5jOr9d+H+UR3PhSCD2rCCEIg0uc+G+muBTwD54JhDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.2.1",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "license": "ISC"
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/has-bigints": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.1.0.tgz",
      "integrity": "sha512-R3pbpkcIqv2Pm3dUwgjclDRVmWpTJW2DcMzcIhEXEx1oh/CEMObMm3KLmRJOdvhM7o4uQBnwr8pzRK2sJWIqfg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.2.tgz",
      "integrity": "sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.2.0.tgz",
      "integrity": "sha512-KIL7eQPfHQRC8+XluaIw7BHUwwqL19bQn4hzNgdr+1wXoU0KKj6rufu47lhY7KbJR2C6T6+PfyN0Ea7wkSS+qQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/hast-util-to-jsx-runtime": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/hast-util-to-jsx-runtime/-/hast-util-to-jsx-runtime-2.3.6.tgz",
      "integrity": "sha512-zl6s8LwNyo1P9uw+XJGvZtdFF1GdAkOg8ujOw+4Pyb76874fLps4ueHXDhXWdk6YHQ6OgUtinliG7RsYvCbbBg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/unist": "^3.0.0",
        "comma-separated-tokens": "^2.0.0",
        "devlop": "^1.0.0",
        "estree-util-is-identifier-name": "^3.0.0",
        "hast-util-whitespace": "^3.0.0",
        "mdast-util-mdx-expression": "^2.0.0",
        "mdast-util-mdx-jsx": "^3.0.0",
        "mdast-util-mdxjs-esm": "^2.0.0",
        "property-information": "^7.0.0",
        "space-separated-tokens": "^2.0.0",
        "style-to-js": "^1.0.0",
        "unist-util-position": "^5.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hast-util-whitespace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/hast-util-whitespace/-/hast-util-whitespace-3.0.0.tgz",
      "integrity": "sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/html-url-attributes": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/html-url-attributes/-/html-url-attributes-3.0.1.tgz",
      "integrity": "sha512-ol6UPyBWqsrO6EJySPz2O7ZSr856WDrEzM5zMqp+FJJLGMW35cLYmmZnl0vztAZxRUoNZJFTCohfjuIJ8I4QBQ==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/ini": {
      "version": "4.1.3",
      "resolved": "https://registry.npmjs.org/ini/-/ini-4.1.3.tgz",
      "integrity": "sha512-X7rqawQBvfdjS10YU1y1YVreA3SsLrW9dX2CewP2EbBJM4ypVNLDkO5y04gejPwKIY9lR+7r9gn3rFPt/kmWFg==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "^14.17.0 || ^16.13.0 || >=18.0.0"
      }
    },
    "node_modules/inline-style-parser": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/inline-style-parser/-/inline-style-parser-0.2.4.tgz",
      "integrity": "sha512-0aO8FkhNZlj/ZIbNi7Lxxr12obT7cL1moPfE4tg1LkX7LlLfC6DeX4l2ZEud1ukP9jNQyNnfzQVqwbwmAATY4Q==",
      "license": "MIT"
    },
    "node_modules/internal-slot": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/internal-slot/-/internal-slot-1.1.0.tgz",
      "integrity": "sha512-4gd7VpWNQNB4UKKCFFVcp1AVv+FMOgs9NKzjHKusc8jTMhd5eL1NqQqOpE0KzMds804/yHlglp3uxgluOqAPLw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "hasown": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/is-alphabetical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-2.0.1.tgz",
      "integrity": "sha512-FWyyY60MeTNyeSRpkM2Iry0G9hpr7/9kD40mD/cGQEuilcZYS4okz8SN2Q6rLCJ8gbCt6fN+rC+6tMGS99LaxQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-alphanumerical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-2.0.1.tgz",
      "integrity": "sha512-hmbYhX/9MUMF5uh7tOXyK/n0ZvWpad5caBA17GsC6vyuCqaWliRG5K1qS9inmUhEMaOBIW7/whAnSwveW/LtZw==",
      "license": "MIT",
      "dependencies": {
        "is-alphabetical": "^2.0.0",
        "is-decimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-array-buffer": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/is-array-buffer/-/is-array-buffer-3.0.5.tgz",
      "integrity": "sha512-DDfANUiiG2wC1qawP66qlTugJeL5HyzMpfr8lLK+jMQirGzNod0B12cFB/9q838Ru27sBwfw78/rdoU7RERz6A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-async-function": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-async-function/-/is-async-function-2.1.1.tgz",
      "integrity": "sha512-9dgM/cZBnNvjzaMYHVoxxfPj2QXt22Ev7SuuPrs+xav0ukGB0S6d4ydZdEiM48kLx5kDV+QBPrpVnFyefL8kkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "async-function": "^1.0.0",
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.1",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bigint": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-bigint/-/is-bigint-1.1.0.tgz",
      "integrity": "sha512-n4ZT37wG78iz03xPRKJrHTdZbe3IicyucEtdRsV5yglwc3GyUfbAfpSeD0FJ41NbUNSt5wbhqfp1fS+BgnvDFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-bigints": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-boolean-object": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/is-boolean-object/-/is-boolean-object-1.2.2.tgz",
      "integrity": "sha512-wa56o2/ElJMYqjCjGkXri7it5FbebW5usLw/nPmCMs5DeZ7eziSYZhSmPRn0txqeW4LnAmQQU7FgqLpsEFKM4A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bun-module": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-bun-module/-/is-bun-module-2.0.0.tgz",
      "integrity": "sha512-gNCGbnnnnFAUGKeZ9PdbyeGYJqewpmc2aKHUEMO5nQPWU9lOmv7jcmQIv+qHD8fXW6W7qfuCwX4rY9LNRjXrkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.7.1"
      }
    },
    "node_modules/is-callable": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.2.7.tgz",
      "integrity": "sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-data-view": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-data-view/-/is-data-view-1.0.2.tgz",
      "integrity": "sha512-RKtWF8pGmS87i2D6gqQu/l7EYRlVdfzemCJN/P3UOs//x1QE7mfhvzHIApBTRf7axvT6DMGwSwBXYCT0nfB9xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-date-object": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.1.0.tgz",
      "integrity": "sha512-PwwhEakHVKTdRNVOw+/Gyh0+MzlCl4R6qKvkhuvLtPMggI1WAHt9sOwZxQLSGpUaDnrdyDsomoRgNnCfKNSXXg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-decimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-2.0.1.tgz",
      "integrity": "sha512-AAB9hiomQs5DXWcRB1rqsxGUstbRroFOPPVAomNk/3XHR5JyEZChOyTWe2oayKnsSsr/kcGqF+z6yuH6HHpN0A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-finalizationregistry": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-finalizationregistry/-/is-finalizationregistry-1.1.1.tgz",
      "integrity": "sha512-1pC6N8qWJbWoPtEjgcL2xyhQOP491EQjeUo3qTKcmV8YSDDJrOepfG8pcC7h/QgnQHYSv0mJ3Z/ZWxmatVrysg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.1.0.tgz",
      "integrity": "sha512-nPUB5km40q9e8UfN/Zc24eLlzdSf9OfKByBw9CIdw4H1giPMeA0OIJvbchsCu4npfI2QcMVBsGEBHKZ7wLTWmQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.0",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-hexadecimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-2.0.1.tgz",
      "integrity": "sha512-DgZQp241c8oO6cA1SbTEWiXeoxV42vlcJxgH+B3hi1AiqqKruZR3ZGF8In3fj4+/y/7rHvlOZLZtgJ/4ttYGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-map": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-map/-/is-map-2.0.3.tgz",
      "integrity": "sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-negative-zero": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-negative-zero/-/is-negative-zero-2.0.3.tgz",
      "integrity": "sha512-5KoIu2Ngpyek75jXodFvnafB6DJgr3u8uuK0LEZJjrU19DrMD3EVERaR8sjz8CCGgpZvxPl9SuE1GMVPFHx1mw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-number-object": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-number-object/-/is-number-object-1.1.1.tgz",
      "integrity": "sha512-lZhclumE1G6VYD8VHe35wFaIif+CTy5SJIi5+3y4psDgWu4wPDoBhF8NxUOinEc7pHgiTsT6MaBb92rKhhD+Xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-plain-obj": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-4.1.0.tgz",
      "integrity": "sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-regex": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.2.1.tgz",
      "integrity": "sha512-MjYsKHO5O7mCsmRGxWcLWheFqN9DJ/2TmngvjKXihe6efViPqc274+Fx/4fYj/r03+ESvBdTXK0V6tA3rgez1g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-set": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-set/-/is-set-2.0.3.tgz",
      "integrity": "sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-shared-array-buffer": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-shared-array-buffer/-/is-shared-array-buffer-1.0.4.tgz",
      "integrity": "sha512-ISWac8drv4ZGfwKl5slpHG9OwPNty4jOWPRIhBpxOoD+hqITiwuipOQ2bNthAzwA3B4fIjO4Nln74N0S9byq8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-string": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-string/-/is-string-1.1.1.tgz",
      "integrity": "sha512-BtEeSsoaQjlSPBemMQIrY1MY0uM6vnS1g5fmufYOtnxLGUZM2178PKbhsk7Ffv58IX+ZtcvoGwccYsh0PglkAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-symbol": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.1.1.tgz",
      "integrity": "sha512-9gGx6GTtCQM73BgmHQXfDmLtfjjTUDSyoxTCbp5WtoixAhfgsDirWIcVQ/IHpvI5Vgd5i/J5F7B9cN/WlVbC/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-symbols": "^1.1.0",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-typed-array": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/is-typed-array/-/is-typed-array-1.1.15.tgz",
      "integrity": "sha512-p3EcsicXjit7SaskXHs1hA91QxgTw46Fv6EFKKGS5DRFLD8yKnohjF3hxoju94b/OcMZoQukzpPpBE9uLVKzgQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakmap": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/is-weakmap/-/is-weakmap-2.0.2.tgz",
      "integrity": "sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-weakref/-/is-weakref-1.1.1.tgz",
      "integrity": "sha512-6i9mGWSlqzNMEqpCp93KwRS1uUOodk2OJ6b+sq7ZPDSy2WuI5NFIxp/254TytR8ftefexkWn5xNiHUNpPOfSew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakset": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/is-weakset/-/is-weakset-2.0.4.tgz",
      "integrity": "sha512-mfcwb6IzQyOKTs84CQMrOwW4gQcaTOAWJ0zzJCl2WSPDrWk/OzDaImWFH3djXhb24g4eudZfLRozAvPGw4d9hQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/isarray": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.5.tgz",
      "integrity": "sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/iterator.prototype": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/iterator.prototype/-/iterator.prototype-1.1.5.tgz",
      "integrity": "sha512-H0dkQoCa3b2VEeKQBOxFph+JAbcrQdE7KC0UkqwpLmv2EC4P41QXP+rqo9wYodACiG5/WM5s9oDApTU8utwj9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "get-proto": "^1.0.0",
        "has-symbols": "^1.1.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/jackspeak": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-3.4.3.tgz",
      "integrity": "sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.7",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz",
      "integrity": "sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json5/-/json5-1.0.2.tgz",
      "integrity": "sha512-g1MWMLBiz8FKi1e4w0UyVL3w+iJceWAFBAaBnnGKOpNa5f8TLktkbre1+s6oICydWAm+HRUGTmI+//xv2hvXYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "minimist": "^1.2.0"
      },
      "bin": {
        "json5": "lib/cli.js"
      }
    },
    "node_modules/jsonc-parser": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/jsonc-parser/-/jsonc-parser-3.3.1.tgz",
      "integrity": "sha512-HUgH65KyejrUFPvHFPbqOY0rsFip3Bo5wb4ngvdi1EpCYWUQDC5V+Y7mZws+DLkr4M//zQJoanu1SP+87Dv1oQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jsonpointer": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/jsonpointer/-/jsonpointer-5.0.1.tgz",
      "integrity": "sha512-p/nXbhSEcu3pZRdkW1OfJhpsVtW1gd4Wa1fnQc9YLiTfAjn0312eMKimbdIQzuZl9aa9xUGaRlP9T/CJE/ditQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/jsx-ast-utils": {
      "version": "3.3.5",
      "resolved": "https://registry.npmjs.org/jsx-ast-utils/-/jsx-ast-utils-3.3.5.tgz",
      "integrity": "sha512-ZZow9HBI5O6EPgSJLUb8n2NKgmVWTwCvHGwFuJlMjvLFqlGG6pjirPhtdsseaLZjSibD8eegzmYpUZwoIlj2cQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.6",
        "array.prototype.flat": "^1.3.1",
        "object.assign": "^4.1.4",
        "object.values": "^1.1.6"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/katex": {
      "version": "0.16.25",
      "resolved": "https://registry.npmjs.org/katex/-/katex-0.16.25.tgz",
      "integrity": "sha512-woHRUZ/iF23GBP1dkDQMh1QBad9dmr8/PAwNA54VrSOVYgI12MAcE14TqnDdQOdzyEonGzMepYnqBMYdsoAr8Q==",
      "dev": true,
      "funding": [
        "https://opencollective.com/katex",
        "https://github.com/sponsors/katex"
      ],
      "license": "MIT",
      "dependencies": {
        "commander": "^8.3.0"
      },
      "bin": {
        "katex": "cli.js"
      }
    },
    "node_modules/katex/node_modules/commander": {
      "version": "8.3.0",
      "resolved": "https://registry.npmjs.org/commander/-/commander-8.3.0.tgz",
      "integrity": "sha512-OkTL9umf+He2DZkUq8f8J9of7yL6RJKI24dVITBmNfZBmri9zYZQrKkuXiKhyfPSu8tUhnVBB1iKXevvnlR4Ww==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 12"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/knip": {
      "version": "5.66.0",
      "resolved": "https://registry.npmjs.org/knip/-/knip-5.66.0.tgz",
      "integrity": "sha512-b1IR8sEgeywrnzhl0ePDM6euAjrC3Jefdpg6EpUc2z+WSYO0UChGQhftZIbnSNTeqYi//7/5vh+lLAxwO1AoVQ==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/webpro"
        },
        {
          "type": "opencollective",
          "url": "https://opencollective.com/knip"
        }
      ],
      "license": "ISC",
      "dependencies": {
        "@nodelib/fs.walk": "^1.2.3",
        "fast-glob": "^3.3.3",
        "formatly": "^0.3.0",
        "jiti": "^2.6.0",
        "js-yaml": "^4.1.0",
        "minimist": "^1.2.8",
        "oxc-resolver": "^11.8.3",
        "picocolors": "^1.1.1",
        "picomatch": "^4.0.1",
        "smol-toml": "^1.4.1",
        "strip-json-comments": "5.0.2",
        "zod": "^4.1.11"
      },
      "bin": {
        "knip": "bin/knip.js",
        "knip-bun": "bin/knip-bun.js"
      },
      "engines": {
        "node": ">=18.18.0"
      },
      "peerDependencies": {
        "@types/node": ">=18",
        "typescript": ">=5.0.4 <7"
      }
    },
    "node_modules/knip/node_modules/jiti": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-2.6.0.tgz",
      "integrity": "sha512-VXe6RjJkBPj0ohtqaO8vSWP3ZhAKo66fKrFNCll4BTcwljPLz03pCbaNKfzGP5MbrCYcbJ7v0nOYYwUzTEIdXQ==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "lib/jiti-cli.mjs"
      }
    },
    "node_modules/knip/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/knip/node_modules/strip-json-comments": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-5.0.2.tgz",
      "integrity": "sha512-4X2FR3UwhNUE9G49aIsJW5hRRR3GXGTBTZRMfv568O60ojM8HcWjV/VxAxCDW3SUND33O6ZY66ZuRcdkj73q2g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14.16"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/language-subtag-registry": {
      "version": "0.3.23",
      "resolved": "https://registry.npmjs.org/language-subtag-registry/-/language-subtag-registry-0.3.23.tgz",
      "integrity": "sha512-0K65Lea881pHotoGEa5gDlMxt3pctLi2RplBb7Ezh4rRdLEOtgi7n4EwK9lamnUCkKBqaeKRVebTq6BAxSkpXQ==",
      "dev": true,
      "license": "CC0-1.0"
    },
    "node_modules/language-tags": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/language-tags/-/language-tags-1.0.9.tgz",
      "integrity": "sha512-MbjN408fEndfiQXbFQ1vnd+1NoLDsnQW41410oQBXiyXDMYH5z505juWa4KUE1LqxRC7DgOgZDbKLxHIwm27hA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "language-subtag-registry": "^0.3.20"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/linkify-it": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/linkify-it/-/linkify-it-5.0.0.tgz",
      "integrity": "sha512-5aHCbzQRADcdP+ATqnDuhhJ/MRIqDkZX5pyjFHRRysS8vZ5AbqGEoFIb6pYHPZ+L/OC2Lc+xT8uHVVR5CAK/wQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "uc.micro": "^2.0.0"
      }
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/longest-streak": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/longest-streak/-/longest-streak-3.1.0.tgz",
      "integrity": "sha512-9Ri+o0JYgehTaVBBDoMqIl8GXtbWg711O3srftcHhZ0dqnETqLaoIK0x17fUw9rFSlK/0NlsKe0Ahhyl5pXE2g==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/loupe": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/loupe/-/loupe-3.2.1.tgz",
      "integrity": "sha512-CdzqowRJCeLU72bHvWqwRBBlLcMEtIvGrlvef74kMnV2AolS9Y8xUv1I0U/MNAWMhBlKIoyuEgoJ0t/bbwHbLQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/lru-cache": {
      "version": "10.4.3",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/lucide-react": {
      "version": "0.452.0",
      "resolved": "https://registry.npmjs.org/lucide-react/-/lucide-react-0.452.0.tgz",
      "integrity": "sha512-kNefjOUOGm+Mu3KDiryONyPba9r+nhcrz5oJs3N6JDzGboQNEXw5GB3yB8rnV9/FA4bPyggNU6CRSihZm9MvSw==",
      "license": "ISC",
      "peerDependencies": {
        "react": "^16.5.1 || ^17.0.0 || ^18.0.0 || ^19.0.0-rc"
      }
    },
    "node_modules/magic-string": {
      "version": "0.30.19",
      "resolved": "https://registry.npmjs.org/magic-string/-/magic-string-0.30.19.tgz",
      "integrity": "sha512-2N21sPY9Ws53PZvsEpVtNuSW+ScYbQdp4b9qUaL+9QkHUrGFKo56Lg9Emg5s9V/qrtNBmiR01sYhUOwu3H+VOw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.5"
      }
    },
    "node_modules/make-error": {
      "version": "1.3.6",
      "resolved": "https://registry.npmjs.org/make-error/-/make-error-1.3.6.tgz",
      "integrity": "sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/markdown-it": {
      "version": "14.1.0",
      "resolved": "https://registry.npmjs.org/markdown-it/-/markdown-it-14.1.0.tgz",
      "integrity": "sha512-a54IwgWPaeBCAAsv13YgmALOF1elABB08FxO9i+r4VFk5Vl4pKokRPeX8u5TCgSsPi6ec1otfLjdOpVcgbpshg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1",
        "entities": "^4.4.0",
        "linkify-it": "^5.0.0",
        "mdurl": "^2.0.0",
        "punycode.js": "^2.3.1",
        "uc.micro": "^2.1.0"
      },
      "bin": {
        "markdown-it": "bin/markdown-it.mjs"
      }
    },
    "node_modules/markdown-table": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/markdown-table/-/markdown-table-3.0.4.tgz",
      "integrity": "sha512-wiYz4+JrLyb/DqW2hkFJxP7Vd7JuTDm77fvbM8VfEQdmSMqcImWeeRbHwZjBjIFki/VaMK2BhFi7oUUZeM5bqw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/markdownlint": {
      "version": "0.38.0",
      "resolved": "https://registry.npmjs.org/markdownlint/-/markdownlint-0.38.0.tgz",
      "integrity": "sha512-xaSxkaU7wY/0852zGApM8LdlIfGCW8ETZ0Rr62IQtAnUMlMuifsg09vWJcNYeL4f0anvr8Vo4ZQar8jGpV0btQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "micromark": "4.0.2",
        "micromark-core-commonmark": "2.0.3",
        "micromark-extension-directive": "4.0.0",
        "micromark-extension-gfm-autolink-literal": "2.1.0",
        "micromark-extension-gfm-footnote": "2.1.0",
        "micromark-extension-gfm-table": "2.1.1",
        "micromark-extension-math": "3.1.0",
        "micromark-util-types": "2.0.2"
      },
      "engines": {
        "node": ">=20"
      },
      "funding": {
        "url": "https://github.com/sponsors/DavidAnson"
      }
    },
    "node_modules/markdownlint-cli": {
      "version": "0.45.0",
      "resolved": "https://registry.npmjs.org/markdownlint-cli/-/markdownlint-cli-0.45.0.tgz",
      "integrity": "sha512-GiWr7GfJLVfcopL3t3pLumXCYs8sgWppjIA1F/Cc3zIMgD3tmkpyZ1xkm1Tej8mw53B93JsDjgA3KOftuYcfOw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "commander": "~13.1.0",
        "glob": "~11.0.2",
        "ignore": "~7.0.4",
        "js-yaml": "~4.1.0",
        "jsonc-parser": "~3.3.1",
        "jsonpointer": "~5.0.1",
        "markdown-it": "~14.1.0",
        "markdownlint": "~0.38.0",
        "minimatch": "~10.0.1",
        "run-con": "~1.3.2",
        "smol-toml": "~1.3.4"
      },
      "bin": {
        "markdownlint": "markdownlint.js"
      },
      "engines": {
        "node": ">=20"
      }
    },
    "node_modules/markdownlint-cli/node_modules/commander": {
      "version": "13.1.0",
      "resolved": "https://registry.npmjs.org/commander/-/commander-13.1.0.tgz",
      "integrity": "sha512-/rFeCpNJQbhSZjGVwO9RFV3xPqbnERS8MmIQzCtD/zl6gpJuV/bMLuN92oG3F7d8oDEHHRrujSXNUr8fpjntKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/markdownlint-cli/node_modules/glob": {
      "version": "11.0.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-11.0.3.tgz",
      "integrity": "sha512-2Nim7dha1KVkaiF4q6Dj+ngPPMdfvLJEOpZk/jKiUAkqKebpGAWQXAq9z1xu9HKu5lWfqw/FASuccEjyznjPaA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.3.1",
        "jackspeak": "^4.1.1",
        "minimatch": "^10.0.3",
        "minipass": "^7.1.2",
        "package-json-from-dist": "^1.0.0",
        "path-scurry": "^2.0.0"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "engines": {
        "node": "20 || >=22"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/markdownlint-cli/node_modules/ignore": {
      "version": "7.0.5",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-7.0.5.tgz",
      "integrity": "sha512-Hs59xBNfUIunMFgWAbGX5cq6893IbWg4KnrjbYwX3tx0ztorVgTDA6B2sxf8ejHJ4wz8BqGUMYlnzNBer5NvGg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/markdownlint-cli/node_modules/jackspeak": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-4.1.1.tgz",
      "integrity": "sha512-zptv57P3GpL+O0I7VdMJNBZCu+BPHVQUk55Ft8/QCJjTVxrnJHuVuX/0Bl2A6/+2oyR/ZMEuFKwmzqqZ/U5nPQ==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "engines": {
        "node": "20 || >=22"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/markdownlint-cli/node_modules/lru-cache": {
      "version": "11.2.2",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-11.2.2.tgz",
      "integrity": "sha512-F9ODfyqML2coTIsQpSkRHnLSZMtkU8Q+mSfcaIyKwy58u+8k5nvAYeiNhsyMARvzNcXJ9QfWVrcPsC9e9rAxtg==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "20 || >=22"
      }
    },
    "node_modules/markdownlint-cli/node_modules/minimatch": {
      "version": "10.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-10.0.3.tgz",
      "integrity": "sha512-IPZ167aShDZZUMdRk66cyQAW3qr0WzbHkPdMYa8bzZhlHhO3jALbKdxcaak7W9FfT2rZNpQuUu4Od7ILEpXSaw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@isaacs/brace-expansion": "^5.0.0"
      },
      "engines": {
        "node": "20 || >=22"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/markdownlint-cli/node_modules/path-scurry": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-2.0.0.tgz",
      "integrity": "sha512-ypGJsmGtdXUOeM5u93TyeIEfEhM6s+ljAhrk5vAvSx8uyY/02OvrZnA0YNGUrPXfpJMgI1ODd3nwz8Npx4O4cg==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^11.0.0",
        "minipass": "^7.1.2"
      },
      "engines": {
        "node": "20 || >=22"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/markdownlint-cli/node_modules/smol-toml": {
      "version": "1.3.4",
      "resolved": "https://registry.npmjs.org/smol-toml/-/smol-toml-1.3.4.tgz",
      "integrity": "sha512-UOPtVuYkzYGee0Bd2Szz8d2G3RfMfJ2t3qVdZUAozZyAk+a0Sxa+QKix0YCwjL/A1RR0ar44nCxaoN9FxdJGwA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">= 18"
      },
      "funding": {
        "url": "https://github.com/sponsors/cyyynthia"
      }
    },
    "node_modules/markdownlint-cli2": {
      "version": "0.18.1",
      "resolved": "https://registry.npmjs.org/markdownlint-cli2/-/markdownlint-cli2-0.18.1.tgz",
      "integrity": "sha512-/4Osri9QFGCZOCTkfA8qJF+XGjKYERSHkXzxSyS1hd3ZERJGjvsUao2h4wdnvpHp6Tu2Jh/bPHM0FE9JJza6ng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "globby": "14.1.0",
        "js-yaml": "4.1.0",
        "jsonc-parser": "3.3.1",
        "markdown-it": "14.1.0",
        "markdownlint": "0.38.0",
        "markdownlint-cli2-formatter-default": "0.0.5",
        "micromatch": "4.0.8"
      },
      "bin": {
        "markdownlint-cli2": "markdownlint-cli2-bin.mjs"
      },
      "engines": {
        "node": ">=20"
      },
      "funding": {
        "url": "https://github.com/sponsors/DavidAnson"
      }
    },
    "node_modules/markdownlint-cli2-formatter-default": {
      "version": "0.0.5",
      "resolved": "https://registry.npmjs.org/markdownlint-cli2-formatter-default/-/markdownlint-cli2-formatter-default-0.0.5.tgz",
      "integrity": "sha512-4XKTwQ5m1+Txo2kuQ3Jgpo/KmnG+X90dWt4acufg6HVGadTUG5hzHF/wssp9b5MBYOMCnZ9RMPaU//uHsszF8Q==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/DavidAnson"
      },
      "peerDependencies": {
        "markdownlint-cli2": ">=0.0.4"
      }
    },
    "node_modules/markdownlint-cli2/node_modules/globby": {
      "version": "14.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-14.1.0.tgz",
      "integrity": "sha512-0Ia46fDOaT7k4og1PDW4YbodWWr3scS2vAr2lTbsplOt2WkKp0vQbkI9wKis/T5LV/dqPjO3bpS/z6GTJB82LA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@sindresorhus/merge-streams": "^2.1.0",
        "fast-glob": "^3.3.3",
        "ignore": "^7.0.3",
        "path-type": "^6.0.0",
        "slash": "^5.1.0",
        "unicorn-magic": "^0.3.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/markdownlint-cli2/node_modules/ignore": {
      "version": "7.0.5",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-7.0.5.tgz",
      "integrity": "sha512-Hs59xBNfUIunMFgWAbGX5cq6893IbWg4KnrjbYwX3tx0ztorVgTDA6B2sxf8ejHJ4wz8BqGUMYlnzNBer5NvGg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/markdownlint-cli2/node_modules/path-type": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-6.0.0.tgz",
      "integrity": "sha512-Vj7sf++t5pBD637NSfkxpHSMfWaeig5+DKWLhcqIYx6mWQz5hdJTGDVMQiJcw1ZYkhs7AazKDGpRVji1LJCZUQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/markdownlint-cli2/node_modules/slash": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-5.1.0.tgz",
      "integrity": "sha512-ZA6oR3T/pEyuqwMgAKT0/hAv8oAXckzbkmR0UkUosQ+Mc4RxGoJkRmwHgHufaenlyAgE1Mxgpdcrf75y6XcnDg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14.16"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/mdast-util-find-and-replace": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-find-and-replace/-/mdast-util-find-and-replace-3.0.2.tgz",
      "integrity": "sha512-Tmd1Vg/m3Xz43afeNxDIhWRtFZgM2VLyaf4vSTYwudTyeuTneoL3qtWMA5jeLyz/O1vDJmmV4QuScFCA2tBPwg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "escape-string-regexp": "^5.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-find-and-replace/node_modules/escape-string-regexp": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-5.0.0.tgz",
      "integrity": "sha512-/veY75JbMK4j1yjvuUxuVsiS/hr/4iHs9FTT6cgTexxdE0Ly/glccBAkloH/DofkjRbZU3bnoj38mOmhkZ0lHw==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/mdast-util-from-markdown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-from-markdown/-/mdast-util-from-markdown-2.0.2.tgz",
      "integrity": "sha512-uZhTV/8NBuw0WHkPTrCqDOl0zVe1BIng5ZtHoDk49ME1qqcjYmmLmOf0gELgcRMxN4w2iuIeVso5/6QymSrgmA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark": "^4.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm/-/mdast-util-gfm-3.1.0.tgz",
      "integrity": "sha512-0ulfdQOM3ysHhCJ1p06l0b0VKlhU0wuQs3thxZQagjcjPrlFRqY215uZGHHJan9GEAXd9MbfPjFJz+qMkVR6zQ==",
      "license": "MIT",
      "dependencies": {
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-gfm-autolink-literal": "^2.0.0",
        "mdast-util-gfm-footnote": "^2.0.0",
        "mdast-util-gfm-strikethrough": "^2.0.0",
        "mdast-util-gfm-table": "^2.0.0",
        "mdast-util-gfm-task-list-item": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-autolink-literal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-autolink-literal/-/mdast-util-gfm-autolink-literal-2.0.1.tgz",
      "integrity": "sha512-5HVP2MKaP6L+G6YaxPNjuL0BPrq9orG3TsrZ9YXbA3vDw/ACI4MEsnoDpn6ZNm7GnZgtAcONJyPhOP8tNJQavQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.0.0",
        "mdast-util-find-and-replace": "^3.0.0",
        "micromark-util-character": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-footnote/-/mdast-util-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-sqpDWlsHn7Ac9GNZQMeUzPQSMzR6Wv0WKRNvQRg0KqHh02fpTz69Qc1QSseNX29bhz1ROIyNyxExfawVKTm1GQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-strikethrough": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-strikethrough/-/mdast-util-gfm-strikethrough-2.0.0.tgz",
      "integrity": "sha512-mKKb915TF+OC5ptj5bJ7WFRPdYtuHv0yTRxK2tJvi+BDqbkiG7h7u/9SI89nRAYcmap2xHQL9D+QG/6wSrTtXg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-table": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-table/-/mdast-util-gfm-table-2.0.0.tgz",
      "integrity": "sha512-78UEvebzz/rJIxLvE7ZtDd/vIQ0RHv+3Mh5DR96p7cS7HsBhYIICDBCu8csTNWNO6tBWfqXPWekRuj2FNOGOZg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "markdown-table": "^3.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-task-list-item": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-task-list-item/-/mdast-util-gfm-task-list-item-2.0.0.tgz",
      "integrity": "sha512-IrtvNvjxC1o06taBAVJznEnkiHxLFTzgonUdy8hzFVeDun0uTjxxrRGVaNFqkU1wJR3RBPEfsxmU6jDWPofrTQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-expression": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-expression/-/mdast-util-mdx-expression-2.0.1.tgz",
      "integrity": "sha512-J6f+9hUp+ldTZqKRSg7Vw5V6MqjATc+3E4gf3CFNcuZNWD8XdyI6zQ8GqH7f8169MM6P7hMBRDVGnn7oHB9kXQ==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-jsx": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-jsx/-/mdast-util-mdx-jsx-3.2.0.tgz",
      "integrity": "sha512-lj/z8v0r6ZtsN/cGNNtemmmfoLAFZnjMbNyLzBafjzikOM+glrjNHPlf6lQDOTccj9n5b0PPihEBbhneMyGs1Q==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "parse-entities": "^4.0.0",
        "stringify-entities": "^4.0.0",
        "unist-util-stringify-position": "^4.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdxjs-esm": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdxjs-esm/-/mdast-util-mdxjs-esm-2.0.1.tgz",
      "integrity": "sha512-EcmOpxsZ96CvlP03NghtH1EsLtr0n9Tm4lPUJUBccV9RwUOneqSycg19n5HGzCf+10LozMRSObtVr3ee1WoHtg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-phrasing": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-phrasing/-/mdast-util-phrasing-4.1.0.tgz",
      "integrity": "sha512-TqICwyvJJpBwvGAMZjj4J2n0X8QWp21b9l0o7eXyVJ25YNWYbJDVIyD1bZXE6WtV6RmKJVYmQAKWa0zWOABz2w==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-hast": {
      "version": "13.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-hast/-/mdast-util-to-hast-13.2.0.tgz",
      "integrity": "sha512-QGYKEuUsYT9ykKBCMOEDLsU5JRObWQusAolFMeko/tYPufNkRffBAQjIE+99jbA87xv6FgmjLtwjh9wBWajwAA==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@ungap/structured-clone": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "trim-lines": "^3.0.0",
        "unist-util-position": "^5.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-markdown": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/mdast-util-to-markdown/-/mdast-util-to-markdown-2.1.2.tgz",
      "integrity": "sha512-xj68wMTvGXVOKonmog6LwyJKrYXZPvlwabaryTjLh9LuvovB/KAH+kvi8Gjj+7rJjsFi23nkUxRQv1KqSroMqA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "longest-streak": "^3.0.0",
        "mdast-util-phrasing": "^4.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "unist-util-visit": "^5.0.0",
        "zwitch": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-string": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-string/-/mdast-util-to-string-4.0.0.tgz",
      "integrity": "sha512-0H44vDimn51F0YwvxSJSm0eCDOJTRlmN0R1yBh4HLj9wiV1Dn0QoXGbvFAWj2hSItVTlCmBF1hqKlIyUBVFLPg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdurl": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdurl/-/mdurl-2.0.0.tgz",
      "integrity": "sha512-Lf+9+2r+Tdp5wXDXC4PcIBjTDtq4UKjCPMQhKIuzpJNW0b96kVqSwW0bT7FhRSfmAiFYgP+SCRvdrDozfh0U5w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromark": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/micromark/-/micromark-4.0.2.tgz",
      "integrity": "sha512-zpe98Q6kvavpCr1NPVSCMebCKfD7CA2NqZ+rykeNhONIJBpc1tFKt9hucLGwha3jNTNI8lHpctWJWoimVF4PfA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "@types/debug": "^4.0.0",
        "debug": "^4.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-core-commonmark": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/micromark-core-commonmark/-/micromark-core-commonmark-2.0.3.tgz",
      "integrity": "sha512-RDBrHEMSxVFLg6xvnXmb1Ayr2WzLAWjeSATAoxwKYJV94TeNavgoIdA0a9ytzDSVzBy2YKFK+emCPOEibLeCrg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-factory-destination": "^2.0.0",
        "micromark-factory-label": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-factory-title": "^2.0.0",
        "micromark-factory-whitespace": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-html-tag-name": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-extension-directive": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-directive/-/micromark-extension-directive-4.0.0.tgz",
      "integrity": "sha512-/C2nqVmXXmiseSSuCdItCMho7ybwwop6RrrRPk0KbOHW21JKoCldC+8rFOaundDoRBUWBnJJcxeA/Kvi34WQXg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-factory-whitespace": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "parse-entities": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm/-/micromark-extension-gfm-3.0.0.tgz",
      "integrity": "sha512-vsKArQsicm7t0z2GugkCKtZehqUm31oeGBV/KVSorWSy8ZlNAv7ytjFhvaryUiCUJYqs+NoE6AFhpQvBTM6Q4w==",
      "license": "MIT",
      "dependencies": {
        "micromark-extension-gfm-autolink-literal": "^2.0.0",
        "micromark-extension-gfm-footnote": "^2.0.0",
        "micromark-extension-gfm-strikethrough": "^2.0.0",
        "micromark-extension-gfm-table": "^2.0.0",
        "micromark-extension-gfm-tagfilter": "^2.0.0",
        "micromark-extension-gfm-task-list-item": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-autolink-literal": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-autolink-literal/-/micromark-extension-gfm-autolink-literal-2.1.0.tgz",
      "integrity": "sha512-oOg7knzhicgQ3t4QCjCWgTmfNhvQbDDnJeVu9v81r7NltNCVmhPy1fJRX27pISafdjL+SVc4d3l48Gb6pbRypw==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-footnote/-/micromark-extension-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-/yPhxI1ntnDNsiHtzLKYnE3vf9JZ6cAisqVDauhp4CEHxlb4uoOTxOCJ+9s51bIB8U1N1FJ1RXOKTIlD5B/gqw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-strikethrough": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-strikethrough/-/micromark-extension-gfm-strikethrough-2.1.0.tgz",
      "integrity": "sha512-ADVjpOOkjz1hhkZLlBiYA9cR2Anf8F4HqZUO6e5eDcPQd0Txw5fxLzzxnEkSkfnD0wziSGiv7sYhk/ktvbf1uw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-table": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-table/-/micromark-extension-gfm-table-2.1.1.tgz",
      "integrity": "sha512-t2OU/dXXioARrC6yWfJ4hqB7rct14e8f7m0cbI5hUmDyyIlwv5vEtooptH8INkbLzOatzKuVbQmAYcbWoyz6Dg==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-tagfilter": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-tagfilter/-/micromark-extension-gfm-tagfilter-2.0.0.tgz",
      "integrity": "sha512-xHlTOmuCSotIA8TW1mDIM6X2O1SiX5P9IuDtqGonFhEK0qgRI4yeC6vMxEV2dgyr2TiD+2PQ10o+cOhdVAcwfg==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-task-list-item": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-task-list-item/-/micromark-extension-gfm-task-list-item-2.1.0.tgz",
      "integrity": "sha512-qIBZhqxqI6fjLDYFTBIa4eivDMnP+OZqsNwmQ3xNLE4Cxwc+zfQEfbs6tzAo2Hjq+bh6q5F+Z8/cksrLFYWQQw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-math": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-math/-/micromark-extension-math-3.1.0.tgz",
      "integrity": "sha512-lvEqd+fHjATVs+2v/8kg9i5Q0AP2k85H0WUOwpIVvUML8BapsMvh1XAogmQjOCsLpoKRCVQqEkQBB3NhVBcsOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/katex": "^0.16.0",
        "devlop": "^1.0.0",
        "katex": "^0.16.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-factory-destination": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-destination/-/micromark-factory-destination-2.0.1.tgz",
      "integrity": "sha512-Xe6rDdJlkmbFRExpTOmRj9N3MaWmbAgdpSrBQvCFqhezUn4AHqJHbaEnfbVYYiexVSs//tqOdY/DxhjdCiJnIA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-label": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-label/-/micromark-factory-label-2.0.1.tgz",
      "integrity": "sha512-VFMekyQExqIW7xIChcXn4ok29YE3rnuyveW3wZQWWqF4Nv9Wk5rgJ99KzPvHjkmPXF93FXIbBp6YdW3t71/7Vg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-space": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-space/-/micromark-factory-space-2.0.1.tgz",
      "integrity": "sha512-zRkxjtBxxLd2Sc0d+fbnEunsTj46SWXgXciZmHq0kDYGnck/ZSGj9/wULTV95uoeYiK5hRXP2mJ98Uo4cq/LQg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-title": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-title/-/micromark-factory-title-2.0.1.tgz",
      "integrity": "sha512-5bZ+3CjhAd9eChYTHsjy6TGxpOFSKgKKJPJxr293jTbfry2KDoWkhBb6TcPVB4NmzaPhMs1Frm9AZH7OD4Cjzw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-whitespace": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-whitespace/-/micromark-factory-whitespace-2.0.1.tgz",
      "integrity": "sha512-Ob0nuZ3PKt/n0hORHyvoD9uZhr+Za8sFoP+OnMcnWK5lngSzALgQYKMr9RJVOWLqQYuyn6ulqGWSXdwf6F80lQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-character": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-util-character/-/micromark-util-character-2.1.1.tgz",
      "integrity": "sha512-wv8tdUTJ3thSFFFJKtpYKOYiGP2+v96Hvk4Tu8KpCAsTMs6yi+nVmGh1syvSCsaxz45J6Jbw+9DD6g97+NV67Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-chunked": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-chunked/-/micromark-util-chunked-2.0.1.tgz",
      "integrity": "sha512-QUNFEOPELfmvv+4xiNg2sRYeS/P84pTW0TCgP5zc9FpXetHY0ab7SxKyAQCNCc1eK0459uoLI1y5oO5Vc1dbhA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-classify-character": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-classify-character/-/micromark-util-classify-character-2.0.1.tgz",
      "integrity": "sha512-K0kHzM6afW/MbeWYWLjoHQv1sgg2Q9EccHEDzSkxiP/EaagNzCm7T/WMKZ3rjMbvIpvBiZgwR3dKMygtA4mG1Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-combine-extensions": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-combine-extensions/-/micromark-util-combine-extensions-2.0.1.tgz",
      "integrity": "sha512-OnAnH8Ujmy59JcyZw8JSbK9cGpdVY44NKgSM7E9Eh7DiLS2E9RNQf0dONaGDzEG9yjEl5hcqeIsj4hfRkLH/Bg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-numeric-character-reference": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-numeric-character-reference/-/micromark-util-decode-numeric-character-reference-2.0.2.tgz",
      "integrity": "sha512-ccUbYk6CwVdkmCQMyr64dXz42EfHGkPQlBj5p7YVGzq8I7CtjXZJrubAYezf7Rp+bjPseiROqe7G6foFd+lEuw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-string": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-string/-/micromark-util-decode-string-2.0.1.tgz",
      "integrity": "sha512-nDV/77Fj6eH1ynwscYTOsbK7rR//Uj0bZXBwJZRfaLEJ1iGBR6kIfNmlNqaqJf649EP0F3NWNdeJi03elllNUQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-encode": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-encode/-/micromark-util-encode-2.0.1.tgz",
      "integrity": "sha512-c3cVx2y4KqUnwopcO9b/SCdo2O67LwJJ/UyqGfbigahfegL9myoEFoDYZgkT7f36T0bLrM9hZTAaAyH+PCAXjw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-html-tag-name": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-html-tag-name/-/micromark-util-html-tag-name-2.0.1.tgz",
      "integrity": "sha512-2cNEiYDhCWKI+Gs9T0Tiysk136SnR13hhO8yW6BGNyhOC4qYFnwF1nKfD3HFAIXA5c45RrIG1ub11GiXeYd1xA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-normalize-identifier": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-normalize-identifier/-/micromark-util-normalize-identifier-2.0.1.tgz",
      "integrity": "sha512-sxPqmo70LyARJs0w2UclACPUUEqltCkJ6PhKdMIDuJ3gSf/Q+/GIe3WKl0Ijb/GyH9lOpUkRAO2wp0GVkLvS9Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-resolve-all": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-resolve-all/-/micromark-util-resolve-all-2.0.1.tgz",
      "integrity": "sha512-VdQyxFWFT2/FGJgwQnJYbe1jjQoNTS4RjglmSjTUlpUMa95Htx9NHeYW4rGDJzbjvCsl9eLjMQwGeElsqmzcHg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-sanitize-uri": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-sanitize-uri/-/micromark-util-sanitize-uri-2.0.1.tgz",
      "integrity": "sha512-9N9IomZ/YuGGZZmQec1MbgxtlgougxTodVwDzzEouPKo3qFWvymFHWcnDi2vzV1ff6kas9ucW+o3yzJK9YB1AQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-subtokenize": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-util-subtokenize/-/micromark-util-subtokenize-2.1.0.tgz",
      "integrity": "sha512-XQLu552iSctvnEcgXw6+Sx75GflAPNED1qx7eBJ+wydBb2KCbRZe+NwvIEEMM83uml1+2WSXpBAcp9IUCgCYWA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-symbol": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-symbol/-/micromark-util-symbol-2.0.1.tgz",
      "integrity": "sha512-vs5t8Apaud9N28kgCrRUdEed4UJ+wWNvicHLPxCa9ENlYuAY31M0ETy5y1vA33YoNPDFTghEbnh6efaE8h4x0Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-types": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-types/-/micromark-util-types-2.0.2.tgz",
      "integrity": "sha512-Yw0ECSpJoViF1qTU4DC6NwtC4aWGt1EkzaQB8KPPyCRR8z9TWeV0HbEFGTO+ZY1wB22zmxnJqhPyTpOVCpeHTA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/minipass": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/napi-postinstall": {
      "version": "0.3.3",
      "resolved": "https://registry.npmjs.org/napi-postinstall/-/napi-postinstall-0.3.3.tgz",
      "integrity": "sha512-uTp172LLXSxuSYHv/kou+f6KW3SMppU9ivthaVTXian9sOt3XM/zHYHpRZiLgQoxeWfYUnslNWQHF1+G71xcow==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "napi-postinstall": "lib/cli.js"
      },
      "engines": {
        "node": "^12.20.0 || ^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/napi-postinstall"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/next": {
      "version": "14.2.33",
      "resolved": "https://registry.npmjs.org/next/-/next-14.2.33.tgz",
      "integrity": "sha512-GiKHLsD00t4ACm1p00VgrI0rUFAC9cRDGReKyERlM57aeEZkOQGcZTpIbsGn0b562FTPJWmYfKwplfO9EaT6ng==",
      "license": "MIT",
      "dependencies": {
        "@next/env": "14.2.33",
        "@swc/helpers": "0.5.5",
        "busboy": "1.6.0",
        "caniuse-lite": "^1.0.30001579",
        "graceful-fs": "^4.2.11",
        "postcss": "8.4.31",
        "styled-jsx": "5.1.1"
      },
      "bin": {
        "next": "dist/bin/next"
      },
      "engines": {
        "node": ">=18.17.0"
      },
      "optionalDependencies": {
        "@next/swc-darwin-arm64": "14.2.33",
        "@next/swc-darwin-x64": "14.2.33",
        "@next/swc-linux-arm64-gnu": "14.2.33",
        "@next/swc-linux-arm64-musl": "14.2.33",
        "@next/swc-linux-x64-gnu": "14.2.33",
        "@next/swc-linux-x64-musl": "14.2.33",
        "@next/swc-win32-arm64-msvc": "14.2.33",
        "@next/swc-win32-ia32-msvc": "14.2.33",
        "@next/swc-win32-x64-msvc": "14.2.33"
      },
      "peerDependencies": {
        "@opentelemetry/api": "^1.1.0",
        "@playwright/test": "^1.41.2",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "sass": "^1.3.0"
      },
      "peerDependenciesMeta": {
        "@opentelemetry/api": {
          "optional": true
        },
        "@playwright/test": {
          "optional": true
        },
        "sass": {
          "optional": true
        }
      }
    },
    "node_modules/next/node_modules/postcss": {
      "version": "8.4.31",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.31.tgz",
      "integrity": "sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.6",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.0.2"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/node-releases": {
      "version": "2.0.21",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.21.tgz",
      "integrity": "sha512-5b0pgg78U3hwXkCM8Z9b2FJdPZlr9Psr9V2gQPESdGHqbntyFJKFW4r5TeWGFzafGY3hzs1JC62VEQMbl1JFkw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object-keys": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
      "integrity": "sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.assign": {
      "version": "4.1.7",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.7.tgz",
      "integrity": "sha512-nK28WOo+QIjBkDduTINE4JkF/UJJKyf2EJxvJKfblDpyg0Q+pkOHNTL0Qwy6NP6FhE/EnzV73BxxqcJaXY9anw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0",
        "has-symbols": "^1.1.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.entries": {
      "version": "1.1.9",
      "resolved": "https://registry.npmjs.org/object.entries/-/object.entries-1.1.9.tgz",
      "integrity": "sha512-8u/hfXFRBD1O0hPUjioLhoWFHRmt6tKA4/vZPyckBr18l1KE9uHrFaFaUi8MDRTpi4uak2goyPTSNJLXX2k2Hw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.fromentries": {
      "version": "2.0.8",
      "resolved": "https://registry.npmjs.org/object.fromentries/-/object.fromentries-2.0.8.tgz",
      "integrity": "sha512-k6E21FzySsSK5a21KRADBd/NGneRegFO5pLHfdQLpRDETUNJueLXs3WCzyQ3tFRDYgbq3KHGXfTbi2bs8WQ6rQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.groupby": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/object.groupby/-/object.groupby-1.0.3.tgz",
      "integrity": "sha512-+Lhy3TQTuzXI5hevh8sBGqbmurHbbIjAi0Z4S63nthVLmLxfbj4T54a4CfZrXIrt9iP4mVAPYMo/v99taj3wjQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.values": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/object.values/-/object.values-1.2.1.tgz",
      "integrity": "sha512-gXah6aZrcUxjWg2zR2MwouP2eHlCBzdV4pygudehaKXSGW4v2AsRQUK+lwwXhii6KFZcunEnmSUoYp5CXibxtA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/own-keys": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/own-keys/-/own-keys-1.0.1.tgz",
      "integrity": "sha512-qFOyK5PjiWZd+QQIh+1jhdb9LpxTF0qs7Pm8o5QHYZ0M3vKqSqzsZaEB6oWlxZ+q2sJBMI/Ktgd2N5ZwQoRHfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "get-intrinsic": "^1.2.6",
        "object-keys": "^1.1.1",
        "safe-push-apply": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/oxc-resolver": {
      "version": "11.8.3",
      "resolved": "https://registry.npmjs.org/oxc-resolver/-/oxc-resolver-11.8.3.tgz",
      "integrity": "sha512-wPY3eiw24QOiNqArh5FWRrKYr1Yuxya8bE8CV7yBfz7jodCrg0HqBu6cvHHSicxFug7D4TN6ox1hysA9arHTqw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "dependencies": {
        "napi-postinstall": "^0.3.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/Boshen"
      },
      "optionalDependencies": {
        "@oxc-resolver/binding-android-arm-eabi": "11.8.3",
        "@oxc-resolver/binding-android-arm64": "11.8.3",
        "@oxc-resolver/binding-darwin-arm64": "11.8.3",
        "@oxc-resolver/binding-darwin-x64": "11.8.3",
        "@oxc-resolver/binding-freebsd-x64": "11.8.3",
        "@oxc-resolver/binding-linux-arm-gnueabihf": "11.8.3",
        "@oxc-resolver/binding-linux-arm-musleabihf": "11.8.3",
        "@oxc-resolver/binding-linux-arm64-gnu": "11.8.3",
        "@oxc-resolver/binding-linux-arm64-musl": "11.8.3",
        "@oxc-resolver/binding-linux-ppc64-gnu": "11.8.3",
        "@oxc-resolver/binding-linux-riscv64-gnu": "11.8.3",
        "@oxc-resolver/binding-linux-riscv64-musl": "11.8.3",
        "@oxc-resolver/binding-linux-s390x-gnu": "11.8.3",
        "@oxc-resolver/binding-linux-x64-gnu": "11.8.3",
        "@oxc-resolver/binding-linux-x64-musl": "11.8.3",
        "@oxc-resolver/binding-wasm32-wasi": "11.8.3",
        "@oxc-resolver/binding-win32-arm64-msvc": "11.8.3",
        "@oxc-resolver/binding-win32-ia32-msvc": "11.8.3",
        "@oxc-resolver/binding-win32-x64-msvc": "11.8.3"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/package-json-from-dist": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/package-json-from-dist/-/package-json-from-dist-1.0.1.tgz",
      "integrity": "sha512-UEZIS3/by4OC8vL3P2dTXRETpebLI2NiI5vIrjaD/5UtrkFX/tNbwjTSRAGC/+7CAo2pIcBaRgWmcBBHcsaCIw==",
      "dev": true,
      "license": "BlueOak-1.0.0"
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-entities": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-4.0.2.tgz",
      "integrity": "sha512-GG2AQYWoLgL877gQIKeRPGO1xF9+eG1ujIb5soS5gPvLQ1y2o8FL90w2QWNdf9I361Mpp7726c+lj3U0qK1uGw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^2.0.0",
        "character-entities-legacy": "^3.0.0",
        "character-reference-invalid": "^2.0.0",
        "decode-named-character-reference": "^1.0.0",
        "is-alphanumerical": "^2.0.0",
        "is-decimal": "^2.0.0",
        "is-hexadecimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/parse-entities/node_modules/@types/unist": {
      "version": "2.0.11",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-2.0.11.tgz",
      "integrity": "sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==",
      "license": "MIT"
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-scurry": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
      "dev": true,
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.18"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pathe": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/pathe/-/pathe-2.0.3.tgz",
      "integrity": "sha512-WUjGcAqP1gQacoQe+OBJsFA7Ld4DyXuUIjZ5cc75cLHvJ7dtNsTugphxIADwspS+AraAUePCKrSVtPLFj/F88w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/pathval": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/pathval/-/pathval-2.0.1.tgz",
      "integrity": "sha512-//nshmD55c46FuFw26xV/xFAaB5HF9Xdap7HJBBnrKdAd6/GxDBaNA1870O79+9ueg61cZLSVc+OaFlfmObYVQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 14.16"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz",
      "integrity": "sha512-TfySrs/5nm8fQJDcBDuUng3VOUKsd7S+zqvbOTiGXHfxX4wK31ard+hoNuvkicM/2YFzlpDgABOevKSsB4G/FA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/playwright": {
      "version": "1.55.1",
      "resolved": "https://registry.npmjs.org/playwright/-/playwright-1.55.1.tgz",
      "integrity": "sha512-cJW4Xd/G3v5ovXtJJ52MAOclqeac9S/aGGgRzLabuF8TnIb6xHvMzKIa6JmrRzUkeXJgfL1MhukP0NK6l39h3A==",
      "devOptional": true,
      "license": "Apache-2.0",
      "dependencies": {
        "playwright-core": "1.55.1"
      },
      "bin": {
        "playwright": "cli.js"
      },
      "engines": {
        "node": ">=18"
      },
      "optionalDependencies": {
        "fsevents": "2.3.2"
      }
    },
    "node_modules/playwright-core": {
      "version": "1.55.1",
      "resolved": "https://registry.npmjs.org/playwright-core/-/playwright-core-1.55.1.tgz",
      "integrity": "sha512-Z6Mh9mkwX+zxSlHqdr5AOcJnfp+xUWLCt9uKV18fhzA8eyxUd8NUWzAjxUh55RZKSYwDGX0cfaySdhZJGMoJ+w==",
      "devOptional": true,
      "license": "Apache-2.0",
      "bin": {
        "playwright-core": "cli.js"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/playwright/node_modules/fsevents": {
      "version": "2.3.2",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.2.tgz",
      "integrity": "sha512-xiqMQR4xAeHTuB9uWm+fFRcIOgKBMiOBP+eXiyT7jsgVCq1bkVygt00oASowB7EdtpOHaaPgKt812P9ab+DDKA==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/possible-typed-array-names": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/possible-typed-array-names/-/possible-typed-array-names-1.1.0.tgz",
      "integrity": "sha512-/+5VFTchJDoVj3bhoqi6UeymcD00DAwb1nJwamzPvHEszJ4FpF6SNNbUbOS8yI56qHzdV8eK0qEfOSiodkTdxg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/postcss": {
      "version": "8.4.40",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.40.tgz",
      "integrity": "sha512-YF2kKIUzAofPMpfH6hOi2cGnv/HrUlfucspc7pDyvv7kGdqXrfj8SCl/t8owkEgKEuu8ZcRjSOxFxVLqwChZ2Q==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "nanoid": "^3.3.7",
        "picocolors": "^1.0.1",
        "source-map-js": "^1.2.0"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.1.0.tgz",
      "integrity": "sha512-oIAOTqgIo7q2EOwbhb8UalYePMvYoIeRY2YKntdpFQXNosSu3vLrniGgmH9OKs/qAkfoj5oB3le/7mINW1LCfw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/prettier": {
      "version": "3.6.2",
      "resolved": "https://registry.npmjs.org/prettier/-/prettier-3.6.2.tgz",
      "integrity": "sha512-I7AIg5boAr5R0FFtJ6rCfD+LFsWHp81dolrFD8S79U9tb8Az2nGrJncnMSnys+bpQJfRUzqs9hnA81OAA3hCuQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "bin": {
        "prettier": "bin/prettier.cjs"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/prettier/prettier?sponsor=1"
      }
    },
    "node_modules/prettier-plugin-tailwindcss": {
      "version": "0.5.14",
      "resolved": "https://registry.npmjs.org/prettier-plugin-tailwindcss/-/prettier-plugin-tailwindcss-0.5.14.tgz",
      "integrity": "sha512-Puaz+wPUAhFp8Lo9HuciYKM2Y2XExESjeT+9NQoVFXZsPPnc9VYss2SpxdQ6vbatmt8/4+SN0oe0I1cPDABg9Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14.21.3"
      },
      "peerDependencies": {
        "@ianvs/prettier-plugin-sort-imports": "*",
        "@prettier/plugin-pug": "*",
        "@shopify/prettier-plugin-liquid": "*",
        "@trivago/prettier-plugin-sort-imports": "*",
        "@zackad/prettier-plugin-twig-melody": "*",
        "prettier": "^3.0",
        "prettier-plugin-astro": "*",
        "prettier-plugin-css-order": "*",
        "prettier-plugin-import-sort": "*",
        "prettier-plugin-jsdoc": "*",
        "prettier-plugin-marko": "*",
        "prettier-plugin-organize-attributes": "*",
        "prettier-plugin-organize-imports": "*",
        "prettier-plugin-sort-imports": "*",
        "prettier-plugin-style-order": "*",
        "prettier-plugin-svelte": "*"
      },
      "peerDependenciesMeta": {
        "@ianvs/prettier-plugin-sort-imports": {
          "optional": true
        },
        "@prettier/plugin-pug": {
          "optional": true
        },
        "@shopify/prettier-plugin-liquid": {
          "optional": true
        },
        "@trivago/prettier-plugin-sort-imports": {
          "optional": true
        },
        "@zackad/prettier-plugin-twig-melody": {
          "optional": true
        },
        "prettier-plugin-astro": {
          "optional": true
        },
        "prettier-plugin-css-order": {
          "optional": true
        },
        "prettier-plugin-import-sort": {
          "optional": true
        },
        "prettier-plugin-jsdoc": {
          "optional": true
        },
        "prettier-plugin-marko": {
          "optional": true
        },
        "prettier-plugin-organize-attributes": {
          "optional": true
        },
        "prettier-plugin-organize-imports": {
          "optional": true
        },
        "prettier-plugin-sort-imports": {
          "optional": true
        },
        "prettier-plugin-style-order": {
          "optional": true
        },
        "prettier-plugin-svelte": {
          "optional": true
        }
      }
    },
    "node_modules/prisma": {
      "version": "5.22.0",
      "resolved": "https://registry.npmjs.org/prisma/-/prisma-5.22.0.tgz",
      "integrity": "sha512-vtpjW3XuYCSnMsNVBjLMNkTj6OZbudcPPTPYHqX0CJfpcdWciI1dM8uHETwmDxxiqEwCIE6WvXucWUetJgfu/A==",
      "devOptional": true,
      "hasInstallScript": true,
      "license": "Apache-2.0",
      "peer": true,
      "dependencies": {
        "@prisma/engines": "5.22.0"
      },
      "bin": {
        "prisma": "build/index.js"
      },
      "engines": {
        "node": ">=16.13"
      },
      "optionalDependencies": {
        "fsevents": "2.3.3"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/property-information": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-7.1.0.tgz",
      "integrity": "sha512-TwEZ+X+yCJmYfL7TPUOcvBZ4QfoT5YenQiJuX//0th53DE6w0xxLEtfK3iyryQFddXuvkIk51EEgrJQ0WJkOmQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/punycode.js": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode.js/-/punycode.js-2.3.1.tgz",
      "integrity": "sha512-uxFIHU0YlHYhDQtV4R9J6a52SLx28BCjT+4ieh7IGbgwVJWO+km431c4yRlREUAsAmt/uMjQUyQHNEPf0M39CA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "18.2.0",
      "resolved": "https://registry.npmjs.org/react/-/react-18.2.0.tgz",
      "integrity": "sha512-/3IjMdb2L9QbBdWiW5e3P2/npwMBaU9mHCSCUzNln0ZCYbcfTsGbTJrU/kGemdH2IWmB2ioZ+zkxtmq6g09fGQ==",
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.2.0",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.2.0.tgz",
      "integrity": "sha512-6IMTriUmvsjHUjNtEDudZfuDQUoWXVxKHhlEGSk81n4YFS+r/Kl99wXiwlVXtPBtJenozv2P+hxDsw9eA7Xo6g==",
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.0"
      },
      "peerDependencies": {
        "react": "^18.2.0"
      }
    },
    "node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/react-markdown": {
      "version": "10.1.0",
      "resolved": "https://registry.npmjs.org/react-markdown/-/react-markdown-10.1.0.tgz",
      "integrity": "sha512-qKxVopLT/TyA6BX3Ue5NwabOsAzm0Q7kAPwq6L+wWDwisYs7R8vZ0nRXqq6rkueboxpkjvLGU9fWifiX/ZZFxQ==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "hast-util-to-jsx-runtime": "^2.0.0",
        "html-url-attributes": "^3.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "remark-parse": "^11.0.0",
        "remark-rehype": "^11.0.0",
        "unified": "^11.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      },
      "peerDependencies": {
        "@types/react": ">=18",
        "react": ">=18"
      }
    },
    "node_modules/react-remove-scroll": {
      "version": "2.7.1",
      "resolved": "https://registry.npmjs.org/react-remove-scroll/-/react-remove-scroll-2.7.1.tgz",
      "integrity": "sha512-HpMh8+oahmIdOuS5aFKKY6Pyog+FNaZV/XyJOq7b4YFwsFHe5yYfdbIalI4k3vU2nSDql7YskmUseHsRrJqIPA==",
      "license": "MIT",
      "dependencies": {
        "react-remove-scroll-bar": "^2.3.7",
        "react-style-singleton": "^2.2.3",
        "tslib": "^2.1.0",
        "use-callback-ref": "^1.3.3",
        "use-sidecar": "^1.1.3"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-remove-scroll-bar": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/react-remove-scroll-bar/-/react-remove-scroll-bar-2.3.8.tgz",
      "integrity": "sha512-9r+yi9+mgU33AKcj6IbT9oRCO78WriSj6t/cF8DWBZJ9aOGPOTEDvdUDz1FwKim7QXWwmHqtdHnRJfhAxEG46Q==",
      "license": "MIT",
      "dependencies": {
        "react-style-singleton": "^2.2.2",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-style-singleton": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/react-style-singleton/-/react-style-singleton-2.2.3.tgz",
      "integrity": "sha512-b6jSvxvVnyptAiLjbkWLE/lOnR4lfTtDAl+eUC7RZy+QQWc6wRzIV2CE6xBuMmDxc2qIihtDCZD5NPOFl7fRBQ==",
      "license": "MIT",
      "dependencies": {
        "get-nonce": "^1.0.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/reflect.getprototypeof": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/reflect.getprototypeof/-/reflect.getprototypeof-1.0.10.tgz",
      "integrity": "sha512-00o4I+DVrefhv+nX0ulyi3biSHCPDe+yLv5o/p6d/UVlirijB8E16FtfwSAi4g3tcqrQ4lRAqQSoFEZJehYEcw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.7",
        "get-proto": "^1.0.1",
        "which-builtin-type": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/regexp.prototype.flags": {
      "version": "1.5.4",
      "resolved": "https://registry.npmjs.org/regexp.prototype.flags/-/regexp.prototype.flags-1.5.4.tgz",
      "integrity": "sha512-dYqgNSZbDwkaJ2ceRd9ojCGjBq+mOm9LmtXnAnEGyHhN/5R7iDW2TRw3h+o/jCFxus3P2LfWIIiwowAjANm7IA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-errors": "^1.3.0",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/remark-gfm": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/remark-gfm/-/remark-gfm-4.0.1.tgz",
      "integrity": "sha512-1quofZ2RQ9EWdeN34S79+KExV1764+wCUGop5CPL1WGdD0ocPpu91lzPGbwWMECpEpd42kJGQwzRfyov9j4yNg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-gfm": "^3.0.0",
        "micromark-extension-gfm": "^3.0.0",
        "remark-parse": "^11.0.0",
        "remark-stringify": "^11.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-parse": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-parse/-/remark-parse-11.0.0.tgz",
      "integrity": "sha512-FCxlKLNGknS5ba/1lmpYijMUzX2esxW5xQqjWxw2eHFfS2MSdaHVINFmhjo+qN1WhZhNimq0dZATN9pH0IDrpA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-rehype": {
      "version": "11.1.2",
      "resolved": "https://registry.npmjs.org/remark-rehype/-/remark-rehype-11.1.2.tgz",
      "integrity": "sha512-Dh7l57ianaEoIpzbp0PC9UKAdCSVklD8E5Rpw7ETfbTl3FqcOOgq5q2LVDhgGCkaBv7p24JXikPdvhhmHvKMsw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "unified": "^11.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-stringify": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-stringify/-/remark-stringify-11.0.0.tgz",
      "integrity": "sha512-1OSmLd3awB/t8qdoEOMazZkNsfVTeY4fTsgzcQFdXNq8ToTN4ZGwrMnlda4K6smTFKD+GRV6O48i6Z4iKgPPpw==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/reusify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz",
      "integrity": "sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/rimraf/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/rimraf/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/rimraf/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/rollup": {
      "version": "4.52.3",
      "resolved": "https://registry.npmjs.org/rollup/-/rollup-4.52.3.tgz",
      "integrity": "sha512-RIDh866U8agLgiIcdpB+COKnlCreHJLfIhWC3LVflku5YHfpnsIKigRZeFfMfCc4dVcqNVfQQ5gO/afOck064A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "1.0.8"
      },
      "bin": {
        "rollup": "dist/bin/rollup"
      },
      "engines": {
        "node": ">=18.0.0",
        "npm": ">=8.0.0"
      },
      "optionalDependencies": {
        "@rollup/rollup-android-arm-eabi": "4.52.3",
        "@rollup/rollup-android-arm64": "4.52.3",
        "@rollup/rollup-darwin-arm64": "4.52.3",
        "@rollup/rollup-darwin-x64": "4.52.3",
        "@rollup/rollup-freebsd-arm64": "4.52.3",
        "@rollup/rollup-freebsd-x64": "4.52.3",
        "@rollup/rollup-linux-arm-gnueabihf": "4.52.3",
        "@rollup/rollup-linux-arm-musleabihf": "4.52.3",
        "@rollup/rollup-linux-arm64-gnu": "4.52.3",
        "@rollup/rollup-linux-arm64-musl": "4.52.3",
        "@rollup/rollup-linux-loong64-gnu": "4.52.3",
        "@rollup/rollup-linux-ppc64-gnu": "4.52.3",
        "@rollup/rollup-linux-riscv64-gnu": "4.52.3",
        "@rollup/rollup-linux-riscv64-musl": "4.52.3",
        "@rollup/rollup-linux-s390x-gnu": "4.52.3",
        "@rollup/rollup-linux-x64-gnu": "4.52.3",
        "@rollup/rollup-linux-x64-musl": "4.52.3",
        "@rollup/rollup-openharmony-arm64": "4.52.3",
        "@rollup/rollup-win32-arm64-msvc": "4.52.3",
        "@rollup/rollup-win32-ia32-msvc": "4.52.3",
        "@rollup/rollup-win32-x64-gnu": "4.52.3",
        "@rollup/rollup-win32-x64-msvc": "4.52.3",
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/run-con": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/run-con/-/run-con-1.3.2.tgz",
      "integrity": "sha512-CcfE+mYiTcKEzg0IqS08+efdnH0oJ3zV0wSUFBNrMHMuxCtXvBCLzCJHatwuXDcu/RlhjTziTo/a1ruQik6/Yg==",
      "dev": true,
      "license": "(BSD-2-Clause OR MIT OR Apache-2.0)",
      "dependencies": {
        "deep-extend": "^0.6.0",
        "ini": "~4.1.0",
        "minimist": "^1.2.8",
        "strip-json-comments": "~3.1.1"
      },
      "bin": {
        "run-con": "cli.js"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/safe-array-concat": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/safe-array-concat/-/safe-array-concat-1.1.3.tgz",
      "integrity": "sha512-AURm5f0jYEOydBj7VQlVvDrjeFgthDdEF5H1dP+6mNpoXOMo1quQqJ4wvJDyRZ9+pO3kGWoOdmV08cSv2aJV6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "has-symbols": "^1.1.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">=0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-push-apply": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/safe-push-apply/-/safe-push-apply-1.0.0.tgz",
      "integrity": "sha512-iKE9w/Z7xCzUMIZqdBsp6pEQvwuEebH4vdpjcDWnyzaI6yl6O9FHvVpmGelvEHNsoY6wGblkxR6Zty/h00WiSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-regex-test": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/safe-regex-test/-/safe-regex-test-1.1.0.tgz",
      "integrity": "sha512-x/+Cz4YrimQxQccJf5mKEbIa1NzeCRNI5Ecl/ekmlYaampdNLPalVyIcCZNNH3MvmqBugV5TMYZXv0ljslUlaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-regex": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.7.2",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.2.tgz",
      "integrity": "sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-function-length": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.2.2.tgz",
      "integrity": "sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-function-name": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/set-function-name/-/set-function-name-2.0.2.tgz",
      "integrity": "sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "functions-have-names": "^1.2.3",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-proto": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/set-proto/-/set-proto-1.0.0.tgz",
      "integrity": "sha512-RJRdvCo6IAnPdsvP/7m6bsQqNnn1FCBX5ZNtFL98MmFF/4xAIJTIg1YbHW5DC2W5SKZanrC6i4HsJqlajw/dZw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/siginfo": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/siginfo/-/siginfo-2.0.0.tgz",
      "integrity": "sha512-ybx0WO1/8bSBLEWXZvEd7gMW3Sn3JFlW3TvX1nREbDLRNQNaeNN8WK0meBwPdAaOI7TtRRRJn/Es1zhrrCHu7g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/smol-toml": {
      "version": "1.4.2",
      "resolved": "https://registry.npmjs.org/smol-toml/-/smol-toml-1.4.2.tgz",
      "integrity": "sha512-rInDH6lCNiEyn3+hH8KVGFdbjc099j47+OSgbMrfDYX1CmXLfdKd7qi6IfcWj2wFxvSVkuI46M+wPGYfEOEj6g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">= 18"
      },
      "funding": {
        "url": "https://github.com/sponsors/cyyynthia"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/space-separated-tokens": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-2.0.2.tgz",
      "integrity": "sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/stable-hash": {
      "version": "0.0.5",
      "resolved": "https://registry.npmjs.org/stable-hash/-/stable-hash-0.0.5.tgz",
      "integrity": "sha512-+L3ccpzibovGXFK+Ap/f8LOS0ahMrHTf3xu7mMLSpEGU0EO9ucaysSylKo9eRDFNhWve/y275iPmIZ4z39a9iA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/stackback": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/stackback/-/stackback-0.0.2.tgz",
      "integrity": "sha512-1XMJE5fQo1jGH6Y/7ebnwPOBEkIEnT4QF32d5R1+VXdXveM0IBMJt8zfaxX1P3QhVwrYe+576+jkANtSS2mBbw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/std-env": {
      "version": "3.9.0",
      "resolved": "https://registry.npmjs.org/std-env/-/std-env-3.9.0.tgz",
      "integrity": "sha512-UGvjygr6F6tpH7o2qyqR6QYpwraIjKSdtzyBdyytFOHmPZY917kwdwLG0RbOjWOnKmnm3PeHjaoLLMie7kPLQw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/stop-iteration-iterator": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/stop-iteration-iterator/-/stop-iteration-iterator-1.1.0.tgz",
      "integrity": "sha512-eLoXW/DHyl62zxY4SCaIgnRhuMr6ri4juEYARS8E6sCEqzKpOiE521Ucofdx+KnDZl5xmvGYaaKCk5FEOxJCoQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "internal-slot": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/streamsearch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/streamsearch/-/streamsearch-1.1.0.tgz",
      "integrity": "sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/string-width-cjs/node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string.prototype.includes": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/string.prototype.includes/-/string.prototype.includes-2.0.1.tgz",
      "integrity": "sha512-o7+c9bW6zpAdJHTtujeePODAhkuicdAryFsfVKwA+wGw89wJ4GTY484WTucM9hLtDEOpOvI+aHnzqnC5lHp4Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/string.prototype.matchall": {
      "version": "4.0.12",
      "resolved": "https://registry.npmjs.org/string.prototype.matchall/-/string.prototype.matchall-4.0.12.tgz",
      "integrity": "sha512-6CC9uyBL+/48dYizRf7H7VAYCMCNTBeM78x/VTUe9bFEaxBepPJDa1Ow99LqI/1yF7kuy7Q3cQsYMrcjGUcskA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "regexp.prototype.flags": "^1.5.3",
        "set-function-name": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.repeat": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/string.prototype.repeat/-/string.prototype.repeat-1.0.0.tgz",
      "integrity": "sha512-0u/TldDbKD8bFCQ/4f5+mNRrXwZ8hg2w7ZR8wa16e8z9XpePWl3eGEcUD0OXpEH/VJH/2G3gjUtR3ZOiBe2S/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.1.3",
        "es-abstract": "^1.17.5"
      }
    },
    "node_modules/string.prototype.trim": {
      "version": "1.2.10",
      "resolved": "https://registry.npmjs.org/string.prototype.trim/-/string.prototype.trim-1.2.10.tgz",
      "integrity": "sha512-Rs66F0P/1kedk5lyYyH9uBzuiI/kNRmwJAR9quK6VOtIpZ2G+hMZd+HQbbv25MgCA6gEffoMZYxlTod4WcdrKA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-data-property": "^1.1.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-object-atoms": "^1.0.0",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimend": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/string.prototype.trimend/-/string.prototype.trimend-1.0.9.tgz",
      "integrity": "sha512-G7Ok5C6E/j4SGfyLCloXTrngQIQU3PWtXGst3yM7Bea9FRURf1S42ZHlZZtsNque2FN2PoUhfZXYLNWwEr4dLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimstart": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimstart/-/string.prototype.trimstart-1.0.8.tgz",
      "integrity": "sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/stringify-entities": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/stringify-entities/-/stringify-entities-4.0.4.tgz",
      "integrity": "sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==",
      "license": "MIT",
      "dependencies": {
        "character-entities-html4": "^2.0.0",
        "character-entities-legacy": "^3.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/strip-ansi": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.2.tgz",
      "integrity": "sha512-gmBGslpoQJtgnMAvOVqGZpEz9dyoKTCzy2nfz/n8aIFhN/jCE/rCmcxabB6jOOHV+0WNnylOxaxBQPSvcWklhA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/strip-literal": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/strip-literal/-/strip-literal-3.1.0.tgz",
      "integrity": "sha512-8r3mkIM/2+PpjHoOtiAW8Rg3jJLHaV7xPwG+YRGrv6FP0wwk/toTpATxWYOW0BKdWwl82VT2tFYi5DlROa0Mxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^9.0.1"
      },
      "funding": {
        "url": "https://github.com/sponsors/antfu"
      }
    },
    "node_modules/strip-literal/node_modules/js-tokens": {
      "version": "9.0.1",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-9.0.1.tgz",
      "integrity": "sha512-mxa9E9ITFOt0ban3j6L5MpjwegGz6lBQmM1IJkWeBZGcMxto50+eWdjC/52xDbS2vy0k7vIMK0Fe2wfL9OQSpQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/style-to-js": {
      "version": "1.1.17",
      "resolved": "https://registry.npmjs.org/style-to-js/-/style-to-js-1.1.17.tgz",
      "integrity": "sha512-xQcBGDxJb6jjFCTzvQtfiPn6YvvP2O8U1MDIPNfJQlWMYfktPy+iGsHE7cssjs7y84d9fQaK4UF3RIJaAHSoYA==",
      "license": "MIT",
      "dependencies": {
        "style-to-object": "1.0.9"
      }
    },
    "node_modules/style-to-object": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/style-to-object/-/style-to-object-1.0.9.tgz",
      "integrity": "sha512-G4qppLgKu/k6FwRpHiGiKPaPTFcG3g4wNVX/Qsfu+RqQM30E7Tyu/TEgxcL9PNLF5pdRLwQdE3YKKf+KF2Dzlw==",
      "license": "MIT",
      "dependencies": {
        "inline-style-parser": "0.2.4"
      }
    },
    "node_modules/styled-jsx": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/styled-jsx/-/styled-jsx-5.1.1.tgz",
      "integrity": "sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==",
      "license": "MIT",
      "dependencies": {
        "client-only": "0.0.1"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "peerDependencies": {
        "react": ">= 16.8.0 || 17.x.x || ^18.0.0-0"
      },
      "peerDependenciesMeta": {
        "@babel/core": {
          "optional": true
        },
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwind-merge": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/tailwind-merge/-/tailwind-merge-2.6.0.tgz",
      "integrity": "sha512-P+Vu1qXfzediirmHOC3xKGAYeZtPcV9g76X+xg2FD4tYgR71ewMA35Y3sCz3zhiN/dwefRpJX0yBcgwi1fXNQA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/dcastil"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.10",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.10.tgz",
      "integrity": "sha512-KWZkVPm7yJRhdu4SRSl9d4AK2wM3a50UsvgHZO7xY77NQr2V+fIrEuoDGQcbvswWvFGbS2f6e+jC/6WJm1Dl0w==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.5.3",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.0",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.0",
        "lilconfig": "^2.1.0",
        "micromatch": "^4.0.5",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.0.0",
        "postcss": "^8.4.23",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.1",
        "postcss-nested": "^6.0.1",
        "postcss-selector-parser": "^6.0.11",
        "resolve": "^1.22.2",
        "sucrase": "^3.32.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tailwindcss-animate": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/tailwindcss-animate/-/tailwindcss-animate-1.0.7.tgz",
      "integrity": "sha512-bl6mpH3T7I3UFxuvDEXLxy/VuFxBk5bbzplh7tXI68mwMokNYd1t9qPBHlnyTwfa4JGC4zP516I1hYYtQ/vspA==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "tailwindcss": ">=3.0.0 || insiders"
      }
    },
    "node_modules/tailwindcss/node_modules/lilconfig": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-2.1.0.tgz",
      "integrity": "sha512-utWOt/GHzuUxnLKxB6dk81RoOeoNeHgbrXiuGk4yyF5qlRz+iIVWu56E2fqGHFrXz0QNUhLB/8nKqvRH66JKGQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tinybench": {
      "version": "2.9.0",
      "resolved": "https://registry.npmjs.org/tinybench/-/tinybench-2.9.0.tgz",
      "integrity": "sha512-0+DUvqWMValLmha6lr4kD8iAMK1HzV0/aKnCtWb9v9641TnP/MFb7Pc2bxoxQjTXAErryXVgUOfv2YqNllqGeg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/tinyexec": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/tinyexec/-/tinyexec-0.3.2.tgz",
      "integrity": "sha512-KQQR9yN7R5+OSwaK0XQoj22pwHoTlgYqmUscPYoknOoWCWfj/5/ABTMRi69FrKU5ffPVh5QcFikpWJI/P1ocHA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/tinyglobby": {
      "version": "0.2.15",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.15.tgz",
      "integrity": "sha512-j2Zq4NyQYG5XMST4cbs02Ak8iJUdxRM0XI5QyxXuZOzKOINmWurp3smXu3y5wDcJrptwpSjgXHzIQxR0omXljQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/tinyglobby/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/tinyglobby/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/tinypool": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/tinypool/-/tinypool-1.1.1.tgz",
      "integrity": "sha512-Zba82s87IFq9A9XmjiX5uZA/ARWDrB03OHlq+Vw1fSdt0I+4/Kutwy8BP4Y/y/aORMo61FQ0vIb5j44vSo5Pkg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^18.0.0 || >=20.0.0"
      }
    },
    "node_modules/tinyrainbow": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/tinyrainbow/-/tinyrainbow-2.0.0.tgz",
      "integrity": "sha512-op4nsTR47R6p0vMUUoYl/a+ljLFVtlfaXkLQmqfLR1qHma1h/ysYk4hEXZ880bf2CYgTskvTa/e196Vd5dDQXw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tinyspy": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/tinyspy/-/tinyspy-4.0.4.tgz",
      "integrity": "sha512-azl+t0z7pw/z958Gy9svOTuzqIk6xq+NSheJzn5MMWtWTFywIacg2wUlzKFGtt3cthx0r2SxMK0yzJOR0IES7Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/trim-lines": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/trim-lines/-/trim-lines-3.0.1.tgz",
      "integrity": "sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/trough": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/trough/-/trough-2.2.0.tgz",
      "integrity": "sha512-tmMpK00BjZiUyVyvrBK7knerNgmgvcV/KLVyuma/SC+TQN167GrMRciANTz09+k3zW8L8t60jWO1GpfkZdjTaw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.4.3.tgz",
      "integrity": "sha512-i3eMG77UTMD0hZhgRS562pv83RC6ukSAC2GMNWc+9dieh/+jDM5u5YG+NHX6VNDRHQcHwmsTHctP9LhbC3WxVw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/ts-node": {
      "version": "10.9.2",
      "resolved": "https://registry.npmjs.org/ts-node/-/ts-node-10.9.2.tgz",
      "integrity": "sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@cspotcode/source-map-support": "^0.8.0",
        "@tsconfig/node10": "^1.0.7",
        "@tsconfig/node12": "^1.0.7",
        "@tsconfig/node14": "^1.0.0",
        "@tsconfig/node16": "^1.0.2",
        "acorn": "^8.4.1",
        "acorn-walk": "^8.1.1",
        "arg": "^4.1.0",
        "create-require": "^1.1.0",
        "diff": "^4.0.1",
        "make-error": "^1.1.1",
        "v8-compile-cache-lib": "^3.0.1",
        "yn": "3.1.1"
      },
      "bin": {
        "ts-node": "dist/bin.js",
        "ts-node-cwd": "dist/bin-cwd.js",
        "ts-node-esm": "dist/bin-esm.js",
        "ts-node-script": "dist/bin-script.js",
        "ts-node-transpile-only": "dist/bin-transpile.js",
        "ts-script": "dist/bin-script-deprecated.js"
      },
      "peerDependencies": {
        "@swc/core": ">=1.2.50",
        "@swc/wasm": ">=1.2.50",
        "@types/node": "*",
        "typescript": ">=2.7"
      },
      "peerDependenciesMeta": {
        "@swc/core": {
          "optional": true
        },
        "@swc/wasm": {
          "optional": true
        }
      }
    },
    "node_modules/ts-node/node_modules/arg": {
      "version": "4.1.3",
      "resolved": "https://registry.npmjs.org/arg/-/arg-4.1.3.tgz",
      "integrity": "sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/tsconfig-paths": {
      "version": "3.15.0",
      "resolved": "https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.15.0.tgz",
      "integrity": "sha512-2Ac2RgzDe/cn48GvOe3M+o82pEFewD3UPbyoUHHdKasHwJKjds4fLXWf/Ux5kATBKN20oaFGu+jbElp1pos0mg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/json5": "^0.0.29",
        "json5": "^1.0.2",
        "minimist": "^1.2.6",
        "strip-bom": "^3.0.0"
      }
    },
    "node_modules/tslib": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.8.1.tgz",
      "integrity": "sha512-oJFu94HQb+KVduSUQL7wnpmqnfmLsOA/nAh6b6EH0wCEoK0/mPeXU6c3wKDV83MkOuHPRHtSXKKU99IBazS/2w==",
      "license": "0BSD"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typed-array-buffer": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-buffer/-/typed-array-buffer-1.0.3.tgz",
      "integrity": "sha512-nAYYwfY3qnzX30IkA6AQZjVbtK6duGontcQm1WSG1MD94YLqK0515GNApXkoxKOWMusVssAHWLh9SeaoefYFGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/typed-array-byte-length": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-byte-length/-/typed-array-byte-length-1.0.3.tgz",
      "integrity": "sha512-BaXgOuIxz8n8pIq3e7Atg/7s+DpiYrxn4vdot3w9KbnBhcRQq6o3xemQdIfynqSeXeDrF32x+WvfzmOjPiY9lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-byte-offset": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/typed-array-byte-offset/-/typed-array-byte-offset-1.0.4.tgz",
      "integrity": "sha512-bTlAFB/FBYMcuX81gbL4OcpH5PmlFHqlCCpAl8AlEzMz5k53oNDvN8p1PNOWLEmI2x4orp3raOFB51tv9X+MFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.15",
        "reflect.getprototypeof": "^1.0.9"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-length": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/typed-array-length/-/typed-array-length-1.0.7.tgz",
      "integrity": "sha512-3KS2b+kL7fsuk/eJZ7EQdnEmQoaho/r6KUef7hxvltNA5DR8NAUM+8wJMbJyZ4G9/7i3v5zPBIMN5aybAh2/Jg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "is-typed-array": "^1.1.13",
        "possible-typed-array-names": "^1.0.0",
        "reflect.getprototypeof": "^1.0.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typescript": {
      "version": "5.4.5",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.4.5.tgz",
      "integrity": "sha512-vcI4UpRgg81oIRUFwR0WSIHKt11nJ7SAVlYNIu+QpqeyXP+gpQJy/Z4+F0aGxSE4MqwjyXvW/TzgkLAx2AGHwQ==",
      "dev": true,
      "license": "Apache-2.0",
      "peer": true,
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/uc.micro": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/uc.micro/-/uc.micro-2.1.0.tgz",
      "integrity": "sha512-ARDJmphmdvUk6Glw7y9DQ2bFkKBHwQHLi2lsaH6PPmz/Ka9sFOBsBluozhDltWmnv9u/cF6Rt87znRTPV+yp/A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/unbox-primitive": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/unbox-primitive/-/unbox-primitive-1.1.0.tgz",
      "integrity": "sha512-nWJ91DjeOkej/TA8pXQ3myruKpKEYgqvpw9lz4OPHj/NWFNluYrjbz9j01CJ8yKQd2g4jFoOkINCTW2I5LEEyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-bigints": "^1.0.2",
        "has-symbols": "^1.1.0",
        "which-boxed-primitive": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/undici-types": {
      "version": "5.26.5",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-5.26.5.tgz",
      "integrity": "sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/unicorn-magic": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/unicorn-magic/-/unicorn-magic-0.3.0.tgz",
      "integrity": "sha512-+QBBXBCvifc56fsbuxZQ6Sic3wqqc3WWaqxs58gvJrcOuN83HGTCwz3oS5phzU9LthRNE9VrJCFCLUgHeeFnfA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/unified": {
      "version": "11.0.5",
      "resolved": "https://registry.npmjs.org/unified/-/unified-11.0.5.tgz",
      "integrity": "sha512-xKvGhPWw3k84Qjh8bI3ZeJjqnyadK+GEFtazSfZv/rKeTkTjOJho6mFqh2SM96iIcZokxiOpg78GazTSg8+KHA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "bail": "^2.0.0",
        "devlop": "^1.0.0",
        "extend": "^3.0.0",
        "is-plain-obj": "^4.0.0",
        "trough": "^2.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-is": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-is/-/unist-util-is-6.0.0.tgz",
      "integrity": "sha512-2qCTHimwdxLfz+YzdGfkqNlH0tLi9xjTnHddPmJwtIG9MGsdbutfTc4P+haPD7l7Cjxf/WZj+we5qfVPvvxfYw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-position": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-position/-/unist-util-position-5.0.0.tgz",
      "integrity": "sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-stringify-position": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-stringify-position/-/unist-util-stringify-position-4.0.0.tgz",
      "integrity": "sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-visit/-/unist-util-visit-5.0.0.tgz",
      "integrity": "sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit-parents": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/unist-util-visit-parents/-/unist-util-visit-parents-6.0.1.tgz",
      "integrity": "sha512-L/PqWzfTP9lzzEa6CKs0k2nARxTdZduw3zyh8d2NVBnsyvHjSX4TWse388YrrQKbvI8w20fGjGlhgT96WwKykw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unrs-resolver": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/unrs-resolver/-/unrs-resolver-1.11.1.tgz",
      "integrity": "sha512-bSjt9pjaEBnNiGgc9rUiHGKv5l4/TGzDmYw3RhnkJGtLhbnnA/5qJj7x3dNDCRx/PJxu774LlH8lCOlB4hEfKg==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "dependencies": {
        "napi-postinstall": "^0.3.0"
      },
      "funding": {
        "url": "https://opencollective.com/unrs-resolver"
      },
      "optionalDependencies": {
        "@unrs/resolver-binding-android-arm-eabi": "1.11.1",
        "@unrs/resolver-binding-android-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-arm64": "1.11.1",
        "@unrs/resolver-binding-darwin-x64": "1.11.1",
        "@unrs/resolver-binding-freebsd-x64": "1.11.1",
        "@unrs/resolver-binding-linux-arm-gnueabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm-musleabihf": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-arm64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-ppc64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-riscv64-musl": "1.11.1",
        "@unrs/resolver-binding-linux-s390x-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-gnu": "1.11.1",
        "@unrs/resolver-binding-linux-x64-musl": "1.11.1",
        "@unrs/resolver-binding-wasm32-wasi": "1.11.1",
        "@unrs/resolver-binding-win32-arm64-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-ia32-msvc": "1.11.1",
        "@unrs/resolver-binding-win32-x64-msvc": "1.11.1"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/use-callback-ref": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/use-callback-ref/-/use-callback-ref-1.3.3.tgz",
      "integrity": "sha512-jQL3lRnocaFtu3V00JToYz/4QkNWswxijDaCVNZRiRTO3HQDLsdu1ZtmIUvV4yPp+rvWm5j0y0TG/S61cuijTg==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/use-sidecar": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/use-sidecar/-/use-sidecar-1.1.3.tgz",
      "integrity": "sha512-Fedw0aZvkhynoPYlA5WXrMCAMm+nSWdZt6lzJQ7Ok8S6Q+VsHmHpRWndVRJ8Be0ZbkfPc5LRYH+5XrzXcEeLRQ==",
      "license": "MIT",
      "dependencies": {
        "detect-node-es": "^1.1.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/v8-compile-cache-lib": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/v8-compile-cache-lib/-/v8-compile-cache-lib-3.0.1.tgz",
      "integrity": "sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/vfile": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/vfile/-/vfile-6.0.3.tgz",
      "integrity": "sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vfile-message": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/vfile-message/-/vfile-message-4.0.3.tgz",
      "integrity": "sha512-QTHzsGd1EhbZs4AsQ20JX1rC3cOlt/IWJruk893DfLRr57lcnOeMaWG4K0JrRta4mIJZKth2Au3mM3u03/JWKw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vite-node": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/vite-node/-/vite-node-3.2.4.tgz",
      "integrity": "sha512-EbKSKh+bh1E1IFxeO0pg1n4dvoOTt0UDiXMd/qn++r98+jPO1xtJilvXldeuQ8giIB5IkpjCgMleHMNEsGH6pg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cac": "^6.7.14",
        "debug": "^4.4.1",
        "es-module-lexer": "^1.7.0",
        "pathe": "^2.0.3",
        "vite": "^5.0.0 || ^6.0.0 || ^7.0.0-0"
      },
      "bin": {
        "vite-node": "vite-node.mjs"
      },
      "engines": {
        "node": "^18.0.0 || ^20.0.0 || >=22.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      }
    },
    "node_modules/vite-node/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/vite-node/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/vite-node/node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/vite-node/node_modules/undici-types": {
      "version": "7.14.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-7.14.0.tgz",
      "integrity": "sha512-QQiYxHuyZ9gQUIrmPo3IA+hUl4KYk8uSA7cHrcKd/l3p1OTpZcM0Tbp9x7FAtXdAYhlasd60ncPpgu6ihG6TOA==",
      "dev": true,
      "license": "MIT",
      "optional": true
    },
    "node_modules/vite-node/node_modules/vite": {
      "version": "7.1.8",
      "resolved": "https://registry.npmjs.org/vite/-/vite-7.1.8.tgz",
      "integrity": "sha512-oBXvfSHEOL8jF+R9Am7h59Up07kVVGH1NrFGFoEG6bPDZP3tGpQhvkBpy5x7U6+E6wZCu9OihsWgJqDbQIm8LQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "esbuild": "^0.25.0",
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3",
        "postcss": "^8.5.6",
        "rollup": "^4.43.0",
        "tinyglobby": "^0.2.15"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^20.19.0 || >=22.12.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^20.19.0 || >=22.12.0",
        "jiti": ">=1.21.0",
        "less": "^4.0.0",
        "lightningcss": "^1.21.0",
        "sass": "^1.70.0",
        "sass-embedded": "^1.70.0",
        "stylus": ">=0.54.8",
        "sugarss": "^5.0.0",
        "terser": "^5.16.0",
        "tsx": "^4.8.1",
        "yaml": "^2.4.2"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "jiti": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        },
        "tsx": {
          "optional": true
        },
        "yaml": {
          "optional": true
        }
      }
    },
    "node_modules/vitest": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/vitest/-/vitest-3.2.4.tgz",
      "integrity": "sha512-LUCP5ev3GURDysTWiP47wRRUpLKMOfPh+yKTx3kVIEiu5KOMeqzpnYNsKyOoVrULivR8tLcks4+lga33Whn90A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/chai": "^5.2.2",
        "@vitest/expect": "3.2.4",
        "@vitest/mocker": "3.2.4",
        "@vitest/pretty-format": "^3.2.4",
        "@vitest/runner": "3.2.4",
        "@vitest/snapshot": "3.2.4",
        "@vitest/spy": "3.2.4",
        "@vitest/utils": "3.2.4",
        "chai": "^5.2.0",
        "debug": "^4.4.1",
        "expect-type": "^1.2.1",
        "magic-string": "^0.30.17",
        "pathe": "^2.0.3",
        "picomatch": "^4.0.2",
        "std-env": "^3.9.0",
        "tinybench": "^2.9.0",
        "tinyexec": "^0.3.2",
        "tinyglobby": "^0.2.14",
        "tinypool": "^1.1.1",
        "tinyrainbow": "^2.0.0",
        "vite": "^5.0.0 || ^6.0.0 || ^7.0.0-0",
        "vite-node": "3.2.4",
        "why-is-node-running": "^2.3.0"
      },
      "bin": {
        "vitest": "vitest.mjs"
      },
      "engines": {
        "node": "^18.0.0 || ^20.0.0 || >=22.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      },
      "peerDependencies": {
        "@edge-runtime/vm": "*",
        "@types/debug": "^4.1.12",
        "@types/node": "^18.0.0 || ^20.0.0 || >=22.0.0",
        "@vitest/browser": "3.2.4",
        "@vitest/ui": "3.2.4",
        "happy-dom": "*",
        "jsdom": "*"
      },
      "peerDependenciesMeta": {
        "@edge-runtime/vm": {
          "optional": true
        },
        "@types/debug": {
          "optional": true
        },
        "@types/node": {
          "optional": true
        },
        "@vitest/browser": {
          "optional": true
        },
        "@vitest/ui": {
          "optional": true
        },
        "happy-dom": {
          "optional": true
        },
        "jsdom": {
          "optional": true
        }
      }
    },
    "node_modules/vitest/node_modules/@vitest/mocker": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/@vitest/mocker/-/mocker-3.2.4.tgz",
      "integrity": "sha512-46ryTE9RZO/rfDd7pEqFl7etuyzekzEhUbTW3BvmeO/BcCMEgq59BKhek3dXDWgAj4oMK6OZi+vRr1wPW6qjEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@vitest/spy": "3.2.4",
        "estree-walker": "^3.0.3",
        "magic-string": "^0.30.17"
      },
      "funding": {
        "url": "https://opencollective.com/vitest"
      },
      "peerDependencies": {
        "msw": "^2.4.9",
        "vite": "^5.0.0 || ^6.0.0 || ^7.0.0-0"
      },
      "peerDependenciesMeta": {
        "msw": {
          "optional": true
        },
        "vite": {
          "optional": true
        }
      }
    },
    "node_modules/vitest/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/vitest/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/vitest/node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/vitest/node_modules/vite": {
      "version": "7.1.8",
      "resolved": "https://registry.npmjs.org/vite/-/vite-7.1.8.tgz",
      "integrity": "sha512-oBXvfSHEOL8jF+R9Am7h59Up07kVVGH1NrFGFoEG6bPDZP3tGpQhvkBpy5x7U6+E6wZCu9OihsWgJqDbQIm8LQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "esbuild": "^0.25.0",
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3",
        "postcss": "^8.5.6",
        "rollup": "^4.43.0",
        "tinyglobby": "^0.2.15"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^20.19.0 || >=22.12.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^20.19.0 || >=22.12.0",
        "jiti": ">=1.21.0",
        "less": "^4.0.0",
        "lightningcss": "^1.21.0",
        "sass": "^1.70.0",
        "sass-embedded": "^1.70.0",
        "stylus": ">=0.54.8",
        "sugarss": "^5.0.0",
        "terser": "^5.16.0",
        "tsx": "^4.8.1",
        "yaml": "^2.4.2"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "jiti": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        },
        "tsx": {
          "optional": true
        },
        "yaml": {
          "optional": true
        }
      }
    },
    "node_modules/walk-up-path": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/walk-up-path/-/walk-up-path-4.0.0.tgz",
      "integrity": "sha512-3hu+tD8YzSLGuFYtPRb48vdhKMi0KQV5sn+uWr8+7dMEq/2G/dtLrdDinkLjqq5TIbIBjYJ4Ax/n3YiaW7QM8A==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "20 || >=22"
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/which-boxed-primitive": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/which-boxed-primitive/-/which-boxed-primitive-1.1.1.tgz",
      "integrity": "sha512-TbX3mj8n0odCBFVlY8AxkqcHASw3L60jIuF8jFP78az3C2YhmGvqbHBpAjTRH2/xqYunrJ9g1jSyjCjpoWzIAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-bigint": "^1.1.0",
        "is-boolean-object": "^1.2.1",
        "is-number-object": "^1.1.1",
        "is-string": "^1.1.1",
        "is-symbol": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-builtin-type": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/which-builtin-type/-/which-builtin-type-1.2.1.tgz",
      "integrity": "sha512-6iBczoX+kDQ7a3+YJBnh3T+KZRxM/iYNPXicqk66/Qfm1b93iu+yOImkg0zHbj5LNOcNv1TEADiZ0xa34B4q6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "function.prototype.name": "^1.1.6",
        "has-tostringtag": "^1.0.2",
        "is-async-function": "^2.0.0",
        "is-date-object": "^1.1.0",
        "is-finalizationregistry": "^1.1.0",
        "is-generator-function": "^1.0.10",
        "is-regex": "^1.2.1",
        "is-weakref": "^1.0.2",
        "isarray": "^2.0.5",
        "which-boxed-primitive": "^1.1.0",
        "which-collection": "^1.0.2",
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-collection": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-collection/-/which-collection-1.0.2.tgz",
      "integrity": "sha512-K4jVyjnBdgvc86Y6BkaLZEN933SwYOuBFkdmBu9ZfkcAbdVbpITnDmjvZ/aQjRXQrv5EPkTnD1s39GiiqbngCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-map": "^2.0.3",
        "is-set": "^2.0.3",
        "is-weakmap": "^2.0.2",
        "is-weakset": "^2.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-typed-array": {
      "version": "1.1.19",
      "resolved": "https://registry.npmjs.org/which-typed-array/-/which-typed-array-1.1.19.tgz",
      "integrity": "sha512-rEvr90Bck4WZt9HHFC4DJMsjvu7x+r6bImz0/BrbWb7A2djJ8hnZMrWnHo9F8ssv0OMErasDhftrfROTyqSDrw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "for-each": "^0.3.5",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/why-is-node-running": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/why-is-node-running/-/why-is-node-running-2.3.0.tgz",
      "integrity": "sha512-hUrmaWBdVDcxvYqnyh09zunKzROWjbZTiNy8dBEjkS7ehEDQibXJ7XvlmtbwuTclUiIyN+CyXQD4Vmko8fNm8w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "siginfo": "^2.0.0",
        "stackback": "0.0.2"
      },
      "bin": {
        "why-is-node-running": "cli.js"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yaml": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.8.1.tgz",
      "integrity": "sha512-lcYcMxX2PO9XMGvAJkJ3OsNMw+/7FKes7/hgerGUYWIoWu5j/+YQqcZr5JnPZWzOsEBgMbSbiSTn/dv/69Mkpw==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14.6"
      }
    },
    "node_modules/yn": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yn/-/yn-3.1.1.tgz",
      "integrity": "sha512-Ux4ygGWsu2c7isFWe8Yu1YluJmqVhxqK2cLXNQA5AcC3QfbGNpM7fu0Y8b/z16pXLnFxZYvWhd3fhBY9DLmC6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/zod": {
      "version": "4.1.12",
      "resolved": "https://registry.npmjs.org/zod/-/zod-4.1.12.tgz",
      "integrity": "sha512-JInaHOamG8pt5+Ey8kGmdcAcg3OL9reK8ltczgHTAwNhMys/6ThXHityHxVV2p3fkw/c+MAvBHFVYHFZDmjMCQ==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/colinhacks"
      }
    },
    "node_modules/zwitch": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/zwitch/-/zwitch-2.0.4.tgz",
      "integrity": "sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    }
  }
}

```

## `package.json`

```json
{
  "name": "atticus-webdev",
  "version": "0.0.0",
  "private": true,
  "workspaces": [
    "admin"
  ],
  "description": "Sandbox copy of the Atticus Next.js frontend for local experimentation.",
  "scripts": {
    "dev": "next dev -p 3000",
    "build": "next build",
    "start": "next start -p 3000",
    "lint": "next lint",
    "format": "prettier --write .",
    "format:check": "prettier --check .",
    "typecheck": "tsc --noEmit",
    "prisma:generate": "prisma generate",
    "db:migrate": "prisma migrate deploy",
    "db:seed": "prisma db seed",
    "test:unit": "vitest run",
    "test:unit:watch": "vitest",
    "test:e2e": "playwright test --reporter=list",
    "audit:icons": "node scripts/icon-audit.mjs",
    "audit:routes": "node scripts/route-audit.mjs"
  },
  "dependencies": {
    "@prisma/client": "^5.18.0",
    "@radix-ui/react-dialog": "^1.1.15",
    "@radix-ui/react-slot": "^1.0.4",
    "@radix-ui/react-tabs": "^1.0.5",
    "clsx": "^2.1.1",
    "lucide-react": "^0.452.0",
    "next": "^14.2.33",
    "react": "18.2.0",
    "react-dom": "18.2.0",
    "react-markdown": "^10.1.0",
    "remark-gfm": "^4.0.1",
    "tailwind-merge": "^2.6.0",
    "zod": "4.1.12"
  },
  "devDependencies": {
    "@playwright/test": "^1.45.2",
    "@types/node": "20.14.9",
    "@types/react": "18.3.5",
    "@types/react-dom": "18.3.0",
    "autoprefixer": "10.4.21",
    "eslint": "8.57.0",
    "eslint-config-next": "14.2.5",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-react": "^7.37.5",
    "eslint-plugin-tailwindcss": "^3.13.0",
    "knip": "5.66.0",
    "markdownlint-cli": "^0.45.0",
    "markdownlint-cli2": "^0.18.1",
    "postcss": "8.4.40",
    "prettier": "^3.3.3",
    "prettier-plugin-tailwindcss": "^0.5.14",
    "prisma": "^5.18.0",
    "tailwindcss": "3.4.10",
    "tailwindcss-animate": "^1.0.7",
    "ts-node": "^10.9.2",
    "typescript": "5.4.5",
    "vitest": "^3.2.4"
  },
  "prisma": {
    "seed": "ts-node --esm prisma/seed.ts"
  }
}

```

## `postcss.config.js`

```javascript
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};

```

## `prisma/migrations/20240702120000_auth_rbac/migration.sql`

```sql
-- Prisma migration for Auth.js + RBAC + glossary storage
-- Phase 3 rollout. Applies tables, enums, triggers, and RLS policies.

CREATE SCHEMA IF NOT EXISTS app_private;

DO $$
DECLARE
  db_name text := current_database();
BEGIN
  EXECUTE format('ALTER DATABASE %I SET app.current_user_role = %L', db_name, 'SERVICE');
  EXECUTE format('ALTER DATABASE %I SET app.current_org_id = %L', db_name, '');
  EXECUTE format('ALTER DATABASE %I SET app.current_user_id = %L', db_name, '');
  EXECUTE format('ALTER DATABASE %I SET app.pgvector_lists = %L', db_name, '100');
  EXECUTE format('ALTER DATABASE %I SET app.pgvector_dimension = %L', db_name, '3072');
END
$$;

CREATE OR REPLACE FUNCTION app_private.update_updated_at()
RETURNS trigger AS $$
BEGIN
  NEW."updatedAt" = CURRENT_TIMESTAMP;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TYPE "Role" AS ENUM ('USER', 'REVIEWER', 'ADMIN');
CREATE TYPE "GlossaryStatus" AS ENUM ('PENDING', 'APPROVED', 'REJECTED');

CREATE TABLE "Organization" (
  "id" TEXT PRIMARY KEY,
  "name" TEXT NOT NULL,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE UNIQUE INDEX "Organization_name_key" ON "Organization" ("name");

CREATE TABLE "User" (
  "id" TEXT PRIMARY KEY,
  "name" TEXT,
  "email" TEXT NOT NULL,
  "emailVerified" TIMESTAMP(3),
  "image" TEXT,
  "role" "Role" NOT NULL DEFAULT 'USER',
  "orgId" TEXT NOT NULL,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  CONSTRAINT "User_email_key" UNIQUE ("email"),
  CONSTRAINT "User_orgId_fkey" FOREIGN KEY ("orgId") REFERENCES "Organization" ("id") ON DELETE CASCADE
);

CREATE TABLE "Account" (
  "id" TEXT PRIMARY KEY,
  "userId" TEXT NOT NULL,
  "type" TEXT NOT NULL,
  "provider" TEXT NOT NULL,
  "providerAccountId" TEXT NOT NULL,
  "refresh_token" TEXT,
  "access_token" TEXT,
  "expires_at" INTEGER,
  "token_type" TEXT,
  "scope" TEXT,
  "id_token" TEXT,
  "session_state" TEXT,
  "oauth_token_secret" TEXT,
  "oauth_token" TEXT,
  CONSTRAINT "Account_provider_providerAccountId_key" UNIQUE ("provider", "providerAccountId"),
  CONSTRAINT "Account_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User" ("id") ON DELETE CASCADE
);

CREATE TABLE "Session" (
  "id" TEXT PRIMARY KEY,
  "sessionToken" TEXT NOT NULL,
  "userId" TEXT NOT NULL,
  "expires" TIMESTAMP(3) NOT NULL,
  CONSTRAINT "Session_sessionToken_key" UNIQUE ("sessionToken"),
  CONSTRAINT "Session_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User" ("id") ON DELETE CASCADE
);

CREATE TABLE "VerificationToken" (
  "identifier" TEXT NOT NULL,
  "token" TEXT NOT NULL,
  "expires" TIMESTAMP(3) NOT NULL,
  CONSTRAINT "VerificationToken_token_key" UNIQUE ("token"),
  CONSTRAINT "VerificationToken_identifier_token_key" UNIQUE ("identifier", "token")
);

CREATE TABLE "GlossaryEntry" (
  "id" TEXT PRIMARY KEY,
  "term" TEXT NOT NULL,
  "definition" TEXT NOT NULL,
  "status" "GlossaryStatus" NOT NULL DEFAULT 'PENDING',
  "orgId" TEXT NOT NULL,
  "authorId" TEXT NOT NULL,
  "updatedById" TEXT,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  CONSTRAINT "GlossaryEntry_orgId_term_key" UNIQUE ("orgId", "term"),
  CONSTRAINT "GlossaryEntry_orgId_fkey" FOREIGN KEY ("orgId") REFERENCES "Organization" ("id") ON DELETE CASCADE,
  CONSTRAINT "GlossaryEntry_authorId_fkey" FOREIGN KEY ("authorId") REFERENCES "User" ("id") ON DELETE RESTRICT,
  CONSTRAINT "GlossaryEntry_updatedById_fkey" FOREIGN KEY ("updatedById") REFERENCES "User" ("id") ON DELETE SET NULL
);

CREATE INDEX "GlossaryEntry_orgId_status_idx" ON "GlossaryEntry" ("orgId", "status");

CREATE TRIGGER set_updated_at_organization
BEFORE UPDATE ON "Organization"
FOR EACH ROW EXECUTE FUNCTION app_private.update_updated_at();

CREATE TRIGGER set_updated_at_user
BEFORE UPDATE ON "User"
FOR EACH ROW EXECUTE FUNCTION app_private.update_updated_at();

CREATE TRIGGER set_updated_at_glossary
BEFORE UPDATE ON "GlossaryEntry"
FOR EACH ROW EXECUTE FUNCTION app_private.update_updated_at();

ALTER TABLE "Organization" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "User" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "Account" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "Session" ENABLE ROW LEVEL SECURITY;
ALTER TABLE "GlossaryEntry" ENABLE ROW LEVEL SECURITY;

-- Helper comment: we intentionally leave VerificationToken without RLS because it contains short-lived tokens only.

CREATE POLICY "Organization_same_org_read" ON "Organization"
  FOR SELECT USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "id" = current_setting('app.current_org_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Organization_admin_update" ON "Organization"
  FOR UPDATE USING (
    current_setting('app.current_org_id', true) IS NOT NULL
    AND "id" = current_setting('app.current_org_id')
    AND current_setting('app.current_user_role', true) = 'ADMIN'
  ) WITH CHECK (
    current_setting('app.current_org_id', true) IS NOT NULL
    AND "id" = current_setting('app.current_org_id')
  );

CREATE POLICY "User_same_org_select" ON "User"
  FOR SELECT USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "User_self_update" ON "User"
  FOR UPDATE USING (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "id" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  ) WITH CHECK (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "id" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "User_admin_update" ON "User"
  FOR UPDATE USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  ) WITH CHECK (
    (
      "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "User_admin_insert" ON "User"
  FOR INSERT WITH CHECK (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Account_same_user" ON "Account"
  USING (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "userId" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  ) WITH CHECK (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "userId" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Session_same_user" ON "Session"
  USING (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "userId" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  ) WITH CHECK (
    (
      current_setting('app.current_user_id', true) IS NOT NULL
      AND "userId" = current_setting('app.current_user_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Glossary_same_org_read" ON "GlossaryEntry"
  FOR SELECT USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Glossary_admin_write" ON "GlossaryEntry"
  FOR INSERT WITH CHECK (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Glossary_admin_update" ON "GlossaryEntry"
  FOR UPDATE USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  ) WITH CHECK (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

CREATE POLICY "Glossary_admin_delete" ON "GlossaryEntry"
  FOR DELETE USING (
    (
      current_setting('app.current_org_id', true) IS NOT NULL
      AND "orgId" = current_setting('app.current_org_id')
      AND current_setting('app.current_user_role', true) = 'ADMIN'
    )
    OR current_setting('app.current_user_role', true) = 'SERVICE'
  );

```

## `prisma/migrations/20240709150000_glossary_review_workflow/migration.sql`

```sql
-- Extend glossary entries with review metadata and synonym support.

ALTER TABLE "GlossaryEntry"
  ADD COLUMN "synonyms" TEXT[] NOT NULL DEFAULT ARRAY[]::TEXT[],
  ADD COLUMN "reviewNotes" TEXT,
  ADD COLUMN "reviewedAt" TIMESTAMP(3),
  ADD COLUMN "reviewerId" TEXT;

ALTER TABLE "GlossaryEntry"
  ADD CONSTRAINT "GlossaryEntry_reviewerId_fkey"
  FOREIGN KEY ("reviewerId") REFERENCES "User"("id") ON DELETE SET NULL;

CREATE INDEX IF NOT EXISTS "GlossaryEntry_status_reviewedAt_idx"
  ON "GlossaryEntry" ("status", "reviewedAt");

```

## `prisma/migrations/20250201090000_fix_updated_at_trigger/migration.sql`

```sql
-- Align update_updated_at trigger with snake_case and camelCase columns
CREATE OR REPLACE FUNCTION app_private.update_updated_at()
RETURNS trigger AS $$
DECLARE
    payload jsonb := to_jsonb(NEW);
BEGIN
    IF payload ? 'updatedAt' THEN
        NEW."updatedAt" = CURRENT_TIMESTAMP;
    ELSIF payload ? 'updated_at' THEN
        NEW.updated_at = CURRENT_TIMESTAMP;
    ELSE
        RAISE EXCEPTION 'update_updated_at() called for table % without updated timestamp column', TG_TABLE_NAME;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

```

## `prisma/migrations/20251018090000_admin_ops_console/migration.sql`

```sql
-- Phase 6: Admin Ops Console support tables
CREATE TABLE "Chat" (
  "id" TEXT PRIMARY KEY,
  "orgId" TEXT NOT NULL,
  "userId" TEXT,
  "question" TEXT NOT NULL,
  "answer" TEXT,
  "confidence" DOUBLE PRECISION NOT NULL,
  "status" TEXT NOT NULL DEFAULT 'ok',
  "topSources" JSONB,
  "requestId" TEXT,
  "reviewedById" TEXT,
  "reviewedAt" TIMESTAMPTZ,
  "followUpPrompt" TEXT,
  "auditLog" JSONB,
  "createdAt" TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE "Ticket" (
  "id" TEXT PRIMARY KEY,
  "orgId" TEXT NOT NULL,
  "key" TEXT NOT NULL,
  "status" TEXT NOT NULL,
  "assignee" TEXT,
  "lastActivity" TIMESTAMPTZ,
  "summary" TEXT,
  "chatId" TEXT,
  "auditLog" JSONB,
  "createdAt" TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

ALTER TABLE "Chat"
  ADD CONSTRAINT "Chat_orgId_fkey" FOREIGN KEY ("orgId") REFERENCES "Organization"("id") ON DELETE CASCADE ON UPDATE CASCADE;

ALTER TABLE "Chat"
  ADD CONSTRAINT "Chat_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE SET NULL ON UPDATE CASCADE;

ALTER TABLE "Chat"
  ADD CONSTRAINT "Chat_reviewedById_fkey" FOREIGN KEY ("reviewedById") REFERENCES "User"("id") ON DELETE SET NULL ON UPDATE CASCADE;

ALTER TABLE "Ticket"
  ADD CONSTRAINT "Ticket_orgId_fkey" FOREIGN KEY ("orgId") REFERENCES "Organization"("id") ON DELETE CASCADE ON UPDATE CASCADE;

ALTER TABLE "Ticket"
  ADD CONSTRAINT "Ticket_chatId_fkey" FOREIGN KEY ("chatId") REFERENCES "Chat"("id") ON DELETE SET NULL ON UPDATE CASCADE;

CREATE UNIQUE INDEX "Ticket_orgId_key_key" ON "Ticket" ("orgId", "key");
CREATE INDEX "Chat_orgId_status_idx" ON "Chat" ("orgId", "status");
CREATE INDEX "Chat_status_reviewedAt_idx" ON "Chat" ("status", "reviewedAt");
CREATE INDEX "Ticket_status_assignee_idx" ON "Ticket" ("status", "assignee");

```

## `prisma/migrations/20251019090500_rag_events_audit/migration.sql`

```sql
-- Capture glossary/chat audit events for administrator actions.
CREATE TABLE "RagEvent" (
    "id" TEXT NOT NULL,
    "orgId" TEXT NOT NULL,
    "actorId" TEXT,
    "actorRole" "Role",
    "action" TEXT NOT NULL,
    "entity" TEXT NOT NULL,
    "glossaryId" TEXT,
    "chatId" TEXT,
    "requestId" TEXT,
    "before" JSONB,
    "after" JSONB,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT "RagEvent_pkey" PRIMARY KEY ("id")
);

CREATE INDEX "RagEvent_orgId_action_createdAt_idx" ON "RagEvent"("orgId", "action", "createdAt");
CREATE INDEX "RagEvent_glossaryId_idx" ON "RagEvent"("glossaryId");
CREATE INDEX "RagEvent_chatId_idx" ON "RagEvent"("chatId");

ALTER TABLE "RagEvent"
  ADD CONSTRAINT "RagEvent_orgId_fkey"
  FOREIGN KEY ("orgId") REFERENCES "Organization"("id") ON DELETE CASCADE ON UPDATE CASCADE;
ALTER TABLE "RagEvent"
  ADD CONSTRAINT "RagEvent_actorId_fkey"
  FOREIGN KEY ("actorId") REFERENCES "User"("id") ON DELETE SET NULL ON UPDATE CASCADE;
ALTER TABLE "RagEvent"
  ADD CONSTRAINT "RagEvent_glossaryId_fkey"
  FOREIGN KEY ("glossaryId") REFERENCES "GlossaryEntry"("id") ON DELETE SET NULL ON UPDATE CASCADE;
ALTER TABLE "RagEvent"
  ADD CONSTRAINT "RagEvent_chatId_fkey"
  FOREIGN KEY ("chatId") REFERENCES "Chat"("id") ON DELETE SET NULL ON UPDATE CASCADE;

```

## `prisma/seed.ts`

```typescript
import { GlossaryStatus, Prisma, PrismaClient, Role } from "@prisma/client";

const prisma = new PrismaClient();

type SeedUser = {
  id: string;
  email: string;
  name: string;
  role: Role;
};

type GlossarySeed = {
  id: string;
  term: string;
  definition: string;
  synonyms: string[];
  status: GlossaryStatus;
  reviewNotes?: string;
  reviewerId?: string;
  reviewedAt?: Date;
};

type ChatSeed = {
  id: string;
  question: string;
  answer?: string;
  confidence: number;
  status: string;
  requestId?: string;
  topSources: Array<{
    path: string;
    score?: number;
    page?: number;
    heading?: string;
    chunkId?: string;
  }>;
  followUpPrompt?: string;
  auditLog?: Array<Record<string, unknown>>;
  createdAt: Date;
  userId?: string;
  reviewedById?: string | null;
  reviewedAt?: Date | null;
  tickets?: TicketSeed[];
};

type TicketSeed = {
  id: string;
  key: string;
  status: string;
  assignee?: string;
  lastActivity?: Date;
  summary?: string;
  auditLog?: Array<Record<string, unknown>>;
};

const seedUsers: SeedUser[] = [
  {
    id: "user-seed-author",
    email: "glossary.author@seed.atticus",
    name: "Glossary Seed Author",
    role: Role.REVIEWER,
  },
  {
    id: "user-seed-approver",
    email: "glossary.approver@seed.atticus",
    name: "Glossary Seed Approver",
    role: Role.ADMIN,
  },
];

async function main() {
  const defaultOrgId = process.env.DEFAULT_ORG_ID ?? "org-atticus";
  const defaultOrgName = process.env.DEFAULT_ORG_NAME ?? "Atticus Default";
  const adminEmail = process.env.ADMIN_EMAIL;
  const adminName = process.env.ADMIN_NAME ?? "Atticus Admin";

  const organization = await prisma.organization.upsert({
    where: { id: defaultOrgId },
    update: { name: defaultOrgName },
    create: {
      id: defaultOrgId,
      name: defaultOrgName,
    },
  });

  if (adminEmail) {
    await prisma.user.upsert({
      where: { email: adminEmail.toLowerCase() },
      update: {
        role: Role.ADMIN,
        orgId: organization.id,
      },
      create: {
        email: adminEmail.toLowerCase(),
        name: adminName,
        role: Role.ADMIN,
        orgId: organization.id,
      },
    });
  }

  const seededUsers = await Promise.all(
    seedUsers.map((user) =>
      prisma.user.upsert({
        where: { id: user.id },
        update: {
          email: user.email,
          name: user.name,
          role: user.role,
          orgId: organization.id,
        },
        create: {
          id: user.id,
          email: user.email,
          name: user.name,
          role: user.role,
          orgId: organization.id,
        },
      })
    )
  );

  const author = seededUsers.find((user) => user.id === "user-seed-author");
  const approver = seededUsers.find((user) => user.id === "user-seed-approver");

  if (!author || !approver) {
    throw new Error("Failed to seed glossary users");
  }

  const glossarySeeds: GlossarySeed[] = [
    {
      id: "glossary-entry-managed-print-services",
      term: "Managed Print Services",
      definition:
        "End-to-end management of printers, consumables, maintenance, and support delivered as a subscription.",
      synonyms: ["MPS", "Print-as-a-service"],
      status: GlossaryStatus.APPROVED,
      reviewNotes: "Approved for launch collateral and onboarding playbooks.",
      reviewerId: approver.id,
      reviewedAt: new Date("2024-05-01T12:00:00Z"),
    },
    {
      id: "glossary-entry-proactive-maintenance",
      term: "Proactive Maintenance",
      definition:
        "Scheduled device inspections and firmware rollouts designed to prevent outages before they impact revenue teams.",
      synonyms: ["Preventative maintenance"],
      status: GlossaryStatus.PENDING,
    },
    {
      id: "glossary-entry-toner-optimization",
      term: "Toner Optimization",
      definition:
        "Adaptive print routing and toner yield tracking that reduce waste while maintaining SLA-compliant image quality.",
      synonyms: ["Smart toner", "Consumable optimisation"],
      status: GlossaryStatus.REJECTED,
      reviewNotes: "Rejected pending customer-ready evidence and usage data.",
      reviewerId: approver.id,
      reviewedAt: new Date("2024-05-15T09:30:00Z"),
    },
  ];

  await Promise.all(
    glossarySeeds.map((entry) =>
      prisma.glossaryEntry.upsert({
        where: { id: entry.id },
        update: {
          term: entry.term,
          definition: entry.definition,
          synonyms: entry.synonyms,
          status: entry.status,
          orgId: organization.id,
          authorId: author.id,
          reviewerId: entry.reviewerId ?? null,
          reviewNotes: entry.reviewNotes ?? null,
          reviewedAt: entry.reviewedAt ?? null,
        },
        create: {
          id: entry.id,
          term: entry.term,
          definition: entry.definition,
          synonyms: entry.synonyms,
          status: entry.status,
          orgId: organization.id,
          authorId: author.id,
          reviewerId: entry.reviewerId ?? null,
          reviewNotes: entry.reviewNotes ?? null,
          reviewedAt: entry.reviewedAt ?? null,
        },
      })
    )
  );

  const chatSeeds: ChatSeed[] = [
    {
      id: "chat-low-confidence-toner",
      question: "Why are toner replacement alerts firing for the West team despite new cartridges?",
      confidence: 0.38,
      status: "pending_review",
      requestId: "req-seed-001",
      topSources: [
        {
          path: "content/operations/toner-optimization.md#alerts",
          score: 0.82,
          heading: "Alert tuning guidance",
          chunkId: "chunk-toner-alerts",
        },
        {
          path: "content/playbooks/ced-toner-guide.pdf",
          score: 0.74,
          page: 3,
          heading: "Replace cartridges sequence",
          chunkId: "chunk-toner-guide-3",
        },
      ],
      createdAt: new Date("2024-07-08T10:15:00Z"),
      auditLog: [
        {
          action: "captured",
          at: "2024-07-08T10:15:10.000Z",
          confidence: 0.38,
        },
        {
          action: "followup",
          at: "2024-07-08T10:17:00.000Z",
          prompt: "Confirm the affected device serial numbers and share recent firmware updates.",
        },
      ],
      userId: author.id,
      followUpPrompt: "Confirm serial numbers and firmware applied last week.",
    },
    {
      id: "chat-escalated-calibration",
      question: "Color calibration fails with streak artifacts on the ProLine 5100 series. What should we try next?",
      confidence: 0.41,
      status: "escalated",
      requestId: "req-seed-002",
      topSources: [
        {
          path: "content/troubleshooting/calibration-checklist.md#step-4",
          score: 0.68,
          heading: "Step 4 — Inspect rollers",
          chunkId: "chunk-calibration-4",
        },
        {
          path: "content/faq/pressroom-maintenance.md#color",
          score: 0.62,
          heading: "Color drift playbook",
          chunkId: "chunk-maintenance-color",
        },
      ],
      createdAt: new Date("2024-06-18T14:45:00Z"),
      auditLog: [
        {
          action: "escalate",
          at: "2024-06-18T15:00:00.000Z",
          actorId: approver.id,
          actorRole: Role.ADMIN,
          summary: "Calibration streaks observed in pilot deployment.",
        },
      ],
      userId: author.id,
      tickets: [
        {
          id: "ticket-ae-1001",
          key: "AE-1001",
          status: "open",
          assignee: "AEX-ops",
          lastActivity: new Date("2024-06-18T15:00:00Z"),
          summary: "Investigate streak artifacts for ProLine 5100 pilot.",
          auditLog: [
            {
              action: "created",
              at: "2024-06-18T15:00:00.000Z",
              actorId: approver.id,
              actorRole: Role.ADMIN,
            },
          ],
        },
      ],
    },
  ];

  for (const chatSeed of chatSeeds) {
    const chat = await prisma.chat.upsert({
      where: { id: chatSeed.id },
      update: {
        question: chatSeed.question,
        answer: chatSeed.answer ?? null,
        confidence: chatSeed.confidence,
        status: chatSeed.status,
        requestId: chatSeed.requestId ?? null,
        topSources: chatSeed.topSources as Prisma.InputJsonValue,
        auditLog: (chatSeed.auditLog ?? []) as Prisma.InputJsonValue,
        userId: chatSeed.userId ?? author.id,
        reviewedById: chatSeed.reviewedById ?? null,
        reviewedAt: chatSeed.reviewedAt ?? null,
        followUpPrompt: chatSeed.followUpPrompt ?? null,
      },
      create: {
        id: chatSeed.id,
        orgId: organization.id,
        userId: chatSeed.userId ?? author.id,
        question: chatSeed.question,
        answer: chatSeed.answer ?? null,
        confidence: chatSeed.confidence,
        status: chatSeed.status,
        requestId: chatSeed.requestId ?? null,
        topSources: chatSeed.topSources as Prisma.InputJsonValue,
        auditLog: (chatSeed.auditLog ?? []) as Prisma.InputJsonValue,
        createdAt: chatSeed.createdAt,
        reviewedById: chatSeed.reviewedById ?? null,
        reviewedAt: chatSeed.reviewedAt ?? null,
        followUpPrompt: chatSeed.followUpPrompt ?? null,
      },
    });

    await prisma.ragEvent.upsert({
      where: { id: `${chatSeed.id}-captured` },
      update: {
        orgId: organization.id,
        actorId: chatSeed.userId ?? author.id,
        actorRole: Role.USER,
        action: "chat.captured",
        entity: "chat",
        chatId: chat.id,
        requestId: chatSeed.requestId ?? null,
        after: {
          status: chatSeed.status,
          confidence: chatSeed.confidence,
        },
      },
      create: {
        id: `${chatSeed.id}-captured`,
        orgId: organization.id,
        actorId: chatSeed.userId ?? author.id,
        actorRole: Role.USER,
        action: "chat.captured",
        entity: "chat",
        chatId: chat.id,
        requestId: chatSeed.requestId ?? null,
        after: {
          status: chatSeed.status,
          confidence: chatSeed.confidence,
        },
      },
    });

    if (chatSeed.followUpPrompt) {
      await prisma.ragEvent.upsert({
        where: { id: `${chatSeed.id}-followup` },
        update: {
          orgId: organization.id,
          actorId: approver.id,
          actorRole: Role.ADMIN,
          action: "chat.followup_recorded",
          entity: "chat",
          chatId: chat.id,
          requestId: chatSeed.requestId ?? null,
          after: {
            followUpPrompt: chatSeed.followUpPrompt,
          },
        },
        create: {
          id: `${chatSeed.id}-followup`,
          orgId: organization.id,
          actorId: approver.id,
          actorRole: Role.ADMIN,
          action: "chat.followup_recorded",
          entity: "chat",
          chatId: chat.id,
          requestId: chatSeed.requestId ?? null,
          after: {
            followUpPrompt: chatSeed.followUpPrompt,
          },
        },
      });
    }

    if (chatSeed.tickets?.length) {
      for (const ticket of chatSeed.tickets) {
        await prisma.ticket.upsert({
          where: { id: ticket.id },
          update: {
            key: ticket.key,
            status: ticket.status,
            assignee: ticket.assignee ?? null,
            lastActivity: ticket.lastActivity ?? null,
            summary: ticket.summary ?? null,
            auditLog: (ticket.auditLog ?? []) as Prisma.InputJsonValue,
            chatId: chat.id,
            orgId: organization.id,
          },
          create: {
            id: ticket.id,
            key: ticket.key,
            status: ticket.status,
            assignee: ticket.assignee ?? null,
            lastActivity: ticket.lastActivity ?? null,
            summary: ticket.summary ?? null,
            auditLog: (ticket.auditLog ?? []) as Prisma.InputJsonValue,
            chatId: chat.id,
            orgId: organization.id,
          },
        });
      }

      await prisma.ragEvent.upsert({
        where: { id: `${chatSeed.id}-escalated` },
        update: {
          orgId: organization.id,
          actorId: approver.id,
          actorRole: Role.ADMIN,
          action: "chat.escalated",
          entity: "chat",
          chatId: chat.id,
          requestId: chatSeed.requestId ?? null,
          after: {
            status: "escalated",
            ticket: chatSeed.tickets.at(0)?.key ?? null,
          },
        },
        create: {
          id: `${chatSeed.id}-escalated`,
          orgId: organization.id,
          actorId: approver.id,
          actorRole: Role.ADMIN,
          action: "chat.escalated",
          entity: "chat",
          chatId: chat.id,
          requestId: chatSeed.requestId ?? null,
          after: {
            status: "escalated",
            ticket: chatSeed.tickets.at(0)?.key ?? null,
          },
        },
      });
    }
  }
}

main()
  .then(async () => {
    await prisma.$disconnect();
  })
  .catch(async (error) => {
    console.error("Seeding failed", error);
    await prisma.$disconnect();
    process.exit(1);
  });

```

## `pyproject.toml`

```toml
[project]
name = "atticus"
dynamic = ["version"]

description = "Atticus Retrieval-Augmented Generation service"
readme = "README.md"
authors = [{ name = "Atticus Ops", email = "ops@example.com" }]
requires-python = ">=3.12"
dependencies = []

[project.optional-dependencies]
dev = [
  "pip-tools",
  "ruff>=0.5",
  "mypy>=1.10",
  "pytest>=8",
  "pytest-cov>=5",
  "pytest-sugar>=0.9.7",
  "pytest-xdist>=3.5",
  "pydantic>=2.7",
  "types-requests",
  "types-PyYAML",
  "vulture>=2.11",
  # Include psycopg wheels so `pip install -e .[dev]` matches Prisma migrations locally
  "psycopg[binary]>=3.2",
  "pre-commit>=3.7"
]

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["atticus", "api", "ingest", "retriever", "eval"]

[tool.setuptools.dynamic]
version = { file = "VERSION" }

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "B", "UP", "ASYNC", "RUF", "PL"]
ignore = [
  "E501",
  "E402",
  "PLR0912",
  "PLR0913",
  "PLR0915",
  "PLR2004",
  "B023",
  "E731",
  "UP035",
  "RUF012",
  "RUF046",
  "RUF100",
]

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["PLR2004", "PLC0415", "PLR0913", "I001"]
"retriever/generator.py" = ["RUF001"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
line-ending = "lf"

[tool.mypy]
python_version = "3.12"
strict = true
packages = ["atticus", "api", "ingest", "retriever", "eval"]
plugins = ["pydantic.mypy"]
ignore_missing_imports = true
warn_unused_configs = true
warn_unused_ignores = true
warn_redundant_casts = true
warn_return_any = true
exclude = "^(scripts|tests|EXAMPLES_ONLY)/"

# Treat optional vendored helpers as 3rd-party to avoid noise
explicit_package_bases = true

[[tool.mypy.overrides]]
module = [
  "atticus.vector_db",
  "api.routes.admin",
  "api.main",
  "eval.runner",
]
ignore_errors = true

[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-ra"
testpaths = ["tests", "eval/harness"]
markers = ["eval: evaluation harness"]
filterwarnings = [
  # Safe to ignore: upstream SWIG/PyMuPDF deprecation noise
  "ignore:.*SwigPyPacked.*:DeprecationWarning",
  "ignore:.*SwigPyObject.*:DeprecationWarning",
  "ignore:.*swigvarlink.*:DeprecationWarning",
]

[tool.coverage.run]
source = ["atticus", "api", "retriever"]
omit = [
  # Temporarily exempted modules pending integration tests
  "api/routes/ask.py",
  "atticus/config.py",
  "atticus/logging.py",
  "atticus/embeddings.py",
  "atticus/vector_db.py",
  "atticus/metrics.py",
  "atticus/tokenization.py",
  "atticus/notify/mailer.py",
  "retriever/generator.py",
  "retriever/vector_store.py",
  "retriever/service.py",
  "api/routes/admin.py",
  "api/routes/eval.py",
  "api/routes/ingest.py",
  "api/routes/health.py",
  "api/dependencies.py",
  "api/middleware.py",
  "api/utils.py",
]

[tool.coverage.report]
fail_under = 90
show_missing = true

```

## `README.md`

```md
# Atticus

> **Atticus for Sales Enablement** accelerates tender responses, keeps Sales self-sufficient, and frees Service/Marketing from ad-hoc requests.

Atticus is a Retrieval-Augmented Generation (RAG) assistant built on **Next.js**, **FastAPI**, **Postgres + pgvector**, and **Prisma**.
It ingests content, indexes it with pgvector, and serves grounded answers with citations. When confidence is low the system sends a cautious partial answer and escalates via email.

> **Release 0.7.10** â€“ Locked the Next.js workspace in as the only UI, aligned API metadata with the central `VERSION` file, and refreshed operations docs for the split frontend/backend stack.
> Enterprise authentication and SSO are managed externally. This app assumes user access is handled upstream.

## Model Disambiguation Flows

- **Direct hit** â€” when a question names a specific model (for example, "Apeos C4570"), retrieval is scoped to that family and a single answer with family-tagged sources is returned.
- **Unclear** â€” if no confident match is found, `/api/ask` returns a `clarification` payload with the available families. The chat UI renders the clarification card and resubmits the prior question with an explicit `models` array when the user picks an option.
- **Multi-model** â€” if several models are detected or supplied, Atticus fans out retrieval per model and responds with `answers[]`, keeping citations separate for each model while still providing the aggregated `sources` list for backwards compatibility.
- **Testing** â€” `tests/test_model_parser.py`, `tests/test_retrieval_filters.py`, `tests/test_chat_route.py`, `tests/test_ui_route.py`, and `tests/playwright/chat.spec.ts` lock these behaviours in place.

---

## Quick Start

1. Bootstrap environment variables

   Generate a local `.env` so secrets stay inside the repository:

   ```bash
   python scripts/generate_env.py
   python scripts/debug_env.py  # inspect precedence when overriding values
   ```

   Populate SMTP settings for escalation email delivery:
   - `CONTACT_EMAIL` â€“ escalation recipient
   - `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASS`, `SMTP_FROM` â€“ SES SMTP credentials
   - `SMTP_ALLOW_LIST` â€“ comma-separated sender/recipient allow list
   - `RAG_SERVICE_URL` â€“ FastAPI retrieval service (defaults to `http://localhost:8000`)

1. Install dependencies

   Install Python tooling (Ruff, mypy, pytest, etc.) and Node packages (Next.js workspace, shadcn/ui, Knip).

   ```powershell
   pip install -U pip pip-tools
   pip-compile -U requirements.in
   pip-sync requirements.txt
   npm install
   ```

1. Database and Prisma

   Launch Postgres, apply migrations, and seed baseline data.

   ```bash
   make db.up
   make db.migrate   # runs `prisma generate` before applying migrations
   # POSIX shells (bash/zsh): export DATABASE_URL before verification
   set -a
   . .env
   set +a
   make db.verify    # pgvector extension, dimension, IVFFlat probes
   make db.seed
   ```

   > Windows users: do **not** run the `set -a` snippetâ€”instead use the PowerShell block below (or rely on `make db.verify`, which now auto-loads `.env` values automatically).

   ```powershell
   make db.up
   make db.migrate
   Get-Content .env | ForEach-Object {
   if ($_ -and $_ -notmatch '^#') {
       $name, $value = $_.Split('=', 2)
       if ($value) { [System.Environment]::SetEnvironmentVariable($name.Trim(), $value.Trim(), 'Process') }
   }
   }
   make db.verify
   make db.seed
   ```

   `make db.verify` auto-loads `.env`, then shells out to `psql` (falling back to `docker compose exec postgres psql` when the CLI is unavailable) and will emit a notice if your pgvector build caps ANN indexes at 2K dimensions; upgrade the image to regain IVFFlat on 3K-dim embeddings.

   Run the verification SQL directly when debugging:

   ```bash
   psql "$DATABASE_URL" \
     -v expected_pgvector_dimension=${PGVECTOR_DIMENSION:-3072} \
     -v expected_pgvector_lists=${PGVECTOR_LISTS:-100} \
     -f scripts/verify_pgvector.sql
   ```

   ```powershell
   if (-not $env:PGVECTOR_DIMENSION) { $env:PGVECTOR_DIMENSION = 3072 }
   if (-not $env:PGVECTOR_LISTS) { $env:PGVECTOR_LISTS = 100 }
   psql "$env:DATABASE_URL" `
   -v expected_pgvector_dimension=$env:PGVECTOR_DIMENSION `
   -v expected_pgvector_lists=$env:PGVECTOR_LISTS `
   -f scripts/verify_pgvector.sql
   ```

1. Ingest documents

   Run ingestion once after the database is ready so the assistant has content to answer with; rerun whenever new documents land. `make eval` and `make seed` help during iteration.

   ```bash
   make ingest     # parse, chunk, embed, and update pgvector index
   make seed       # generate deterministic seed manifest (seeds/seed_manifest.json)
   make eval       # run retrieval evaluation and emit metrics under eval/runs/
   ```

   > **Note:** The CED chunker now operates with zero token overlap by default
   > (`CHUNK_OVERLAP_TOKENS=0`). Override the environment variable if a
   > different stride is required for specialised corpora.

1. Run services

   Use separate terminals for the FastAPI backend and the Next.js UI.

   ```bash
   make api        # FastAPI service on http://localhost:8000
   make web-dev    # Next.js workspace on http://localhost:3000
   ```

   ```powershell
   make api
   make web-dev
   ```

1. Quality gates (before committing)

   ```bash
   make quality
   ```

   ```powershell
   make quality
   ```

  > `make quality` mirrors CI by running Ruff, mypy, pytest (>=90% coverage), Vitest unit tests, Next.js lint/typecheck/build, Playwright RBAC coverage, version parity checks, and all audit scripts (Knip, icon usage, route inventory, Python dead-code audit).
  > Pre-commit hooks now include Ruff, mypy, ESLint (Next + tailwindcss), Prettier (with tailwind sorting), and markdownlint. Install with `pre-commit install`.

1. Authenticate with magic link

1. `/api/ask` contract

   The Next.js app exposes `/api/ask`, proxying the FastAPI retrieval service through server-sent events (SSE).
   FastAPI still returns canonical JSON; the proxy synthesises `start`, `answer`, and `end` events so the UI can subscribe using a single streaming interface.

## Request

```json
{
  "question": "What is the pilot timeline?",
  "contextHints": ["Managed print"],
  "topK": 8
}
```

## Response

```json
{
  "answer": "...",
  "sources": [{ "path": "content/pilot.pdf", "page": 3 }],
  "confidence": 0.82,
  "request_id": "abc123",
  "should_escalate": false
}
```

Send `Accept: text/event-stream` to receive incremental events; `lib/ask-client.ts` handles SSE parsing, JSON fallback, and request-id logging.

---

## Developer workflow

1. **Environment**:
   - Generate `.env` and update SMTP + Postgres credentials.
2. **Dependencies**:
   - install Python + Node dependencies (`pip-sync` and `npm install`).
3. **Database**:
   - Run `make db.up && make db.migrate && make db.seed`.
   - Export `.env` before `make db.verify` so `DATABASE_URL` is available (`set -a; . .env; set +a` on POSIX shells, or use the PowerShell snippet in Quick Start on Windows).
4. **Quality**:
   - Run `make quality` locally before every PR.
   - Fix formatting with `npm run format` (Prettier) and `make format` (Ruff) as needed.
5. **Run**
   - `make api`
   - `make web-dev` for local development.
6. **Observe**
   - `logs/app.jsonl`
   - `logs/errors.jsonl`
   - `/admin/metrics` (dashboard)
7. **Release**
   - Follow [RELEASE.md](docs/RELEASE.md) for tagging.
   - Upgrade/rollback steps, confirming `VERSION` matches `package.json` before tagging.

8. **Git**
   - Git pre-commit hooks enforce Ruff, mypy, ESLint, Prettier, markdownlint, and repository hygiene
   - Use `pre-commit run --all-files` to verify manually.

## Legacy UI

The legacy HTML/CSS demo under `archive/legacy-ui/` is for reference only and excluded from builds and linting. The canonical UI is the Next.js app under `app/`. Avoid editing legacy files unless documenting history.

---

## Frontend design system

- Shared primitives built on shadcn/ui live under [`components/ui`](components/ui). Compose new surfaces with these building blocks instead of bespoke Tailwind markup to keep typography, spacing, and focus states consistent.
- Cards (`Card`, `CardHeader`, `CardContent`, etc.) wrap dashboard panels, admin glossaries, and contact forms with rounded borders and responsive padding.
- Badges (`Badge`) expose semantic variants (`default`, `success`, `warning`, `destructive`, etc.) for status chips, streaming indicators, and keyboard shortcut callouts.
- Buttons now support the `asChild` pattern for wrapping Next.js `Link` components, ensuring consistent styling for navigation pills and in-form actions.

---

## CI and quality gates

GitHub Actions enforces:

- **frontend-quality** â€“ Node 20 + Postgres service, running `npm run lint`, `npm run typecheck`, `npm run build`, and all audit scripts (`npm run audit:ts`, `npm run audit:icons`, `npm run audit:routes`, `npm run audit:py`). Audit outputs are uploaded as artifacts under `frontend-audit-reports`.
- **lint-test** â€“ Python 3.12 toolchain running Ruff (lint + format check), mypy, pytest with â‰¥90% coverage, and pre-commit.
- **pgvector-check** â€“ Applies Prisma migrations against pgvector-enabled Postgres and runs `make db.verify`.
- **eval-gate** â€“ Retrieval evaluation regression checks (see [eval-gate.yml](.github/workflows/eval-gate.yml)).

Always confirm local `make quality` mirrors CI before pushing.

---

## Make targets

| Target                      | Description                                                            |
| --------------------------- | ---------------------------------------------------------------------- |
| `make env`                  | Generate `.env` from defaults                                          |
| `make ingest`               | Parse, chunk, embed, and update the pgvector index                     |
| `make seed`                 | Generate deduplicated seed manifest (`seeds/seed_manifest.json`)       |
| `make eval`                 | Run retrieval evaluation and write metrics under `eval/runs/`          |
| `make api`                  | Start FastAPI backend                                                  |
| `make web-dev`              | Run Next.js dev server (port 3000)                                     |
| `make app-dev`              | Alias for `make web-dev`                                               |
| `make db.up`                | Start Postgres (Docker)                                                |
| `make db.down`              | Stop Postgres (Docker)                                                 |
| `make db.migrate`           | Run Prisma migrations                                                  |
| `make db.verify`            | Ensure pgvector extension, dimensions, and IVFFlat settings            |
| `make db.seed`              | Seed baseline demo content                                             |
| `make help`                 | List available make targets                                            |
| `make web-build`            | Build the production Next.js bundle                                    |
| `make web-start`            | Start the built Next.js app                                            |
| `make web-lint`             | Run Next.js lint checks                                                |
| `make web-typecheck`        | Type-check the UI with TypeScript                                      |
| `make web-test`             | Run Vitest unit tests                                                  |
| `make web-e2e`              | Run Playwright smoke tests                                             |
| `make smtp-test`            | Send an SES test email                                                 |
| `make smoke`                | Run FastAPI health probe                                               |
| `make test.unit`            | Unit tests for hashing, config reload, mailer, chunker, seeds, eval    |
| `make test.api`             | API contract tests (ask/contact/error schema/UI)                       |
| `make test`                 | Run pytest suite with coverage >=90%                                   |
| `make lint` / `make format` | Ruff lint + auto-fix                                                   |
| `make typecheck`            | Run mypy over atticus/api/ingest/retriever/eval                        |
| `make quality`              | Combined Python + Next quality gates, version-parity check, and audits |
| `make web-audit`            | Run Node and Python audit scripts                                      |

---

## Observability & guardrails

- Every request receives a `request_id` propagated through logs, metrics, and escalation emails.
- Rate limiting enforces `RATE_LIMIT_REQUESTS` per `RATE_LIMIT_WINDOW_SECONDS`; extra calls return a structured `429 rate_limited` payload.
- Metrics (queries, escalations, latency) persist via `atticus.metrics.MetricsRecorder` and surface on `/admin/metrics` and CSV exports under `reports/`.
- Evaluation artifacts live under `eval/runs/<timestamp>/` and `reports/` for CI comparisons.

---

## Web UI

The Next.js application in `app/` is the supported interface.

- `app/page.tsx` hosts the streaming chat surface using `/api/ask` and renders citations.
- `app/contact/page.tsx` handles escalations to the FastAPI `/contact` endpoint.
- `app/admin/page.tsx` powers the glossary workflow and respects upstream reviewer/admin context.

Legacy static assets live under `archive/legacy-ui/` for reference only.

---

## Access Control

Enterprise authentication and SSO are managed upstream. The Atticus web workspace trusts the incoming request context and no longer performs session management or magic-link delivery internally.

## Admin Service (port 3101)

A separate Next.js workspace (`admin/`) now powers escalation review and answer curation. Run it alongside the main UI:

```bash
npm run dev --workspace admin    # http://localhost:3101
```

Reviewers can browse escalated chats, edit responses, and approve or reject items without impacting the primary chat surface. Approved answers are appended to `content/<family>/<model>.csv`, keeping the knowledge base synchronised with curator feedback.

## Content Management & Ingestion

The in-app **Content Manager** (`/admin/content`) exposes a file-browser for the `content/` tree:

- Upload Markdown, PDF, and text sources
- Create or delete folders and files (with audit logging to `reports/content-actions.log`)
- Trigger ingestion via a dedicated “Re-ingest Content” control that runs `scripts/ingest_cli.py`
- Receive a prompt whenever changes are made so ingestion occurs intentionally

Ingestion output includes the total document count indexed and a transcript of the underlying CLI run for quick diagnostics.

---

## Documentation map

- [AGENTS.md](docs/AGENTS.md) â€“ architecture, environment settings, audit/CI requirements
- [ARCHITECTURE.md](docs/ARCHITECTURE.md) â€“ system diagram, data flow, SSE contract
- [OPERATIONS.md](docs/OPERATIONS.md) â€“ runbooks, metrics, and incident response
- [RELEASE.md](docs/RELEASE.md) â€“ release process, upgrade/rollback steps
- [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) – common setup, pgvector, and SSE issues
- [REQUIREMENTS.md](docs/REQUIREMENTS.md) â€“ functional/non-functional requirements for the Next.js + pgvector stack
- [docs/AUDIT_REPORT.md](docs/AUDIT_REPORT.md) / [docs/IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md) â€“ remediation history
- [CHANGELOG.md](CHANGELOG.md) â€“ release history
- [CONTRIBUTING.md](CONTRIBUTING.md) â€“ contributor workflow
- [STYLEGUIDE.md](docs/STYLEGUIDE.md) â€“ code and writing standards
- [ADMIN_SERVICE.md](docs/ADMIN_SERVICE.md) – standalone escalation tooling and reviewer workflow
- [TODO.md](TODO.md) / [TODO_COMPLETE.md](TODO_COMPLETE.md) â€“ authoritative backlog

---

## License

See [LICENSE](LICENSE).

## Token Count Test

```powershell
# GPT 4o-mini
python scripts/run_token_eval.py `
    --input "TOKEN_EVAL.xlsx" `
    --output "reports/4o_mini_ac7070_token_eval_atticus.csv" `
    --atticus-endpoint "http://localhost:8000/ask" `
    --model gpt-4o-mini `
    --tokenizer-model gpt-4o-mini
# GPT 4.1
python scripts/run_token_eval.py `
    --input "TOKEN_EVAL.xlsx" `
    --output "reports/gpt4_1_ac7070_token_eval_atticus.csv" `
    --atticus-endpoint "http://localhost:8000/ask" `
    --model gpt-4.1 `
    --tokenizer-model gpt-4.1

# GPT 5
python scripts/run_token_eval.py `
    --input "TOKEN_EVAL.xlsx" `
    --output "reports/gpt5_ac7070_token_eval_atticus.csv" `
    --atticus-endpoint "http://localhost:8000/ask" `
    --model gpt-5 `
    --tokenizer-model gpt-5
```

```

## `REPO_STRUCTURE.md`

```md
# Repository Structure Snapshot

Key directories to understand when working on Atticus.

- `app/`
  - `page.tsx` – streaming chat surface using the unified `/api/ask` contract.
  - `admin/` – admin console surfacing Uncertain, Tickets, and Glossary tabs for reviewers/admins.
  - `contact/` – escalation form backed by the FastAPI `/contact` endpoint.
  - `signin/`, `settings/`, `apps/` – additional Next.js routes.
- `components/`
  - `chat/` – chat panel client components.
  - `admin/` – console widgets (tabs, tables) powering `/admin`.
  - `glossary/` – admin glossary UI using shadcn-style primitives.
  - `ui/` – shared button/input/table components.
- `lib/`
  - `ask-client.ts`, `ask-contract.ts` – shared DTOs and streaming helpers.
  - `auth.ts`, `rls.ts`, `utils.ts` – auth, row-level security, and UI helpers.
- `api/`
  - `main.py` – FastAPI entry point wiring dependencies/middleware.
  - `routes/` – JSON APIs (`chat.py`, `contact.py`, `ingest.py`, etc.); no templates or static mounts remain in FastAPI.
  - `middleware.py`, `schemas.py` – shared FastAPI utilities and contracts.
- `atticus/`, `retriever/`, `ingest/`, `eval/` – Python services and pipelines for ingestion, retrieval, and evaluation.
- `prisma/` – Prisma schema and migrations for auth, glossary, chat review, and ticket data.
- `scripts/` – operational tooling (env generation, audits, ingestion, eval, etc.).
- `tests/`
  - Python pytest suites covering API contracts, ingestion utilities, and auth flows.
- `archive/legacy-ui/` – historical static HTML prototype retained for reference only.
- `content/`, `indexes/`, `reports/`, `logs/` – document corpus, vector indices, evaluation artifacts, and log outputs.

Supporting docs live at the repository root (`README.md`, `AGENTS.md`, `ARCHITECTURE.md`, `OPERATIONS.md`, etc.).

```

## `reports/npm-audit-initial.json`

```json
{
  "auditReportVersion": 2,
  "vulnerabilities": {
    "@auth/core": {
      "name": "@auth/core",
      "severity": "moderate",
      "isDirect": false,
      "via": [
        "cookie",
        "nodemailer"
      ],
      "effects": [
        "@auth/prisma-adapter",
        "next-auth"
      ],
      "range": "*",
      "nodes": [
        "node_modules/@auth/core",
        "node_modules/@auth/prisma-adapter/node_modules/@auth/core"
      ],
      "fixAvailable": false
    },
    "@auth/prisma-adapter": {
      "name": "@auth/prisma-adapter",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        "@auth/core"
      ],
      "effects": [],
      "range": "*",
      "nodes": [
        "node_modules/@auth/prisma-adapter"
      ],
      "fixAvailable": false
    },
    "cookie": {
      "name": "cookie",
      "severity": "low",
      "isDirect": false,
      "via": [
        {
          "source": 1103907,
          "name": "cookie",
          "dependency": "cookie",
          "title": "cookie accepts cookie name, path, and domain with out of bounds characters",
          "url": "https://github.com/advisories/GHSA-pxg6-pf52-xh8x",
          "severity": "low",
          "cwe": [
            "CWE-74"
          ],
          "cvss": {
            "score": 0,
            "vectorString": null
          },
          "range": "<0.7.0"
        }
      ],
      "effects": [
        "@auth/core"
      ],
      "range": "<0.7.0",
      "nodes": [
        "node_modules/cookie"
      ],
      "fixAvailable": false
    },
    "next-auth": {
      "name": "next-auth",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        "@auth/core",
        "nodemailer"
      ],
      "effects": [],
      "range": "<=0.0.0-semantically-released || 1.1.0 - 1.5.0 || >=2.0.0-beta.0",
      "nodes": [
        "node_modules/next-auth"
      ],
      "fixAvailable": {
        "name": "next-auth",
        "version": "1.12.1",
        "isSemVerMajor": true
      }
    },
    "nodemailer": {
      "name": "nodemailer",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        {
          "source": 1108571,
          "name": "nodemailer",
          "dependency": "nodemailer",
          "title": "Nodemailer: Email to an unintended domain can occur due to Interpretation Conflict",
          "url": "https://github.com/advisories/GHSA-mm7p-fcc7-pg87",
          "severity": "moderate",
          "cwe": [
            "CWE-20",
            "CWE-436"
          ],
          "cvss": {
            "score": 0,
            "vectorString": null
          },
          "range": "<7.0.7"
        }
      ],
      "effects": [
        "@auth/core",
        "next-auth"
      ],
      "range": "<7.0.7",
      "nodes": [
        "node_modules/nodemailer"
      ],
      "fixAvailable": false
    }
  },
  "metadata": {
    "vulnerabilities": {
      "info": 0,
      "low": 1,
      "moderate": 4,
      "high": 0,
      "critical": 0,
      "total": 5
    },
    "dependencies": {
      "prod": 181,
      "dev": 619,
      "optional": 111,
      "peer": 23,
      "peerOptional": 0,
      "total": 823
    }
  }
}

```

## `reports/npm-audit-postfix.json`

```json
{
  "auditReportVersion": 2,
  "vulnerabilities": {
    "@auth/core": {
      "name": "@auth/core",
      "severity": "moderate",
      "isDirect": false,
      "via": [
        "cookie",
        "nodemailer"
      ],
      "effects": [
        "@auth/prisma-adapter",
        "next-auth"
      ],
      "range": "*",
      "nodes": [
        "node_modules/@auth/core",
        "node_modules/@auth/prisma-adapter/node_modules/@auth/core"
      ],
      "fixAvailable": false
    },
    "@auth/prisma-adapter": {
      "name": "@auth/prisma-adapter",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        "@auth/core"
      ],
      "effects": [],
      "range": "*",
      "nodes": [
        "node_modules/@auth/prisma-adapter"
      ],
      "fixAvailable": false
    },
    "cookie": {
      "name": "cookie",
      "severity": "low",
      "isDirect": false,
      "via": [
        {
          "source": 1103907,
          "name": "cookie",
          "dependency": "cookie",
          "title": "cookie accepts cookie name, path, and domain with out of bounds characters",
          "url": "https://github.com/advisories/GHSA-pxg6-pf52-xh8x",
          "severity": "low",
          "cwe": [
            "CWE-74"
          ],
          "cvss": {
            "score": 0,
            "vectorString": null
          },
          "range": "<0.7.0"
        }
      ],
      "effects": [
        "@auth/core"
      ],
      "range": "<0.7.0",
      "nodes": [
        "node_modules/cookie"
      ],
      "fixAvailable": false
    },
    "next-auth": {
      "name": "next-auth",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        "@auth/core",
        "nodemailer"
      ],
      "effects": [],
      "range": "<=0.0.0-semantically-released || 1.1.0 - 1.5.0 || >=2.0.0-beta.0",
      "nodes": [
        "node_modules/next-auth"
      ],
      "fixAvailable": {
        "name": "next-auth",
        "version": "1.12.1",
        "isSemVerMajor": true
      }
    },
    "nodemailer": {
      "name": "nodemailer",
      "severity": "moderate",
      "isDirect": true,
      "via": [
        {
          "source": 1108571,
          "name": "nodemailer",
          "dependency": "nodemailer",
          "title": "Nodemailer: Email to an unintended domain can occur due to Interpretation Conflict",
          "url": "https://github.com/advisories/GHSA-mm7p-fcc7-pg87",
          "severity": "moderate",
          "cwe": [
            "CWE-20",
            "CWE-436"
          ],
          "cvss": {
            "score": 0,
            "vectorString": null
          },
          "range": "<7.0.7"
        }
      ],
      "effects": [
        "@auth/core",
        "next-auth"
      ],
      "range": "<7.0.7",
      "nodes": [
        "node_modules/nodemailer"
      ],
      "fixAvailable": false
    }
  },
  "metadata": {
    "vulnerabilities": {
      "info": 0,
      "low": 1,
      "moderate": 4,
      "high": 0,
      "critical": 0,
      "total": 5
    },
    "dependencies": {
      "prod": 181,
      "dev": 619,
      "optional": 111,
      "peer": 23,
      "peerOptional": 0,
      "total": 823
    }
  }
}

```

## `reports/playwright/data/c1c5d0240037389d3ee24e7a8eeb72555ba69dbe.md`

```md
# Page snapshot

```yaml
- generic [active] [ref=e1]:
  - banner [ref=e2]:
    - generic [ref=e3]:
      - link "A Atticus" [ref=e4] [cursor=pointer]:
        - /url: /
        - generic [ref=e5] [cursor=pointer]: A
        - generic [ref=e6] [cursor=pointer]: Atticus
      - navigation "Primary" [ref=e7]:
        - link "Chat" [ref=e8] [cursor=pointer]:
          - /url: /
        - link "Contact" [ref=e9] [cursor=pointer]:
          - /url: /contact
        - link "Apps" [ref=e10] [cursor=pointer]:
          - /url: /apps
      - link "Sign in" [ref=e12] [cursor=pointer]:
        - /url: /signin
  - main [ref=e13]:
    - generic [ref=e14]:
      - generic [ref=e15]:
        - paragraph [ref=e16]: Access
        - heading "Sign in to Atticus" [level=1] [ref=e17]
        - paragraph [ref=e18]: Use your company email to receive a secure, single-use magic link.
      - generic [ref=e19]:
        - generic [ref=e20]:
          - generic [ref=e21]: Work email
          - textbox "Work email" [ref=e22]
        - button "Email me a magic link" [ref=e23] [cursor=pointer]
      - paragraph [ref=e24]:
        - text: Need access? Contact an administrator or
        - link "submit a request" [ref=e25] [cursor=pointer]:
          - /url: /contact
        - text: .
  - contentinfo [ref=e26]:
    - paragraph [ref=e28]: © 2025 Atticus. All rights reserved.
  - alert [ref=e29]
```
```

## `reports/README.md`

```md
# Evaluation Reports

CI and local evaluation runs should publish structured artifacts under this directory.
Each run should include:

* `metrics.csv` – aggregate retrieval metrics (Recall@k, MRR@k, accuracy, latency).
* `summary.json` – machine-readable summary for regression gates.
* `metrics.html` – human-friendly dashboard for reviewers (captured by CI artifacts).

The repository ships with `sample-eval.csv` and `sample-eval.html` to illustrate the
expected schema. `make eval` will populate fresh artifacts and overwrite previous snapshots.
GitHub Actions uploads
the contents of `eval/runs/ci` (`metrics.csv`, `summary.json`, `metrics.html`) as the
`evaluation-ci` artifact for every PR and push to `main`.

```

## `retriever/__init__.py`

```python
"""Retriever package exports."""

from .models import Answer, Citation
from .service import answer_question
from .vector_store import VectorStore

__all__ = ["Answer", "Citation", "VectorStore", "answer_question"]

```

## `retriever/answer_format.py`

```python
from __future__ import annotations

import re
from pathlib import Path
from typing import Any, Iterable

_TRAILING_MD_ANCHOR = re.compile(r"\s*\(\[[^\]]+\]\(#\d+\)\)\.?\s*$")
_TRAILING_PG_PAREN = re.compile(r"\s*\(\s*p{1,2}\.?\s*[\d\-\u2013, ]+\s*\)\.?\s*$", re.IGNORECASE)
_TRAILING_SOURCEY = re.compile(
    r"\s*\([\w\s\-,&]+p{0,2}\.?\s*[\d\-\u2013, ]+\)\.?\s*$", re.IGNORECASE
)
_INLINE_BULLET = re.compile(r"\s(?P<bullet>-|\u2022|\u2013|\u2014)\s+")
_NUMBERED_ITEM_RE = re.compile(r"(?m)^\s*\d+\.\s+")
# Find " 2. " / " 3. " even mid-paragraph (avoid years by requiring a period + space)
# We will insert TWO newlines so Markdown renderers reliably break paragraphs.
# Insert a single newline before mid-paragraph numbers (ReactMarkdown handles lists fine)
_MIDPARA_NUMBERED = re.compile(r"(?<!^)\s+(\d+)\.\s+")
_SOURCES_SECTION = re.compile(r"(?is)\n+[-*_]{3,}\s*\n*[*_]*sources?[*_]*\s*\n.*\Z")
_SOURCES_LABEL = re.compile(r"(?im)^\s*sources?\s*:?\s*$")
_INLINE_SOURCES_TOKEN = re.compile(r"(?i)\*{0,2}sources\*{0,2}\s*:?\s*")
_INTRO_RE = re.compile(r"^(?P<intro>[^:\n]+:)\s*(?P<body>.+)$", re.DOTALL)


def _strip_inline_citation_tails(text: str) -> str:
    overall = _TRAILING_MD_ANCHOR.sub("", text)
    overall = _TRAILING_PG_PAREN.sub("", overall)
    overall = _TRAILING_SOURCEY.sub("", overall)

    cleaned_lines: list[str] = []
    for raw_line in overall.splitlines():
        tmp = _TRAILING_MD_ANCHOR.sub("", raw_line)
        tmp = _TRAILING_PG_PAREN.sub("", tmp)
        tmp = _TRAILING_SOURCEY.sub("", tmp)
        cleaned_lines.append(tmp.rstrip())
    return "\n".join(cleaned_lines).strip()


def _strip_existing_sources_section(text: str) -> str:
    trimmed = _SOURCES_SECTION.sub("", text)
    trimmed = _INLINE_SOURCES_TOKEN.sub("\n\n", trimmed)
    lines = [ln for ln in trimmed.splitlines() if not _SOURCES_LABEL.match(ln)]
    return "\n".join(lines).rstrip()


def _normalize_bullets(body: str) -> str:
    normalized: list[str] = []
    for line in body.splitlines():
        bullet_match = re.match(r"^\s*(?:-|\u2022|\u2013|\u2014)\s+", line)
        if bullet_match:
            bullet = bullet_match.group(0)
            text = re.sub(r"\s+", " ", line[len(bullet) :]).strip()
            normalized.append(f"{bullet}{text}")
        else:
            normalized.append(line.rstrip())
    return "\n".join(normalized).strip()


def _to_numbered_list(text: str) -> str:
    body = text.strip()

    if re.search(r"(?m)^\s*(?:-|\u2022|\u2013|\u2014)\s+", body):
        return _normalize_bullets(body)

    if _INLINE_BULLET.search(body):

        def _replace(match: re.Match[str]) -> str:
            return f"\n{match.group('bullet')} "

        return _normalize_bullets(_INLINE_BULLET.sub(_replace, body))

    body = _MIDPARA_NUMBERED.sub(r"\n\1. ", body)

    starts = [m.start() for m in _NUMBERED_ITEM_RE.finditer(body)]
    if not starts:
        body = re.sub(r"\s+(?=[2-9]\.\s)", "\n", body)
        return body
    starts.append(len(body))

    items: list[str] = []
    for idx in range(len(starts) - 1):
        segment = body[starts[idx] : starts[idx + 1]].strip()
        segment = re.sub(r"\s+", " ", segment)
        items.append(segment)
    return "\n\n".join(items)


def _fmt_source_line(item: Any) -> str:
    source_path = getattr(item, "source_path", None)
    if source_path is None and isinstance(item, dict):
        source_path = item.get("source_path", "")
    source_path = str(source_path or "")

    page_data = (
        getattr(item, "page_range", None)
        or getattr(item, "pages", None)
        or (item.get("page_range") if isinstance(item, dict) else None)
        or (item.get("pages") if isinstance(item, dict) else None)
    )

    basename = Path(source_path).name
    suffix = ""
    if isinstance(page_data, (list, tuple, set)) and page_data:
        ints = sorted({int(str(p)) for p in page_data if str(p).isdigit()})
        if ints:
            suffix = f" (p. {', '.join(str(p) for p in ints)})"

    return f"{basename}{suffix} — {source_path}"


def format_answer_markdown(answer_text: str, citations: Iterable[Any]) -> str:  # noqa: ARG001
    sans_sources = _strip_existing_sources_section(answer_text)
    cleaned = _strip_inline_citation_tails(sans_sources)

    intro: str | None = None
    match = _INTRO_RE.match(cleaned.strip())
    if match:
        intro = match.group("intro").strip()
        body_text = match.group("body").strip()
    else:
        body_text = cleaned.strip()

    body = _to_numbered_list(body_text)

    if intro:
        return f"{intro}\n\n{body}"
    return body

```

## `retriever/citation_utils.py`

```python
from __future__ import annotations

from pathlib import Path
from typing import Any, Iterable


def _getattr_or_key(obj: Any, name: str, default: Any = None) -> Any:
    """Support both attr and dict access (Citation object vs dict)."""
    if hasattr(obj, name):
        return getattr(obj, name)
    if isinstance(obj, dict):
        return obj.get(name, default)
    return default


def _norm_source_path(value: str | None) -> str:
    if not value:
        return ""
    try:
        path = Path(value)
        return path.stem.lower()
    except Exception:
        return str(value).strip().lower()


def _norm_pages(pages: Any) -> tuple[int, ...]:
    if pages is None:
        return ()
    try:
        if isinstance(pages, (list, tuple, set)):
            return tuple(sorted(int(x) for x in pages))
        if isinstance(pages, int):
            return (pages,)
        if isinstance(pages, str):
            normalized: list[int] = []
            for token in pages.replace(",", " ").split():
                if token.isdigit():
                    normalized.append(int(token))
            return tuple(sorted(normalized))
    except Exception:
        return ()
    return ()


def dedupe_citations(items: Iterable[Any] | None) -> list[Any]:
    """Return citations with unique (normalized path, normalized page range)."""
    seen: set[tuple[str, tuple[int, ...]]] = set()
    result: list[Any] = []
    if not items:
        return result
    for item in items:
        source_path = _getattr_or_key(item, "source_path")
        page_range = _getattr_or_key(item, "page_range", _getattr_or_key(item, "pages"))
        key = (_norm_source_path(source_path), _norm_pages(page_range))
        if key in seen:
            continue
        seen.add(key)
        result.append(item)
    return result

```

## `retriever/generator.py`

```python
"""LLM generation helpers."""

from __future__ import annotations

import hashlib
import importlib
import logging
import os
import re
from collections.abc import Iterable
from typing import Any, cast

from rapidfuzz import fuzz

from atticus.config import AppSettings

UNCERTAINTY_PATTERNS: tuple[str, ...] = (
    r"\b(?:i|we)\s+(?:am|are)\s+(?:not\s+sure|unsure)\b",
    r"\b(?:i|we)\s+(?:cannot|can't|am\s+unable\s+to)\s+(?:answer|determine|confirm)\b",
    r"\b(?:i|we)\s+(?:do\s+not|don't)\s+know\b",
    r"\b(?:i|we)\s+(?:do\s+not|don't)\s+have\s+enough\s+(?:info|information|context)\b",
    r"\b(?:cannot|can't|unable\s+to)\s+(?:answer|determine|confirm)\b",
    r"\binsufficient\s+(?:information|context)\b",
)


class GeneratorClient:
    """Wrapper around OpenAI responses with offline fallback."""

    def __init__(self, settings: AppSettings, logger: logging.Logger | None = None) -> None:
        self.settings = settings
        self.logger = logger or logging.getLogger("atticus")
        # Resolve API key and record source for diagnostics
        source = "none"
        api_key = None
        if getattr(settings, "openai_api_key", None):
            api_key = settings.openai_api_key
            source = "settings"
        elif os.getenv("OPENAI_API_KEY"):
            api_key = os.getenv("OPENAI_API_KEY")
            source = "os.environ"
        self._client: Any | None = None
        if api_key:  # pragma: no cover - requires network
            try:
                openai_module = importlib.import_module("openai")
                openai_class = cast(Any, openai_module).OpenAI
                # Pass the key explicitly so we don't rely on process env
                self._client = openai_class(api_key=api_key)
                # Safe fingerprint (sha256 prefix) for troubleshooting without leaking secrets
                try:
                    fp = hashlib.sha256(str(api_key).encode("utf-8")).hexdigest()[:12]
                except Exception:
                    fp = "unknown"
                self.logger.info(
                    "openai_client_initialized",
                    extra={
                        "extra_payload": {
                            "client": "generator",
                            "source": source,
                            "key_fp": fp,
                            "model": self.settings.generation_model,
                        }
                    },
                )
            except Exception as exc:  # pragma: no cover - network path
                self.logger.warning(
                    "OpenAI client unavailable; using offline summarizer",
                    extra={"extra_payload": {"error": str(exc)}},
                )
        else:
            self.logger.info("No OpenAI API key detected; using offline summarizer")

    def generate(  # noqa: PLR0912, PLR0915
        self,
        prompt: str,
        contexts: Iterable[str],
        citations: Iterable[str] | None = None,
        temperature: float = 0.2,
    ) -> str:
        context_text = "\n\n".join(contexts)
        if not context_text:
            return "I was unable to find supporting context for this question."

        if self._client is not None:  # pragma: no cover - requires network
            try:
                system_prompt = "You are Atticus, a factual assistant. Respond with concise paragraphs and cite the provided context snippets."
                user_prompt = f"Context:\n{context_text}\n\nPrompt:\n{prompt}"
                response: Any = self._client.responses.create(
                    model=self.settings.generation_model,
                    input=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=temperature,
                )
                if getattr(response, "output", None):
                    first_output = response.output[0]
                    content = getattr(first_output, "content", None)
                    if content and getattr(content[0], "text", None):
                        return str(content[0].text).strip()
            except Exception as exc:
                self.logger.error(
                    "OpenAI generation failed; using offline summarizer",
                    extra={"extra_payload": {"error": str(exc)}},
                )

        # Offline: try Q/A matching first, then specialized heuristics, then summary
        lowered_prompt = prompt.lower()
        # Q/A pairs like: "Q: ..." followed later by "A: ..."
        try:
            QA_MATCH_THRESHOLD = 0.6
            for block in contexts:
                lines = block.splitlines()
                content_lines = lines[1:] if lines and ":" in lines[0] else lines
                for i, line in enumerate(content_lines):
                    if line.strip().lower().startswith("q:"):
                        q_text = line.split(":", 1)[1].strip()
                        score = fuzz.partial_ratio(lowered_prompt, q_text.lower()) / 100.0
                        if score >= QA_MATCH_THRESHOLD:
                            for j in range(i + 1, min(i + 5, len(content_lines))):
                                nxt = content_lines[j].strip()
                                if nxt.lower().startswith("a:"):
                                    return nxt.split(":", 1)[1].strip()
        except Exception:
            pass

        # Lightweight heuristic for common spec-style questions when offline
        lowered_prompt = prompt.lower()
        if any(key in lowered_prompt for key in ["resolution", "dpi", "print resolution"]):
            phrases: list[str] = []
            for block in contexts:
                # Search each line for DPI patterns (e.g., 1200 x 1200 dpi, 600 dpi)
                for line in block.splitlines():
                    m_iter = re.finditer(
                        r"\b(?:up to\s*)?(?:\d{2,4}\s*[x×]\s*\d{2,4}|\d{2,4})\s*dpi\b(?:\s*[A-Za-z/ ]*)?",
                        line,
                        flags=re.IGNORECASE,
                    )
                    for m in m_iter:
                        phrase = re.sub(r"\s+", " ", m.group(0)).strip()
                        if phrase.lower() not in {p.lower() for p in phrases}:
                            phrases.append(phrase)
            if phrases:
                header = "Print resolution"
                # Prefer the richest phrase (contains x)
                phrases.sort(key=lambda p: ("x" not in p.lower(), len(p)))
                body = "; ".join(phrases[:3])
                lines = [f"{header}: {body}"]
                cite_list = list(citations or [])
                if cite_list:
                    lines.append("")
                    lines.append("Citations:")
                    for idx, citation in enumerate(cite_list[:10], start=1):
                        lines.append(f"[{idx}] {citation}")
                return "\n".join(lines)

        summary_lines = ["I found the following grounded details:"]
        for idx, snippet in enumerate(contexts, start=1):
            headline = snippet.splitlines()[0][:200]
            summary_lines.append(f"- [{idx}] {headline}")
        citation_list = list(citations or [])
        if citation_list:
            summary_lines.append("")
            summary_lines.append("Citations:")
            for idx, citation in enumerate(citation_list, start=1):
                summary_lines.append(f"[{idx}] {citation}")
        return "\n".join(summary_lines)

    def heuristic_confidence(self, answer: str) -> float:
        lowered = answer.lower()
        # If we produced a clear spec with DPI, boost confidence slightly
        if "dpi" in lowered:
            if re.search(r"\b\d{2,4}\s*(?:[x×]\s*\d{2,4}\s*)?dpi\b", lowered):
                return 0.9
        if any(re.search(pattern, lowered) for pattern in UNCERTAINTY_PATTERNS):
            return 0.3
        if "confidence" in lowered and "%" in lowered:
            try:
                percent_tokens = (
                    int(token.strip("%"))
                    for token in lowered.split()
                    if token.strip("% ").isdigit()
                )
                percent = next(percent_tokens)
                return max(0.0, min(1.0, percent / 100.0))
            except Exception:
                return 0.6
        return 0.8

```

## `retriever/models.py`

```python
"""Data models and catalog utilities for retrieval."""

from __future__ import annotations

import json
import re
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path
from typing import Any, Iterable

from atticus.config import load_settings


@dataclass(slots=True)
class Citation:
    chunk_id: str
    source_path: str
    page_number: int | None
    heading: str | None
    score: float


@dataclass(slots=True)
class Answer:
    question: str
    response: str
    citations: list[Citation]
    confidence: float
    should_escalate: bool
    model: str | None = None
    family: str | None = None
    family_label: str | None = None


@dataclass(frozen=True, slots=True)
class FamilyOption:
    """Selectable family used for clarifications."""

    id: str
    label: str


@dataclass(frozen=True, slots=True)
class ModelIdentifier:
    canonical: str
    family_id: str
    family_label: str


@dataclass(slots=True)
class FamilyCatalogEntry:
    id: str
    label: str
    aliases: set[str]
    models: dict[str, ModelIdentifier]


@dataclass(slots=True)
class ModelCatalog:
    families: dict[str, FamilyCatalogEntry]
    ordered_families: list[FamilyCatalogEntry]
    alias_to_model: dict[str, ModelIdentifier]
    compact_alias_to_model: dict[str, ModelIdentifier]
    family_alias_to_id: dict[str, FamilyOption]
    compact_family_alias_to_id: dict[str, FamilyOption]

    def match_model(self, raw: str) -> ModelIdentifier | None:
        norm = _normalize(raw)
        if norm in self.alias_to_model:
            return self.alias_to_model[norm]
        compact = _compact(raw)
        return self.compact_alias_to_model.get(compact)

    def match_family(self, raw: str) -> FamilyOption | None:
        norm = _normalize(raw)
        if norm in self.family_alias_to_id:
            return self.family_alias_to_id[norm]
        compact = _compact(raw)
        return self.compact_family_alias_to_id.get(compact)

    def family_options(self) -> list[FamilyOption]:
        return [FamilyOption(entry.id, entry.label) for entry in self.ordered_families]


@dataclass(slots=True)
class ModelExtraction:
    models: set[str]
    families: set[str]
    confidence: float


STRICT_MODEL_PATTERN = re.compile(r"\bapeos\s+c\s*(\d{4})\b", re.IGNORECASE)


def _normalize(value: str) -> str:
    return re.sub(r"[^a-z0-9]+", " ", value.lower()).strip()


def _compact(value: str) -> str:
    return re.sub(r"[^a-z0-9]+", "", value.lower()).strip()


def _load_catalog_path(path: str | Path | None = None) -> Path:
    if path is not None:
        return Path(path)
    settings = load_settings()
    return (settings.indices_dir / "model_catalog.json").resolve()


def _load_catalog_json(path: Path) -> dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Model catalog not found at {path}")
    payload = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(payload, dict):
        raise ValueError("Model catalog must be a JSON object at the top level.")
    return payload


def _entry_aliases(raw_aliases: Iterable[str], canonical: str) -> set[str]:
    aliases = {canonical}
    aliases.update(raw_aliases)
    normalized: set[str] = set()
    for alias in aliases:
        cleaned_alias = alias.strip()
        if not cleaned_alias:
            continue
        normalized.add(cleaned_alias)
        compact = _compact(cleaned_alias)
        # Ensure we have single-token shorthand for values such as "Apeos C 7070"
        if len(compact) > 3:
            normalized.add(compact.upper())
    return normalized


@lru_cache(maxsize=2)
def load_model_catalog(path: str | Path | None = None) -> ModelCatalog:
    catalog_path = _load_catalog_path(path)
    payload = _load_catalog_json(catalog_path)
    families: dict[str, FamilyCatalogEntry] = {}
    ordered: list[FamilyCatalogEntry] = []
    alias_to_model: dict[str, ModelIdentifier] = {}
    compact_alias_to_model: dict[str, ModelIdentifier] = {}
    family_alias_to_id: dict[str, FamilyOption] = {}
    compact_family_alias_to_id: dict[str, FamilyOption] = {}

    for entry in payload.get("families", []):
        family_id = str(entry.get("id", "")).strip()
        label = str(entry.get("label", "")).strip() or family_id
        if not family_id:
            continue
        aliases_raw = entry.get("aliases", []) or []
        family_option = FamilyOption(family_id, label)
        entry_aliases = {_normalize(alias) for alias in aliases_raw if alias}
        entry_aliases.add(_normalize(label))
        entry_aliases.add(_normalize(family_id))
        compact_aliases = {_compact(alias) for alias in aliases_raw if alias}
        compact_aliases.add(_compact(label))
        compact_aliases.add(_compact(family_id))

        family_alias_to_id.update({alias: family_option for alias in entry_aliases if alias})
        compact_family_alias_to_id.update(
            {alias: family_option for alias in compact_aliases if alias}
        )

        models_map: dict[str, ModelIdentifier] = {}
        for model_entry in entry.get("models", []):
            canonical = str(model_entry.get("canonical", "")).strip()
            if not canonical:
                continue
            identifier = ModelIdentifier(
                canonical=canonical, family_id=family_id, family_label=label
            )
            aliases = _entry_aliases(model_entry.get("aliases", []) or [], canonical)
            for alias in aliases:
                normalized_alias = _normalize(alias)
                if normalized_alias:
                    alias_to_model.setdefault(normalized_alias, identifier)
                compact_alias = _compact(alias)
                if compact_alias:
                    compact_alias_to_model.setdefault(compact_alias, identifier)
            models_map[canonical] = identifier

        family_entry = FamilyCatalogEntry(
            id=family_id,
            label=label,
            aliases={_normalize(alias) for alias in aliases_raw if alias},
            models=models_map,
        )
        families[family_id] = family_entry
        ordered.append(family_entry)

    return ModelCatalog(
        families=families,
        ordered_families=ordered,
        alias_to_model=alias_to_model,
        compact_alias_to_model=compact_alias_to_model,
        family_alias_to_id=family_alias_to_id,
        compact_family_alias_to_id=compact_family_alias_to_id,
    )


def extract_models(question: str, catalog: ModelCatalog | None = None) -> ModelExtraction:
    """Extract explicit model or family references from a question."""

    catalog = catalog or load_model_catalog()
    normalized_question = _normalize(question)
    compact_question = _compact(question)
    tokens = set(normalized_question.split())

    models: set[str] = set()
    families: set[str] = set()
    confidences: list[float] = []

    for match in STRICT_MODEL_PATTERN.finditer(question):
        series = match.group(1)
        candidate = f"Apeos C{series}"
        identifier = catalog.match_model(candidate)
        if identifier:
            models.add(identifier.canonical)
            families.add(identifier.family_id)
            confidences.append(0.95)

    matched_aliases: set[str] = set()

    for alias, identifier in catalog.alias_to_model.items():
        if alias in matched_aliases:
            continue
        if " " in alias:
            padded = f" {alias} "
            if padded in f" {normalized_question} ":
                models.add(identifier.canonical)
                families.add(identifier.family_id)
                confidences.append(0.85)
                matched_aliases.add(alias)
        elif alias in tokens:
            models.add(identifier.canonical)
            families.add(identifier.family_id)
            confidences.append(0.8)
            matched_aliases.add(alias)
        else:
            compact_alias = _compact(alias)
            if compact_alias and compact_alias in compact_question:
                models.add(identifier.canonical)
                families.add(identifier.family_id)
                confidences.append(0.75)
                matched_aliases.add(alias)

    for alias, option in catalog.family_alias_to_id.items():
        if alias in matched_aliases:
            continue
        if " " in alias:
            if f" {alias} " in f" {normalized_question} ":
                families.add(option.id)
                confidences.append(0.7)
        elif alias in tokens:
            families.add(option.id)
            confidences.append(0.65)
        else:
            compact_alias = _compact(alias)
            if compact_alias and compact_alias in compact_question:
                families.add(option.id)
                confidences.append(0.6)

    confidence = max(confidences) if confidences else 0.0
    return ModelExtraction(models=models, families=families, confidence=confidence)

```

## `retriever/resolver.py`

```python
"""Utilities for resolving model references into retrieval scopes."""

from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, Sequence

from .models import (
    FamilyOption,
    ModelCatalog,
    ModelExtraction,
    ModelIdentifier,
    extract_models,
    load_model_catalog,
)


@dataclass(slots=True)
class ModelScope:
    family_id: str
    family_label: str
    model: str | None = None


@dataclass(slots=True)
class ModelResolution:
    scopes: list[ModelScope]
    confidence: float
    needs_clarification: bool
    clarification_options: list[FamilyOption]

    @property
    def families(self) -> set[str]:
        return {scope.family_id for scope in self.scopes if scope.family_id}


def _resolve_explicit_models(
    requested_models: Sequence[str],
    catalog: ModelCatalog,
) -> tuple[list[ModelScope], float]:
    scopes: list[ModelScope] = []
    for raw in requested_models:
        ident: ModelIdentifier | None = catalog.match_model(raw)
        if ident:
            scopes.append(
                ModelScope(
                    family_id=ident.family_id,
                    family_label=ident.family_label,
                    model=ident.canonical,
                )
            )
            continue
        family = catalog.match_family(raw)
        if family:
            # Avoid duplicate family-only scopes if multiple aliases map to the same family.
            if not any(scope.family_id == family.id and scope.model is None for scope in scopes):
                scopes.append(ModelScope(family_id=family.id, family_label=family.label))
    confidence = 1.0 if scopes else 0.0
    return scopes, confidence


def resolve_models(
    question: str,
    requested_models: Iterable[str] | None = None,
    *,
    catalog: ModelCatalog | None = None,
    clarification_threshold: float = 0.65,
) -> ModelResolution:
    """Resolve models/families mentioned in a question or supplied explicitly."""

    catalog = catalog or load_model_catalog()
    options = catalog.family_options()
    requested: Sequence[str] = list(requested_models or [])

    scopes, confidence = _resolve_explicit_models(requested, catalog)
    if scopes:
        return ModelResolution(
            scopes=scopes,
            confidence=confidence,
            needs_clarification=False,
            clarification_options=options,
        )

    extraction: ModelExtraction = extract_models(question, catalog=catalog)
    scopes = []

    for model_name in sorted(extraction.models):
        ident = catalog.match_model(model_name)
        if not ident:
            continue
        scopes.append(
            ModelScope(
                family_id=ident.family_id,
                family_label=ident.family_label,
                model=ident.canonical,
            )
        )

    missing_families = extraction.families - {scope.family_id for scope in scopes}
    for family_id in sorted(missing_families):
        family_entry = catalog.families.get(family_id)
        if not family_entry:
            continue
        scopes.append(
            ModelScope(
                family_id=family_entry.id,
                family_label=family_entry.label,
            )
        )

    needs_clarification = not scopes and extraction.confidence < clarification_threshold

    return ModelResolution(
        scopes=scopes,
        confidence=extraction.confidence,
        needs_clarification=needs_clarification,
        clarification_options=options,
    )

```

## `retriever/service.py`

```python
"""High-level question answering orchestration."""

from __future__ import annotations

import logging

from atticus.config import AppSettings, load_settings
from atticus.logging import configure_logging, log_event

from .answer_format import format_answer_markdown
from .citation_utils import dedupe_citations
from .generator import GeneratorClient
from .models import Answer, Citation
from .vector_store import SearchResult, VectorStore


def _format_contexts(results: list[SearchResult], limit: int) -> tuple[list[str], list[Citation]]:
    contexts: list[str] = []
    citations: list[Citation] = []
    seen: set[tuple[str, int | None]] = set()

    for result in results:
        page_value = result.page_number
        if isinstance(page_value, str):
            try:
                page_key = int(page_value)
            except ValueError:
                page_key = page_value.strip()
        else:
            page_key = page_value

        key = (result.source_path, page_key)
        if key in seen:
            continue

        seen.add(key)
        descriptor = result.source_path
        if page_value:
            descriptor += f" (page {page_value})"
        contexts.append(result.text)
        citations.append(
            Citation(
                chunk_id=result.chunk_id,
                source_path=result.source_path,
                page_number=page_key if isinstance(page_key, int) else result.page_number,
                heading=result.heading,
                score=round(result.score, 4),
            )
        )

        if len(contexts) >= limit:
            break

    return contexts, citations


LLM_CONF_SWITCH = 0.80


def answer_question(
    question: str,
    settings: AppSettings | None = None,
    filters: dict[str, str] | None = None,
    logger: logging.Logger | None = None,
    *,
    top_k: int | None = None,
    context_hints: list[str] | None = None,
    product_family: str | None = None,
    family_label: str | None = None,
    model: str | None = None,
) -> Answer:
    settings = settings or load_settings()
    logger = logger or configure_logging(settings)
    store = VectorStore(settings, logger)
    window = top_k or settings.top_k
    merged_filters = dict(filters or {})
    if product_family:
        merged_filters["product_family"] = product_family
    results = store.search(question, top_k=window, filters=merged_filters, hybrid=True)

    if not results:
        response = "I don't have enough information in the current index to answer this."
        confidence = 0.2
        should_escalate = True
        answer = Answer(
            question=question,
            response=response,
            citations=[],
            confidence=confidence,
            should_escalate=should_escalate,
            model=model,
            family=product_family,
            family_label=family_label,
        )
        log_event(
            logger,
            "answer_generated",
            confidence=confidence,
            citations=0,
            escalate=should_escalate,
            filters=merged_filters,
        )
        return answer

    contexts, citations = _format_contexts(results, settings.max_context_chunks)
    if context_hints:
        contexts.extend(context_hints)
    generator = GeneratorClient(settings, logger)
    citation_texts = []
    for item in citations:
        descriptor = item.source_path
        if item.page_number is not None:
            descriptor += f" (page {item.page_number})"
        if item.heading:
            descriptor += f" — {item.heading}"
        citation_texts.append(descriptor)

    response = generator.generate(question, contexts, citation_texts)

    # Emphasize the head of the ranking when computing retrieval confidence
    head = min(5, settings.max_context_chunks)
    top_scores = [max(0.0, min(1.0, result.score)) for result in results[:head]]
    retrieval_conf = sum(top_scores) / len(top_scores) if top_scores else 0.0
    llm_conf = generator.heuristic_confidence(response)
    w_r, w_l = 0.6, 0.4
    if llm_conf >= LLM_CONF_SWITCH:
        w_r, w_l = 0.2, 0.8
    confidence = round(w_r * retrieval_conf + w_l * llm_conf, 2)
    should_escalate = confidence < settings.confidence_threshold

    citations = dedupe_citations(citations)
    formatted_response = format_answer_markdown(response, citations)
    answer = Answer(
        question=question,
        response=formatted_response,
        citations=citations,
        confidence=confidence,
        should_escalate=should_escalate,
        model=model,
        family=product_family,
        family_label=family_label,
    )

    log_event(
        logger,
        "answer_generated",
        confidence=confidence,
        citations=len(citations),
        escalate=should_escalate,
        filters=merged_filters,
    )
    return answer

```

## `scripts/atticus_cli.py`

```python
#!/usr/bin/env python3
"""Unified CLI dispatcher for Atticus utilities."""

from __future__ import annotations

import argparse
import subprocess
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.logging_utils import get_logger

log = get_logger("atticus_cli")

COMMANDS = {
    "ingest": [sys.executable, str(ROOT / "scripts" / "ingest_cli.py")],
    "eval": [sys.executable, str(ROOT / "scripts" / "eval_run.py")],
    "qa": [sys.executable, str(ROOT / "scripts" / "eval_qa.py")],
    "chunk-ced": [sys.executable, str(ROOT / "scripts" / "chunk_ced.py")],
    "db-verify": [sys.executable, str(ROOT / "scripts" / "db_verify.py")],
    "openapi": [sys.executable, str(ROOT / "scripts" / "generate_api_docs.py")],
    "audit-unused": [sys.executable, str(ROOT / "scripts" / "audit_unused.py")],
    "env": [sys.executable, str(ROOT / "scripts" / "generate_env.py")],
    "e2e-smoke": [sys.executable, str(ROOT / "scripts" / "e2e_smoke.py")],
    "debug-env": [sys.executable, str(ROOT / "scripts" / "debug_env.py")],
}


def main(argv: list[str] | None = None) -> int:
    argv = list(sys.argv[1:] if argv is None else argv)

    parser = argparse.ArgumentParser(prog="atticus", description="Atticus unified CLI")
    parser.add_argument(
        "command", nargs="?", choices=sorted(COMMANDS.keys()), help="subcommand to run"
    )
    parser.add_argument(
        "args", nargs=argparse.REMAINDER, help="arguments passed to subcommand (prefix with --)"
    )
    if not argv:
        parser.print_help()
        return 0

    ns = parser.parse_args(argv)
    if ns.command is None:
        parser.print_help()
        return 0

    cmd = COMMANDS[ns.command] + ns.args
    log.info("dispatch", command=ns.command, args=ns.args)
    try:
        return subprocess.call(cmd)
    except KeyboardInterrupt:
        log.warning("interrupt")
        return 130


if __name__ == "__main__":
    raise SystemExit(main())

```

## `scripts/audit_unused.py`

```python
#!/usr/bin/env python3
"""Audit script for unused Python modules and dead code.

Runs vulture (if installed) against default project paths and prints a JSON
summary. The script degrades gracefully when optional tools are missing.
"""

from __future__ import annotations

import argparse
import json
import shutil
import subprocess
import sys
from pathlib import Path

DEFAULT_PATHS: list[str] = [
    "atticus",
    "api",
    "ingest",
    "retriever",
    "eval",
    "scripts",
    "tests",
]


def run_vulture(paths: list[str], min_confidence: int) -> dict[str, object]:
    executable = shutil.which("vulture")
    if executable is None:
        return {
            "tool": "vulture",
            "error": "vulture not installed. Install with `pip install vulture` or add to dev dependencies.",
        }

    cmd: list[str] = [executable, *paths, "--min-confidence", str(min_confidence), "--sort-by-size"]
    result = subprocess.run(cmd, capture_output=True, text=True, check=False)
    return {
        "tool": "vulture",
        "returncode": result.returncode,
        "stdout": result.stdout.strip(),
        "stderr": result.stderr.strip(),
    }


def main(argv: list[str]) -> int:
    parser = argparse.ArgumentParser(description="Audit unused Python code via vulture")
    parser.add_argument("paths", nargs="*", default=DEFAULT_PATHS, help="Paths to inspect")
    parser.add_argument(
        "--min-confidence", type=int, default=80, help="Minimum confidence threshold for vulture"
    )
    parser.add_argument("--json", action="store_true", help="Emit machine-readable JSON output")
    args = parser.parse_args(argv)

    resolved_paths: list[str] = []
    for path in args.paths:
        candidate = Path(path)
        if candidate.exists():
            resolved_paths.append(str(candidate))
    if not resolved_paths:
        resolved_paths = DEFAULT_PATHS

    report = {"vulture": run_vulture(resolved_paths, args.min_confidence)}

    if args.json:
        json.dump(report, sys.stdout, indent=2)
        sys.stdout.write("\n")
    else:
        sys.stdout.write(json.dumps(report, indent=2))
        sys.stdout.write("\n")

    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

```

## `scripts/check_version_parity.py`

```python
"""Ensure repository version metadata stays in sync across toolchains."""

from __future__ import annotations

import json
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]


def read_version_file() -> str:
    version_path = ROOT / "VERSION"
    try:
        version = version_path.read_text(encoding="utf-8").strip()
    except OSError as exc:
        raise SystemExit(f"Failed to read VERSION: {exc}") from exc
    if not version:
        raise SystemExit("VERSION file is empty.")
    return version


def read_package_version() -> str:
    package_path = ROOT / "package.json"
    try:
        package_data = json.loads(package_path.read_text(encoding="utf-8"))
    except (OSError, json.JSONDecodeError) as exc:
        raise SystemExit(f"Failed to parse package.json: {exc}") from exc
    version = package_data.get("version")
    if not isinstance(version, str) or not version:
        raise SystemExit("package.json is missing a version field")
    return version


def read_package_lock_version() -> str:
    lock_path = ROOT / "package-lock.json"
    try:
        lock_data = json.loads(lock_path.read_text(encoding="utf-8"))
    except (OSError, json.JSONDecodeError) as exc:
        raise SystemExit(f"Failed to parse package-lock.json: {exc}") from exc
    version = lock_data.get("version")
    if not isinstance(version, str) or not version:
        raise SystemExit("package-lock.json is missing a top-level version")
    return version


def main() -> int:
    repo_version = read_version_file()
    package_version = read_package_version()
    lock_version = read_package_lock_version()

    mismatches: list[str] = []
    if package_version != repo_version:
        mismatches.append(
            f"package.json version {package_version} does not match VERSION {repo_version}"
        )
    if lock_version != repo_version:
        mismatches.append(
            f"package-lock.json version {lock_version} does not match VERSION {repo_version}"
        )

    if mismatches:
        for mismatch in mismatches:
            print(f"[WARN] {mismatch}")
        return 1

    print(f"[OK] Version parity check passed: {repo_version}")
    return 0


if __name__ == "__main__":
    sys.exit(main())

```

## `scripts/chunk_ced.py`

```python
#!/usr/bin/env python3
"""Chunk CED PDF documents into JSONL artifacts."""

from __future__ import annotations

import argparse
import json
import os
import re
import sys
from collections import Counter
from collections.abc import Iterable
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from statistics import median

import fitz  # type: ignore[import-untyped]

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.config import load_settings  # noqa: E402
from atticus.logging_utils import get_logger  # noqa: E402
from atticus.tokenization import decode, encode, split_tokens  # noqa: E402
from atticus.utils import sha256_file, sha256_text  # noqa: E402

log = get_logger("chunk_ced")

try:  # pragma: no cover - optional dependency
    import camelot  # type: ignore[import-untyped]
except Exception:  # pragma: no cover
    camelot = None

try:  # pragma: no cover - optional dependency
    import tabula  # type: ignore[import-untyped]
except Exception:  # pragma: no cover
    tabula = None

STOPWORDS = {
    "the",
    "and",
    "for",
    "with",
    "that",
    "from",
    "this",
    "will",
    "your",
    "have",
    "into",
    "when",
    "where",
    "such",
    "each",
    "over",
    "there",
    "should",
    "their",
    "which",
    "these",
    "between",
}

HEADING_WORD_LIMIT = 12
TABLE_EMPTY_RATIO = 0.2
GARBLE_THRESHOLD = 0.05
FONT_SIZE_PADDING = 2.0


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Chunk a CED PDF into JSONL outputs")
    parser.add_argument("--input", type=Path, required=True, help="Path to the source PDF")
    parser.add_argument("--output", type=Path, required=True, help="JSONL file for text chunks")
    parser.add_argument("--tables", type=Path, required=True, help="JSONL file for table chunks")
    parser.add_argument(
        "--doc-index",
        type=Path,
        required=True,
        help="Path to write document-level index metadata",
    )
    parser.add_argument("--target-tokens", type=int)
    parser.add_argument("--min-tokens", type=int)
    parser.add_argument("--overlap", type=int)
    parser.add_argument("--config", type=Path, help="Alternate config.yaml path")
    return parser.parse_args()


@dataclass(slots=True)
class Section:
    heading: str | None
    text: str
    pages: set[int]
    breadcrumbs: list[str]


@dataclass(slots=True)
class Chunk:
    text: str
    pages: set[int]
    headings: set[str]
    breadcrumbs: list[str]
    token_count: int
    is_table: bool = False
    table_headers: list[str] | None = None


def _sanitize(text: str) -> str:
    return re.sub(r"\s+", " ", text).strip()


def _extract_models(source: Path) -> list[str]:
    stem = source.stem
    match = re.search(r"CED[-_]?(\d+)", stem, flags=re.IGNORECASE)
    prefix = stem
    if match:
        prefix = stem[: match.start()].rstrip("-_ ")
    if "_" in prefix:
        prefix = prefix.split("_", 1)[1]
    models_part = re.split(r"-CED[-_]?\d+", prefix, flags=re.IGNORECASE)[0]
    raw_models = [item for item in re.split(r"[-_]", models_part) if item]
    return raw_models


def _ced_id(source: Path) -> tuple[str, str]:
    match = re.search(r"CED[-_]?(\d+)", source.stem, flags=re.IGNORECASE)
    if not match:
        return ("ced-unknown", "0")
    value = match.group(1)
    return (f"ced-{value}", value)


def _compute_font_baseline(document: fitz.Document) -> float:
    sizes: list[float] = []
    for page in document:
        content = page.get_text("dict")
        for block in content.get("blocks", []):
            for line in block.get("lines", []):
                for span in line.get("spans", []):
                    size = span.get("size")
                    if size:
                        sizes.append(float(size))
    if not sizes:
        return 11.0
    return median(sizes)


def extract_sections(document: fitz.Document, heading_threshold: float) -> list[Section]:
    sections: list[Section] = []
    buffer: list[str] = []
    pages: set[int] = set()
    current_heading: str | None = None

    def flush() -> None:
        nonlocal buffer, pages
        if not buffer:
            return
        sections.append(
            Section(
                heading=current_heading,
                text="\n".join(buffer).strip(),
                pages=pages.copy() or {1},
                breadcrumbs=[
                    breadcrumb for breadcrumb in ([current_heading] if current_heading else [])
                ],
            )
        )
        buffer.clear()
        pages.clear()

    for index, page in enumerate(document, start=1):
        page_dict = page.get_text("dict")
        for block in page_dict.get("blocks", []):
            for line in block.get("lines", []):
                spans = line.get("spans", [])
                text = _sanitize("".join(span.get("text", "") for span in spans))
                if not text:
                    continue
                max_size = max(float(span.get("size", 0.0)) for span in spans)
                if max_size >= heading_threshold and len(text.split()) <= HEADING_WORD_LIMIT:
                    flush()
                    current_heading = text
                    continue
                buffer.append(text)
                pages.add(index)

    flush()
    return sections


def extract_tables(path: Path) -> list[Chunk]:  # noqa: PLR0912
    tables: list[Chunk] = []
    if camelot is not None:  # pragma: no cover - requires camelot deps
        try:
            camelot_tables = camelot.read_pdf(str(path), pages="all")
        except Exception:
            camelot_tables = []
        for index, table in enumerate(camelot_tables, start=1):
            try:
                dataframe = table.df  # type: ignore[attr-defined]
            except Exception:
                continue
            if dataframe.empty:
                continue
            cleaned = dataframe.fillna("")
            total_cells = cleaned.size
            empty_cells = sum(1 for value in cleaned.to_numpy().flatten() if not str(value).strip())
            if total_cells and (empty_cells / total_cells) > TABLE_EMPTY_RATIO:
                continue
            header = [str(item).strip() for item in cleaned.iloc[0].tolist()]
            body = cleaned.iloc[1:]
            rows = [
                " | ".join(str(cell).strip() for cell in row.tolist()) for _, row in body.iterrows()
            ]
            text = "\n".join(rows).strip()
            if not text:
                continue
            table_breadcrumbs = [f"Table {index}"]
            tables.append(
                Chunk(
                    text=text,
                    pages={int(getattr(table, "page", 1))},
                    headings={f"Table {index}"},
                    breadcrumbs=table_breadcrumbs,
                    token_count=len(encode(text)),
                    is_table=True,
                    table_headers=header,
                )
            )
        if tables:
            return tables
    if tabula is not None:  # pragma: no cover - requires java
        try:
            dataframes = tabula.read_pdf(str(path), pages="all", multiple_tables=True)
        except Exception:
            dataframes = []
        for index, dataframe in enumerate(dataframes, start=1):
            if dataframe is None or dataframe.empty:
                continue
            cleaned = dataframe.fillna("")
            total_cells = cleaned.size
            empty_cells = sum(1 for value in cleaned.to_numpy().flatten() if not str(value).strip())
            if total_cells and (empty_cells / total_cells) > TABLE_EMPTY_RATIO:
                continue
            header = [str(col).strip() for col in cleaned.columns]
            rows = [" | ".join(str(cell).strip() for cell in row) for row in cleaned.to_numpy()]
            text = "\n".join(rows).strip()
            if not text:
                continue
            table_breadcrumbs = [f"Table {index}"]
            tables.append(
                Chunk(
                    text=text,
                    pages={1},
                    headings={f"Table {index}"},
                    breadcrumbs=table_breadcrumbs,
                    token_count=len(encode(text)),
                    is_table=True,
                    table_headers=header,
                )
            )
    return tables


def merge_small_chunks(chunks: list[Chunk], min_tokens: int) -> list[Chunk]:
    if not chunks:
        return chunks
    merged: list[Chunk] = []
    for chunk in chunks:
        if merged and chunk.token_count < min_tokens and not chunk.is_table:
            target = merged[-1]
            target.text = f"{target.text}\n{chunk.text}".strip()
            target.token_count += chunk.token_count
            target.pages.update(chunk.pages)
            target.headings.update(chunk.headings)
            target.breadcrumbs = list(dict.fromkeys(target.breadcrumbs + chunk.breadcrumbs))
        else:
            merged.append(chunk)
    return merged


def chunk_sections(
    sections: list[Section],
    target_tokens: int,
    min_tokens: int,
    overlap: int,
    base_breadcrumbs: list[str],
) -> list[Chunk]:
    all_chunks: list[Chunk] = []
    for section in sections:
        tokens = encode(section.text)
        if not tokens:
            continue
        splits = list(split_tokens(tokens, target_tokens, overlap))
        section_chunks: list[Chunk] = []
        for start, end in splits:
            piece = tokens[start:end]
            text = decode(piece).strip()
            if not text:
                continue
            section_chunks.append(
                Chunk(
                    text=text,
                    pages=section.pages.copy() or {1},
                    headings={heading for heading in [section.heading] if heading},
                    breadcrumbs=list(
                        dict.fromkeys(
                            base_breadcrumbs + (section.breadcrumbs if section.breadcrumbs else [])
                        )
                    ),
                    token_count=len(piece),
                )
            )
        section_chunks = merge_small_chunks(section_chunks, min_tokens)
        all_chunks.extend(section_chunks)
    return all_chunks


def garble_ratio(text: str) -> float:
    if not text:
        return 0.0
    garbled = sum(1 for char in text if char == "\ufffd")
    return garbled / max(1, len(text))


def summarize(text: str) -> str:
    sentences = re.split(r"(?<=[.!?])\s+", text.strip())
    return sentences[0][:240] if sentences else text[:240]


# Remove trailing markdown anchors like: ([Secondary Ethernet Limitations](#37)).
_TRAILING_ANCHOR_RE = re.compile(r"\s*\(\[[^\]]+\]\(#\d+\)\)\.?\s*$")


def clean_summary(text: str) -> str:
    """Summarize and strip dangling anchor-style citations."""
    summary = summarize(text)
    return _TRAILING_ANCHOR_RE.sub("", summary).strip()


def extract_keywords(text: str, top_n: int = 5) -> list[str]:
    words = [re.sub(r"[^a-z0-9]", "", token.lower()) for token in text.split()]
    words = [word for word in words if word and word not in STOPWORDS]
    counts = Counter(words)
    return [word for word, _ in counts.most_common(top_n)]


def write_jsonl(path: Path, entries: Iterable[dict]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as handle:
        for entry in entries:
            handle.write(json.dumps(entry, ensure_ascii=False) + "\n")


def main() -> None:
    args = parse_args()
    if args.config:
        os.environ["CONFIG_PATH"] = str(args.config)

    settings = load_settings()
    source_file = args.input
    if not source_file.exists():
        raise FileNotFoundError(source_file)

    ced_id, version = _ced_id(source_file)
    models = _extract_models(source_file)
    timestamp = datetime.utcnow().isoformat(timespec="seconds") + "Z"

    log.info("open_document", path=str(source_file))
    document = fitz.open(str(source_file))
    font_baseline = _compute_font_baseline(document)
    sections = extract_sections(document, font_baseline + FONT_SIZE_PADDING)
    tables = extract_tables(source_file)
    base_breadcrumbs = [ced_id.upper(), source_file.stem]
    target_tokens = args.target_tokens or settings.chunk_target_tokens or 800
    min_tokens = args.min_tokens or settings.chunk_min_tokens or 400
    if args.overlap is not None:
        overlap = max(0, args.overlap)
    else:
        overlap = settings.chunk_overlap_tokens
    chunks = chunk_sections(sections, target_tokens, min_tokens, overlap, base_breadcrumbs)
    document.close()

    chunk_payloads: list[dict[str, object]] = []
    table_payloads: list[dict[str, object]] = []
    chunk_index = 0
    for chunk in chunks:
        ratio = garble_ratio(chunk.text)
        if ratio > GARBLE_THRESHOLD:
            log.warning(
                "skip_garbled_chunk",
                pages=sorted(chunk.pages),
                garble_ratio=ratio,
                chunk_id=f"{ced_id}::chunk_{chunk_index + 1:04d}",
            )
            continue
        chunk_index += 1
        pages = sorted(chunk.pages)
        models_present = [model for model in models if model.lower() in chunk.text.lower()]
        payload = {
            "chunk_id": f"{ced_id}::chunk_{chunk_index:04d}",
            "source_file": str(source_file),
            "doc_type": "ced",
            "ced_id": ced_id,
            "version": version,
            "page_range": pages,
            "section_titles": sorted(chunk.headings),
            "breadcrumbs": chunk.breadcrumbs or base_breadcrumbs,
            "is_table": False,
            "table_headers": [],
            "models": models,
            "models_present": models_present,
            "token_index": chunk_index - 1,
            "token_count": chunk.token_count,
            "embedding_model": settings.embed_model,
            "embedding_model_version": settings.embedding_model_version,
            "ingested_at": timestamp,
            "hash": sha256_text(chunk.text),
            "keywords": extract_keywords(chunk.text),
            "context_summary": clean_summary(chunk.text),
            "text": chunk.text,
        }
        chunk_payloads.append(payload)

    table_index = 0
    for table in tables:
        if garble_ratio(table.text) > GARBLE_THRESHOLD:
            continue
        table_index += 1
        pages = sorted(table.pages)
        models_present = [model for model in models if model.lower() in table.text.lower()]
        payload = {
            "table_id": f"{ced_id}::table_{table_index:04d}",
            "source_file": str(source_file),
            "doc_type": "ced",
            "ced_id": ced_id,
            "version": version,
            "page_range": pages,
            "section_titles": sorted(table.headings),
            "breadcrumbs": table.breadcrumbs or base_breadcrumbs,
            "is_table": True,
            "table_headers": table.table_headers or [],
            "models": models,
            "models_present": models_present,
            "token_index": chunk_index + table_index - 1,
            "token_count": table.token_count,
            "embedding_model": settings.embed_model,
            "embedding_model_version": settings.embedding_model_version,
            "ingested_at": timestamp,
            "hash": sha256_text(table.text),
            "keywords": extract_keywords(table.text),
            "context_summary": clean_summary(table.text),
            "text": table.text,
        }
        table_payloads.append(payload)

    write_jsonl(args.output, chunk_payloads)
    write_jsonl(args.tables, table_payloads)
    log.info(
        "write_chunks_complete",
        text_chunks=len(chunk_payloads),
        table_chunks=len(table_payloads),
        output=str(args.output),
        tables=str(args.tables),
    )

    doc_index = {
        "ced_id": ced_id,
        "version": version,
        "source_file": str(source_file),
        "models": models,
        "chunk_count": len(chunk_payloads),
        "table_count": len(table_payloads),
        "generated_at": timestamp,
        "embedding_model": settings.embed_model,
        "embedding_model_version": settings.embedding_model_version,
        "document_hash": sha256_file(source_file),
    }
    args.doc_index.parent.mkdir(parents=True, exist_ok=True)
    args.doc_index.write_text(json.dumps(doc_index, indent=2), encoding="utf-8")

    log.info(
        "chunk_ced_complete",
        chunks=len(chunk_payloads),
        tables=len(table_payloads),
        doc_index=str(args.doc_index),
        models=models,
        ced_id=ced_id,
    )


if __name__ == "__main__":
    main()

```

## `scripts/db_seed.py`

```python
"""Database seeding utility used by the test suite and CLI."""

from __future__ import annotations

import argparse
import os
import sys
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

import psycopg
from psycopg.types.json import Jsonb

SEED_USERS = [
    {
        "id": "user-seed-author",
        "email": "glossary.author@seed.atticus",
        "name": "Glossary Seed Author",
        "role": "REVIEWER",
    },
    {
        "id": "user-seed-approver",
        "email": "glossary.approver@seed.atticus",
        "name": "Glossary Seed Approver",
        "role": "ADMIN",
    },
]

GLOSSARY_SEEDS = [
    {
        "id": "glossary-entry-managed-print-services",
        "term": "Managed Print Services",
        "definition": (
            "End-to-end management of printers, consumables, maintenance, and support "
            "delivered as a subscription."
        ),
        "synonyms": ["MPS", "Print-as-a-service"],
        "status": "APPROVED",
        "review_notes": "Approved for launch collateral and onboarding playbooks.",
        "reviewer_id": "user-seed-approver",
        "reviewed_at": "2024-05-01T12:00:00Z",
    },
    {
        "id": "glossary-entry-proactive-maintenance",
        "term": "Proactive Maintenance",
        "definition": (
            "Scheduled device inspections and firmware rollouts designed to prevent "
            "outages before they impact revenue teams."
        ),
        "synonyms": ["Preventative maintenance"],
        "status": "PENDING",
    },
    {
        "id": "glossary-entry-toner-optimization",
        "term": "Toner Optimization",
        "definition": (
            "Adaptive print routing and toner yield tracking that reduce waste while "
            "maintaining SLA-compliant image quality."
        ),
        "synonyms": ["Smart toner", "Consumable optimisation"],
        "status": "REJECTED",
        "review_notes": "Rejected pending customer-ready evidence and usage data.",
        "reviewer_id": "user-seed-approver",
        "reviewed_at": "2024-05-15T09:30:00Z",
    },
]

CHAT_SEEDS = [
    {
        "id": "chat-low-confidence-toner",
        "question": (
            "Why are toner replacement alerts firing for the West team despite new cartridges?"
        ),
        "confidence": 0.38,
        "status": "pending_review",
        "request_id": "req-seed-001",
        "top_sources": [
            {
                "path": "content/operations/toner-optimization.md#alerts",
                "score": 0.82,
                "heading": "Alert tuning guidance",
                "chunkId": "chunk-toner-alerts",
            },
            {
                "path": "content/playbooks/ced-toner-guide.pdf",
                "score": 0.74,
                "page": 3,
                "heading": "Replace cartridges sequence",
                "chunkId": "chunk-toner-guide-3",
            },
        ],
        "created_at": "2024-07-08T10:15:00Z",
        "audit_log": [
            {
                "action": "captured",
                "at": "2024-07-08T10:15:10.000Z",
                "confidence": 0.38,
            },
            {
                "action": "followup",
                "at": "2024-07-08T10:17:00.000Z",
                "prompt": (
                    "Confirm the affected device serial numbers and share recent firmware updates."
                ),
            },
        ],
        "user_id": "user-seed-author",
        "follow_up_prompt": "Confirm serial numbers and firmware applied last week.",
    },
    {
        "id": "chat-escalated-calibration",
        "question": (
            "Color calibration fails with streak artifacts on the ProLine 5100 series. "
            "What should we try next?"
        ),
        "confidence": 0.41,
        "status": "escalated",
        "request_id": "req-seed-002",
        "top_sources": [
            {
                "path": "content/troubleshooting/calibration-checklist.md#step-4",
                "score": 0.68,
                "heading": "Step 4 - Inspect rollers",
                "chunkId": "chunk-calibration-4",
            },
            {
                "path": "content/faq/pressroom-maintenance.md#color",
                "score": 0.62,
                "heading": "Color drift playbook",
                "chunkId": "chunk-maintenance-color",
            },
        ],
        "created_at": "2024-06-18T14:45:00Z",
        "audit_log": [
            {
                "action": "escalate",
                "at": "2024-06-18T15:00:00.000Z",
                "actorId": "user-seed-approver",
                "actorRole": "ADMIN",
                "summary": "Calibration streaks observed in pilot deployment.",
            },
        ],
        "user_id": "user-seed-author",
        "tickets": [
            {
                "id": "ticket-ae-1001",
                "key": "AE-1001",
                "status": "open",
                "assignee": "AEX-ops",
                "last_activity": "2024-06-18T15:00:00Z",
                "summary": "Investigate streak artifacts for ProLine 5100 pilot.",
                "audit_log": [
                    {
                        "action": "created",
                        "at": "2024-06-18T15:00:00.000Z",
                        "actorId": "user-seed-approver",
                        "actorRole": "ADMIN",
                    },
                ],
            },
        ],
    },
]


def _load_env_from_file(env_path: Path) -> None:
    if not env_path.exists():
        return
    for raw_line in env_path.read_text(encoding="utf-8").splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        key, sep, value = line.partition("=")
        if not sep:
            continue
        key = key.strip()
        if not key or key in os.environ:
            continue
        cleaned = value.strip()
        if (cleaned.startswith('"') and cleaned.endswith('"')) or (
            cleaned.startswith("'") and cleaned.endswith("'")
        ):
            cleaned = cleaned[1:-1]
        os.environ[key] = cleaned


def _parse_datetime(value: str | datetime | None) -> datetime | None:
    if value is None:
        return None
    if isinstance(value, datetime):
        dt = value
    else:
        normalized = value.replace("Z", "+00:00")
        dt = datetime.fromisoformat(normalized)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=UTC)
    return dt.astimezone(UTC)


def _json(value: Any) -> Jsonb:
    return Jsonb(value)


def seed_database(*, verbose: bool = False) -> None:
    _load_env_from_file(Path(".env"))
    database_url = os.environ.get("DATABASE_URL")
    if not database_url:
        raise RuntimeError("DATABASE_URL must be set before running db:seed")

    org_id = os.environ.get("DEFAULT_ORG_ID", "org-atticus")
    org_name = os.environ.get("DEFAULT_ORG_NAME", "Atticus Default")
    admin_email = os.environ.get("ADMIN_EMAIL")
    admin_name = os.environ.get("ADMIN_NAME", "Atticus Admin")

    with psycopg.connect(database_url) as conn:
        with conn.transaction():
            with conn.cursor() as cur:
                cur.execute(
                    """
                    INSERT INTO "Organization" ("id", "name")
                    VALUES (%s, %s)
                    ON CONFLICT ("id") DO UPDATE
                    SET "name" = EXCLUDED."name"
                    """,
                    (org_id, org_name),
                )
                if verbose:
                    print(f"Upserted organization {org_id}", file=sys.stderr)

                if admin_email:
                    admin_id = "user-seed-admin"
                    cur.execute(
                        """
                        INSERT INTO "User" ("id", "email", "name", "role", "orgId")
                        VALUES (%s, %s, %s, %s, %s)
                        ON CONFLICT ("email") DO UPDATE
                        SET "name" = EXCLUDED."name",
                            "role" = EXCLUDED."role",
                            "orgId" = EXCLUDED."orgId"
                        """,
                        (admin_id, admin_email.lower(), admin_name, "ADMIN", org_id),
                    )
                    if verbose:
                        print(f"Ensured admin account {admin_email}", file=sys.stderr)

                user_ids: dict[str, str] = {}
                for user in SEED_USERS:
                    cur.execute(
                        """
                        INSERT INTO "User" ("id", "email", "name", "role", "orgId")
                        VALUES (%s, %s, %s, %s, %s)
                        ON CONFLICT ("id") DO UPDATE
                        SET "email" = EXCLUDED."email",
                            "name" = EXCLUDED."name",
                            "role" = EXCLUDED."role",
                            "orgId" = EXCLUDED."orgId"
                        RETURNING "id"
                        """,
                        (
                            user["id"],
                            user["email"],
                            user["name"],
                            user["role"],
                            org_id,
                        ),
                    )
                    returned_id = cur.fetchone()[0]
                    user_ids[user["id"]] = returned_id
                    if verbose:
                        print(f"Seeded user {returned_id}", file=sys.stderr)

                author_id = user_ids["user-seed-author"]
                approver_id = user_ids["user-seed-approver"]

                for entry in GLOSSARY_SEEDS:
                    cur.execute(
                        """
                        INSERT INTO "GlossaryEntry"
                            ("id", "term", "definition", "synonyms", "status",
                             "orgId", "authorId", "reviewerId", "reviewNotes", "reviewedAt")
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT ("id") DO UPDATE
                        SET "term" = EXCLUDED."term",
                            "definition" = EXCLUDED."definition",
                            "synonyms" = EXCLUDED."synonyms",
                            "status" = EXCLUDED."status",
                            "orgId" = EXCLUDED."orgId",
                            "authorId" = EXCLUDED."authorId",
                            "reviewerId" = EXCLUDED."reviewerId",
                            "reviewNotes" = EXCLUDED."reviewNotes",
                            "reviewedAt" = EXCLUDED."reviewedAt"
                        """,
                        (
                            entry["id"],
                            entry["term"],
                            entry["definition"],
                            entry["synonyms"],
                            entry["status"],
                            org_id,
                            author_id,
                            entry.get("reviewer_id"),
                            entry.get("review_notes"),
                            _parse_datetime(entry.get("reviewed_at")),
                        ),
                    )
                    if verbose:
                        print(f"Seeded glossary entry {entry['id']}", file=sys.stderr)

                for chat in CHAT_SEEDS:
                    chat_id = chat["id"]
                    chat_user = chat.get("user_id", author_id)
                    reviewed_by = chat.get("reviewed_by_id")
                    reviewed_at = _parse_datetime(chat.get("reviewed_at"))
                    follow_up = chat.get("follow_up_prompt")

                    cur.execute(
                        """
                        INSERT INTO "Chat"
                            ("id", "orgId", "userId", "question", "answer", "confidence",
                             "status", "requestId", "topSources", "auditLog", "createdAt",
                             "reviewedById", "reviewedAt", "followUpPrompt")
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT ("id") DO UPDATE
                        SET "question" = EXCLUDED."question",
                            "answer" = EXCLUDED."answer",
                            "confidence" = EXCLUDED."confidence",
                            "status" = EXCLUDED."status",
                            "requestId" = EXCLUDED."requestId",
                            "topSources" = EXCLUDED."topSources",
                            "auditLog" = EXCLUDED."auditLog",
                            "userId" = EXCLUDED."userId",
                            "reviewedById" = EXCLUDED."reviewedById",
                            "reviewedAt" = EXCLUDED."reviewedAt",
                            "followUpPrompt" = EXCLUDED."followUpPrompt"
                        RETURNING "id"
                        """,
                        (
                            chat_id,
                            org_id,
                            chat_user,
                            chat["question"],
                            chat.get("answer"),
                            chat["confidence"],
                            chat["status"],
                            chat.get("request_id"),
                            _json(chat.get("top_sources", [])),
                            _json(chat.get("audit_log", [])),
                            _parse_datetime(chat.get("created_at")),
                            reviewed_by,
                            reviewed_at,
                            follow_up,
                        ),
                    )
                    cur.fetchone()
                    if verbose:
                        print(f"Upserted chat {chat_id}", file=sys.stderr)

                    cur.execute(
                        """
                        INSERT INTO "RagEvent"
                            ("id", "orgId", "actorId", "actorRole", "action", "entity",
                             "chatId", "requestId", "after")
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT ("id") DO UPDATE
                        SET "orgId" = EXCLUDED."orgId",
                            "actorId" = EXCLUDED."actorId",
                            "actorRole" = EXCLUDED."actorRole",
                            "action" = EXCLUDED."action",
                            "entity" = EXCLUDED."entity",
                            "chatId" = EXCLUDED."chatId",
                            "requestId" = EXCLUDED."requestId",
                            "after" = EXCLUDED."after"
                        """,
                        (
                            f"{chat_id}-captured",
                            org_id,
                            chat_user,
                            "USER",
                            "chat.captured",
                            "chat",
                            chat_id,
                            chat.get("request_id"),
                            _json({"status": chat["status"], "confidence": chat["confidence"]}),
                        ),
                    )

                    if follow_up:
                        cur.execute(
                            """
                            INSERT INTO "RagEvent"
                                ("id", "orgId", "actorId", "actorRole", "action", "entity",
                                 "chatId", "requestId", "after")
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT ("id") DO UPDATE
                            SET "orgId" = EXCLUDED."orgId",
                                "actorId" = EXCLUDED."actorId",
                                "actorRole" = EXCLUDED."actorRole",
                                "action" = EXCLUDED."action",
                                "entity" = EXCLUDED."entity",
                                "chatId" = EXCLUDED."chatId",
                                "requestId" = EXCLUDED."requestId",
                                "after" = EXCLUDED."after"
                            """,
                            (
                                f"{chat_id}-followup",
                                org_id,
                                approver_id,
                                "ADMIN",
                                "chat.followup_recorded",
                                "chat",
                                chat_id,
                                chat.get("request_id"),
                                _json({"followUpPrompt": follow_up}),
                            ),
                        )

                    tickets = chat.get("tickets", [])
                    for ticket in tickets:
                        cur.execute(
                            """
                            INSERT INTO "Ticket"
                                ("id", "orgId", "chatId", "key", "status", "assignee",
                                 "lastActivity", "summary", "auditLog")
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT ("id") DO UPDATE
                            SET "key" = EXCLUDED."key",
                                "status" = EXCLUDED."status",
                                "assignee" = EXCLUDED."assignee",
                                "lastActivity" = EXCLUDED."lastActivity",
                                "summary" = EXCLUDED."summary",
                                "auditLog" = EXCLUDED."auditLog",
                                "chatId" = EXCLUDED."chatId",
                                "orgId" = EXCLUDED."orgId"
                            """,
                            (
                                ticket["id"],
                                org_id,
                                chat_id,
                                ticket["key"],
                                ticket["status"],
                                ticket.get("assignee"),
                                _parse_datetime(ticket.get("last_activity")),
                                ticket.get("summary"),
                                _json(ticket.get("audit_log", [])),
                            ),
                        )

                    if tickets:
                        first_ticket = tickets[0]
                        cur.execute(
                            """
                            INSERT INTO "RagEvent"
                                ("id", "orgId", "actorId", "actorRole", "action", "entity",
                                 "chatId", "requestId", "after")
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT ("id") DO UPDATE
                            SET "orgId" = EXCLUDED."orgId",
                                "actorId" = EXCLUDED."actorId",
                                "actorRole" = EXCLUDED."actorRole",
                                "action" = EXCLUDED."action",
                                "entity" = EXCLUDED."entity",
                                "chatId" = EXCLUDED."chatId",
                                "requestId" = EXCLUDED."requestId",
                                "after" = EXCLUDED."after"
                            """,
                            (
                                f"{chat_id}-escalated",
                                org_id,
                                approver_id,
                                "ADMIN",
                                "chat.escalated",
                                "chat",
                                chat_id,
                                chat.get("request_id"),
                                _json({"status": "escalated", "ticket": first_ticket["key"]}),
                            ),
                        )

                if verbose:
                    print("Database seed completed", file=sys.stderr)


def _parse_args(argv: list[str] | None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Seed the Atticus database with reference data.",
        allow_abbrev=False,
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Echo progress information while seeding.",
    )
    args, unknown = parser.parse_known_args(argv)
    if unknown and args.verbose:
        print(f"Ignoring extra arguments: {unknown}", file=sys.stderr)
    return args


def main(argv: list[str] | None = None) -> int:
    args = _parse_args(argv)
    try:
        seed_database(verbose=args.verbose)
    except Exception as exc:  # pragma: no cover - surfaced in tests if triggered
        print(f"Seeding failed: {exc}", file=sys.stderr)
        return 1
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())

```

## `scripts/db_verify.py`

```python
"""Helper to invoke the pgvector verification SQL in a cross-platform way."""

from __future__ import annotations

import os
import shutil
import subprocess
import sys
from pathlib import Path
from tempfile import NamedTemporaryFile
from urllib.parse import urlsplit, urlunsplit


def _load_env_from_file(env_path: Path) -> None:
    """Populate os.environ with values from `.env` if they are not already set."""
    if not env_path.exists():
        return
    for raw_line in env_path.read_text(encoding="utf-8").splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        key, sep, value = line.partition("=")
        if not sep:
            continue
        key = key.strip()
        if not key or key in os.environ:
            continue
        cleaned = value.strip()
        if (cleaned.startswith('"') and cleaned.endswith('"')) or (
            cleaned.startswith("'") and cleaned.endswith("'")
        ):
            cleaned = cleaned[1:-1]
        os.environ[key] = cleaned


def main() -> int:
    _load_env_from_file(Path(".env"))

    database_url = os.environ.get("DATABASE_URL")
    if not database_url:
        print("DATABASE_URL is not set. Export it before running db.verify.", file=sys.stderr)
        return 1

    sql_path = Path("scripts/verify_pgvector.sql")
    if not sql_path.exists():
        print("scripts/verify_pgvector.sql not found.", file=sys.stderr)
        return 1

    dimension = os.environ.get("PGVECTOR_DIMENSION", "3072")
    lists = os.environ.get("PGVECTOR_LISTS", "100")
    sql_template = sql_path.read_text(encoding="utf-8")
    sql_rendered = sql_template.replace(":expected_pgvector_dimension", dimension).replace(
        ":expected_pgvector_lists", lists
    )

    with NamedTemporaryFile("w", encoding="utf-8", suffix=".sql", delete=False) as tmp_file:
        tmp_file.write(sql_rendered)
        tmp_path = Path(tmp_file.name)

    extra_cleanup: list[list[str]] = [["rm", "-f", str(tmp_path)]]

    psql_path = shutil.which("psql")
    docker_path = shutil.which("docker")
    docker_compose_path = shutil.which("docker-compose")

    compose_base: list[str] | None = None

    adjusted_database_url = database_url

    if psql_path:
        command_prefix: list[str] = [psql_path]
        sql_arg = str(tmp_path)
    else:
        if docker_path:
            compose_base = [docker_path, "compose"]
        elif docker_compose_path:
            compose_base = [docker_compose_path]
        else:
            print(
                "psql is required but not found on PATH, and docker compose is unavailable for fallback execution.",
                file=sys.stderr,
            )
            return 1

        command_prefix = [*compose_base, "exec", "-T", "postgres", "psql"]
        remote_path = "/tmp/verify_pgvector.sql"
        copy_cmd = [*compose_base, "cp", str(tmp_path), f"postgres:{remote_path}"]
        subprocess.run(copy_cmd, check=True)
        sql_arg = remote_path
        extra_cleanup.append([*compose_base, "exec", "-T", "postgres", "rm", "-f", remote_path])

        parsed = urlsplit(database_url)
        host_port = os.environ.get("POSTGRES_PORT")
        try:
            host_port_int = int(host_port) if host_port else None
        except ValueError:
            host_port_int = None

        if parsed.hostname in {"localhost", "127.0.0.1"} and host_port_int is not None:
            if parsed.port == host_port_int:
                userinfo = ""
                if parsed.username:
                    userinfo = parsed.username
                    if parsed.password:
                        userinfo = f"{userinfo}:{parsed.password}"
                    userinfo = f"{userinfo}@"
                netloc = f"{userinfo}{parsed.hostname}:5432"
                adjusted_database_url = urlunsplit(parsed._replace(netloc=netloc))

    cmd: list[str] = [
        *command_prefix,
        "--dbname",
        adjusted_database_url,
        "-v",
        f"expected_pgvector_dimension={dimension}",
        "-v",
        f"expected_pgvector_lists={lists}",
        "-f",
        sql_arg,
    ]

    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as exc:
        return exc.returncode
    finally:
        for cleanup_cmd in extra_cleanup:
            try:
                if cleanup_cmd[0] == "rm":
                    Path(cleanup_cmd[-1]).unlink(missing_ok=True)
                else:
                    subprocess.run(cleanup_cmd, check=False)
            except Exception:
                pass

    return 0


if __name__ == "__main__":
    sys.exit(main())

```

## `scripts/debug_env.py`

```python
#!/usr/bin/env python3
"""Inspect Atticus environment configuration without leaking secrets."""

from __future__ import annotations

import json
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.config import environment_diagnostics, reset_settings_cache  # noqa: E402


def main() -> int:
    diagnostics = environment_diagnostics()
    diagnostics["repo_root"] = str(ROOT)
    print(json.dumps(diagnostics, indent=2, sort_keys=True))
    reset_settings_cache()
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

```

## `scripts/dump_all_files.ps1`

```powershell
# Utility: concatenate repository files into a single Markdown bundle.
# Usage: pwsh -File scripts/dump_all_files.ps1 [-Output ALL_FILES_FULL.md] [-MaxKB 400]

[CmdletBinding()]
param(
    [string]$Output = "ALL_FILES_FULL.md",
    [int]$MaxKB = 400
)

$root = (Get-Location).ProviderPath
$sizeLimitBytes = $MaxKB * 1024
$encoding = [System.Text.Encoding]::UTF8

$excludeDirNames = @(
    ".git", ".github", ".next", ".venv", ".pytest_cache", ".ruff_cache", ".mypy_cache",
    "node_modules", "dist", "build", "coverage", "reports", "eval", "_backup"
)
$excludeExt = @(
    ".png", ".jpg", ".jpeg", ".gif", ".ico", ".pdf", ".zip", ".7z", ".rar", ".jar",
    ".exe", ".dll", ".pdb", ".wasm", ".map", ".lock", ".tsbuildinfo", ".woff",
    ".woff2", ".ttf", ".eot"
)
$includeExt = @(
    ".md", ".mdx", ".ts", ".tsx", ".js", ".jsx", ".mjs", ".cjs", ".json", ".jsonc",
    ".yml", ".yaml", ".toml", ".ini", ".cfg", ".conf", ".py", ".ps1", ".psm1", ".sh",
    ".bash", ".zsh", ".fish", ".bat", ".cmd", ".sql", ".prisma", ".html", ".htm",
    ".css", ".scss", ".env", ".dockerfile", ".txt", ".cs", ".java"
)
$includeNames = @("Dockerfile", "Makefile", ".env", ".env.example")

$langMap = @{
    ".ts" = "ts"; ".tsx" = "tsx"; ".js" = "js"; ".jsx" = "jsx"; ".mjs" = "js"; ".cjs" = "js";
    ".py" = "python"; ".ps1" = "powershell"; ".psm1" = "powershell"; ".sh" = "bash";
    ".bash" = "bash"; ".zsh" = "bash"; ".fish" = "fish"; ".bat" = "bat"; ".cmd" = "bat";
    ".yml" = "yaml"; ".yaml" = "yaml"; ".json" = "json"; ".jsonc" = "jsonc"; ".toml" = "toml";
    ".ini" = "ini"; ".cfg" = "ini"; ".conf" = "ini"; ".md" = "markdown"; ".mdx" = "markdown";
    ".txt" = "text"; ".css" = "css"; ".scss" = "scss"; ".html" = "html"; ".htm" = "html";
    ".sql" = "sql"; ".prisma" = "prisma"; ".dockerfile" = "dockerfile"; ".env" = "properties"
}

function Get-RelativePath([string]$fullPath) {
    if ($fullPath.StartsWith($root, [System.StringComparison]::OrdinalIgnoreCase)) {
        return $fullPath.Substring($root.Length).TrimStart('\', '/')
    }
    return $fullPath
}

function Should-Exclude([string]$relativePath) {
    $segments = $relativePath -split '[\\/]' | Where-Object { $_ -ne "" }
    foreach ($segment in $segments) {
        if ($excludeDirNames -contains $segment) { return $true }
        if ($segment -like "_backup*") { return $true }
    }
    return $false
}

function Get-Language([System.IO.FileInfo]$file) {
    $ext = $file.Extension.ToLowerInvariant()
    if (-not $ext -and $file.Name.Equals("Dockerfile", "OrdinalIgnoreCase")) {
        return "dockerfile"
    }
    return $langMap[$ext]
}

$outputPath = Join-Path $root $Output
if (Test-Path $outputPath) {
    Remove-Item $outputPath -Force
}

$files = Get-ChildItem -Recurse -File | Where-Object {
    $rel = Get-RelativePath $_.FullName
    if (-not $rel) { return $false }
    if ($rel -eq $Output) { return $false }
    if (Should-Exclude $rel) { return $false }

    $ext = $_.Extension.ToLowerInvariant()
    if ($excludeExt -contains $ext) { return $false }

    $inAllowList =
        ($includeExt -contains $ext) -or
        ($includeNames -contains $_.Name) -or
        ($ext -eq "" -and $includeNames -contains $_.Name)

    if (-not $inAllowList) { return $false }
    if ($_.Length -gt $sizeLimitBytes) { return $false }
    return $true
} | Sort-Object FullName

$included = 0
$skipped = New-Object System.Collections.Generic.List[string]

$writer = New-Object System.IO.StreamWriter($outputPath, $false, $encoding)
try {
    $headerLines = @(
        "# Atticus - FULL REPO DUMP",
        "",
        "Generated: $(Get-Date -Format 'yyyy-MM-dd HH:mm:ss zzz')",
        "Max file size: ${MaxKB}KB",
        "Excluded directories: $($excludeDirNames -join ', ')",
        "Excluded extensions: $($excludeExt -join ', ')",
        "",
        "---",
        ""
    )
    $headerLines | ForEach-Object { $writer.WriteLine($_) }

    foreach ($file in $files) {
        $relative = Get-RelativePath $file.FullName
        $lang = Get-Language $file

        try {
            $content = Get-Content -LiteralPath $file.FullName -Raw -ErrorAction Stop
        } catch {
            $skipped.Add("$relative :: $($_.Exception.Message)")
            continue
        }

        $writer.WriteLine()
        $writer.WriteLine("## $relative")
        $writer.WriteLine()
        $writer.WriteLine(("```{0}" -f $lang))
        $writer.Write($content)
        if (-not $content.EndsWith("`n")) { $writer.WriteLine() }
        $writer.WriteLine("```")
        $included++
    }

    $writer.WriteLine()
    $writer.WriteLine("---")
    $writer.WriteLine([string]::Format("Included files: {0}", $included))
    $writer.WriteLine([string]::Format("Skipped files: {0}", $skipped.Count))
    $writer.WriteLine()

    if ($skipped.Count -gt 0) {
        $writer.WriteLine("### Skipped (errors or filtered):")
        foreach ($item in $skipped) {
            $writer.WriteLine($item)
        }
        $writer.WriteLine()
    }
}
finally {
    $writer.Dispose()
}

Write-Host "Done. Created $Output with $included files (<= ${MaxKB}KB each)."

```

## `scripts/e2e_smoke.py`

```python
"""E2E smoke checks for Atticus API and UI make targets."""

from __future__ import annotations

import contextlib
import os
import socket
import subprocess
import sys
import time
from pathlib import Path

import requests

HOST = os.environ.get("ATTICUS_E2E_HOST", "127.0.0.1")
API_PORT = int(os.environ.get("ATTICUS_API_PORT", "8000"))
UI_PORT = int(os.environ.get("ATTICUS_UI_PORT", "8081"))
ROOT = Path(__file__).resolve().parents[1]
WEB_DIR = ROOT / "web"


class ManagedProcess:
    """Launch a long-running command and surface logs if checks fail."""

    def __init__(self, name: str, args: list[str], cwd: Path) -> None:
        self.name = name
        self.args = args
        self.cwd = cwd
        self.proc: subprocess.Popen | None = None
        self.stdout: str = ""
        self.stderr: str = ""
        self._should_dump = False

    def __enter__(self) -> ManagedProcess:
        self.proc = subprocess.Popen(
            self.args,
            cwd=self.cwd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        return self

    def __exit__(self, exc_type, exc, tb) -> bool:
        self._should_dump = exc_type is not None
        if self.proc and self.proc.poll() is None:
            self.proc.terminate()
        if self.proc:
            try:
                out, err = self.proc.communicate(timeout=5)
            except subprocess.TimeoutExpired:
                self.proc.kill()
                out, err = self.proc.communicate()
            self.stdout = out or ""
            self.stderr = err or ""
            if self._should_dump:
                if self.stdout.strip():
                    print(f"[{self.name} stdout]\n{self.stdout}")
                if self.stderr.strip():
                    print(f"[{self.name} stderr]\n{self.stderr}", file=sys.stderr)
        return False


def wait_for_port(host: str, port: int, timeout: float = 20.0) -> None:
    deadline = time.time() + timeout
    while time.time() < deadline:
        with contextlib.closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
            sock.settimeout(1.0)
            if sock.connect_ex((host, port)) == 0:
                return
        time.sleep(0.25)
    raise RuntimeError(f"Timed out waiting for {host}:{port}")


def request_with_retry(url: str, *, attempts: int = 5, delay: float = 0.5) -> requests.Response:
    last_error: Exception | None = None
    for _ in range(attempts):
        try:
            response = requests.get(url, timeout=5)
            response.raise_for_status()
            return response
        except requests.RequestException as exc:
            last_error = exc
            time.sleep(delay)
    raise RuntimeError(f"Failed to GET {url}") from last_error


def check_api(host: str, port: int) -> None:
    base = f"http://{host}:{port}"
    health = request_with_retry(f"{base}/health")
    payload = health.json()
    if payload.get("status") != "ok":
        raise RuntimeError("API health check did not return status 'ok'")

    root_page = request_with_retry(f"{base}/")
    lower_html = root_page.text.lower()
    if "<html" not in lower_html or "atticus" not in lower_html:
        raise RuntimeError("API root did not render an Atticus UI shell")
    if "/static/" not in lower_html:
        raise RuntimeError("API root is missing static asset references")

    static_asset = request_with_retry(f"{base}/static/js/script.js")
    if not static_asset.text.strip():
        raise RuntimeError("API static assets are empty or missing")


def check_ui(host: str, port: int) -> None:
    base = f"http://{host}:{port}"
    ui_page = request_with_retry(f"{base}/templates/index.html")
    lower_html = ui_page.text.lower()
    if "<html" not in lower_html or "atticus" not in lower_html:
        raise RuntimeError("Standalone UI did not include Atticus branding")
    if "/static/" not in lower_html:
        raise RuntimeError("Standalone UI page is missing static asset references")

    ui_script = request_with_retry(f"{base}/static/js/script.js")
    if not ui_script.text.strip():
        raise RuntimeError("Standalone UI cannot serve static JavaScript")


def main() -> None:
    if not WEB_DIR.exists():
        raise RuntimeError(f"Expected UI directory at {WEB_DIR}")

    api_cmd = [
        sys.executable,
        "-m",
        "uvicorn",
        "api.main:app",
        "--port",
        str(API_PORT),
    ]
    ui_cmd = [
        sys.executable,
        "-m",
        "http.server",
        str(UI_PORT),
        "--directory",
        str(WEB_DIR),
    ]

    with ManagedProcess("api", api_cmd, ROOT):
        wait_for_port(HOST, API_PORT)
        check_api(HOST, API_PORT)
        print(f"API smoke passed on {HOST}:{API_PORT}")

        with ManagedProcess("ui", ui_cmd, ROOT):
            wait_for_port(HOST, UI_PORT)
            check_ui(HOST, UI_PORT)
            print(f"UI static smoke passed on {HOST}:{UI_PORT}")

    print("E2E API/UI checks completed.")


if __name__ == "__main__":
    main()

```

## `scripts/eval_qa.py`

```python
#!/usr/bin/env python3
"""Run simple end-to-end QA evaluation using expected answers.

For each gold example with an `expected_answer`, this script:
- calls the retrieval+generation pipeline (`answer_question`)
- computes token-level F1 between model response and expected
- computes embedding cosine similarity between response and expected

Outputs a CSV and JSON summary alongside the retrieval metrics outputs for the same day.
"""

from __future__ import annotations

import argparse
import csv
import json
import os
import sys
from collections import Counter
from collections.abc import Iterable
from pathlib import Path

import numpy as np

# Ensure repository root on sys.path for local imports
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.config import AppSettings, load_settings  # noqa: E402
from atticus.embeddings import EmbeddingClient  # noqa: E402
from eval.runner import _default_output_dir, load_gold_set  # noqa: E402
from retriever.service import answer_question  # noqa: E402


def _tokens(text: str) -> list[str]:
    return [t for t in "".join(c.lower() if c.isalnum() else " " for c in text).split() if t]


def _f1(a: str, b: str) -> float:
    ta, tb = _tokens(a), _tokens(b)
    if not ta or not tb:
        return 0.0
    set_a = ta
    set_b = tb
    ca, cb = Counter(set_a), Counter(set_b)
    common = sum((ca & cb).values())
    if common == 0:
        return 0.0
    precision = common / max(1, sum(cb.values()))
    recall = common / max(1, sum(ca.values()))
    if precision + recall == 0:
        return 0.0
    return 2 * precision * recall / (precision + recall)


def _cosine(a: Iterable[float], b: Iterable[float]) -> float:
    va = np.array(list(a), dtype=float)
    vb = np.array(list(b), dtype=float)
    na = np.linalg.norm(va)
    nb = np.linalg.norm(vb)
    if na == 0 or nb == 0:
        return 0.0
    return float(va.dot(vb) / (na * nb))


def run_qa_eval(
    settings: AppSettings, gold_path: Path | None = None, output_dir: Path | None = None
) -> dict[str, object]:
    gold_path = gold_path or settings.gold_set_path
    output_dir = output_dir or _default_output_dir(settings)
    examples = [g for g in load_gold_set(gold_path) if g.expected_answer]

    output_dir.mkdir(parents=True, exist_ok=True)
    csv_path = output_dir / "qa_metrics.csv"
    json_path = output_dir / "qa_summary.json"

    if not examples:
        payload = {"count": 0, "avg_f1": 0.0, "avg_cosine": 0.0}
        json_path.write_text(json.dumps(payload, indent=2) + "\n", encoding="utf-8")
        return payload

    embed = EmbeddingClient(settings)
    f1_scores: list[float] = []
    cos_scores: list[float] = []
    rows: list[dict[str, object]] = []

    for ex in examples:
        ans = answer_question(ex.question, settings=settings)
        f1 = _f1(ans.response, ex.expected_answer or "")
        v_expected, v_response = embed.embed_texts([ex.expected_answer or "", ans.response])
        cos = _cosine(v_expected, v_response)
        top_doc = ans.citations[0].source_path if ans.citations else None
        f1_scores.append(f1)
        cos_scores.append(cos)
        rows.append(
            {
                "question": ex.question,
                "top_document": top_doc,
                "confidence": ans.confidence,
                "f1": round(f1, 4),
                "cosine": round(cos, 4),
            }
        )

    with csv_path.open("w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(
            handle, fieldnames=["question", "top_document", "confidence", "f1", "cosine"]
        )
        writer.writeheader()
        writer.writerows(rows)
        writer.writerow(
            {
                "question": "AVERAGE",
                "top_document": "",
                "confidence": round(sum(r.get("confidence", 0.0) for r in rows) / len(rows), 4),
                "f1": round(sum(f1_scores) / len(f1_scores), 4),
                "cosine": round(sum(cos_scores) / len(cos_scores), 4),
            }
        )

    payload = {
        "count": len(rows),
        "avg_f1": round(sum(f1_scores) / len(f1_scores), 4),
        "avg_cosine": round(sum(cos_scores) / len(cos_scores), 4),
        "summary_csv": str(csv_path),
        "summary_json": str(json_path),
    }
    json_path.write_text(json.dumps(payload, indent=2) + "\n", encoding="utf-8")
    return payload


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description="Run QA eval using expected answers in the gold set")
    p.add_argument("--gold-set", type=Path, help="Optional path to override the default gold set")
    p.add_argument("--output-dir", type=Path, help="Directory for storing QA eval outputs")
    p.add_argument("--config", type=Path, help="Path to an alternate config.yaml file")
    p.add_argument("--json", action="store_true", help="Print results as JSON to stdout")
    return p


def main() -> None:
    args = build_parser().parse_args()
    if args.config:
        os.environ["CONFIG_PATH"] = str(args.config)

    settings = load_settings()
    result = run_qa_eval(settings, gold_path=args.gold_set, output_dir=args.output_dir)
    if args.json or not args.output_dir:
        print(json.dumps(result, indent=2))


if __name__ == "__main__":
    main()

```

## `scripts/eval_run.py`

```python
#!/usr/bin/env python3
"""Run the Atticus evaluation harness from the command line."""

from __future__ import annotations

import argparse
import json
import os
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.config import load_settings  # noqa: E402
from atticus.logging_utils import get_logger  # noqa: E402
from eval.runner import run_evaluation  # noqa: E402

log = get_logger("eval_run")


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Execute the retrieval evaluation harness")
    parser.add_argument(
        "--gold-set",
        type=Path,
        help="Optional path to override the default gold set",
    )
    parser.add_argument(
        "--baseline",
        type=Path,
        help="Optional path to override the baseline metrics JSON",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        help="Directory for storing evaluation outputs",
    )
    parser.add_argument(
        "--config",
        type=Path,
        help="Path to an alternate config.yaml file",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Print results as JSON to stdout",
    )
    return parser


def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    if args.config:
        os.environ["CONFIG_PATH"] = str(args.config)

    settings = load_settings()
    log.info(
        "eval_start",
        gold_override=bool(args.gold_set),
        baseline_override=bool(args.baseline),
        output_dir=str(args.output_dir) if args.output_dir else None,
    )
    result = run_evaluation(
        settings=settings,
        gold_path=args.gold_set,
        baseline_path=args.baseline,
        output_dir=args.output_dir,
    )

    payload = {
        "metrics": result.metrics,
        "deltas": result.deltas,
        "summary_csv": str(result.summary_csv),
        "summary_json": str(result.summary_json),
        "summary_html": str(result.summary_html),
    }

    if args.json or not args.output_dir:
        log.info("eval_result", **payload)
    else:
        summary_path = args.output_dir / "run_summary.json"
        summary_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        log.info("eval_summary_written", path=str(summary_path))

    threshold = settings.eval_regression_threshold / 100.0
    if any(delta < -threshold for delta in result.deltas.values()):
        log.error("eval_regression_detected", threshold=threshold, deltas=result.deltas)
        raise SystemExit(1)
    log.info("eval_ok")


if __name__ == "__main__":
    main()

```

## `scripts/export_repo.py`

```python
#!/usr/bin/env python3
"""
Export all relevant, human-readable files into ONE markdown file for code review,
plus a MANIFEST with sizes and skip reasons.

Includes (by extension / name):
  .py .ts .tsx .js .jsx .json .yaml .yml .toml .ini .cfg .config .md .mdx .sql .graphql .gql .sh .ps1
  Dockerfile .env.example .envrc .editorconfig .prettierrc .eslintrc .eslintignore .gitignore .gitattributes

Skips (dir substrings, case-insensitive, at any depth):
  node_modules .git __pycache__ .venv .mypy_cache .pytest_cache .ruff_cache .next .turbo .cache dist build
  coverage .parcel-cache indexes indices vector cache

Also skips obvious binary/asset extensions and any file containing NUL bytes.
Hard-excludes the absolute path: C:\Dev\Atticus\indices (and below).

Outputs:
  - ALL_FILES.md  (sections with ``` fences, language autodetected)
  - MANIFEST.txt  (every file with size + included/skipped reason + totals)

Usage (from repo root):
  python scripts/export_repo.py --root . --output ALL_FILES.md --manifest MANIFEST.txt --max-file-mb 5
"""

from __future__ import annotations

import argparse
import os
from pathlib import Path
from typing import Iterable, Iterator, Sequence

# ---------- Config ----------
BLOAT_DIR_KEYWORDS = tuple(
    k.casefold()
    for k in (
        "node_modules",
        ".git",
        "__pycache__",
        ".venv",
        ".mypy_cache",
        ".pytest_cache",
        ".ruff_cache",
        ".next",
        ".turbo",
        ".cache",
        "dist",
        "build",
        "coverage",
        ".parcel-cache",
        "indexes",
        "indices",
        "vector",
        "cache",
    )
)
# Absolute hard-excludes (and all their subpaths)
HARD_EXCLUDE_DIRS = {Path(r"C:\Dev\Atticus\indices")}

# Human-readable include set (lowercased suffixes or exact basenames)
INCLUDE_EXTENSIONS = {
    ".py",
    ".ts",
    ".tsx",
    ".js",
    ".jsx",
    ".json",
    ".yaml",
    ".yml",
    ".toml",
    ".ini",
    ".cfg",
    ".config",
    ".md",
    ".mdx",
    ".sql",
    ".graphql",
    ".gql",
    ".sh",
    ".ps1",
}
INCLUDE_BASENAMES = {
    "dockerfile",
    ".env",
    ".env.example",
    ".envrc",
    ".editorconfig",
    ".prettierrc",
    ".eslintrc",
    ".eslintignore",
    ".gitignore",
    ".gitattributes",
}

# Obvious binary-ish or huge assets to skip by extension
BINARY_LIKE_EXTS = {
    ".png",
    ".jpg",
    ".jpeg",
    ".gif",
    ".webp",
    ".bmp",
    ".tiff",
    ".ico",
    ".svg",
    ".woff",
    ".woff2",
    ".ttf",
    ".otf",
    ".eot",
    ".mp4",
    ".mp3",
    ".wav",
    ".flac",
    ".mkv",
    ".mov",
    ".zip",
    ".tar",
    ".gz",
    ".bz2",
    ".xz",
    ".7z",
    ".rar",
    ".pdf",
    ".doc",
    ".docx",
    ".ppt",
    ".pptx",
    ".xls",
    ".xlsx",
    ".wasm",
    ".bin",
    ".dll",
    ".exe",
    ".so",
    ".dylib",
    ".obj",
    ".class",
    ".psd",
    ".ai",
    ".sketch",
    ".fig",
}

LANGUAGE_BY_EXTENSION = {
    ".py": "python",
    ".ts": "typescript",
    ".tsx": "tsx",
    ".js": "javascript",
    ".jsx": "jsx",
    ".sh": "bash",
    ".ps1": "powershell",
    ".rb": "ruby",
    ".php": "php",
    ".go": "go",
    ".rs": "rust",
    ".java": "java",
    ".kt": "kotlin",
    ".swift": "swift",
    ".cs": "csharp",
    ".c": "c",
    ".h": "c",
    ".cpp": "cpp",
    ".hpp": "cpp",
    ".mjs": "javascript",
    ".cjs": "javascript",
    ".json": "json",
    ".yaml": "yaml",
    ".yml": "yaml",
    ".toml": "toml",
    ".ini": "ini",
    ".cfg": "ini",
    ".sql": "sql",
    ".md": "md",
    ".mdx": "mdx",
    ".gql": "graphql",
    ".graphql": "graphql",
}
# ---------- End Config ----------


def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(description=__doc__)
    p.add_argument("--root", type=Path, default=Path.cwd(), help="Root to scan (repo root).")
    p.add_argument(
        "--output", type=Path, default=Path("ALL_FILES.md"), help="Output markdown file."
    )
    p.add_argument(
        "--manifest", type=Path, default=Path("MANIFEST.txt"), help="Manifest text file."
    )
    p.add_argument(
        "--include-hidden", action="store_true", help="Include hidden files/dirs (dotfiles)."
    )
    p.add_argument(
        "--max-file-mb", type=float, default=5.0, help="Max single file size to include (MB)."
    )
    return p.parse_args(argv)


def _resolve_set(paths: set[Path]) -> set[Path]:
    out = set()
    for p in paths:
        try:
            out.add(p.resolve())
        except OSError:
            out.add(p)
    return out


def _is_under_any(path: Path, roots: set[Path]) -> bool:
    try:
        resolved = path.resolve()
    except OSError:
        return False
    for r in roots:
        try:
            rr = r.resolve()
        except OSError:
            continue
        if resolved == rr or resolved.is_relative_to(rr):
            return True
    return False


def should_skip_dir_parts(parts: Iterable[str], include_hidden: bool) -> bool:
    for part in parts:
        if not include_hidden and part.startswith("."):
            return True
        lowered = part.casefold()
        if any(k in lowered for k in BLOAT_DIR_KEYWORDS):
            return True
    return False


def is_binary_quick(path: Path) -> bool:
    # quick sniff: NUL byte → likely binary
    try:
        with path.open("rb") as f:
            chunk = f.read(4096)
        return b"\x00" in chunk
    except OSError:
        return True  # unreadable → treat as binary to be safe


def is_included_file(path: Path) -> bool:
    name = path.name
    if name.casefold() in (n.casefold() for n in INCLUDE_BASENAMES):
        return True
    ext = path.suffix.lower()
    return ext in INCLUDE_EXTENSIONS


def iter_candidates(root: Path, include_hidden: bool) -> Iterator[Path]:
    hard_ex = _resolve_set(HARD_EXCLUDE_DIRS)
    for current_dir, dirnames, filenames in os.walk(root):
        dir_path = Path(current_dir)

        # hard excludes short-circuit
        if _is_under_any(dir_path, hard_ex):
            dirnames[:] = []
            continue

        rel_parts = dir_path.relative_to(root).parts if dir_path != root else ()

        # skip this dir?
        if should_skip_dir_parts(rel_parts, include_hidden):
            dirnames[:] = []
            continue

        # prune children
        pruned = []
        for d in dirnames:
            cand = dir_path / d
            if _is_under_any(cand, hard_ex):
                continue
            if should_skip_dir_parts(rel_parts + (d,), include_hidden):
                continue
            pruned.append(d)
        dirnames[:] = pruned

        for fn in filenames:
            fp = dir_path / fn
            # hidden path check
            if not include_hidden and any(p.startswith(".") for p in fp.relative_to(root).parts):
                continue
            yield fp


def detect_language(path: Path) -> str:
    # special basenames
    if path.name.lower() == "dockerfile":
        return "dockerfile"
    return LANGUAGE_BY_EXTENSION.get(path.suffix.lower(), "")


def format_bytes(n: int) -> str:
    return f"{n:,} bytes"


def mb(n: int) -> float:
    return n / (1024 * 1024)


def build_exports(
    root: Path, files: Iterable[Path], output_md: Path, manifest_txt: Path, max_file_mb: float
) -> None:
    max_bytes = int(max_file_mb * 1024 * 1024)
    lines_md: list[str] = ["# Consolidated Repository Files", ""]
    lines_manifest: list[str] = ["# Export Manifest", f"Root: {root}", ""]

    included_count = 0
    skipped_count = 0
    total_bytes_included = 0
    total_bytes_seen = 0

    for fp in sorted(files):
        rel = fp.relative_to(root)
        ext = fp.suffix.lower()
        name_lower = fp.name.lower()

        # extension-based quick skips (binary-ish)
        if ext in BINARY_LIKE_EXTS:
            try:
                sz = fp.stat().st_size
                total_bytes_seen += sz
            except OSError:
                pass
            lines_manifest.append(f"[SKIP: binary-ext] {rel.as_posix()}")
            skipped_count += 1
            continue

        # include filter
        if not is_included_file(fp) and name_lower not in (n.casefold() for n in INCLUDE_BASENAMES):
            # not in whitelist → skip (keeps output lean)
            try:
                sz = fp.stat().st_size
                total_bytes_seen += sz
            except OSError:
                pass
            lines_manifest.append(f"[SKIP: not-in-include-list] {rel.as_posix()}")
            skipped_count += 1
            continue

        # size checks
        try:
            size = fp.stat().st_size
        except OSError as exc:
            lines_manifest.append(f"[SKIP: unreadable: {exc}] {rel.as_posix()}")
            skipped_count += 1
            continue

        total_bytes_seen += size

        if size > max_bytes:
            lines_manifest.append(
                f"[SKIP: too-large ({mb(size):.2f} MB > {max_file_mb:.2f} MB)] {rel.as_posix()} ({format_bytes(size)})"
            )
            skipped_count += 1
            continue

        # binary sniff
        if is_binary_quick(fp):
            lines_manifest.append(f"[SKIP: binary-sniff] {rel.as_posix()} ({format_bytes(size)})")
            skipped_count += 1
            continue

        # read & append to MD
        try:
            text = fp.read_text(encoding="utf-8", errors="replace")
        except OSError as exc:
            lines_manifest.append(
                f"[SKIP: read-error: {exc}] {rel.as_posix()} ({format_bytes(size)})"
            )
            skipped_count += 1
            continue

        lang = detect_language(fp)
        lines_md.append(f"## `{rel.as_posix()}`")
        lines_md.append("")
        code_fence = f"```{lang}".rstrip()
        lines_md.append(code_fence)
        lines_md.append(text)
        lines_md.append("```")
        lines_md.append("")

        lines_manifest.append(
            f"[INCLUDED] {rel.as_posix()} ({format_bytes(size)} / {mb(size):.2f} MB)"
        )
        included_count += 1
        total_bytes_included += size

    # manifest footer
    lines_manifest.append("")
    lines_manifest.append(f"Files included: {included_count}")
    lines_manifest.append(f"Files skipped : {skipped_count}")
    lines_manifest.append(
        f"Total seen    : {format_bytes(total_bytes_seen)} ({mb(total_bytes_seen):.2f} MB)"
    )
    lines_manifest.append(
        f"Included size : {format_bytes(total_bytes_included)} ({mb(total_bytes_included):.2f} MB)"
    )
    lines_manifest.append(f"Per-file cap  : {max_file_mb:.2f} MB")

    output_md.write_text("\n".join(lines_md).rstrip() + "\n", encoding="utf-8")
    manifest_txt.write_text("\n".join(lines_manifest).rstrip() + "\n", encoding="utf-8")


def main(argv: Sequence[str] | None = None) -> None:
    args = parse_args(argv)
    root = args.root.resolve()
    if not root.exists():
        raise SystemExit(f"Root path does not exist: {root}")

    # Resolve hard excludes
    hard_ex = _resolve_set(HARD_EXCLUDE_DIRS)

    # Walk and filter
    candidates = []
    for fp in iter_candidates(root, args.include_hidden):
        # hard exclude check on parent chain
        if _is_under_any(fp.parent, hard_ex):
            continue
        # bloat dir check on full path parts (defense-in-depth)
        if any(k in part.casefold() for part in fp.parts for k in BLOAT_DIR_KEYWORDS):
            continue
        candidates.append(fp)

    # Compute output paths (relative → under root)
    out_md = (args.output if args.output.is_absolute() else root / args.output).resolve()
    out_manifest = (
        args.manifest if args.manifest.is_absolute() else root / args.manifest
    ).resolve()

    build_exports(root, candidates, out_md, out_manifest, args.max_file_mb)
    print(f"Wrote {out_md} and {out_manifest} (from {len(candidates)} candidate files).")


if __name__ == "__main__":
    main()

```

## `scripts/generate_api_docs.py`

```python
"""CLI to export the FastAPI OpenAPI schema to disk."""

from __future__ import annotations

import argparse
import inspect
import json
import sys
from pathlib import Path
from typing import Any, get_type_hints

import yaml

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from api.main import app  # noqa: E402

# --- Pydantic v2 forward-ref rebuild shim (autogenerated) ---
try:
    from pydantic import BaseModel

    def __rebuild_pydantic_models() -> None:
        visited: set[type[BaseModel]] = set()

        def _recurse(cls: type[BaseModel]) -> None:
            if cls in visited:
                return
            visited.add(cls)
            try:
                rebuild = getattr(cls, "model_rebuild", None)
                if callable(rebuild):
                    try:
                        rebuild(_recursive_=True)
                    except TypeError:
                        rebuild(recursive=True)
            except Exception:
                pass
            for sub in getattr(cls, "__subclasses__", lambda: [])():
                _recurse(sub)

        for root in list(BaseModel.__subclasses__()):
            _recurse(root)

    __rebuild_pydantic_models()
except Exception:
    # Non-fatal: generator should still run
    pass
# ------------------------------------------------------------


FAILED_HINTS: list[str] = []


def __resolve_forward_refs() -> None:
    """Best-effort resolution for postponed annotations under Pydantic v2."""

    processed: dict[object, str] = {}

    def _update_annotations(callable_obj: Any) -> None:
        if callable_obj is None:
            return
        target = getattr(callable_obj, "__wrapped__", callable_obj)
        if target in processed:
            return
        if not (inspect.isfunction(target) or inspect.ismethod(target)):
            return
        processed[target] = getattr(target, "__qualname__", repr(target))

        module = sys.modules.get(getattr(target, "__module__", ""), None)
        namespace: dict[str, Any] = getattr(module, "__dict__", {}) if module else {}

        try:
            evaluated = get_type_hints(
                target, globalns=namespace, localns=namespace, include_extras=True
            )
        except TypeError:
            try:
                evaluated = get_type_hints(target, globalns=namespace, localns=namespace)
            except Exception as exc:
                FAILED_HINTS.append(
                    f"{target.__module__}.{getattr(target, '__qualname__', repr(target))}: {exc}"
                )
                return
        except Exception as exc:
            FAILED_HINTS.append(
                f"{target.__module__}.{getattr(target, '__qualname__', repr(target))}: {exc}"
            )
            return

        annotations = getattr(target, "__annotations__", None)
        if isinstance(annotations, dict):
            annotations.update(evaluated)

    def _walk_dependant(dependant: Any) -> None:
        if dependant is None:
            return
        _update_annotations(getattr(dependant, "call", None))
        for child in getattr(dependant, "dependencies", []) or []:
            _walk_dependant(child)

    for route in getattr(app, "routes", []):
        _update_annotations(getattr(route, "endpoint", None))
        dependant = getattr(route, "dependant", None)
        _walk_dependant(dependant)

    for route in getattr(app, "routes", []):
        try:
            route.dependant = route.get_dependant()
            route.body_field = route.get_body_field()
        except AttributeError:
            continue


__resolve_forward_refs()

if FAILED_HINTS:
    debug_log = ROOT / "reports" / "openapi-typehint-failures.txt"
    debug_log.parent.mkdir(parents=True, exist_ok=True)
    debug_log.write_text("\n".join(FAILED_HINTS) + "\n", encoding="utf-8")


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Generate API documentation artifacts")
    parser.add_argument(
        "--output",
        type=Path,
        default=ROOT / "docs" / "api" / "openapi.json",
        help="Path to write the OpenAPI document (defaults to docs/api/openapi.json)",
    )
    parser.add_argument(
        "--format",
        choices=("json", "yaml"),
        default="json",
        help="Output format for the schema",
    )
    parser.add_argument(
        "--indent",
        type=int,
        default=2,
        help="Indentation for JSON output",
    )
    return parser


def export_schema(output_path: Path, output_format: str, indent: int = 2) -> None:
    schema = app.openapi()
    output_path.parent.mkdir(parents=True, exist_ok=True)

    if output_format == "json":
        payload = json.dumps(schema, indent=indent, sort_keys=True)
        output_path.write_text(payload + "\n", encoding="utf-8")
    else:
        payload = yaml.safe_dump(schema, sort_keys=False)
        output_path.write_text(payload, encoding="utf-8")


def main() -> None:
    parser = build_parser()
    args = parser.parse_args()
    export_schema(output_path=args.output, output_format=args.format, indent=args.indent)


if __name__ == "__main__":
    main()

```

## `scripts/generate_compendiums.py`

```python
"""
Generate repository compendiums:

- ALL_CODE.md: concatenates source/config files into one Markdown file, with an Index
  of included paths and a header before each file's contents.
- ALL_DOCS.md: concatenates all Markdown documents with an Index and per-file sections.

Reasonable exclusions are applied to avoid binary/data artifacts and lockfiles.
"""

from __future__ import annotations

import io
import os
from pathlib import Path
from typing import Iterable

REPO_ROOT = Path(__file__).resolve().parent.parent


CODE_EXTS = {
    ".py": "python",
    ".ts": "ts",
    ".tsx": "tsx",
    ".js": "javascript",
    ".mjs": "javascript",
    ".cjs": "javascript",
    ".json": "json",
    ".sql": "sql",
    ".yml": "yaml",
    ".yaml": "yaml",
    ".toml": "toml",
    ".ini": "ini",
    ".ps1": "powershell",
    ".sh": "bash",
    ".css": "css",
    ".scss": "scss",
    ".html": "html",
    ".env": "bash",
}

ALWAYS_INCLUDE = {"Makefile"}

# Exclude heavy or non-source directories/files
EXCLUDE_DIRS = {
    "content",
    "content_unused",
    "indices",
    "logs",
    "node_modules",
    ".next",
    ".git",
    ".venv",
    ".mypy_cache",
    ".pytest_cache",
    "eval/runs",
    "reports/playwright-artifacts",
}

EXCLUDE_FILES = {
    "pnpm-lock.yaml",
    "package-lock.json",
}


def should_exclude(path: Path) -> bool:
    rel = path.relative_to(REPO_ROOT)
    # Exclude directories in any segment
    for part in rel.parts:
        if part in EXCLUDE_DIRS:
            return True
    # Exclude specific filenames
    if path.name in EXCLUDE_FILES:
        return True
    return False


def iter_code_files() -> Iterable[Path]:
    for p in REPO_ROOT.rglob("*"):
        if p.is_dir():
            continue
        if should_exclude(p):
            continue
        if p.suffix in CODE_EXTS or p.name in ALWAYS_INCLUDE:
            yield p


def iter_doc_files() -> Iterable[Path]:
    for p in REPO_ROOT.rglob("*.md"):
        if p.is_dir():
            continue
        if p.name in {"ALL_DOCS.md", "ALL_CODE.md"}:  # avoid self-inclusion/cycles
            continue
        if should_exclude(p):
            continue
        yield p


def guess_lang(path: Path) -> str:
    if path.name in ALWAYS_INCLUDE:
        return "makefile"
    return CODE_EXTS.get(path.suffix, "")


def read_text(path: Path) -> str:
    # Best-effort UTF-8 with replacement to avoid failures on odd files
    with path.open("r", encoding="utf-8", errors="replace") as f:
        return f.read()


def write_all_code(target: Path) -> None:
    files = sorted({p for p in iter_code_files()}, key=lambda p: p.as_posix().lower())
    buf = io.StringIO()
    buf.write("# All Code\n\n")
    buf.write("## Index\n")
    for p in files:
        rel = p.relative_to(REPO_ROOT).as_posix()
        buf.write(f"- `{rel}`\n")
    buf.write("\n")
    for p in files:
        rel = p.relative_to(REPO_ROOT).as_posix()
        buf.write(f"## {rel}\n\n")
        lang = guess_lang(p)
        fence = f"```{lang}" if lang else "```"
        buf.write(f"{fence}\n")
        content = read_text(p)
        buf.write(content)
        if not content.endswith("\n"):
            buf.write("\n")
        buf.write("```\n\n")
    target.write_text(buf.getvalue(), encoding="utf-8")


def write_all_docs(target: Path) -> None:
    files = sorted({p for p in iter_doc_files()}, key=lambda p: p.as_posix().lower())
    buf = io.StringIO()
    buf.write("# All Documentation\n\n")
    buf.write("## Index\n")
    for p in files:
        rel = p.relative_to(REPO_ROOT).as_posix()
        buf.write(f"- `{rel}`\n")
    buf.write("\n")
    for p in files:
        rel = p.relative_to(REPO_ROOT).as_posix()
        buf.write(f"## {rel}\n\n")
        content = read_text(p)
        buf.write(content)
        if not content.endswith("\n"):
            buf.write("\n")
        buf.write("\n")
    target.write_text(buf.getvalue(), encoding="utf-8")


def main() -> None:
    write_all_code(REPO_ROOT / "ALL_CODE.md")
    write_all_docs(REPO_ROOT / "ALL_DOCS.md")
    print("Wrote ALL_CODE.md and ALL_DOCS.md")


if __name__ == "__main__":
    os.chdir(REPO_ROOT)
    main()

```

## `scripts/generate_env.py`

```python
#!/usr/bin/env python3
"""Create or refresh the repository .env file.

Usage examples::

    python scripts/generate_env.py            # creates .env if missing
    python scripts/generate_env.py --force    # overwrite existing .env
    python scripts/generate_env.py --ignore-env   # ignore host env vars when writing
"""

from __future__ import annotations

import argparse
import hashlib
import os
from pathlib import Path


def _fingerprint(value: str | None) -> str | None:
    if not value:
        return None
    return hashlib.sha256(value.encode("utf-8")).hexdigest()[:12]


DEFAULTS = {
    # Core models
    "OPENAI_API_KEY": "sk-your-openai-key",
    "EMBED_MODEL": "text-embedding-3-large",
    "EMBEDDING_MODEL_VERSION": "text-embedding-3-large@2025-01-15",
    "GEN_MODEL": "gpt-4.1",
    "CONFIDENCE_THRESHOLD": "0.70",
    "CHUNK_TARGET_TOKENS": "512",
    "CHUNK_MIN_TOKENS": "256",
    "CHUNK_OVERLAP_TOKENS": "100",
    "MAX_CONTEXT_CHUNKS": "10",
    "ENABLE_RERANKER": "0",
    "TOP_K": "20",
    "EVAL_REGRESSION_THRESHOLD": "3.0",
    # Paths & storage
    "CONTENT_ROOT": "./content",
    "INDICES_DIR": "./indices",
    "LOG_PATH": "./logs/app.jsonl",
    "ERROR_LOG_PATH": "./logs/errors.jsonl",
    "DICTIONARY_PATH": "./indices/dictionary.json",
    # Database & vector search
    "DATABASE_URL": "postgresql://atticus:atticus@localhost:5432/atticus",
    "POSTGRES_DB": "atticus",
    "POSTGRES_USER": "atticus",
    "POSTGRES_PASSWORD": "atticus",
    "PGVECTOR_LISTS": "100",
    "PGVECTOR_PROBES": "4",
    # Logging & telemetry
    "LOG_LEVEL": "INFO",
    "LOG_VERBOSE": "0",
    "LOG_TRACE": "0",
    "LOG_FORMAT": "json",
    "TIMEZONE": "UTC",
    # Rate limiting
    "RATE_LIMIT_REQUESTS": "5",
    "RATE_LIMIT_WINDOW_SECONDS": "60",
    # Notifications & escalation
    "CONTACT_EMAIL": "atticus-contact@example.com",
    "SMTP_HOST": "smtp.example.com",
    "SMTP_PORT": "587",
    "SMTP_USER": "smtp-user",
    "SMTP_PASS": "change-me-smtp-password",
    "SMTP_FROM": "atticus-escalations@example.com",
    "SMTP_TO": "atticus-technical-support@example.com",
    "SMTP_DRY_RUN": "1",
    "EMAIL_SANDBOX": "true",
    "SMTP_ALLOW_LIST": "",
    # Frontend/API integration
    "RAG_SERVICE_URL": "http://localhost:8000",
    "ASK_SERVICE_URL": "http://localhost:8000",
}


def main() -> int:
    parser = argparse.ArgumentParser(description="Generate a .env file for Atticus")
    parser.add_argument("--force", action="store_true", help="overwrite an existing .env file")
    parser.add_argument(
        "--ignore-env",
        action="store_true",
        help="ignore host environment variables when populating values",
    )
    args = parser.parse_args()

    root = Path(__file__).resolve().parents[1]
    env_path = root / ".env"

    if env_path.exists() and not args.force:
        print(f"[generate_env] .env already exists at {env_path}. Use --force to overwrite.")
        return 0

    if args.ignore_env:
        print("[generate_env] Ignoring host environment variables; writing defaults.")

    lines = []
    used_openai_key: str | None = None
    for k, v in DEFAULTS.items():
        if args.ignore_env:
            val = v
        else:
            val = os.environ.get(k, v)
        if isinstance(val, str):
            val = val.strip()
        if k == "OPENAI_API_KEY":
            used_openai_key = val
        lines.append(f"{k}={val}")

    env_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
    print(f"[generate_env] Wrote {env_path}")
    if used_openai_key:
        source = (
            "environment" if not args.ignore_env and "OPENAI_API_KEY" in os.environ else "defaults"
        )
        fingerprint = _fingerprint(used_openai_key) or "none"
        print(f"[generate_env] OPENAI_API_KEY resolved from {source} (fingerprint={fingerprint})")
    else:
        print(
            "[generate_env] Note: OPENAI_API_KEY is empty. Set it via environment before running, e.g.\n"
            "  PowerShell:  $env:OPENAI_API_KEY='sk-...' ; python scripts/generate_env.py --force\n"
            "  Bash:        OPENAI_API_KEY='sk-...' python scripts/generate_env.py --force"
        )
    if (
        not args.ignore_env
        and "OPENAI_API_KEY" in os.environ
        and os.environ.get("OPENAI_API_KEY", "").strip() != (used_openai_key or "")
    ):
        print(
            "[generate_env] Warning: host OPENAI_API_KEY differs from written value. Run with --ignore-env to bypass host overrides."
        )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

```

## `scripts/ingest_cli.py`

```python
#!/usr/bin/env python3
"""CLI entrypoint for the Atticus ingestion pipeline."""

from __future__ import annotations

import argparse
import json
import os
import sys
from collections.abc import Sequence
from dataclasses import asdict
from pathlib import Path

# Ensure repository root on import path when running as a script
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from atticus.config import load_settings  # noqa: E402
from ingest.pipeline import IngestionOptions, ingest_corpus  # noqa: E402


def _paths(value: Sequence[str] | None) -> list[Path] | None:
    if not value:
        return None
    return [Path(item).expanduser().resolve() for item in value]


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Run the Atticus ingestion pipeline")
    parser.add_argument(
        "--paths",
        nargs="*",
        help="Optional subset of files or directories to ingest",
    )
    parser.add_argument(
        "--full-refresh",
        action="store_true",
        help="Force reprocessing of all documents even if unchanged",
    )
    parser.add_argument(
        "--config",
        type=Path,
        help="Path to an alternate config.yaml file",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="Optional path to write the ingestion summary JSON",
    )
    return parser


def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    if args.config:
        os.environ["CONFIG_PATH"] = str(args.config)

    settings = load_settings()
    options = IngestionOptions(full_refresh=bool(args.full_refresh), paths=_paths(args.paths))
    summary = ingest_corpus(settings=settings, options=options)
    payload = asdict(summary)

    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        args.output.write_text(json.dumps(payload, indent=2, default=str), encoding="utf-8")
    else:
        print(json.dumps(payload, indent=2, default=str))


if __name__ == "__main__":
    main()

```

## `scripts/list_make_targets.py`

```python
"""List unique make targets defined in provided makefiles."""

from __future__ import annotations

import pathlib
import re
import sys


def collect_targets(paths: list[str]) -> list[str]:
    pattern = re.compile(r"^[A-Za-z0-9_.-]+:")
    targets: set[str] = set()
    for raw_path in paths:
        path = pathlib.Path(raw_path)
        if not path.exists():
            continue
        for line in path.read_text().splitlines():
            if pattern.match(line):
                name = line.split(":", 1)[0]
                if name != ".PHONY":
                    targets.add(name)
    return sorted(targets)


def main(argv: list[str]) -> int:
    targets = collect_targets(argv or ["Makefile"])
    for name in targets:
        print(name)
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

```

## `scripts/make_seed.py`

```python
"""Generate a lightweight seed manifest from the current CED corpus."""

from __future__ import annotations

import json
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

try:  # pragma: no cover - optional dependency
    import pgvector.psycopg  # type: ignore
    import psycopg  # type: ignore
except ModuleNotFoundError:  # pragma: no cover - lightweight fallback for seed generation
    import types

    psycopg = types.ModuleType("psycopg")
    psycopg.rows = types.SimpleNamespace(dict_row=None)
    psycopg.types = types.SimpleNamespace(json=types.SimpleNamespace(Json=lambda value: value))
    psycopg.connect = lambda *args, **kwargs: (_ for _ in ()).throw(
        RuntimeError("psycopg unavailable")
    )
    sys.modules.setdefault("psycopg", psycopg)

    pgvector = types.ModuleType("pgvector")
    sys.modules.setdefault("pgvector", pgvector)

    pgvector_psycopg = types.ModuleType("pgvector.psycopg")
    pgvector_psycopg.register_vector = lambda conn: None
    pgvector_psycopg.Vector = list
    sys.modules["pgvector.psycopg"] = pgvector_psycopg

    ingest_pkg = types.ModuleType("ingest")
    ingest_pkg.__path__ = [str(ROOT / "ingest")]
    sys.modules.setdefault("ingest", ingest_pkg)

    sys.modules.setdefault("camelot", types.SimpleNamespace(read_pdf=lambda *args, **kwargs: []))
    sys.modules.setdefault("tabula", types.SimpleNamespace(read_pdf=lambda *args, **kwargs: []))

from atticus.config import load_settings
from atticus.utils import sha256_file
from ingest.chunker import chunk_document
from ingest.parsers import discover_documents, parse_document


def build_seed_manifest() -> list[dict[str, object]]:
    settings = load_settings()
    settings.ensure_directories()
    manifest: list[dict[str, object]] = []
    for index, path in enumerate(discover_documents(settings.content_dir)):
        document = parse_document(path)
        document.sha256 = sha256_file(path)
        chunks = chunk_document(document, settings)
        manifest.append(
            {
                "document": str(path),
                "sha256": document.sha256,
                "source_type": document.source_type,
                "chunk_count": len(chunks),
                "chunks": [
                    {
                        "chunk_id": chunk.chunk_id,
                        "sha256": chunk.sha256,
                        "heading": chunk.heading,
                        "chunking": chunk.extra.get("chunking"),
                        "page_number": chunk.page_number,
                    }
                    for chunk in chunks[:25]
                ],
            }
        )
        if index >= 9:  # keep seed small
            break
    return manifest


def main() -> None:
    output_path = Path("seeds/seed_manifest.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    manifest = build_seed_manifest()
    output_path.write_text(
        json.dumps(manifest, indent=2, ensure_ascii=False) + "\n",
        encoding="utf-8",
    )
    print(f"Wrote seed manifest with {len(manifest)} documents to {output_path}")


if __name__ == "__main__":
    main()

```

## `scripts/prisma_cli.py`

```python
"""Wrapper to run Prisma CLI commands with deterministic environment loading."""

from __future__ import annotations

import argparse
import os
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Iterable


def _load_env(env_path: Path, *, overwrite: bool = False) -> None:
    if not env_path.exists():
        return

    for raw_line in env_path.read_text(encoding="utf-8").splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        key, sep, value = line.partition("=")
        if not sep:
            continue
        key = key.strip()
        if not key:
            continue
        cleaned = value.strip()
        if (cleaned.startswith('"') and cleaned.endswith('"')) or (
            cleaned.startswith("'") and cleaned.endswith("'")
        ):
            cleaned = cleaned[1:-1]
        if overwrite or key not in os.environ or not os.environ[key]:
            os.environ[key] = cleaned


def _build_command(args: Iterable[str]) -> list[str]:
    command = [str(part) for part in args if part is not None]
    return command


def main(argv: list[str] | None = None) -> int:
    parser = argparse.ArgumentParser(
        description="Run Prisma CLI with .env variables overriding existing values.",
        allow_abbrev=False,
    )
    parser.add_argument(
        "--env-file",
        default=".env",
        help="Path to the .env file to load before invoking Prisma (default: %(default)s).",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Echo the Prisma command before execution.",
    )
    parser.add_argument(
        "prisma_args",
        nargs=argparse.REMAINDER,
        help="Arguments to forward to `npx prisma ...`.",
    )

    args = parser.parse_args(argv)
    if not args.prisma_args:
        parser.error("No Prisma arguments supplied.")

    env_path = Path(args.env_file)
    _load_env(env_path, overwrite=True)

    npx_path = shutil.which("npx")
    if npx_path:
        command = _build_command([npx_path, "prisma", *args.prisma_args])
    else:
        npm_path = shutil.which("npm")
        if not npm_path:
            print(
                "Neither npx nor npm were found on PATH. Install Node.js before running Prisma commands.",
                file=sys.stderr,
            )
            return 1
        command = _build_command([npm_path, "exec", "--", "prisma", *args.prisma_args])

    if args.verbose:
        print(f"Executing: {' '.join(command)}", file=sys.stderr)
        print(f"Using env file: {env_path}", file=sys.stderr)

    try:
        subprocess.run(command, check=True)
    except FileNotFoundError as exc:
        print(
            f"Failed to execute {' '.join(command)}: {exc}. Ensure Node.js and Prisma CLI are installed.",
            file=sys.stderr,
        )
        return 1
    except subprocess.CalledProcessError as exc:
        return exc.returncode
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

```

## `scripts/rollback.md`

```md
# Rollback Runbook (§7)

1. **Identify the prior release tag.**

   ```bash
   git fetch --tags
   git tag --sort=-creatordate | head
   ```

2. **Checkout the previous release.**

   ```bash
   git checkout <previous-tag>
   ```

3. **Restore the matching index snapshot.**
   - Locate the snapshot in `indexes/snapshots/` stamped with the release timestamp.
   - Copy it over the active index:

     ```bash
     cp indexes/snapshots/<snapshot>.json indexes/atticus_index.json
     ```

4. **Re-pin configuration.**
   - Verify `requirements.txt` and `package.json` match the target tag.
   - Confirm embedding/LLM identifiers (`text-embedding-3-large`, `gpt-4.1`) in `atticus/config.py`.
5. **Smoke test with gold queries.**

   ```bash
   pytest eval/harness -k retrieval --maxfail=1
   ```

   Review `eval/runs/YYYYMMDD/` outputs for the top queries (nDCG@10, Recall@50, MRR).

6. **Log the rollback.**
   - Append the action to `CHANGELOG.md`.
   - Tag the rollback release (e.g., `v0.1.0-rollback1`) with a short summary of the trigger and outcome.

```

## `scripts/rollback.py`

```python
"""Restore the Atticus index to a previous snapshot."""

from __future__ import annotations

import argparse
import os
import shutil
from pathlib import Path

from atticus.config import AppSettings, load_manifest, load_settings, write_manifest
from atticus.logging import configure_logging, log_event
from atticus.vector_db import PgVectorRepository, load_metadata
from eval.runner import load_gold_set
from retriever.vector_store import VectorStore

SNAPSHOT_METADATA = "index_metadata.json"
SNAPSHOT_MANIFEST = "manifest.json"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Rollback Atticus vector index")
    parser.add_argument(
        "--snapshot", type=Path, default=None, help="Specific snapshot directory to restore"
    )
    parser.add_argument("--skip-smoke", action="store_true", help="Skip smoke tests after rollback")
    parser.add_argument(
        "--limit", type=int, default=20, help="Number of gold queries for smoke testing"
    )
    parser.add_argument("--config", type=Path, help="Path to an alternate config.yaml")
    return parser.parse_args()


def _latest_snapshot_dir(directory: Path) -> Path:
    candidates = sorted([path for path in directory.iterdir() if path.is_dir()])
    if not candidates:
        raise FileNotFoundError(f"No snapshots found in {directory}")
    return candidates[-1]


def _run_smoke_tests(settings: AppSettings, logger, limit: int) -> list[str]:
    store = VectorStore(settings, logger)
    gold_examples = load_gold_set(settings.gold_set_path)[:limit]
    missing: list[str] = []
    for example in gold_examples:
        results = store.search(example.question, top_k=5)
        if not results:
            missing.append(example.question)
    return missing


def main() -> None:
    args = parse_args()
    if args.config:
        os.environ["CONFIG_PATH"] = str(args.config)
    settings = load_settings()
    logger = configure_logging(settings)

    if not settings.database_url:
        raise ValueError("DATABASE_URL must be configured before running rollback")

    snapshot_dir = args.snapshot or _latest_snapshot_dir(settings.snapshots_dir)
    metadata_path = snapshot_dir / SNAPSHOT_METADATA
    manifest_path = snapshot_dir / SNAPSHOT_MANIFEST
    if not metadata_path.exists() or not manifest_path.exists():
        raise FileNotFoundError(
            f"Snapshot {snapshot_dir} is missing {SNAPSHOT_METADATA} or {SNAPSHOT_MANIFEST}"
        )

    snapshot_manifest = load_manifest(manifest_path)
    if snapshot_manifest is None:
        raise FileNotFoundError(f"Snapshot manifest {manifest_path} is invalid or missing")

    chunks = load_metadata(metadata_path)
    repository = PgVectorRepository(settings)
    repository.ensure_schema()
    repository.truncate()

    documents = snapshot_manifest.documents
    ingest_time = snapshot_manifest.created_at

    chunks_by_document: dict[str, list] = {}
    for chunk in chunks:
        entry = chunks_by_document.setdefault(chunk.document_id, [])
        entry.append(chunk)

    for document_id, doc_chunks in chunks_by_document.items():
        if not doc_chunks:
            continue
        source_path = doc_chunks[0].source_path
        metadata = documents.get(source_path, {})
        repository.replace_document(
            document_id=document_id,
            source_path=source_path,
            sha256=str(metadata.get("sha256", "")),
            source_type=metadata.get("source_type"),
            chunks=doc_chunks,
            ingest_time=ingest_time,
        )

    shutil.copy2(metadata_path, settings.metadata_path)
    shutil.copy2(manifest_path, settings.manifest_path)

    restored_manifest = load_manifest(settings.manifest_path)
    if restored_manifest is None:
        write_manifest(settings.manifest_path, snapshot_manifest)
        restored_manifest = snapshot_manifest

    log_event(
        logger,
        "rollback_restored",
        snapshot=str(snapshot_dir),
        chunk_count=len(chunks),
        document_count=len(restored_manifest.documents),
    )

    if args.skip_smoke:
        print("Rollback complete. Smoke tests skipped.")
        return

    missing = _run_smoke_tests(settings, logger, args.limit)
    if missing:
        print("Rollback completed, but some queries returned no results:")
        for query in missing:
            print(f"  - {query}")
        print("Investigate the restored index before releasing.")
    else:
        print("Rollback validated successfully. All smoke tests returned results.")
    print("Tag the rollback commit and update CHANGELOG.md with details.")


if __name__ == "__main__":
    main()

```

## `scripts/run_ingestion.py`

```python
#!/usr/bin/env python3
"""Legacy wrapper for the Atticus ingestion CLI."""

from __future__ import annotations

import runpy
from pathlib import Path


def main() -> None:
    target = Path(__file__).with_name("ingest_cli.py")
    runpy.run_path(str(target), run_name="__main__")


if __name__ == "__main__":
    main()

```

## `scripts/run_token_eval.py`

```python
#!/usr/bin/env python3
"""Run a batch of evaluation questions against an OpenAI model and log token usage."""

from __future__ import annotations

import argparse
import os
import sys
import time
from pathlib import Path
from typing import Any, Iterable

import pandas as pd
import requests
from openai import OpenAI

try:
    import tiktoken
except ImportError:  # pragma: no cover - optional dependency
    tiktoken = None


def _load_env_from_file(path: Path) -> None:
    if not path.exists():
        return
    for raw_line in path.read_text(encoding="utf-8").splitlines():
        line = raw_line.strip()
        if not line or line.startswith("#"):
            continue
        if line.startswith("export "):
            line = line[len("export ") :]
        if "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        if not key or key in os.environ:
            continue
        cleaned = value.strip().strip('"').strip("'")
        if cleaned:
            os.environ[key] = cleaned


def _parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("ac7070_TOKEN_EVAL.xlsx"),
        help="Path to the Excel workbook containing questions (default: %(default)s)",
    )
    parser.add_argument(
        "--question-column",
        default="Question",
        help="Column name in the workbook that contains the questions",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("reports/ac7070_token_eval.csv"),
        help="Destination CSV file for results (default: %(default)s)",
    )
    parser.add_argument(
        "--model",
        default="gpt-4o-mini",
        help="OpenAI chat completion model to use (default: %(default)s)",
    )
    parser.add_argument(
        "--tokenizer-model",
        default=None,
        help="Model name to use for token estimation (defaults to --model)",
    )
    parser.add_argument(
        "--system",
        default=(
            "You are Atticus, an internal knowledge assistant. Answer clearly and cite relevant "
            "documents when possible. If you lack context, say so explicitly."
        ),
        help="System prompt applied to every question (default: concise Atticus instructions)",
    )
    parser.add_argument(
        "--sleep",
        type=float,
        default=0.5,
        help="Seconds to sleep between requests to avoid rate limits (default: %(default)s)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="List the questions but skip calling the API",
    )
    parser.add_argument(
        "--atticus-endpoint",
        type=str,
        default=None,
        help="Optional Atticus /api/ask endpoint (e.g. http://localhost:3000/api/ask). When provided, "
        "the script calls Atticus instead of the OpenAI API.",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=None,
        help="Optional topK override when calling Atticus.",
    )
    return parser.parse_args(list(argv) if argv is not None else None)


def _normalise_question(value: Any) -> str | None:
    if isinstance(value, str):
        stripped = value.strip()
        return stripped or None
    return None


def main(argv: Iterable[str] | None = None) -> int:
    args = _parse_args(argv)

    for stream in (sys.stdout, sys.stderr):
        try:
            stream.reconfigure(encoding="utf-8")  # type: ignore[attr-defined]
        except AttributeError:
            pass

    tokenizer_model = args.tokenizer_model or args.model

    if not args.input.exists():
        print(f"Input workbook not found: {args.input}", file=sys.stderr)
        return 2

    df = pd.read_excel(args.input)
    if args.question_column not in df.columns:
        print(
            f"Column '{args.question_column}' not found in {args.input}. "
            f"Available columns: {', '.join(df.columns)}",
            file=sys.stderr,
        )
        return 2

    questions = []
    for index, raw in df[args.question_column].items():
        text = _normalise_question(raw)
        if text:
            questions.append((index, text))

    if not questions:
        print("No questions found in the workbook.", file=sys.stderr)
        return 0

    args.output.parent.mkdir(parents=True, exist_ok=True)

    if args.dry_run:
        for index, question in questions:
            print(f"[{index}] {question}")
        print(f"Dry run only. Would write results to {args.output}")
        return 0

    client: OpenAI | None = None
    if not args.atticus_endpoint:
        _load_env_from_file(Path(".env"))
        if "OPENAI_API_KEY" not in os.environ:
            print(
                "OPENAI_API_KEY is not set. Export it or add it to .env before running this script.",
                file=sys.stderr,
            )
            return 2
        client = OpenAI()

    results: list[dict[str, Any]] = []
    total_input_tokens = 0
    total_output_tokens = 0

    for position, (index, question) in enumerate(questions, start=1):
        print(f"[{position}/{len(questions)}] Asking: {question}")
        answer_content = None
        prompt_tokens = None
        completion_tokens = None
        total_tokens = None
        response_id = None
        error_message = None

        if args.atticus_endpoint:
            payload: dict[str, Any] = {"question": question}
            if args.top_k is not None:
                payload["topK"] = args.top_k
            try:
                atticus_response = requests.post(
                    args.atticus_endpoint,
                    json=payload,
                    timeout=60,
                )
                atticus_response.raise_for_status()
                data = atticus_response.json()
                response_id = data.get("request_id")
                if data.get("answer"):
                    answer_content = data.get("answer")
                elif data.get("answers"):
                    answers = data.get("answers")
                    if isinstance(answers, list):
                        answer_content = "\n\n".join(
                            str(answer.get("answer", ""))
                            for answer in answers
                            if isinstance(answer, dict)
                        )
                else:
                    answer_content = None
            except Exception as exc:  # noqa: BLE001
                error_message = str(exc)
        else:
            assert client is not None  # for type checker
            try:
                response = client.chat.completions.create(
                    model=args.model,
                    messages=[
                        {"role": "system", "content": args.system},
                        {"role": "user", "content": question},
                    ],
                )
                usage = response.usage or None
                prompt_tokens = usage.prompt_tokens if usage else None
                completion_tokens = usage.completion_tokens if usage else None
                total_tokens = usage.total_tokens if usage else None
                total_input_tokens += prompt_tokens or 0
                total_output_tokens += completion_tokens or 0
                response_id = response.id
                answer_content = response.choices[0].message.content if response.choices else None
            except Exception as exc:  # noqa: BLE001
                error_message = str(exc)

        def _estimate(text: str | None) -> int | None:
            if text is None or not text.strip():
                return None
            if tiktoken is None:
                return None
            try:
                encoding = tiktoken.encoding_for_model(tokenizer_model)
            except Exception:  # pragma: no cover - fallback when model unknown
                encoding = tiktoken.get_encoding("cl100k_base")
            return len(encoding.encode(text))

        question_tokens = _estimate(question)
        answer_tokens = _estimate(answer_content)

        if args.atticus_endpoint:
            if prompt_tokens is None:
                prompt_tokens = question_tokens
            if completion_tokens is None:
                completion_tokens = answer_tokens
            if prompt_tokens is not None or completion_tokens is not None:
                total_tokens = (prompt_tokens or 0) + (completion_tokens or 0)
                total_input_tokens += prompt_tokens or 0
                total_output_tokens += completion_tokens or 0

        results.append(
            {
                "row_index": index,
                "question": question,
                "answer": answer_content,
                "error": error_message,
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens,
                "response_id": response_id,
                "question_tokens": question_tokens,
                "answer_tokens": answer_tokens,
            }
        )

        if args.sleep:
            time.sleep(args.sleep)

    results_df = pd.DataFrame(results)
    results_df.to_csv(args.output, index=False)
    print(f"Saved results for {len(results)} questions to {args.output}")
    print(f"Total prompt tokens: {total_input_tokens}")
    print(f"Total completion tokens: {total_output_tokens}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

```

## `scripts/smtp_test.py`

```python
"""Manual SMTP smoke test used by `make smtp-test`."""

from __future__ import annotations

import sys

try:
    from atticus.notify.mailer import send_escalation
except Exception as exc:  # pragma: no cover - import is optional for devs
    IMPORT_ERROR = exc
    send_escalation = None
else:
    IMPORT_ERROR = None


def main() -> None:
    if send_escalation is None:
        print("SMTP mailer is unavailable: atticus.notify.mailer could not be imported.")
        if IMPORT_ERROR:
            print(f"Reason: {IMPORT_ERROR}")
        sys.exit(1)

    send_escalation("Atticus SMTP test", "This is a test from make smtp-test")
    print("smtp ok")


if __name__ == "__main__":
    main()

```

## `scripts/test_health.py`

```python
from __future__ import annotations

import sys
from pathlib import Path

from fastapi.testclient import TestClient

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from api.main import app  # noqa: E402


def main() -> None:
    with TestClient(app) as client:
        res = client.get("/health")
        print("status:", res.status_code)
        print("json:", res.json())


if __name__ == "__main__":
    main()

```

## `seeds/seed_manifest.json`

```json
[
  {
    "document": "content\\catalog\\capabilities.txt",
    "sha256": "4fba014083f43ecd08eabdd391394306a4cced2fa0d0cdfd956d82eb3a2b9f02",
    "source_type": "text",
    "chunk_count": 1,
    "chunks": [
      {
        "chunk_id": "content\\catalog\\capabilities.txt::chunk_0",
        "sha256": "2bd0a2cb3364ab9f9c97f76db78579d84eaf185e202094fad91c99d53d62732a",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      }
    ]
  },
  {
    "document": "content\\catalog\\spec.txt",
    "sha256": "4fba014083f43ecd08eabdd391394306a4cced2fa0d0cdfd956d82eb3a2b9f02",
    "source_type": "text",
    "chunk_count": 1,
    "chunks": [
      {
        "chunk_id": "content\\catalog\\spec.txt::chunk_0",
        "sha256": "ab76fe3e543d91140f09220d7cf85ccabee1d51103fa49383d6dafe828927b8a",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      }
    ]
  },
  {
    "document": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf",
    "sha256": "4f2a7a02784415c6881f55ee575391b1ed879b400f93bc168535181a0e038a4e",
    "source_type": "pdf",
    "chunk_count": 1058,
    "chunks": [
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_0",
        "sha256": "cb839572a8165ebda3258a12beea3300aa2bc32456d8b33774120948703dd8c0",
        "heading": null,
        "chunking": "prose",
        "page_number": 1
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_1",
        "sha256": "1ae4a134dd2dac8df45dabfdc127a70cdca5375626102804937807a0f3edf215",
        "heading": null,
        "chunking": "prose",
        "page_number": 2
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_2",
        "sha256": "32d706d8817d0d7b060912ff12c4975f8b858fd241f51a4f795f95b78d2234a8",
        "heading": null,
        "chunking": "prose",
        "page_number": 3
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_3",
        "sha256": "f956dbfff9dcaf8c938f20a3269d61e916016fe78a93e6cb65458e5ed6230399",
        "heading": null,
        "chunking": "prose",
        "page_number": 4
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_4",
        "sha256": "ef4d8011518b0992ffd10ba4fcf4fe305a352e3d98595b99d84cacc5219d3377",
        "heading": null,
        "chunking": "prose",
        "page_number": 5
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_5",
        "sha256": "626c670f39caa88a5cc718a48e93663eff5045d4a5531c9b81a34773cfa948ff",
        "heading": null,
        "chunking": "prose",
        "page_number": 6
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_6",
        "sha256": "89fc5277a1bc3ea18a4b359fd7e549689b13987bfe9f59d75671846a19fc1c22",
        "heading": null,
        "chunking": "prose",
        "page_number": 7
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_7",
        "sha256": "a15965b0c065179bd376c1a96501e77ed8d37ab2b8a0fd6c24d6867d6ab66fbe",
        "heading": null,
        "chunking": "prose",
        "page_number": 8
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_9",
        "sha256": "e060d50e7dcbb1332715618c03312a05ea2408ca13f5dc3e19d05292156c357d",
        "heading": null,
        "chunking": "prose",
        "page_number": 9
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_11",
        "sha256": "2db710570e33a561955e902a48c33e7e616d6b3425235d55cc085ec2b289c717",
        "heading": null,
        "chunking": "prose",
        "page_number": 10
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_13",
        "sha256": "73669d9a2ba028e11d1f296b1e0b07c87fae6a210d7ea1cfc148cd04ad1d0496",
        "heading": null,
        "chunking": "prose",
        "page_number": 11
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_14",
        "sha256": "e2c716ccf0578e8497c580acff267865ade690593700fbc473a84f8c0061639d",
        "heading": null,
        "chunking": "prose",
        "page_number": 12
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_16",
        "sha256": "22a1554e8830d9bc6c2a05b1eb1f434c4ad49f3c63b9de248b41133638f11811",
        "heading": null,
        "chunking": "prose",
        "page_number": 13
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_17",
        "sha256": "eff12c6125c7632327cdf617352f5c880acb5412350cfbaa35f700dbf73fc12f",
        "heading": null,
        "chunking": "prose",
        "page_number": 13
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_18",
        "sha256": "3304351e746675dfe452d0795d3a957333a0de41f5720584dfb91a6c3924092d",
        "heading": null,
        "chunking": "prose",
        "page_number": 14
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_19",
        "sha256": "f6c48a923a0487ed604dfcb9f1ee33740b27742e71e9eb1941f7298c91a3a517",
        "heading": null,
        "chunking": "prose",
        "page_number": 14
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_20",
        "sha256": "eb6062358af35eb23bacd04ee2373369d7d51f9229d1a9bda6f0260e502552c5",
        "heading": null,
        "chunking": "prose",
        "page_number": 15
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_22",
        "sha256": "ae12fc963e94a43bdb6dcbe379511294c303479f638bc2929b66dd6125a44421",
        "heading": null,
        "chunking": "prose",
        "page_number": 16
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_24",
        "sha256": "fa1e9924046fed28b43476a4e2bceabcec2f16b231d55057d42da404c61ca406",
        "heading": null,
        "chunking": "prose",
        "page_number": 17
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_25",
        "sha256": "7d6bdecb46649ffe7ce2f690027287c92dc5ce071587beb31576e5455c50bd67",
        "heading": null,
        "chunking": "prose",
        "page_number": 18
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_26",
        "sha256": "736b46f4e1ae6f24cf396ab701038d96922909a876c5fb0182bc85c03a828015",
        "heading": null,
        "chunking": "prose",
        "page_number": 19
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_28",
        "sha256": "6ba7605039af20510308b9a5624cbe8684e8edd30455904930bbe21a69aa9b22",
        "heading": null,
        "chunking": "prose",
        "page_number": 20
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_29",
        "sha256": "57751342ada375afff23d5bf02aac3eceb9bc2a2e3ea3b8bc9698bb891d843b9",
        "heading": null,
        "chunking": "prose",
        "page_number": 21
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_31",
        "sha256": "65cae6cfd25828f79330d41f25da0fbe4c96b7835c347965590c7fd0c3d4dcb2",
        "heading": null,
        "chunking": "prose",
        "page_number": 22
      },
      {
        "chunk_id": "content\\model\\Reiki\\Apeos C8180 C7580 C6580 CSO-FN-CED 363.pdf::chunk_33",
        "sha256": "c1541d65b75a88eab63ec002e9cf332c5a5ccc76bca333141ff96d68f5a9043b",
        "heading": null,
        "chunking": "prose",
        "page_number": 23
      }
    ]
  },
  {
    "document": "content\\model\\Shobu\\ac7070_qna.xlsx",
    "sha256": "c0d72ca9f382f0db017f06097edfe13b226545e3ba5d73a33f35743f783a6757",
    "source_type": "xlsx",
    "chunk_count": 117,
    "chunks": [
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_0",
        "sha256": "7cf1bb6de7dfdac7fd3feaffc0cabe2f01baa98c63bb3307b096de18f4c62ec2",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_1",
        "sha256": "13880f3151b3e9bb27ac2bcdb16f61ca09eaf7c66e9ad0cb0b5e5b88d69f1a0f",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_2",
        "sha256": "8891e8fd10e804ae4fd8c66d719c748feb6266b03aa64f1a7fce25f1fe0cb598",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_3",
        "sha256": "033dfaafb450dd183a7af2576eaf2aa64a7208f36bd9f56bf9ab723f61e81bb1",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_4",
        "sha256": "e59f1029a9a28737d392365fb6343010ce063229f62810a686e286012417cd4a",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_5",
        "sha256": "7e0edafdbdac79915500593e60bab47703d42e57dd3dbccc05fc7486dfde1818",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_6",
        "sha256": "f7b4ceb80336e8cb95adcdfb91942f274e268aa34341355247d0231c6473df51",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_7",
        "sha256": "2e3c4654bd6a62007f692ba01febd7390949334f233c4c09787c8b3af5704e0b",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_8",
        "sha256": "f5af0f5d11dfbd0854a596a78596213b14ea25209a3a1c8eb5b5848a13e24537",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_9",
        "sha256": "0b594d90e887f0a45e7c208355e13ba9801cfe7f2e825270207636c05584c6a2",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_10",
        "sha256": "b1c0de67769ec1e36d138e293dab62ddcd6eea183438eea309b94e5bbaf64447",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_11",
        "sha256": "7b7f838c2d7b06eb289c7beab16b16cd24ac02017c392f884370d0bc5e1135d7",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_12",
        "sha256": "1c0e08f27e471791b9a649f32309620da01019b3135edd1ec653223e6b805206",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_13",
        "sha256": "090c2b714aa864189ad8eab9b966fa90a69842cac8c26d1f4430ed1d860d1de0",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_14",
        "sha256": "e7601bd65121f2b0940afeea5d60038500d4112fd338a45341ff69f9e0a4c5e9",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_15",
        "sha256": "d66c7161231589a82aa6b304f74df91ebd24538223af500cb729fbaf74ed32bd",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_16",
        "sha256": "7631fb86a4a2d76e6031f7117264288b1f95441b94cdd9b30115ee4e2d411255",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_17",
        "sha256": "2fb2f537236479e75b2a3d12560d577d97cabdc52064f04637ac3f58c3024b05",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_18",
        "sha256": "6ec0ac148c6135d91b6ec010b45b8d9cead7b5a4511d7018125ee3af7e7a69dc",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_19",
        "sha256": "a81468d242651084980bad6e8e0afbd320c1bcadf96d6e278576ca83501d6c39",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_20",
        "sha256": "7f7601647f55e29fabfa923c7e06f73bac9a239a933446963ff84f8e3a4b2ef3",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_21",
        "sha256": "f4033694c3a1c6e17a405f0746fd36325f3323da9708b2cb7c42350ab8e98761",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_22",
        "sha256": "be18eba8f66690d0a714f97a181a9868f4afe9caeec7883255d978844cf4e845",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_23",
        "sha256": "e52d17359179a6df4f480519af365886580f0fce1087900857ba38abfd60611d",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      },
      {
        "chunk_id": "content\\model\\Shobu\\ac7070_qna.xlsx::chunk_24",
        "sha256": "bfbd0662fac6ec006bbbc1c5c13fb79e05561aa602dd3e0162a39db9dbce2cec",
        "heading": null,
        "chunking": "prose",
        "page_number": null
      }
    ]
  },
  {
    "document": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf",
    "sha256": "aed11959541cc0aec6b9777ce48adbb9d23cfc76ba8e909176aef049502bccbe",
    "source_type": "pdf",
    "chunk_count": 1018,
    "chunks": [
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_0",
        "sha256": "e1ae4325e5a5f62e098114ecd9a010edf0ffb33e52e133dd40229c8d6e8a73d3",
        "heading": null,
        "chunking": "prose",
        "page_number": 1
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_1",
        "sha256": "677b8e7035ee0a9481a32b318b2a6f6e73985da7985803bb1d88bfe5058eb7db",
        "heading": null,
        "chunking": "prose",
        "page_number": 2
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_2",
        "sha256": "7ca4171fbcef1751f7ba6c9341b227d2a5b9f66940b9253a5a11f32082a68044",
        "heading": null,
        "chunking": "prose",
        "page_number": 3
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_3",
        "sha256": "d8606c71852624995bc2654d504e9231892af9fde44bc3eeea2a5aec34b33571",
        "heading": null,
        "chunking": "prose",
        "page_number": 4
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_4",
        "sha256": "4ec2a87a6d6ac6d12db51db9258196297bd51bf8b7fe020705ecabec781fd7f3",
        "heading": null,
        "chunking": "prose",
        "page_number": 5
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_6",
        "sha256": "d18a9a3bba2a200a4e0f3d05a30b77e1982840240f7a05b6223161d255a53ef8",
        "heading": null,
        "chunking": "prose",
        "page_number": 6
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_7",
        "sha256": "9f527220321be5baf56fbb9664207cd82f2c7c2ef743f8c5ac389529cd415bc9",
        "heading": null,
        "chunking": "prose",
        "page_number": 7
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_8",
        "sha256": "6f03a1ccff7c66d9235a57cde8296388f78edadac6faa59bcf2bee07d42eb074",
        "heading": null,
        "chunking": "prose",
        "page_number": 8
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_9",
        "sha256": "7c465e81afe8d6a46dfc688b2ebb4333d5be8582fad5dd63c065867688eba6f9",
        "heading": null,
        "chunking": "prose",
        "page_number": 9
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_10",
        "sha256": "a0d8f44c5937321003c47544b7ab6c149e2e615b2da1b99b2d520c7526a5b388",
        "heading": null,
        "chunking": "prose",
        "page_number": 9
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_11",
        "sha256": "fdd673f3cf1d47c867f173452d063adaa909986b471ad17c2792ebe0ca281fc1",
        "heading": null,
        "chunking": "prose",
        "page_number": 10
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_12",
        "sha256": "532629cf28325702cbdc8effaed77c89b50de06ee3d4a3c652f8b7642dc49685",
        "heading": null,
        "chunking": "prose",
        "page_number": 11
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_14",
        "sha256": "c358d0570d4704f9c8980fa49ce529496b524b81ef35e558bdadee608d736022",
        "heading": null,
        "chunking": "prose",
        "page_number": 12
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_16",
        "sha256": "6e6662c4142ac769db3cd83a03a7b87978565e1ed821adf9244ad80c557e3573",
        "heading": null,
        "chunking": "prose",
        "page_number": 13
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_18",
        "sha256": "464e043cfe590d6f0391ceff7ce1dfb030fc8e0fe29c590b23834bc2f587c7a2",
        "heading": null,
        "chunking": "prose",
        "page_number": 14
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_19",
        "sha256": "820d02a6b4cdb132e6e65b5c6c4f6092eabda2538583f1f640f3d23b0ad5db64",
        "heading": null,
        "chunking": "prose",
        "page_number": 15
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_20",
        "sha256": "a4c30064241e986b345c94db76daa736b58bd77a5482eff9642056ac530639f8",
        "heading": null,
        "chunking": "prose",
        "page_number": 16
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_21",
        "sha256": "aaa8cee91d8c8662181a3a2010281e7a7ed10faf84bcc9922cb5c7f25d428f25",
        "heading": null,
        "chunking": "prose",
        "page_number": 17
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_22",
        "sha256": "4fc259f07f8c7a0773b1e12ab35cc4d5b233c5086180e78c533e0346862cf803",
        "heading": null,
        "chunking": "prose",
        "page_number": 17
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_23",
        "sha256": "701cc17a4f825d44930c05416759ac6dfe4cd42c3437220b490011f4f72e7b0d",
        "heading": null,
        "chunking": "prose",
        "page_number": 18
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_24",
        "sha256": "428925a7037eee62b2c6053c2763b7789e1b67589928e5723d480b9520adf962",
        "heading": null,
        "chunking": "prose",
        "page_number": 18
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_26",
        "sha256": "e856ec5af26db3a59c545299d886c9e004e70f2d8ca0f9121c786590055c05a3",
        "heading": null,
        "chunking": "prose",
        "page_number": 19
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_28",
        "sha256": "dd3c9a91aef4a3cd392d1af3da70f0206975d415a7dad3ab4df2f731cf96d31a",
        "heading": null,
        "chunking": "prose",
        "page_number": 20
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_29",
        "sha256": "8d865f64fa5def85560098a7b3d73a4705ef94520ad0e832428d2d0776358fec",
        "heading": null,
        "chunking": "prose",
        "page_number": 21
      },
      {
        "chunk_id": "content\\model\\Shobu\\Apeos C7070-C6570-C5570-C4570-C3570-C3070-C2570-CSO-FN-CED-362.pdf::chunk_30",
        "sha256": "3cf0186f601d22363a1e8bad8268c58e12199c5bbfc7d01296c4986b89291ef3",
        "heading": null,
        "chunking": "prose",
        "page_number": 22
      }
    ]
  }
]

```

## `tailwind.config.js`

```javascript
/** @type {import('tailwindcss').Config} */
const animate = require("tailwindcss-animate");
const { fontFamily } = require("tailwindcss/defaultTheme");

module.exports = {
  darkMode: ["class"],
  content: ["./app/**/*.{ts,tsx,js,jsx,mdx}", "./components/**/*.{ts,tsx,js,jsx,mdx}", "./pages/**/*.{ts,tsx,js,jsx,mdx}"],
  theme: {
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
      fontFamily: {
        sans: ["var(--font-sans)", ...fontFamily.sans],
        mono: ["var(--font-mono)", ...fontFamily.mono],
      },
      keyframes: {
        "accordion-down": {
          from: { height: "0" },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: "0" },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
      boxShadow: {
        subtle: "0 10px 30px -15px rgba(15, 23, 42, 0.25)",
      },
    },
  },
  plugins: [animate],
};


```

## `tests/playwright/chat.spec.ts`

```typescript
import { expect, test } from "@playwright/test";

const shouldRun = process.env.PLAYWRIGHT_CHAT_CLARIFICATION === "true";

test.describe("chat clarification flow", () => {
  test.skip(!shouldRun, "Enable by setting PLAYWRIGHT_CHAT_CLARIFICATION=true");

  test("prompts for model selection and completes follow-up", async ({ page }) => {
    await page.goto("/");
    await page.getByRole("textbox", { name: /message/i }).fill("Can the printer handle glossy stock?");
    await page.getByRole("button", { name: /send/i }).click();

    const clarificationCard = page.getByRole("heading", { name: /Need a little more detail/i });
    await expect(clarificationCard).toBeVisible();

    await page.getByRole("button", { name: "Apeos C7070 range" }).click();
    await expect(page.getByText(/Apeos C7070/i)).toBeVisible();
    await expect(page.getByRole("heading", { name: /Sources/i })).toBeVisible();
  });
});

```

## `tests/test_admin_route.py`

```python
from __future__ import annotations

import json
from pathlib import Path

import pytest


def test_admin_dictionary_round_trip(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()
    dictionary_path = tmp_path / "dictionary.json"
    monkeypatch.setenv("DICTIONARY_PATH", str(dictionary_path))
    monkeypatch.setenv("ADMIN_API_TOKEN", "test-admin-token")
    settings = config_module.load_settings()
    assert settings.dictionary_path == dictionary_path

    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    with TestClient(api_main.app) as client:
        payload = {
            "entries": [{"term": "Managed print", "synonyms": ["MPS", "Print-as-a-service"]}]
        }
        response = client.post(
            "/admin/dictionary", json=payload, headers={"X-Admin-Token": "test-admin-token"}
        )
        assert response.status_code == 200
        assert response.json()["entries"][0]["term"] == "Managed print"

        retrieved = client.get("/admin/dictionary", headers={"X-Admin-Token": "test-admin-token"})
        assert retrieved.status_code == 200
        data = retrieved.json()
        assert data["entries"]
        entry = data["entries"][0]
        assert entry["term"] == "Managed print"
        assert entry["synonyms"] == ["MPS", "Print-as-a-service"]

    raw_file = json.loads(dictionary_path.read_text(encoding="utf-8"))
    assert raw_file[0]["synonyms"] == ["MPS", "Print-as-a-service"]


def test_admin_dictionary_requires_token(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()
    dictionary_path = tmp_path / "dictionary.json"
    monkeypatch.setenv("DICTIONARY_PATH", str(dictionary_path))
    monkeypatch.setenv("ADMIN_API_TOKEN", "test-admin-token")
    settings = config_module.load_settings()
    assert settings.dictionary_path == dictionary_path

    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    with TestClient(api_main.app) as client:
        response = client.get("/admin/dictionary")
        assert response.status_code == 401
        data = response.json()
        assert data["error"] == "unauthorized"
        assert data["request_id"]


def test_admin_dictionary_rejects_invalid_token(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()
    dictionary_path = tmp_path / "dictionary.json"
    monkeypatch.setenv("DICTIONARY_PATH", str(dictionary_path))
    monkeypatch.setenv("ADMIN_API_TOKEN", "test-admin-token")
    settings = config_module.load_settings()
    assert settings.dictionary_path == dictionary_path

    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    with TestClient(api_main.app) as client:
        response = client.get("/admin/dictionary", headers={"X-Admin-Token": "wrong-token"})
        assert response.status_code == 403
        data = response.json()
        assert data["error"] == "forbidden"
        assert data["detail"] == "Invalid admin token."
        assert data["request_id"]

```

## `tests/test_answer_format.py`

```python
from types import SimpleNamespace

from retriever import answer_format


def test_strip_inline_citation_tails_removes_markdown() -> None:
    text = "Finding ([source](#3)).\nAnother line (p. 2-3)."
    cleaned = answer_format._strip_inline_citation_tails(text)
    assert "source" not in cleaned
    assert "(p. 2-3)" not in cleaned


def test_strip_existing_sources_section() -> None:
    body = "Summary\n\n---\nSources\n- doc.pdf"
    trimmed = answer_format._strip_existing_sources_section(body)
    assert "Sources" not in trimmed
    assert trimmed.strip() == "Summary"


def test_to_numbered_list_handles_inline_items() -> None:
    text = "Here are steps 1. Turn on 2. Calibrate"
    numbered = answer_format._to_numbered_list(text)
    assert "1. Turn on" in numbered
    assert "2. Calibrate" in numbered


def test_fmt_source_line_with_page_collection() -> None:
    citation = SimpleNamespace(source_path="content/manual.pdf", page_range=[3, 1, 3])
    line = answer_format._fmt_source_line(citation)
    assert line.startswith("manual.pdf")
    assert "(p. 1, 3)" in line


def test_format_answer_markdown_with_intro_and_bullets() -> None:
    raw = "Intro summary: - item one - item two\n\nSources:\n- doc.pdf"
    result = answer_format.format_answer_markdown(raw, [])
    assert "Sources" not in result
    assert result.startswith("Intro summary:")

```

## `tests/test_api_errors.py`

```python
import asyncio
from types import SimpleNamespace
from fastapi import status
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from starlette.requests import Request

from api.errors import (
    http_exception_handler,
    unhandled_exception_handler,
    validation_exception_handler,
)


class _Recorder:
    def __init__(self) -> None:
        self.info_calls: list[tuple[str, dict | None]] = []
        self.error_calls: list[tuple[str, dict | None]] = []

    def info(self, event: str, *, extra: dict | None = None) -> None:
        self.info_calls.append((event, extra))

    def error(self, event: str, *, extra: dict | None = None) -> None:
        self.error_calls.append((event, extra))


def _make_request(logger: _Recorder | None = None) -> Request:
    app = SimpleNamespace(state=SimpleNamespace(logger=logger))
    scope = {
        "type": "http",
        "http_version": "1.1",
        "method": "GET",
        "path": "/tests",
        "headers": [],
        "app": app,
    }

    async def _receive() -> dict:
        return {"type": "http.request"}

    request = Request(scope, _receive)
    request.state.request_id = "req-123"
    return request


def test_http_exception_handler_logs_server_errors() -> None:
    logger = _Recorder()
    request = _make_request(logger)
    exc = StarletteHTTPException(status_code=500, detail="boom")

    response = asyncio.run(http_exception_handler(request, exc))

    assert response.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
    assert logger.error_calls
    payload = logger.error_calls[0][1]
    assert payload and payload["extra_payload"]["detail"] == "boom"


def test_validation_exception_handler_collects_fields() -> None:
    logger = _Recorder()
    request = _make_request(logger)
    exc = RequestValidationError(
        [
            {"loc": ("body", "question"), "msg": "field required"},
            {"loc": ("body", "filters", "source"), "msg": "invalid source"},
        ]
    )

    response = asyncio.run(validation_exception_handler(request, exc))

    assert response.status_code == status.HTTP_422_UNPROCESSABLE_ENTITY
    body = response.body.decode("utf-8")
    assert '"fields"' in body
    assert logger.error_calls  # validation errors are logged


def test_unhandled_exception_handler_logs_error() -> None:
    logger = _Recorder()
    request = _make_request(logger)

    response = asyncio.run(unhandled_exception_handler(request, RuntimeError("unexpected")))

    assert response.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
    assert logger.error_calls

```

## `tests/test_api_version.py`

```python
"""Ensure API metadata stays aligned with the repository VERSION file."""

from __future__ import annotations

from pathlib import Path

from api.main import app


def test_api_version_matches_repo_version() -> None:
    version_path = Path(__file__).resolve().parents[1] / "VERSION"
    expected = version_path.read_text(encoding="utf-8").strip()
    assert app.version == expected

```

## `tests/test_chat_route.py`

```python
import asyncio
from types import SimpleNamespace
from typing import Any

import pytest

from api.routes.chat import ask_endpoint
from api.schemas import AskRequest
from retriever.models import Answer, Citation, FamilyOption
from retriever.resolver import ModelResolution, ModelScope


class _DummyLogger:
    def info(self, *args, **kwargs):
        pass


def test_chat_route_or_skip() -> None:
    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    client = TestClient(api_main.app)
    try:
        r = client.post("/ask", json={"question": "ping"})
    except FileNotFoundError as exc:
        pytest.skip(f"index not built: {exc}")
        return
    except ValueError as exc:
        pytest.skip(f"vector store unavailable: {exc}")
        return

    assert r.status_code == 200
    data: dict[str, Any] = r.json()
    assert data["request_id"]
    assert r.headers.get("X-Request-ID") == data["request_id"]
    assert "answer" in data
    assert "sources" in data
    assert isinstance(data["sources"], list)
    if data["sources"]:
        first = data["sources"][0]
        assert {"path"}.issubset(first)
        assert "chunkId" in first
    assert isinstance(data["confidence"], (float, int))
    assert isinstance(data["should_escalate"], bool)


def test_chat_route_rejects_placeholder_or_skip() -> None:
    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    client = TestClient(api_main.app)
    try:
        r = client.post("/ask", json={"question": "string"})
    except FileNotFoundError as exc:
        pytest.skip(f"index not built: {exc}")
        return
    except ValueError as exc:
        pytest.skip(f"vector store unavailable: {exc}")
        return

    assert r.status_code == 400
    data = r.json()
    assert data["error"] == "bad_request"
    assert "Provide a real question" in data["detail"]
    assert data["request_id"]
    assert r.headers.get("X-Request-ID") == data["request_id"]


def test_chat_route_rate_limit(monkeypatch) -> None:
    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()
    monkeypatch.setenv("RATE_LIMIT_REQUESTS", "1")
    monkeypatch.setenv("RATE_LIMIT_WINDOW_SECONDS", "60")

    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient

    client = TestClient(api_main.app)
    try:
        first = client.post("/ask", json={"question": "ping"})
    except FileNotFoundError as exc:
        pytest.skip(f"index not built: {exc}")
        return
    except ValueError as exc:
        pytest.skip(f"vector store unavailable: {exc}")
        return

    if first.status_code != 200:
        pytest.skip("first request did not succeed; skipping rate limit assertion")
        return

    second = client.post("/ask", json={"question": "another"})
    assert second.status_code == 429
    data = second.json()
    assert data["error"] == "rate_limited"
    assert "request_id" in data


def test_ask_endpoint_returns_clarification(monkeypatch: pytest.MonkeyPatch) -> None:
    options = [
        FamilyOption(id="C7070", label="Apeos C7070 range"),
        FamilyOption(id="C8180", label="Apeos C8180 series"),
    ]

    def fake_resolve_models(*args, **kwargs) -> ModelResolution:
        return ModelResolution(
            scopes=[], confidence=0.0, needs_clarification=True, clarification_options=options
        )

    monkeypatch.setattr("api.routes.chat.resolve_models", fake_resolve_models)
    monkeypatch.setattr(
        "api.routes.chat.answer_question",
        lambda *args, **kwargs: pytest.fail(
            "answer_question should not be called when clarification is needed"
        ),
    )

    payload = AskRequest(question="Can the printer handle glossy stock?")
    request = SimpleNamespace(state=SimpleNamespace(request_id="req-clarify"))
    settings = SimpleNamespace(verbose_logging=False, trace_logging=False, openai_api_key=None)

    response = asyncio.run(ask_endpoint(payload, request, settings, _DummyLogger()))

    assert response.clarification is not None
    assert response.clarification.message
    assert {option.id for option in response.clarification.options} == {"C7070", "C8180"}
    assert response.answers == []
    assert response.sources == []
    assert response.confidence == 0.0
    assert response.should_escalate is False


def test_ask_endpoint_fans_out_answers(monkeypatch: pytest.MonkeyPatch) -> None:
    options = [
        FamilyOption(id="C7070", label="Apeos C7070 range"),
        FamilyOption(id="C8180", label="Apeos C8180 series"),
    ]
    scopes = [
        ModelScope(family_id="C7070", family_label="Apeos C7070 range", model="Apeos C4570"),
        ModelScope(family_id="C8180", family_label="Apeos C8180 series", model="Apeos C6580"),
    ]

    def fake_resolve_models(*args, **kwargs) -> ModelResolution:
        return ModelResolution(
            scopes=list(scopes),
            confidence=0.9,
            needs_clarification=False,
            clarification_options=options,
        )

    calls = []

    def fake_answer_question(
        question: str,
        *,
        product_family: str | None = None,
        family_label: str | None = None,
        model: str | None = None,
        **kwargs,
    ) -> Answer:
        calls.append((product_family, model))
        citation = Citation(
            chunk_id=f"{model}-chunk",
            source_path=f"content/{product_family}.pdf",
            page_number=5,
            heading=f"{model} Specs",
            score=0.88,
        )
        return Answer(
            question=question,
            response=f"{model} capabilities summary.",
            citations=[citation],
            confidence=0.92,
            should_escalate=False,
            model=model,
            family=product_family,
            family_label=family_label,
        )

    monkeypatch.setattr("api.routes.chat.resolve_models", fake_resolve_models)
    monkeypatch.setattr("api.routes.chat.answer_question", fake_answer_question)

    payload = AskRequest(question="Compare the Apeos C4570 and C6580 models.", top_k=2)
    request = SimpleNamespace(state=SimpleNamespace(request_id="req-multi"))
    settings = SimpleNamespace(verbose_logging=False, trace_logging=False, openai_api_key=None)

    response = asyncio.run(ask_endpoint(payload, request, settings, _DummyLogger()))

    assert len(calls) == 2
    assert ("C7070", "Apeos C4570") in calls
    assert ("C8180", "Apeos C6580") in calls

    assert response.answers is not None
    assert len(response.answers) == 2
    assert {answer.model for answer in response.answers} == {"Apeos C4570", "Apeos C6580"}
    assert all(answer.sources for answer in response.answers)
    assert response.should_escalate is False
    assert response.confidence is not None and response.confidence >= 0.0
    assert "###" in (response.answer or "")

```

## `tests/test_chat_verbose.py`

```python
import asyncio
from types import SimpleNamespace

import pytest

from api.routes.chat import ask_endpoint
from api.schemas import AskRequest


class _DummyLogger:
    def info(self, *args, **kwargs):
        pass


def test_ask_endpoint_emits_verbose_logs(monkeypatch: pytest.MonkeyPatch) -> None:
    citations = [
        SimpleNamespace(
            chunk_id="chunk-1",
            source_path="content/manuals/guide.pdf",
            page_number=5,
            heading="Overview",
            score=0.87,
        )
    ]

    def fake_answer_question(*args, **kwargs):
        return SimpleNamespace(
            response="All systems operational.",
            confidence=0.72,
            should_escalate=False,
            citations=citations,
        )

    log_calls: list[tuple[str, dict]] = []

    def fake_log_event(logger, event: str, **payload):
        log_calls.append((event, payload))

    def fake_count_tokens(value: str) -> int:
        return len(value.split())

    monkeypatch.setattr("api.routes.chat.answer_question", fake_answer_question)
    monkeypatch.setattr("api.routes.chat.log_event", fake_log_event)
    monkeypatch.setattr("api.routes.chat.count_tokens", fake_count_tokens)

    payload = AskRequest(
        question="Explain the workflow", filters={"family": "C7070"}, top_k=3, models=["C7070"]
    )
    request = SimpleNamespace(state=SimpleNamespace(request_id="req-001"))
    settings = SimpleNamespace(verbose_logging=True, trace_logging=True, openai_api_key=None)

    response = asyncio.run(ask_endpoint(payload, request, settings, _DummyLogger()))

    assert response.answer == "All systems operational."
    assert response.sources[0].path == "content/manuals/guide.pdf"
    assert response.answers is not None and len(response.answers) == 1
    first_answer = response.answers[0]
    assert first_answer.model in (None, "Apeos C7070")

    # Two log events: completion + verbose chat turn
    assert {event for event, _ in log_calls} == {"ask_endpoint_complete", "chat_turn"}
    chat_turn_payload = dict(log_calls)["chat_turn"]  # keys are unique in this test, safe to coerce
    assert "Overview" in chat_turn_payload["sources"][0]

```

## `tests/test_chunker.py`

```python
from pathlib import Path

import sys
import types

from atticus.config import AppSettings

psycopg_stub = types.ModuleType("psycopg")
psycopg_stub.rows = types.SimpleNamespace(dict_row=None)
psycopg_stub.types = types.SimpleNamespace(json=types.SimpleNamespace(Json=lambda value: value))
psycopg_stub.connect = lambda *args, **kwargs: (_ for _ in ()).throw(
    RuntimeError("psycopg stubbed")
)
sys.modules.setdefault("psycopg", psycopg_stub)

pgvector_stub = types.ModuleType("pgvector")
pgvector_psycopg_stub = types.ModuleType("pgvector.psycopg")


class _Vector(list):
    def __init__(self, values):
        super().__init__(values)


pgvector_psycopg_stub.register_vector = lambda conn: None
pgvector_psycopg_stub.Vector = _Vector
sys.modules.setdefault("pgvector", pgvector_stub)
sys.modules["pgvector.psycopg"] = pgvector_psycopg_stub

ingest_pkg = types.ModuleType("ingest")
ingest_pkg.__path__ = [str(Path("ingest"))]
sys.modules.setdefault("ingest", ingest_pkg)


from ingest.chunker import chunk_document
from ingest.models import ParsedDocument, ParsedSection


def test_ced_chunker_deduplicates_and_labels() -> None:
    settings = AppSettings()
    sections = [
        ParsedSection(text="Paragraph alpha beta.", heading="Intro"),
        ParsedSection(text="Paragraph alpha beta.", heading="Intro"),
        ParsedSection(
            text="A | B\nC | D",
            heading="Table 1",
            extra={"is_table": "true", "table_headers": "col1 | col2"},
        ),
        ParsedSection(text="See warranty schedule.", heading="Footnote 1"),
    ]
    document = ParsedDocument(
        source_path=Path("/tmp/doc.txt"),
        source_type="text",
        sections=sections,
    )

    chunks = chunk_document(document, settings)

    # Duplicate prose section should be deduped by SHA-256 hash
    prose_chunks = [chunk for chunk in chunks if chunk.extra.get("chunking") == "prose"]
    assert len(prose_chunks) == 1

    # Table chunk should serialise rows and include metadata
    table_chunks = [chunk for chunk in chunks if chunk.extra.get("chunking") == "table_row"]
    assert table_chunks, "expected table row chunks"
    first_table = table_chunks[0]
    assert first_table.extra["table_headers"] == "col1 | col2"
    assert first_table.extra["chunk_sha"] == first_table.sha256

    # Footnote chunk retains chunking label and SHA metadata
    footnote = next(chunk for chunk in chunks if chunk.extra.get("chunking") == "footnote")
    assert footnote.extra["chunk_sha"] == footnote.sha256


def test_chunker_assigns_traceable_metadata() -> None:
    settings = AppSettings(chunk_target_tokens=64, chunk_min_tokens=0)
    sections = [
        ParsedSection(
            text="Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod.",
            heading="Overview",
            breadcrumbs=["Section 1"],
        ),
    ]
    document = ParsedDocument(
        source_path=Path("/tmp/manual.txt"),
        source_type="manual",
        sections=sections,
    )

    chunks = chunk_document(document, settings)
    assert len(chunks) >= 1
    for chunk in chunks:
        assert chunk.extra["chunk_sha"] == chunk.sha256
        assert "breadcrumbs" in chunk.extra
        assert chunk.extra.get("source_type") == "manual"

```

## `tests/test_citation_dedupe.py`

```python
from __future__ import annotations

from retriever.citation_utils import dedupe_citations


def test_dedupe_by_path_and_pages_simple_dicts() -> None:
    items = [
        {"source_path": "docs/Guide-A.pdf", "page_range": [10, 11]},
        {"source_path": "docs/Guide-A.pdf", "page_range": [10, 11]},
        {"source_path": "docs/Guide-A.pdf", "page_range": [12]},
        {"source_path": "docs/Guide-B.pdf", "page_range": [1]},
        {"source_path": "docs/guide-a.PDF", "page_range": [12]},
    ]
    out = dedupe_citations(items)
    assert len(out) == 3
    assert out[0]["page_range"] == [10, 11]
    assert out[1]["page_range"] == [12]
    assert out[2]["source_path"].endswith("Guide-B.pdf")


class Obj:
    def __init__(self, source_path: str, page_range: object) -> None:
        self.source_path = source_path
        self.page_range = page_range


def test_dedupe_supports_objects_and_sets_pages() -> None:
    items = [
        Obj("docs/Ref.pdf", {2, 3}),
        Obj("docs/Ref.pdf", [3, 2]),
        Obj("docs/Ref.pdf", (4,)),
    ]
    out = dedupe_citations(items)
    assert len(out) == 2
    assert isinstance(out[0], Obj)

```

## `tests/test_citation_utils_extra.py`

```python
from types import SimpleNamespace

from retriever.citation_utils import (
    _norm_pages,
    _norm_source_path,
    dedupe_citations,
)


class BadPath:
    def __fspath__(self):
        raise RuntimeError("boom")


def test_norm_source_path_handles_exceptions() -> None:
    assert _norm_source_path(None) == ""
    assert _norm_source_path("Content/Doc.PDF") == "doc"
    fallback = _norm_source_path(BadPath())
    assert fallback  # falls back to string representation


def test_norm_pages_parses_iterables_and_strings() -> None:
    assert _norm_pages([3, 1, 3]) == (1, 3, 3)
    assert _norm_pages("1, 2 3") == (1, 2, 3)
    assert _norm_pages(5) == (5,)


def test_dedupe_citations_varied_inputs() -> None:
    items = [
        {"source_path": "docs/file.pdf", "page_range": [1, 2]},
        SimpleNamespace(source_path="docs/file.pdf", pages={2, 1}),
        {"source_path": "docs/other.pdf", "pages": "3 4"},
        {"source_path": None, "pages": None},
    ]
    result = dedupe_citations(items)
    assert len(result) == 3

```

## `tests/test_config_reload.py`

```python
from pathlib import Path
import importlib
import os
import sys
import time

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

config_module = importlib.import_module("atticus.config")


def test_load_settings_refreshes_env(tmp_path, monkeypatch):
    # Prepare isolated temp repo
    env_path = tmp_path / ".env"
    env_path.write_text("OPENAI_API_KEY=first-key\n", encoding="utf-8")
    (tmp_path / "config.yaml").write_text("{}\n", encoding="utf-8")

    # Make sure no ambient OS key can override our .env
    monkeypatch.delenv("OPENAI_API_KEY", raising=False)
    # Tell the app we want .env to win
    monkeypatch.setenv("ATTICUS_ENV_PRIORITY", "env")

    # Optional: if your loader supports a DOTENV_PATH override, pin it
    monkeypatch.setenv("DOTENV_PATH", str(env_path))

    old_cwd = os.getcwd()
    try:
        os.chdir(tmp_path)
        # Reload module so it (re)reads env with our settings
        cfg = importlib.reload(config_module)
        cfg.reset_settings_cache()

        first = cfg.load_settings()
        assert first.openai_api_key == "first-key"

        # Update .env and ensure mtime changes
        time.sleep(1.1)
        env_path.write_text("OPENAI_API_KEY=second-key\n", encoding="utf-8")
        os.utime(env_path, None)

        # Either reset cache or reload to force re-read
        cfg.reset_settings_cache()
        second = cfg.load_settings()
        assert second.openai_api_key == "second-key"

    finally:
        os.chdir(old_cwd)
        importlib.reload(config_module)
        config_module.reset_settings_cache()

```

## `tests/test_contact_route.py`

```python
# tests/test_contact_route.py
import pytest


# Fixture lives in THIS file (no conftest.py needed)
@pytest.fixture
def patch_smtp(monkeypatch):
    class FakeSMTP:
        def __init__(self, *a, **k):
            pass

        def __enter__(self):
            return self

        def __exit__(self, *a):
            return False

        def connect(self, *a, **k):
            pass

        def ehlo(self, *a, **k):
            pass

        def starttls(self, *a, **k):
            pass

        def login(self, *a, **k):
            pass

        def sendmail(self, *a, **k):
            pass

        def send_message(self, *a, **k):
            pass

        def quit(self, *a, **k):
            pass

        def close(self, *a, **k):
            pass

    # Patch both import styles used by mailer
    for t in [
        "atticus.notify.mailer.smtplib.SMTP",
        "atticus.notify.mailer.SMTP",
        "atticus.notify.mailer.smtplib.SMTP_SSL",
        "atticus.notify.mailer.SMTP_SSL",
    ]:
        try:
            monkeypatch.setattr(t, FakeSMTP, raising=True)
        except Exception:
            pass


def _mk_client():
    api_main = pytest.importorskip("api.main")
    TestClient = pytest.importorskip("fastapi.testclient").TestClient
    return TestClient(api_main.app), api_main.app


def test_contact_route_smoke_or_skip(monkeypatch, patch_smtp):
    client = app = None
    # Minimal env so startup doesn't bail
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "1025")
    monkeypatch.setenv("SMTP_USER", "user")
    monkeypatch.setenv("SMTP_PASS", "pass")
    monkeypatch.setenv("SMTP_FROM", "atticus-escalations@agentk.fyi")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    try:
        client, app = _mk_client()
    except Exception as e:
        pytest.skip(f"api not importable yet: {e}")
        return

    known = {r.path for r in app.routes}
    for path in ("/contact", "/api/contact"):
        if path not in known:
            continue
        r = client.post(path, json={"reason": "test"})
        if r.status_code in (200, 202):
            try:
                data = r.json()
            except Exception:
                data = {}
            assert data.get("status") in {None, "accepted", "ok", "queued", "success"}
            return

    pytest.fail(f"No working contact endpoint. routes={sorted(known)}")


def test_contact_route_with_transcript_or_skip(monkeypatch, patch_smtp):
    client = app = None
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "1025")
    monkeypatch.setenv("SMTP_USER", "user")
    monkeypatch.setenv("SMTP_PASS", "pass")
    monkeypatch.setenv("SMTP_FROM", "atticus-escalations@agentk.fyi")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    try:
        client, app = _mk_client()
    except Exception as e:
        pytest.skip(f"api not importable yet: {e}")
        return

    payload = {"reason": "test_with_transcript", "transcript": ["Q: hi", "A: hello"]}
    known = {r.path for r in app.routes}
    for path in ("/contact", "/api/contact"):
        if path not in known:
            continue
        r = client.post(path, json=payload)
        if r.status_code in (200, 202):
            try:
                data = r.json()
            except Exception:
                data = {}
            assert data.get("status") in {"accepted", "ok", "queued", "success", None}
            return

    pytest.fail("No contact endpoint accepted the request.")


def test_contact_route_handles_mailer_failure(monkeypatch, patch_smtp):
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "1025")
    monkeypatch.setenv("SMTP_FROM", "atticus-escalations@agentk.fyi")
    monkeypatch.setenv("CONTACT_EMAIL", "support@example.com")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    try:
        client, _app = _mk_client()
    except Exception as e:
        pytest.skip(f"api not importable yet: {e}")
        return

    notify_module = pytest.importorskip("atticus.notify")

    def boom(*_args, **_kwargs):
        raise notify_module.EscalationDeliveryError("boom", reason="connection_error")

    monkeypatch.setattr("api.routes.contact.send_escalation", boom, raising=True)

    response = client.post("/contact", json={"reason": "failing"})

    assert response.status_code == 502
    data = response.json()
    assert data["error"] == "internal_error"
    assert "Unable to deliver" in data["detail"]
    assert data["request_id"]

```

## `tests/test_contact_route_trace.py`

```python
import asyncio
from types import SimpleNamespace

import pytest

from api.routes.contact import (
    ContactRequest,
    EscalationTrace,
    TraceDocument,
    contact,
)


class _Recorder:
    def __init__(self) -> None:
        self.info_calls: list[tuple[str, dict]] = []
        self.error_calls: list[tuple[str, dict]] = []

    def info(self, event: str, *, extra: dict | None = None) -> None:
        self.info_calls.append((event, extra or {}))

    def error(self, event: str, *, extra: dict | None = None) -> None:
        self.error_calls.append((event, extra or {}))


def test_contact_route_with_trace(monkeypatch: pytest.MonkeyPatch) -> None:
    logger = _Recorder()
    captured: dict[str, str | dict | None] = {}

    monkeypatch.setattr("api.routes.contact.load_settings", lambda: SimpleNamespace())
    monkeypatch.setattr("api.routes.contact.configure_logging", lambda settings: logger)

    def fake_send_escalation(*, subject: str, body: str, trace: dict | None):
        captured["subject"] = subject
        captured["body"] = body
        captured["trace"] = trace

    monkeypatch.setattr("api.routes.contact.send_escalation", fake_send_escalation)

    trace = EscalationTrace(
        user_id="user-1",
        request_id="trace-001",
        documents=[
            TraceDocument(chunk_id="c1", score=0.9, source_path="docs/file.pdf", page_number=2)
        ],
    )
    payload = ContactRequest(reason="low_confidence", transcript="step 1", trace=trace)
    request = SimpleNamespace(state=SimpleNamespace(request_id="req-001"))

    result = asyncio.run(contact(payload, request))

    assert result == {"status": "accepted"}
    assert captured["trace"]["request_id"] == "trace-001"
    assert "Trace Payload" in captured["body"]
    assert logger.info_calls

```

## `tests/test_environment_diagnostics.py`

```python
"""Tests for environment diagnostics helper."""

from __future__ import annotations

import hashlib
from pathlib import Path

import pytest

from atticus import config as config_module


@pytest.fixture(autouse=True)
def reset_settings_cache():
    config_module.reset_settings_cache()
    yield
    config_module.reset_settings_cache()


def test_environment_diagnostics_reports_sources(
    tmp_path: Path, monkeypatch: pytest.MonkeyPatch
) -> None:
    env_file = tmp_path / ".env"
    env_file.write_text(
        """
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/atticus
OPENAI_API_KEY=sk-debug
PGVECTOR_LISTS=256
""".strip()
        + "\n",
        encoding="utf-8",
    )

    config_path = tmp_path / "config.yaml"
    config_path.write_text("pgvector_lists: 128\n", encoding="utf-8")

    monkeypatch.chdir(tmp_path)
    monkeypatch.delenv("DATABASE_URL", raising=False)
    monkeypatch.delenv("OPENAI_API_KEY", raising=False)
    monkeypatch.setenv("SMTP_USER", "smtp-user")

    diagnostics = config_module.environment_diagnostics()

    assert diagnostics["env_file"]["path"] == str(env_file)
    assert diagnostics["env_file"]["exists"] is True
    assert diagnostics["config_file"]["path"] == str(config_path)
    assert diagnostics["config_file"]["exists"] is True

    secrets = diagnostics["secrets"]
    db_secret = secrets["database_url"]
    assert db_secret["source"] == ".env:DATABASE_URL"
    expected_fp = hashlib.sha256(
        b"postgresql://postgres:postgres@localhost:5432/atticus"
    ).hexdigest()[:12]
    assert db_secret["fingerprint"] == expected_fp
    assert secrets["openai_api_key"]["source"] == ".env:OPENAI_API_KEY"
    assert secrets["smtp_user"]["source"] == "os.environ:SMTP_USER"
    assert secrets["smtp_user"]["defined"] is True

    settings_snapshot = diagnostics["settings"]
    assert settings_snapshot["pgvector_lists"]["value"] == 256
    assert settings_snapshot["pgvector_lists"]["source"] == ".env:PGVECTOR_LISTS"

    # Ensure secrets are excluded from the public settings snapshot.
    assert "database_url" not in settings_snapshot
    assert "openai_api_key" not in settings_snapshot

    overrides = diagnostics["overrides"]
    assert "SMTP_USER" in overrides["environment"]
    assert "DATABASE_URL" in overrides[".env"]

```

## `tests/test_error_schema.py`

```python
import pytest


@pytest.fixture
def app_with_settings(monkeypatch):
    api_main = pytest.importorskip("api.main")

    # Provide minimal SMTP configuration so startup validations succeed consistently.
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "1025")
    monkeypatch.setenv("SMTP_FROM", "atticus-escalations@agentk.fyi")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    return api_main.app


def test_validation_error_schema(app_with_settings):
    TestClient = pytest.importorskip("fastapi.testclient").TestClient
    with TestClient(app_with_settings) as client:
        response = client.post("/contact", json={})

    assert response.status_code == 422
    payload = response.json()
    assert payload["error"] == "validation_error"
    assert "reason" in payload.get("fields", {})
    assert payload["request_id"]
    assert response.headers.get("X-Request-ID") == payload["request_id"]


def test_unauthorized_error_schema(app_with_settings):
    fastapi = pytest.importorskip("fastapi")
    app = app_with_settings

    async def raise_unauthorized():
        raise fastapi.HTTPException(status_code=401, detail="Auth required")

    if not any(getattr(route, "path", None) == "/__unauthorized" for route in app.routes):
        app.add_api_route("/__unauthorized", raise_unauthorized)

    TestClient = pytest.importorskip("fastapi.testclient").TestClient
    with TestClient(app) as client:
        response = client.get("/__unauthorized")
    assert response.status_code == 401
    payload = response.json()
    assert payload["error"] == "unauthorized"
    assert payload["detail"] == "Auth required"
    assert payload["request_id"]

```

## `tests/test_eval_runner.py`

```python
"""Tests for evaluation runner artifact generation."""

from __future__ import annotations


from eval.runner import _write_outputs


def test_write_outputs_creates_csv_json_and_html(tmp_path):
    rows = [
        {
            "query": "What is the toner yield?",
            "nDCG@10": 0.8123,
            "Recall@50": 0.9,
            "MRR": 0.75,
            "top_document": "/docs/ced/toner.pdf",
        }
    ]
    metrics = {"nDCG@10": 0.8123, "Recall@50": 0.9, "MRR": 0.75}

    csv_path, json_path, html_path = _write_outputs(tmp_path, rows, metrics)

    assert csv_path.exists()
    assert json_path.exists()
    assert html_path.exists()

    html = html_path.read_text(encoding="utf-8")
    assert "Atticus Evaluation Summary" in html
    assert "What is the toner yield?" in html
    assert "metrics" in html.lower()
    assert "0.8123" in html
    assert "0.9" in html

```

## `tests/test_hashing.py`

```python
from pathlib import Path


def test_sha256_text_and_file(tmp_path: Path):
    from atticus.utils.hashing import sha256_text, sha256_file

    text = "hello world"
    expected = "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9"
    assert sha256_text(text) == expected

    f = tmp_path / "sample.txt"
    f.write_text(text, encoding="utf-8")
    assert sha256_file(f) == expected

```

## `tests/test_ingestion_retrieval_integration.py`

```python
"""Integration coverage for pgvector-backed ingestion and retrieval."""

from __future__ import annotations

import copy
import json
import logging
from pathlib import Path
from typing import Any
from collections.abc import Iterable, Sequence

import pytest

from atticus.config import AppSettings, load_manifest, reset_settings_cache
from atticus.vector_db import StoredChunk
from ingest.pipeline import IngestionOptions, ingest_corpus
from retriever.service import answer_question
from retriever.vector_store import VectorStore


class InMemoryPgVectorRepository:
    """In-memory substitute for PgVectorRepository used in tests."""

    _state: dict[str, dict[str, Any]] = {}

    def __init__(self, settings: AppSettings) -> None:
        self.settings = settings
        key = settings.database_url or "default"
        bucket = self._state.setdefault(
            key,
            {
                "documents": {},
                "chunks": {},
            },
        )
        self._documents: dict[str, dict[str, Any]] = bucket["documents"]
        self._chunks: dict[str, StoredChunk] = bucket["chunks"]

    @classmethod
    def reset(cls) -> None:
        cls._state.clear()

    def ensure_schema(self) -> None:  # pragma: no cover - behaviour is implicit in memory
        return

    def fetch_document(self, source_path: str) -> dict[str, Any] | None:
        document = self._documents.get(source_path)
        if not document:
            return None
        return {
            "document_id": document["document_id"],
            "sha256": document["sha256"],
            "source_type": document.get("source_type"),
            "chunk_count": len(document.get("chunks", ())),
        }

    def fetch_chunks_for_source(self, source_path: str) -> list[StoredChunk]:
        document = self._documents.get(source_path)
        if not document:
            return []
        return [copy.deepcopy(chunk) for chunk in document.get("chunks", [])]

    def load_all_chunk_metadata(self) -> list[StoredChunk]:
        return [copy.deepcopy(chunk) for chunk in self._chunks.values()]

    def replace_document(
        self,
        *,
        document_id: str,
        source_path: str,
        sha256: str,
        source_type: str | None,
        chunks: Sequence[StoredChunk],
        ingest_time: str,
    ) -> None:
        stored_chunks = [copy.deepcopy(chunk) for chunk in chunks]
        for chunk in stored_chunks:
            if chunk.embedding is None:
                raise ValueError(f"Chunk {chunk.chunk_id} missing embedding")
        self._documents[source_path] = {
            "document_id": document_id,
            "sha256": sha256,
            "source_type": source_type,
            "ingested_at": ingest_time,
            "chunks": stored_chunks,
        }
        for chunk in stored_chunks:
            self._chunks[chunk.chunk_id] = chunk

    def query_similar_chunks(
        self,
        embedding: Sequence[float],
        *,
        limit: int,
        probes: int | None = None,
    ) -> list[dict[str, Any]]:
        def dot_product(lhs: Iterable[float], rhs: Iterable[float]) -> float:
            return sum(float(a) * float(b) for a, b in zip(lhs, rhs, strict=False))

        results: list[dict[str, Any]] = []
        for chunk in self._chunks.values():
            if chunk.embedding is None:
                continue
            similarity = dot_product(chunk.embedding, embedding)
            distance = max(0.0, 1.0 - similarity)
            results.append(
                {
                    "chunk_id": chunk.chunk_id,
                    "document_id": chunk.document_id,
                    "source_path": chunk.source_path,
                    "text": chunk.text,
                    "metadata": dict(chunk.extra),
                    "page_number": chunk.page_number,
                    "section": chunk.section,
                    "distance": distance,
                }
            )
        results.sort(key=lambda row: row.get("distance", 1.0))
        return results[:limit]

    def truncate(self) -> None:
        self._documents.clear()
        self._chunks.clear()


@pytest.fixture(autouse=True)
def _patch_pgvector(monkeypatch: pytest.MonkeyPatch) -> None:
    InMemoryPgVectorRepository.reset()
    monkeypatch.setattr(
        "ingest.pipeline.PgVectorRepository", InMemoryPgVectorRepository, raising=False
    )
    monkeypatch.setattr(
        "atticus.vector_db.PgVectorRepository", InMemoryPgVectorRepository, raising=False
    )
    monkeypatch.setattr(
        "retriever.vector_store.PgVectorRepository", InMemoryPgVectorRepository, raising=False
    )
    yield
    InMemoryPgVectorRepository.reset()


@pytest.fixture
def test_settings(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> AppSettings:
    reset_settings_cache()
    base = tmp_path
    monkeypatch.setenv(
        "DATABASE_URL", "postgresql://postgres:postgres@localhost:5432/test_ingestion"
    )
    settings = AppSettings(
        content_dir=base / "content",
        indices_dir=base / "indices",
        snapshots_dir=base / "indices" / "snapshots",
        manifest_path=base / "indices" / "manifest.json",
        metadata_path=base / "indices" / "index_metadata.json",
        logs_path=base / "logs" / "app.jsonl",
        errors_path=base / "logs" / "errors.jsonl",
        evaluation_runs_dir=base / "eval",
        embed_dimensions=128,
        chunk_target_tokens=48,
        chunk_min_tokens=0,
        chunk_overlap_tokens_setting=8,
        top_k=5,
        confidence_threshold=0.4,
    )
    monkeypatch.setattr(AppSettings, "timestamp", lambda self: "2025-02-01T12:00:00")
    yield settings
    reset_settings_cache()


def _write_sample_document(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(
        "Atticus printers support up to 1200 x 1200 dpi resolution.\n"
        "Recommended duty cycle is 5,000 pages per month.",
        encoding="utf-8",
    )


def test_ingest_corpus_creates_manifest_and_metadata(test_settings: AppSettings) -> None:
    document_path = test_settings.content_dir / "catalog" / "spec.txt"
    _write_sample_document(document_path)

    summary = ingest_corpus(settings=test_settings, options=IngestionOptions(paths=[document_path]))

    assert summary.documents_processed == 1
    assert summary.chunks_indexed > 0
    assert Path(summary.manifest_path).exists()
    assert Path(summary.snapshot_path).exists()

    manifest = load_manifest(test_settings.manifest_path)
    assert manifest is not None
    record = manifest.documents.get(str(document_path))
    assert record is not None
    assert int(record.get("chunk_count", 0)) == summary.chunks_indexed

    metadata_payload = json.loads(test_settings.metadata_path.read_text(encoding="utf-8"))
    assert metadata_payload, "metadata snapshot should contain chunks"
    first_chunk = metadata_payload[0]
    assert first_chunk["extra"]["chunk_sha"] == first_chunk["sha256"]
    assert first_chunk["extra"]["source_type"] == "text"


def test_retrieval_pipeline_answers_question(test_settings: AppSettings) -> None:
    document_path = test_settings.content_dir / "catalog" / "capabilities.txt"
    _write_sample_document(document_path)

    ingest_corpus(settings=test_settings, options=IngestionOptions(paths=[document_path]))

    store = VectorStore(test_settings, logging.getLogger("atticus.test"))
    results = store.search("What resolution do printers support?", top_k=3, hybrid=True)
    assert results
    top_result = results[0]
    assert top_result.source_path == str(document_path)
    assert top_result.metadata.get("chunking") == "prose"

    answer = answer_question(
        "Summarise the supported print resolution.",
        settings=test_settings,
        logger=logging.getLogger("atticus.test"),
    )
    assert answer.citations, "expected citations in answer"
    assert any(
        "resolution" in cite.source_path or "capabilities" in cite.source_path
        for cite in answer.citations
    )
    assert answer.response
    assert answer.confidence >= 0.4
    assert answer.should_escalate is False

```

## `tests/test_logging_utils.py`

```python
import importlib
from typing import Any

import pytest


def _reload_logging_utils(monkeypatch: pytest.MonkeyPatch, **env: Any):
    for key in ("LOG_LEVEL", "LOG_FORMAT"):
        monkeypatch.delenv(key, raising=False)
    for key, value in env.items():
        monkeypatch.setenv(key, str(value))
    module = importlib.import_module("atticus.logging_utils")
    return importlib.reload(module)


def test_get_logger_json_format(monkeypatch: pytest.MonkeyPatch) -> None:
    logging_utils = _reload_logging_utils(monkeypatch, LOG_LEVEL="INFO", LOG_FORMAT="json")

    logger = logging_utils.get_logger("atticus-tests")
    assert hasattr(logger, "bind")
    logging_utils.get_logger("atticus-tests")
    assert getattr(logging_utils._configure_once, "_did", False)


def test_get_logger_console_format(monkeypatch: pytest.MonkeyPatch) -> None:
    logging_utils = _reload_logging_utils(monkeypatch, LOG_LEVEL="DEBUG", LOG_FORMAT="console")

    logger = logging_utils.get_logger("atticus-console")
    assert hasattr(logger, "bind")
    assert getattr(logging_utils._configure_once, "_did", False)

```

## `tests/test_mailer.py`

```python
from __future__ import annotations

import pytest


def test_mailer_import_or_skip():
    try:
        from atticus.notify.mailer import send_escalation  # noqa: F401
    except Exception as e:
        pytest.skip(f"mailer not implemented yet: {e}")


def test_send_escalation_smoke(monkeypatch):
    # Arrange: set minimal SMTP env so code paths that read env won't bail
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "1025")
    monkeypatch.setenv("SMTP_USER", "user")
    monkeypatch.setenv("SMTP_PASS", "pass")
    monkeypatch.setenv("SMTP_FROM", "atticus-escalations@agentk.fyi")
    monkeypatch.setenv("CONTACT_EMAIL", "support@example.com")
    monkeypatch.setenv("SMTP_ALLOW_LIST", "support@example.com,atticus-escalations@agentk.fyi")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    mailer = pytest.importorskip("atticus.notify.mailer")

    created: list[FakeSMTP] = []

    class FakeSMTP:
        def __init__(self, host, port, timeout=None):
            # Assert the code is wiring host/port correctly
            assert host == "smtp.test.local"
            assert str(port) in ("1025", 1025)
            self.started_tls = False
            self.logged_in = False
            self.sent = False
            self.timeout = timeout
            self.message = None
            created.append(self)

        # If your code uses context manager: with smtplib.SMTP(...) as s:
        def __enter__(self):
            return self

        def __exit__(self, exc_type, exc, tb):
            return False

        def ehlo(self):
            pass

        # Real code often passes an ssl context
        def starttls(self, context=None):
            self.started_tls = True

        def login(self, u, p):
            # Should be called if SMTP_USER is set
            assert u == "user" and p == "pass"
            self.logged_in = True

        # Some code uses send_message; some uses sendmail
        def send_message(self, msg):
            assert msg["From"]
            assert msg["To"]
            assert msg["Subject"] is not None
            self.sent = True
            self.message = msg.get_content()

        def sendmail(self, a, b, c):
            # Accept either API
            self.sent = True

        def quit(self):
            pass

    # Patch the exact lookup site: atticus.notify.mailer.smtplib.SMTP
    monkeypatch.setattr("atticus.notify.mailer.smtplib.SMTP", FakeSMTP, raising=True)

    # Act: call your function
    trace = {
        "user_id": "user-123",
        "request_id": "req-abc",
        "top_documents": [{"chunk_id": "chunk-1", "score": 0.8, "source_path": "doc.pdf"}],
        "question": "Explain toner yield",
    }
    result = mailer.send_escalation("Unit Test", "body", trace=trace)

    # Assert: whatever your mailer returns; at least it shouldn't raise
    # If your function returns None, just assert True
    assert (
        result is None
        or result is True
        or (isinstance(result, dict) and result.get("status") in ("ok", "dry-run"))
    )
    assert created, "SMTP client should be instantiated"
    sent_client = created[-1]
    assert sent_client.sent
    assert sent_client.message is not None
    assert "Trace Payload" in sent_client.message
    assert "chunk-1" in sent_client.message


def test_send_escalation_dry_run(monkeypatch):
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "2525")
    monkeypatch.setenv("SMTP_FROM", "atticus-dry-run@example.com")
    monkeypatch.setenv("CONTACT_EMAIL", "sales@example.com")
    monkeypatch.setenv("SMTP_DRY_RUN", "1")
    monkeypatch.setenv("SMTP_ALLOW_LIST", "sales@example.com,atticus-dry-run@example.com")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    mailer = pytest.importorskip("atticus.notify.mailer")

    def fail_connect(*_args, **_kwargs):
        raise AssertionError("SMTP connection should not be attempted in dry-run mode")

    monkeypatch.setattr("atticus.notify.mailer.smtplib.SMTP", fail_connect, raising=True)

    result = mailer.send_escalation("Dry Run", "body", trace={"request_id": "req-1"})

    assert isinstance(result, dict)
    assert result.get("status") == "dry-run"
    assert result.get("host") == "smtp.test.local"
    assert str(result.get("port")) == "2525"


def test_send_escalation_raises_on_connection_error(monkeypatch):
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "2525")
    monkeypatch.setenv("CONTACT_EMAIL", "sales@example.com")
    monkeypatch.setenv("SMTP_FROM", "atticus@example.com")
    monkeypatch.setenv("SMTP_ALLOW_LIST", "sales@example.com,atticus@example.com")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    mailer = pytest.importorskip("atticus.notify.mailer")

    class BrokenSMTP:
        def __init__(self, *args, **kwargs):
            raise OSError("connection refused")

    monkeypatch.setattr("atticus.notify.mailer.smtplib.SMTP", BrokenSMTP, raising=True)

    with pytest.raises(mailer.EscalationDeliveryError) as excinfo:
        mailer.send_escalation("Fail", "body")

    assert excinfo.value.reason == "connection_error"


def test_send_escalation_rejects_recipient(monkeypatch):
    monkeypatch.setenv("SMTP_HOST", "smtp.test.local")
    monkeypatch.setenv("SMTP_PORT", "2525")
    monkeypatch.setenv("CONTACT_EMAIL", "blocked@example.com")
    monkeypatch.setenv("SMTP_FROM", "atticus@example.com")
    monkeypatch.setenv("SMTP_ALLOW_LIST", "atticus@example.com")

    config_module = pytest.importorskip("atticus.config")
    config_module.reset_settings_cache()

    mailer = pytest.importorskip("atticus.notify.mailer")

    with pytest.raises(mailer.EscalationDeliveryError) as excinfo:
        mailer.send_escalation("Blocked", "body")

    assert excinfo.value.reason == "recipient_not_allowed"

```

## `tests/test_model_parser.py`

```python
import pytest

from retriever.models import extract_models, load_model_catalog
from retriever.resolver import resolve_models


@pytest.fixture(scope="module")
def catalog():
    return load_model_catalog()


def test_extract_models_direct_hit(catalog):
    result = extract_models("Can the Apeos C7070 handle heavy cardstock?", catalog=catalog)
    assert "Apeos C7070" in result.models
    assert "C7070" in result.families
    assert result.confidence > 0.8


def test_extract_models_alias_hit(catalog):
    result = extract_models("Does the 6580 support stapling?", catalog=catalog)
    assert "Apeos C6580" in result.models
    assert "C8180" in result.families
    assert result.confidence >= 0.6


def test_extract_models_none_requires_clarification(catalog):
    result = extract_models("How do I replace the toner cartridge?", catalog=catalog)
    assert not result.models
    assert not result.families
    assert result.confidence == 0


def test_resolve_models_explicit_selection(catalog):
    resolution = resolve_models(
        question="ignored when models are explicit",
        requested_models=["Apeos C4570", "Apeos C6580"],
        catalog=catalog,
    )
    assert not resolution.needs_clarification
    assert {scope.family_id for scope in resolution.scopes} == {"C7070", "C8180"}
    assert {scope.model for scope in resolution.scopes} == {"Apeos C4570", "Apeos C6580"}


def test_resolve_models_requests_clarification(monkeypatch, catalog):
    resolution = resolve_models(
        "Tell me about the printer", catalog=catalog, clarification_threshold=0.9
    )
    assert resolution.needs_clarification
    assert resolution.scopes == []
    assert {option.id for option in resolution.clarification_options} >= {"C7070", "C8180"}

```

## `tests/test_rate_limit.py`

```python
from api.rate_limit import RateLimiter


def test_rate_limiter_allows_and_blocks(monkeypatch) -> None:
    times = iter([100.0, 100.2, 101.5])

    def _monotonic():
        return next(times)

    limiter = RateLimiter(limit=1, window_seconds=1)
    monkeypatch.setattr("api.rate_limit.time.monotonic", _monotonic)

    allowed, remaining = limiter.allow("user")
    assert allowed and remaining == 0

    allowed_second, retry_after = limiter.allow("user")
    assert not allowed_second and retry_after >= 1
    assert limiter.blocked == 1

    allowed_third, remaining_third = limiter.allow("user")
    assert allowed_third and remaining_third == 0

    snapshot = limiter.snapshot()
    assert snapshot["active_keys"] == 1

    # Ensure reset clears counters and buckets.
    limiter.reset()
    assert limiter.blocked == 0
    assert limiter._buckets == {}

```

## `tests/test_retrieval_filters.py`

```python
from types import SimpleNamespace

from atticus.vector_db import StoredChunk
from retriever.vector_store import VectorStore


def _make_chunk(product_family: str) -> StoredChunk:
    chunk = StoredChunk(
        chunk_id="chunk-1",
        document_id="doc-1",
        source_path="content/model/manual.pdf",
        text="Example chunk text.",
        start_token=0,
        end_token=10,
        page_number=1,
        section="Overview",
        sha256="fake",
        extra={"product_family": product_family, "source_type": "ced"},
    )
    return chunk


def _make_vector_store(manifest_overrides: dict | None = None) -> VectorStore:
    vs: VectorStore = VectorStore.__new__(VectorStore)  # bypass __init__
    vs.settings = SimpleNamespace()
    vs.logger = SimpleNamespace()
    vs.repository = SimpleNamespace()
    vs.manifest = SimpleNamespace(
        documents=manifest_overrides or {"content/model/manual.pdf": {"source_type": "ced"}}
    )
    return vs


def test_apply_filters_allows_matching_family():
    vs = _make_vector_store()
    chunk = _make_chunk("C7070")
    assert vs._apply_filters(chunk, {"product_family": "C7070"})


def test_apply_filters_blocks_non_matching_family():
    vs = _make_vector_store()
    chunk = _make_chunk("C8180")
    assert not vs._apply_filters(chunk, {"product_family": "C7070"})


def test_apply_filters_passes_without_family_constraint():
    vs = _make_vector_store()
    chunk = _make_chunk("C7070")
    assert vs._apply_filters(chunk, {"path_prefix": "content"})

```

## `tests/test_seed_manifest.py`

```python
"""Tests for the seed manifest generation workflow."""

from __future__ import annotations

import os
import shutil
import subprocess
from pathlib import Path

import pytest

config_module = pytest.importorskip("atticus.config")
utils_module = pytest.importorskip("atticus.utils")
chunker_module = pytest.importorskip("ingest.chunker")
parsers_module = pytest.importorskip("ingest.parsers")
seed_module = pytest.importorskip("scripts.make_seed")

load_settings = config_module.load_settings
reset_settings_cache = config_module.reset_settings_cache
sha256_file = utils_module.sha256_file
chunk_document = chunker_module.chunk_document
parse_document = parsers_module.parse_document
build_seed_manifest = seed_module.build_seed_manifest


@pytest.fixture(autouse=True)
def _reset_settings():
    try:
        yield
    finally:
        reset_settings_cache()


def test_build_seed_manifest_includes_chunk_metadata(tmp_path, monkeypatch):
    content_dir = tmp_path / "content"
    content_dir.mkdir()

    document_path = content_dir / "sample.txt"
    document_path.write_text(
        "Heading\n" * 2
        + "Atticus seeds capture deterministic chunk metadata for CI verification." * 3,
        encoding="utf-8",
    )

    monkeypatch.setenv("CONTENT_ROOT", str(content_dir))
    indices_dir = tmp_path / "indices"
    monkeypatch.setenv("INDICES_DIR", str(indices_dir))
    monkeypatch.setenv("SNAPSHOTS_DIR", str(indices_dir / "snapshots"))
    monkeypatch.setenv("LOG_PATH", str(tmp_path / "logs" / "app.jsonl"))
    monkeypatch.setenv("ERROR_LOG_PATH", str(tmp_path / "logs" / "errors.jsonl"))
    monkeypatch.setenv("EVALUATION_RUNS_DIR", str(tmp_path / "eval_runs"))

    manifest = build_seed_manifest()
    assert len(manifest) == 1

    entry = manifest[0]
    assert entry["document"].endswith("sample.txt")
    assert entry["sha256"] == sha256_file(document_path)

    chunk_count = entry["chunk_count"]
    assert isinstance(chunk_count, int) and chunk_count > 0

    chunks = entry["chunks"]
    assert isinstance(chunks, list) and chunks
    assert chunk_count >= len(chunks)

    hashes = {chunk["sha256"] for chunk in chunks}
    assert len(hashes) == len(chunks)

    # Cross-check against the chunker directly for metadata consistency.
    settings = load_settings()
    parsed = parse_document(Path(entry["document"]))
    parsed.sha256 = entry["sha256"]
    actual_chunks = chunk_document(parsed, settings)
    assert chunk_count == len(actual_chunks)

    for chunk in chunks:
        assert chunk["chunk_id"]
        assert chunk["chunking"] in {"prose", "table", "footnote"}
        assert chunk["sha256"]


def test_glossary_seed_entries_round_trip() -> None:
    database_url = os.environ.get("DATABASE_URL")
    if not database_url:
        pytest.skip("DATABASE_URL must be set to verify glossary seeds.")

    if shutil.which("npm") is None:
        pytest.skip("npm is required to execute make db.seed")

    psycopg = pytest.importorskip("psycopg")

    env = os.environ.copy()
    env.setdefault("DEFAULT_ORG_ID", "org-atticus")
    env.setdefault("DEFAULT_ORG_NAME", "Atticus Default")
    env.setdefault("ADMIN_NAME", "Seed Admin")
    env.setdefault("ADMIN_EMAIL", "seed-admin@example.com")

    subprocess.run(["npm", "run", "db:seed"], check=True, env=env)

    expected = {
        "glossary-entry-managed-print-services": {
            "term": "Managed Print Services",
            "status": "APPROVED",
            "synonyms": ["MPS", "Print-as-a-service"],
            "requires_reviewer": True,
        },
        "glossary-entry-proactive-maintenance": {
            "term": "Proactive Maintenance",
            "status": "PENDING",
            "synonyms": ["Preventative maintenance"],
            "requires_reviewer": False,
        },
        "glossary-entry-toner-optimization": {
            "term": "Toner Optimization",
            "status": "REJECTED",
            "synonyms": ["Smart toner", "Consumable optimisation"],
            "requires_reviewer": True,
        },
    }

    with psycopg.connect(database_url) as connection:  # type: ignore[attr-defined]
        with connection.cursor() as cursor:
            cursor.execute(
                'SELECT "id", "term", "status", "synonyms", "authorId", "reviewerId", "reviewNotes", "reviewedAt" '
                'FROM "GlossaryEntry" WHERE "id" = ANY(%s)',
                (list(expected.keys()),),
            )
            rows = {
                row[0]: {
                    "term": row[1],
                    "status": row[2],
                    "synonyms": list(row[3] or ()),
                    "authorId": row[4],
                    "reviewerId": row[5],
                    "reviewNotes": row[6],
                    "reviewedAt": row[7],
                }
                for row in cursor.fetchall()
            }

            cursor.execute(
                'SELECT "id", "status", "topSources", "auditLog" FROM "Chat" WHERE "id" = ANY(%s)',
                (["chat-low-confidence-toner", "chat-escalated-calibration"],),
            )
            chats = {
                row[0]: {"status": row[1], "topSources": row[2], "auditLog": row[3]}
                for row in cursor.fetchall()
            }

            cursor.execute(
                'SELECT "id", "key", "status", "assignee", "summary" FROM "Ticket" WHERE "id" = %s',
                ("ticket-ae-1001",),
            )
            ticket = cursor.fetchone()

    for entry_id, expectations in expected.items():
        assert entry_id in rows, f"Missing glossary seed {entry_id}"
        record = rows[entry_id]
        assert record["term"] == expectations["term"]
        assert record["status"] == expectations["status"]
        assert record["synonyms"] == expectations["synonyms"]
        assert record["authorId"], "Seed glossary entries must have an author"

        if expectations["requires_reviewer"]:
            assert record["reviewerId"], "Reviewer metadata should be present"
            assert record["reviewNotes"], "Reviewer notes should be populated"
            assert record["reviewedAt"], "Reviewed timestamp should be stored"
        else:
            assert record["reviewerId"] is None
            assert record["reviewNotes"] in (None, "")

    assert chats["chat-low-confidence-toner"]["status"] == "pending_review"
    assert isinstance(chats["chat-low-confidence-toner"]["topSources"], list)
    assert chats["chat-escalated-calibration"]["status"] == "escalated"
    assert chats["chat-escalated-calibration"]["auditLog"], (
        "Escalated chat should have audit history"
    )

    assert ticket is not None, "Expected AE escalation ticket to be seeded"
    assert ticket[1] == "AE-1001"
    assert ticket[2] == "open"

```

## `tests/unit/ask-client.test.ts`

```typescript
import { afterEach, describe, expect, it, vi } from "vitest";
import { askRequestSchema, askResponseSchema } from "@/lib/ask-contract";
import { streamAsk } from "@/lib/ask-client";

const encoder = new TextEncoder();

function createSseResponse(payload: unknown, requestId = "req-123") {
  const stream = new ReadableStream<Uint8Array>({
    start(controller) {
      controller.enqueue(encoder.encode(`event: start\ndata: {"request_id":"${requestId}"}\n\n`));
      controller.enqueue(encoder.encode(`event: answer\ndata: ${JSON.stringify(payload)}\n\n`));
      controller.enqueue(encoder.encode(`event: end\ndata: {"request_id":"${requestId}"}\n\n`));
      controller.close();
    },
  });
  return new Response(stream, {
    status: 200,
    headers: { "Content-Type": "text/event-stream" },
  });
}

afterEach(() => {
  vi.restoreAllMocks();
});

describe("askRequestSchema", () => {
  it("normalises optional fields", () => {
    const parsed = askRequestSchema.parse({
      question: "  hello  ",
      filters: null,
      contextHints: ["  product A  "],
      topK: null,
      models: null,
    });
    expect(parsed.question).toBe("hello");
    expect(parsed.filters).toBeUndefined();
    expect(parsed.contextHints).toEqual(["  product A  "]);
    expect(parsed.topK).toBeUndefined();
    expect(parsed.models).toBeUndefined();
  });
});

describe("streamAsk", () => {
  it("parses SSE payloads and resolves with AskResponse", async () => {
    const payload = askResponseSchema.parse({
      answer: "Yes, the pilot is four weeks.",
      confidence: 0.82,
      should_escalate: false,
      request_id: "req-123",
      sources: [
        {
          path: "content/pilot.pdf",
          page: 3,
          heading: "Implementation timeline",
          chunkId: "chunk-1",
        },
      ],
    });
    vi.spyOn(globalThis, "fetch").mockResolvedValue(createSseResponse(payload));

    const response = await streamAsk({
      question: "timeline?",
      filters: undefined,
      contextHints: undefined,
      topK: undefined,
      models: undefined,
    });
    expect(response).toEqual(payload);
  });

  it("falls back to JSON responses when streaming is unavailable", async () => {
    const payload = {
      answer: "Fallback response",
      confidence: 0.66,
      should_escalate: true,
      request_id: "req-456",
      sources: [],
    };
    vi.spyOn(globalThis, "fetch").mockResolvedValue(
      new Response(JSON.stringify(payload), {
        status: 200,
        headers: { "Content-Type": "application/json" },
      })
    );

    const response = await streamAsk({
      question: "fallback?",
      filters: undefined,
      contextHints: undefined,
      topK: undefined,
      models: undefined,
    });
    expect(response).toEqual(askResponseSchema.parse(payload));
  });
});

```

## `tests/unit/rbac.test.ts`

```typescript
import { describe, expect, it } from "vitest";
import { Role } from "@prisma/client";
import {
  canEditGlossary,
  canReviewGlossary,
  ensureRole,
  requireUser,
  ForbiddenError,
  UnauthorizedError,
} from "@/lib/rbac";
import type { RequestUser } from "@/lib/request-context";

const baseUser: RequestUser = {
  id: "user-1",
  role: Role.ADMIN,
  orgId: "org-1",
  email: "admin@example.com",
  name: "Admin",
};

describe("RBAC helpers", () => {
  it("requires a user context", () => {
    expect(() => requireUser(null)).toThrow(UnauthorizedError);
    expect(requireUser(baseUser)).toBe(baseUser);
  });

  it("checks allowed roles", () => {
    expect(ensureRole(baseUser, [Role.ADMIN, Role.REVIEWER])).toBe(baseUser);
    const userContext: RequestUser = {
      ...baseUser,
      role: Role.USER,
    };
    expect(() => ensureRole(userContext, [Role.ADMIN])).toThrow(ForbiddenError);
  });

  it("allows reviewers to view glossary but not edit", () => {
    const reviewerContext: RequestUser = {
      ...baseUser,
      role: Role.REVIEWER,
    };
    expect(canReviewGlossary(reviewerContext)).toBe(reviewerContext);
    expect(() => canEditGlossary(reviewerContext)).toThrow(ForbiddenError);
  });

  it("allows admins to edit glossary", () => {
    expect(canEditGlossary(baseUser)).toBe(baseUser);
  });
});

```

## `TODO.md`

```md
# TODO - Atticus

All previously tracked items have been delivered and validated. See `TODO_COMPLETE.md#2025-10-30` for the detailed audit log covering implementation references.

There are no outstanding TODO entries at this time.

```

## `TODO_COMPLETE.md`

```md

# TODO — Completed / Obsolete

This file is the **permanent log of completed tasks**.
Each entry includes the completion date and commit reference for traceability.

The following items are done or no longer relevant and are recorded here for traceability.

## Completed
- **FND-001 → FND-008** (Audit): Next.js UI, proxy contracts, schema ownership, env scaffolding, request-id propagation, CI audits — delivered.
- **Ask Contract & Streaming**: `/api/ask` SSE endpoint and UI consumer normalised; error contracts include `request_id`.
- **Frontend Hygiene & Repo Structure**: Legacy FastAPI UI archived; canonical Next.js app; docs updated.
- **DX & Docs**: Makefile `quality` runs Python + Next gates + audits; pre-commit configured; release docs added.
- **Structured Logging**: Centralised logger with JSON output; instrumented key scripts.
- **Unified CLI**: `scripts/atticus_cli.py` with Makefile alias `atticus`.

## Obsolete / Superseded
- “Prisma duplicates and `Glossary.synonyms` type fix” — resolved in current schema/migrations.
- “Decide on Framer Motion” — kept as optional; AGENTS reflects this.
- “Archive web/static” — done; legacy moved under `archive/legacy-ui/`.
- “CONTENT_DIR → CONTENT_ROOT rename” — standardised across code/docs.
- “Rebuild evaluator harness” — present via tests and `eval` target.
- “Glossary API error normalisation” — implemented with `request_id`.

---

## 2025-10-10

- [x] Added model parser/resolver unit tests, retrieval filter coverage, API clarification regressions, UI integration tests, and a gated Playwright chat clarification flow — completed 2025-10-10 (this change set).
- [x] Documented model disambiguation behaviour in `AGENTS.md`, `README.md`, and `docs/ATTICUS_DETAILED_GUIDE.md`; updated `CHANGELOG.md`, and reconciled TODO status — completed 2025-10-10 (this change set).
- [x] Verified direct/unclear/multi-model acceptance criteria via automated tests and ensured `make quality` (lint, typecheck, pytest, Next build, ts audit) passes end-to-end — completed 2025-10-10 (this change set).

---

## 2025-09-21

- [x] Provided `.env.example` for local configuration scaffolding — completed 2025-09-21 (commit 5df0d73).
- [x] Delivered Dockerized stack (API/Nginx Dockerfiles, docker-compose workflow, healthchecks, Makefile targets) — completed 2025-09-21 (commit 5df0d73).
- [x] Published hardened `nginx.conf` for TLS termination and proxying to the FastAPI service — completed 2025-09-21 (commit 5df0d73).
- [x] Established single-node, containerized stack with minimal dependencies — completed 2025-09-21 (commit 3013a1a).
- [x] Removed Azure AD/SSO code paths and noted migration in README — completed 2025-09-21 (commit 3013a1a).
- [x] Pinned OpenAI defaults to `text-embedding-3-large` and `gpt-4.1` — completed 2025-09-21 (commit 3013a1a).
- [x] Created base repository structure (`atticus/`, `api/`, `ingest/`, etc.) — completed 2025-09-21 (commit 3013a1a).
- [x] Added `.editorconfig`, `.gitattributes`, `.gitignore`, and `.vscode` settings — completed 2025-09-21 (commit 3013a1a).
- [x] Implemented pre-commit hooks with `ruff`, `mypy`, `markdownlint-cli2` — completed 2025-09-21 (commit 3013a1a).
- [x] Adopted `pip-tools` for locked dependencies — completed 2025-09-21 (commit 3013a1a).
- [x] Pinned core libraries (`fastapi`, `uvicorn`, `pydantic`, etc.) — completed 2025-09-21 (commit 3013a1a).
- [x] Built parsers for PDF, DOCX, XLSX, and HTML with OCR support — completed 2025-09-21 (commit 3013a1a).
- [x] Implemented evaluation harness with baseline metrics and gold set — completed 2025-09-21 (commit 3013a1a).

## 2025-09-23

- [x] Added environment generator (`scripts/generate_env.py`) with `--force` flag — completed 2025-09-23.
- [x] Implemented SMTP mailer (`atticus/notify/mailer.py`) using `.env` — completed 2025-09-23.
- [x] Created API `/contact` route for escalation email (202 Accepted) — completed 2025-09-23.
- [x] Built API `/ask` endpoint returning `{answer, sources, confidence}` — completed 2025-09-23.
- [x] Integrated modern UI served by FastAPI templates and static mounts — completed 2025-09-23.
- [x] Added `examples/dev.http` with sample `/ask` and `/contact` requests — completed 2025-09-23.

## 2025-09-25

- [x] Verified README/AGENTS/OPERATIONS cross-links and fixed relative paths - completed 2025-09-25 (commit 2a3b760).
- [x] Added SES IAM policy region lock guidance to SECURITY.md and reinforced README cross-link - completed 2025-09-25 (commit 2a3b760).
- [x] TODO "SECURITY.md — env-only secrets; SMTP `From` allow-list; RLS examples." - completed 2025-09-25 (commit 2a3b760).

- [x] Reviewed repository documentation set and normalised coverage messaging - completed 2025-09-25 (commit cd280f8).
- [x] Published secure remote access playbook (Tailscale, Cloudflare Tunnel, SSH) - completed 2025-09-25 (commit cd280f8).

## 2025-09-27

- [x] Implemented shared JSON error schema for API responses with request ID propagation tests — completed 2025-09-27 (commit 6dbf0b8).
- [x] TODO "Error JSON contract" - completed 2025-09-27 (commit 6dbf0b8).
- [x] Verified API-served UI via automated tests (pytest) and captured guidance in ATTICUS detailed guide - completed 2025-09-25 (commit cd280f8).
- [x] Enabled optional hybrid reranker with `ENABLE_RERANKER` flag and documented behaviour - completed 2025-09-25 (commit cd280f8).
- [x] Updated README hero copy to spotlight Sales/tender acceleration messaging - completed 2025-09-25 (commit cd280f8).
- [x] Documented `/ask` request/response schema in docs/api/README.md - completed 2025-09-25 (commit cd280f8).
- [x] Added `SMTP_DRY_RUN` mailer branch with tests and surfaced behaviour in docs - completed 2025-09-25 (commit cd280f8).
- [x] Made pytest parallelism conditional on pytest-xdist availability - completed 2025-09-25 (commit cd280f8).
- [x] Retired the legacy Jinja2/Eleventy UI in favour of a Tailwind-powered Next.js app covering chat, admin, settings, contact, and apps — completed 2025-09-27.

## 2025-09-28

- [x] TODO "Sample Seed corpus — Add verification tests and contributor docs." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "reports/ — Update evaluation pipeline to emit CSV/HTML artifacts." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "reports/ — Configure CI to upload artifacts and document consumption workflow." — completed 2025-09-28 (commit 19bdc5d).
- [x] TODO "README.md — rewrite for Next.js/pgvector stack with Windows guidance and quick start." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "ARCHITECTURE.md — update diagrams/narrative for Next.js + SSE flow." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "OPERATIONS.md — document pgvector maintenance, CI parity, and dependency risk handling." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "TROUBLESHOOTING.md — capture Auth.js email flow, SSE mitigation, lint/format guidance." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "REQUIREMENTS.md — align runtime/tooling requirements with Next.js + Prisma stack." — completed 2025-09-28 (commit 5c4ff5e).
- [x] TODO "CI gates — align GitHub Actions + local make quality" — completed 2025-09-28 (commit 5c4ff5e).
  > Continue logging future completed tasks below, grouped by date, to maintain a clear historical record.

## 2025-09-29

- [x] TODO "Tests: ingestion/retrieval unit + integration suite, regenerate requirements lock." — completed 2025-09-29 (commit 04216be).

## 2025-09-30

- [x] TODO "TROUBLESHOOTING.md — Add pgvector + Prisma troubleshooting (extension enablement, migration drift)." — completed 2025-09-30 (commit b7779b8).

## 2025-10-04

- [x] TODO "`Makefile` — remove `ui` target (`http.server`); add Next.js scripts (`dev`, `build`, `start`); keep `api` until migration complete." — completed 2025-10-04 (commit b7779b8).

- [x] TODO "`api/routes/chat.py` and `api/routes/ask.py` — consolidate; ensure request_id & should_escalate; remove unused import in api/routes/**init**.py." — completed 2025-10-04 (commit 2af9f6e).
- [x] TODO "Dictionary/glossary admin — Design Prisma schema/API contracts for glossary records with approval workflow." — completed 2025-10-04 (commit 2bc7206).
- [x] TODO "Dictionary/glossary admin — Implement admin UI for propose/review/approve flows with RBAC checks." — completed 2025-10-04 (commit 2bc7206).

## 2025-10-05

- [x] TODO "`api/main.py` — drop Jinja2 templates/static mounts; stop serving `/` HTML; keep JSON APIs; Next.js owns UI." — completed 2025-10-05 (present in commit 9a7620b9; verified during backlog audit).
- [x] TODO "`ARCHITECTURE.md` & legacy `AGENTS.md` — replace FAISS/FastAPI mentions with references to this doc; mark migration phases." — completed 2025-10-05 (present in commit 9a7620b9; verified during backlog audit).

## 2025-10-10

- [x] TODO "Glossary Seed & Runbook" — completed 2025-10-10 (this PR aligns Prisma seeds, docs, and verification tests).

## 2025-10-11

- [x] TODO "Glossary UX Follow-through" — completed 2025-10-11 (added workflow sequence diagram, decision notes, and backlog links in `docs/glossary-spec.md`).

## 2025-10-12

- [x] TODO "RBAC Integration Coverage" — completed 2025-10-12 (Playwright reviewer/admin coverage, Next.js route RBAC tests, FastAPI admin token assertions, and `make quality` wiring).

## 2025-10-14

- [x] TODO "Phase 5 — Orphans & Structure Cleanup" — completed 2025-10-14 (FastAPI now sources its version from `VERSION`, docs highlight Next.js as the canonical UI, and release notes capture the separation of backend and frontend responsibilities).

## 2025-10-15

- [x] TODO "Admin Ops Console (Uncertain Chats, Tickets, Glossary)" — completed 2025-10-15 (introduced Prisma chat/ticket models, Next.js admin tabs, RBAC-aware API routes, and seeds/tests covering the reviewer/admin workflow).

## 2025-10-19

- [x] TODO "pgvector GUC Bootstrap" - completed 2025-10-19 (release 0.8.0 adds migrations and verification checks for `app.pgvector_lists`).
- [x] TODO "Version Parity Automation" - completed 2025-10-19 (release 0.8.0 ships `scripts/check_version_parity.py`, Makefile wiring, and docs).
- [x] TODO "Uncertain Chat Validation Flow" - completed 2025-10-19 (release 0.8.0 captures low-confidence chats, follow-up prompts, admin drawer UX, and audit events).
- [x] TODO "Dictionary (Glossary) Update Semantics" - completed 2025-10-19 (release 0.8.0 adds POST upsert/PUT updates, inline editing, and rag event auditing).

## 2025-10-30

- [x] Audited `TODO.md` and confirmed no outstanding backlog items remain; updated the file to reference the completion log.
- [x] Verified the model catalog in `indices/model_catalog.json` maps families ⇄ models/aliases as required by the backlog item.
- [x] Confirmed disambiguation utilities (`retriever/models.py`, `retriever/resolver.py`) and scoped retrieval (`retriever/service.py`) implement the parser/resolver tasks.
- [x] Checked the API and client flow updates in `api/routes/chat.py`, `app/api/ask/route.ts`, `lib/ask-contract.ts`, `lib/ask-client.ts`, and `components/AnswerRenderer.tsx` to ensure clarification + multi-answer behaviour is live.
- [x] Reviewed ingestion tagging updates in `ingest/pipeline.py` and supporting docs (`docs/api/README.md`, `README.md`) covering the model-family flows.

```

## `tsconfig.json`

```json
{
  "compilerOptions": {
    "target": "es2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": false,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./*"],
      "@/components/*": ["components/*"],
      "@/app/*": ["app/*"]
    },
    "types": ["node", "vitest"],
    "plugins": [
      {
        "name": "next"
      }
    ]
  },
  "include": [
    "next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    "**/*.cjs",
    "**/*.mjs",
    ".next/types/**/*.ts"
  ],
  "exclude": ["node_modules"]
}

```

## `vitest.config.ts`

```typescript
import { defineConfig } from "vitest/config";
import path from "node:path";

export default defineConfig({
  test: {
    include: ["tests/unit/**/*.test.ts"],
    environment: "node",
    globals: true,
    coverage: {
      provider: "v8",
      reporter: ["text", "html"],
      reportsDirectory: "reports/vitest",
    },
  },
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "."),
    },
  },
});

```
